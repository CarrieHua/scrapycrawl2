id=279055	REOPENED	PDT	PHP Explorer & Projects management	2.1	PC Windows XP	P1 major	PHP UI	2009-06-04 01:02 EDT by	Toshihiro Izumi	2016-06-08 07:23 EDT (	4 users	0. Create project/folders/files project1 folder1 folder2 newfile.php newfile.txt1. Drag folder1 and drop it to folder2 => 'Move Resources' dialog pops up <= folder1 must be moved immediately2. Drag newfile1.php and drop it to folder1 => 'Move Resources' dialog pops up <= newfile1.php must be moved immediately3. Drag newfile1.txt and drop it to folder1 => Nothing happen <= newfile1.txt must be moved immediately4. Drag newfile1.txt and drop it to folder1 with pressing shift key (Copy) => Nothing happen <= newfile1.txt must be copied immediately	Reproducible in N20100124Fixed[Petyo Tanchev]Tested on 2.2.0 from 13.08.2010.txt file can be moved with D&D but can not be copied using Ctrl+D&DCopy works with Ctrl+C -> Ctrl+V***has been marked as a duplicate of this bug. ***	4.0
id=270725	REOPENED	PDT	Code Formatter	2.1	PC Linux-GTK	P1 major	PHP UI	2009-04-01 04:42 EDT by	Anton Danilchenko	2010-08-02 05:28 EDT (	3 users	Type code (4 lines, first line not counted):<?php $sPlaceholders = 'if'; $sTemplateSource = preg_replace("`<(({$sPlaceholders}) +\([^>]+\)) *>`", '<?php $1 { ?>', $sTemplateSource); $sPlaceholders = 'foreach'; $sTemplateSource = preg_replace("`<(({$sPlaceholders}) +\( *([^ ]+)[^>]+\)) *>`", '--><?php if(!empty($3)) $1 { ?>', $sTemplateSource);Go to line 2 and comment it (press ctrl+slash).Actual result: string 2 commented incorrectly, but string 3 and 4 too incorrect highlighted!Expected result: if I comment one line - one line need to comment, and all next lines not affected!	CreatedAfter comment lineCreatedAfter commentCreatedAfter uncommentI delete comment and view incorrect code highlightIncorrection: in first attachement screenshot - show BEFORE comment line.Example 2. Type code:<?php$aTest = array( 'one' => 1, 'two' => 2, 'three' => 3, "^ *(<\?php.*\?>) *$" => '$1',);Step 1: please, comment line ("^ *(<\?php.*\?>) *$" => '$1',) by combination of keys "ctrl+/".You see correct comment://"^ *(<\?php.*\?>) *$" => '$1',Step 2: uncomment this line, press "ctrl+/". Wow - you see next result:<!--// "^ *(<\?php.*\?>) *$" => '$1',-->Please, fix this bug.I see that this doesn't happen in 2.1.0RC3. May be it was fixed already.1st example by Anton is still reproducible.It seems that if you have a ?> somewhere inside a string the line will be commented until ?> and not until the end and in this way considering the ?> as closing the last opened <?php tag, so that everything that follows until the next open <?php tag is not considered a PHP code anymore.Reproduced in Win/Lin. Reopening[Sylvia Tancheva]	7.0
id=253879	REOPENED	PDT	Code Assist	2.0.0	PC Windows XP	P1 normal	PHP UI	2008-11-05 03:53 EST by	Kalin	2014-01-17 14:18 EST (	4 users	Have the next code in PHP editor:<?phpclass marker{public $yellow = 23;public function write(){}public function draw(){$this->| // <--- Launch Code Assist here, where the cursor "|" is located?>Expected:Code Assist is popped for the class members:write()draw()yellowActual:No completions available	Code:=====<?phpclass marker{ public $yellow = 23; public function write() { } public function draw() { $this->?>The method draw() appears twice: as method and as function outside of class.A similar problem here in the next code:<?phpclass Street {public function explore() {}}class Germany{/** * @var Street */public $street;}class Europe extends Germany { function walk(){ $this->street->| // <--- Launch Code Assist here ?>Code Assist was not launched, furthermore an exception was trown.See the attached screen shot. eclipse.buildId=M20080911-1700java.version=1.6.0_05java.vendor=Sun Microsystems Inc.BootLoader constants: OS=win32, ARCH=x86, WS=win32, NL=en_USCommand-line arguments: -os win32 -ws win32 -arch x86 -cleanWarningWed Nov 05 12:44:14 EET 2008The 'org.eclipse.php.ui.PHPCompletionProposalComputer' proposal computer from the 'org.eclipse.php.ui' plug-in did not complete normally. The extension has thrown a runtime exception.java.lang.NullPointerExceptionat org.eclipse.php.core.codeassist.CodeAssistUtils.getVariableType(Unknown Source)at org.eclipse.php.core.codeassist.CodeAssistUtils.getTypesFor(Unknown Source)at org.eclipse.php.core.codeassist.PHPCompletionEngine.isClassFunctionCompletion(Unknown Source)at org.eclipse.php.core.codeassist.PHPCompletionEngine.calcCompletionOption(Unknown Source)at org.eclipse.php.core.codeassist.PHPCompletionEngine.complete(Unknown Source)at org.eclipse.dltk.internal.core.Openable.codeComplete(Openable.java:488)at org.eclipse.dltk.internal.core.SourceModule.codeComplete(SourceModule.java:121)at org.eclipse.dltk.internal.core.SourceModule.codeComplete(SourceModule.java:111)at org.eclipse.dltk.ui.text.completion.ScriptCompletionProposalComputer.computeScriptCompletionProposals(ScriptCompletionProposalComputer.java:210)at org.eclipse.dltk.ui.text.completion.ScriptCompletionProposalComputer.computeCompletionProposals(ScriptCompletionProposalComputer.java:262)at org.eclipse.dltk.ui.text.completion.CompletionProposalComputerDescriptor.computeCompletionProposals(CompletionProposalComputerDescriptor.java:330)at org.eclipse.dltk.ui.text.completion.CompletionProposalCategory.computeCompletionProposals(CompletionProposalCategory.java:266)at org.eclipse.dltk.ui.text.completion.ContentAssistProcessor.collectProposals(ContentAssistProcessor.java:266)at org.eclipse.dltk.ui.text.completion.ContentAssistProcessor.computeCompletionProposals(ContentAssistProcessor.java:225)at org.eclipse.wst.sse.ui.internal.contentassist.CompoundContentAssistProcessor.computeCompletionProposals(CompoundContentAssistProcessor.java:300)at org.eclipse.jface.text.contentassist.ContentAssistant.computeCompletionProposals(ContentAssistant.java:1836)at org.eclipse.jface.text.contentassist.CompletionProposalPopup.computeProposals(CompletionProposalPopup.java:553)at org.eclipse.jface.text.contentassist.CompletionProposalPopup.access$16(CompletionProposalPopup.java:550)at org.eclipse.jface.text.contentassist.CompletionProposalPopup$2.run(CompletionProposalPopup.java:485)at org.eclipse.swt.custom.BusyIndicator.showWhile(BusyIndicator.java:70)at org.eclipse.jface.text.contentassist.CompletionProposalPopup.showProposals(CompletionProposalPopup.java:479)at org.eclipse.jface.text.contentassist.ContentAssistant.showPossibleCompletions(ContentAssistant.java:1664)at org.eclipse.wst.sse.ui.internal.StructuredTextViewer.doOperation(StructuredTextViewer.java:437)at org.eclipse.php.internal.ui.editor.PHPStructuredTextViewer.doOperation(Unknown Source)at org.eclipse.ui.texteditor.TextOperationAction$1.run(TextOperationAction.java:131)at org.eclipse.swt.custom.BusyIndicator.showWhile(BusyIndicator.java:70)at org.eclipse.ui.texteditor.TextOperationAction.run(TextOperationAction.java:129)at org.eclipse.jface.action.Action.runWithEvent(Action.java:498)at org.eclipse.ui.commands.ActionHandler.execute(ActionHandler.java:185)at org.eclipse.ui.internal.handlers.LegacyHandlerWrapper.execute(LegacyHandlerWrapper.java:109)at org.eclipse.core.commands.Command.executeWithChecks(Command.java:476)at org.eclipse.core.commands.ParameterizedCommand.executeWithChecks(ParameterizedCommand.java:508)at org.eclipse.ui.internal.handlers.HandlerService.executeCommand(HandlerService.java:169)at org.eclipse.ui.internal.keys.WorkbenchKeyboard.executeCommand(WorkbenchKeyboard.java:472)at org.eclipse.ui.internal.keys.WorkbenchKeyboard.press(WorkbenchKeyboard.java:824)at org.eclipse.ui.internal.keys.WorkbenchKeyboard.processKeyEvent(WorkbenchKeyboard.java:882)at org.eclipse.ui.internal.keys.WorkbenchKeyboard.filterKeySequenceBindings(WorkbenchKeyboard.java:571)at org.eclipse.ui.internal.keys.WorkbenchKeyboard.access$3(WorkbenchKeyboard.java:512)at org.eclipse.ui.internal.keys.WorkbenchKeyboard$KeyDownFilter.handleEvent(WorkbenchKeyboard.java:127)at org.eclipse.swt.widgets.EventTable.sendEvent(EventTable.java:84)at org.eclipse.swt.widgets.Display.filterEvent(Display.java:1184)at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1002)at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1027)at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1012)at org.eclipse.swt.widgets.Widget.sendKeyEvent(Widget.java:1040)at org.eclipse.swt.widgets.Widget.sendKeyEvent(Widget.java:1036)at org.eclipse.swt.widgets.Widget.wmChar(Widget.java:1352)at org.eclipse.swt.widgets.Control.WM_CHAR(Control.java:3894)at org.eclipse.swt.widgets.Canvas.WM_CHAR(Canvas.java:341)at org.eclipse.swt.widgets.Control.windowProc(Control.java:3787)at org.eclipse.swt.widgets.Canvas.windowProc(Canvas.java:337)at org.eclipse.swt.widgets.Display.windowProc(Display.java:4528)at org.eclipse.swt.internal.win32.OS.DispatchMessageW(Native Method)at org.eclipse.swt.internal.win32.OS.DispatchMessage(OS.java:2371)at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3420)at org.eclipse.ui.internal.Workbench.runEventLoop(Workbench.java:2382)at org.eclipse.ui.internal.Workbench.runUI(Workbench.java:2346)at org.eclipse.ui.internal.Workbench.access$4(Workbench.java:2198)at org.eclipse.ui.internal.Workbench$5.run(Workbench.java:493)at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:288)at org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:488)at org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:149)at org.eclipse.ui.internal.ide.application.IDEApplication.start(IDEApplication.java:113)at org.eclipse.equinox.internal.app.EclipseAppHandle.run(EclipseAppHandle.java:193)at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:110)at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:79)at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:386)at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:179)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)at java.lang.reflect.Method.invoke(Unknown Source)at org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:549)at org.eclipse.equinox.launcher.Main.basicRun(Main.java:504)at org.eclipse.equinox.launcher.Main.run(Main.java:1236)CreatedCodeAssistThrowsAnExceptionPatch:This patch fixes one half of the issue - that unclosed method declaration appears twice in the model. This caused additional issue with validation.The other half of the issue - missing code completion - is still open.wow that's an old one..great work!Code assist still needs to be fixed.	6.0
id=201979	REOPENED	PDT	Code Formatter	2.0.0	PC Windows XP	P1 normal	PHP UI	2007-09-01 09:26 EDT by	Pepa Chmel	2015-08-26 04:11 EDT (	15 users	Build ID: I20070625-1500Steps To Reproduce:1.New php filewith code private function ShowExportButton() { $d=new CDiv('xmlexport'); //TODO - predelat to podle Rebe45L - raw $l=new CAppLink('raw'.$this->m_action,"xexp",$_GET['data'], $GLOBALS['str_XmlExport'], "", "", "", true); $GLOBALS['app']->ShowImage('images/xml_export.gif', 32, 10, $GLOBALS['str_XmlExport']); $l->Fin(); /*$l=new CAppLink('raw'.$this->m_action,"xexp",$_GET['data']); echo $GLOBALS['str_XmlExport']; $l->Fin();*/ $d->Fin(); }2. paste this to next line from TODO $l=new CAppLink(array(apModule=>$this->m_moduleId, apMethod=>'edit', apParam=>$aRecord[$this->m_tbl->m_idname]));3. wrong result is private function ShowExportButton() { $d=new CDiv('xmlexport'); //TODO - predelat to podle Rebe45L - raw $l=new CAppLink(array(apModule=>$this->m_moduleId, apMethod=>'edit', apParam=>$aRecord[$this->m_tbl->m_idname])); $l=new CAppLink('raw'.$this->m_action,"xexp",$_GET['data'], $GLOBALS['str_XmlExport'], "", "", "", true); $GLOBALS['app']->ShowImage('images/xml_export.gif', 32, 10, $GLOBALS['str_XmlExport']); $l->Fin(); /*$l=new CAppLink('raw'.$this->m_action,"xexp",$_GET['data']); echo $GLOBALS['str_XmlExport']; $l->Fin();*/ $d->Fin(); }line $l=new CAppLink('raw'.$this->.... is idented to front without reasonMore information:i have night build org.eclipse.php_feature-incubation-N20070830.zip	***has been marked as a duplicate of this bug. ******has been marked as a duplicate of this bug. ***Still relevant - changing version to 2.0.0Since the example is quite complicated, just try pasting a few lines of code at a place that is already indented -> indentation changes.[Sylvia Tancheva]This bug is really a big showstopper. PDT has problems keeping the correct indentation when repeatedly pasting the same code segment ever since its first version while PhpEclipse has never had problems with this. I know of developers who stay with PhpEclipse just because they "can't properly edit code with PDT".Simple example: Start with this code:function x(){ $a = 1;}Now copy the $a = 1 code line, move the cursor to the beginning of that same line an repeatedly press CTRL+V. This yields:function x(){ $a = 1; $a = 1; $a = 1; $a = 1; $a = 1; $a = 1; $a = 1;}Since the duplication of similar code segments is a very common operation in any programming language this bug affects every programmer, which is why I just can't imagine why the bug still exists...might be related.Closing.See.This bug andneed to be reopened.See my comments on.I agree with Oliver and, it is actually quite ridiculous that this bug still exists, let alone the fact that someone just attempted to close it!I just want to reaffirm here that this is a BUG in the formatting logic, NOT a feature request of any sort.I will allow someone else the opportunity to re-open this one.InVadim Punski says in:What if not pasting code is a well defined case in programming? And why should other cases be out of scope? Becaus current quad core systems are too slow for performing such tasks directly? Then why do Java programmers get ridiculous comfort like "compile on save"?Seriously, for a couple of seconds I thought I should personally mark PDT as "Broken. WONTFIX." for myself and return to one of those five year old versions of Phpeclipse for Eclipse 3.2 where every implemented feature was working. After that, Phpeclipse introduced broken stuff and PDT never reached the level of editing quality that those early versions of Phpeclipse had (working F3 aside).I suggest to merge the very similarinto this one and then reopen this one.I am getting more and more emails about my other followed bugs so I think this means someone is finally cleaning up the bug backlog. On the other hand, this bug was closed as WONTFIX a long time ago. I couldn't believe it. In daily work, this is the bug that most prominently destroys effectively working with PDT in comparison to PhpEclipse.To say that "formatting code in real time during text editing and paste operations is out of scope" is just plain wrong. Neither the Java version of Eclipse with Java code nor PhpEclipse with PHP code exhibit this wrong behaviour when pasting code (tesetd today with fresh installs of both IDEs) so this is a BUG in PDT which needs to be fixed.HiI think I have done something for this bug,but we will not applied it in this release,because it may be a little risky.I am sorry for this:(Um, shouldn't this bug then get moved to another milestone instead of getting wontfixed?Hi,how about now?Thanks!fixed in headShould be verified in PDT 2.3Verified in pdt 3.0 0 - Fixed.I can not verify this as fixed. I am currently running the very recent "3.0.0.v201112050311-7V--F8NcJTTTcK4JmTT" Hudson build of the "PHP Development Tools (PDT) Runtime Feature". The situation is the same as described in.Some auto-indentation is obviously performed on the pasted code. This is OK but if it is performed then it should be done right. Otherwise not auto-indenting at all but keeping the indent as is would be better solution.To dig a little deeper:Start with this code:function x(){ if (true) { $a = 1; }}Now copy the $a = 1 code line, move the cursor to the beginning of the line above the if statement and repeatedly press CTRL+V. This yields:function x(){ $a = 1; $a = 1; $a = 1; $a = 1; $a = 1; if (true) { $a = 1; }}This is terrible. Completely deactivating auto-indentation it should yield:function x(){ $a = 1; $a = 1; $a = 1; $a = 1; $a = 1; if (true) { $a = 1; }}This is still not correct but better than the current result that also damages the correct indentation of the if statement. Fully fixing the bug should yield:function x(){ $a = 1; $a = 1; $a = 1; $a = 1; $a = 1; if (true) { $a = 1; }}hi,download the latest pdt version fromThanks!I tried this with the 2011-12-06 build from Hudson.In recent builds the problem is fixed for many cases but not for all of them. The wrong indentation mostly happens when repeating the paste operation. For example, the case fromstill occurs when pasting on the link containing the "$a = 1;" and not below that line. Here is a more practical example where the problem still occurs. Start with protected $a = array( 'a' => 1, );inside a class. Now you want to add several new entries to this array. So you copy the line containing the "a" entry, move to the line below it and paste three times. Expected result: protected $x = array( 'a' => 1, 'a' => 1, 'a' => 1, 'a' => 1, );Instead ot this you get: protected $x = array( 'a' => 1, 'a' => 1, 'a' => 1, 'a' => 1, );After the first paste the cursor moves from the left edge to just left of the closing ");" and repeated paste operations yield one indent too much.I will try to post more practical examples once I experience them to provide more information regarding this bug. Some of the indent problems also occur in conjunction with wrong indentation when typing (not when pasting). I will try to search for a corresponding bug for that problem or open a new one.Also, loosely related to this: PDT is completely missing the coding style GUI (one like "Java / Code Style / Formatter"). For this there is one to be found at(which is pretty nice but has some problems like not being limited to the current selection when using "Format active elements" for which I am about to submit bug requests over there) but this really should be part of the core PDT distribution. Perhaps some code could be integrated from there.ok,thanks!btw,you can disable the indentation when paste through preferences,PHP->editor-typing.When will this fix be available in a stable packaged release?I tried the examples in this bug in PDT 3.0.0.v201201110400, which was just released to the update site. Still broken. This bug really needs to be reopened.Bump! Still not fixed as pf 3.5.0.201506101710 (five years later)Can you give example what exactly is not working for you?Placing the cursor in column zero anywhere in the text below, hold down shift and press down arrow. Copy, then paste twice. The expected result is that the pasted lines would line up vertically with the existing lines. if (!($statement->bind_param('iisssssssssisssi', $type, $status, $username, $fname, $mname, $lname, $nsuffix, $email, $addressone, $addresstwo, $city, $stateID, $zip, $cellphone, $otherphone, $userID))) { Admin::bail("$method Bind Params failed", $statement); } // ends ifThe result is this: if (!($statement->bind_param('iisssssssssissssi', $type, $status, $username, $username, $fname, $mname, $lname, $nsuffix, $email, $addressone, $addresstwo, $city, $stateID, $zip, $cellphone, $otherphone, formatMYSQLDateTime($backgroundcheckexpiry, 'date'), $userID))) { Admin::bail("$method Bind Params failed", $statement); } // ends ifThe line following the paste is changed to move it in for some reason, even when smartPaste is false.OK, I reopened the bug and we will check this caseThanks	26.0
id=343572	REOPENED	PDT	Editor	2.2.1	PC Linux	P1 normal	PHP UI	2011-04-21 12:07 EDT by	Daniel Robert	2011-11-11 07:29 EST (	2 users	I have my general Text Editors tab policy to be set to use tabs rather than spaces. While editing PHP files, hitting 'enter' on a new line causes an indentation based on spaces rather than tabs (the new line begins with spaces and is not indented as deep as the line above it).It seems this value is taken from my "Web -> HTML Files -> Editor" settings which has a "2 spaces" indentation policy.It looks like it's converting the tabs from the previous line into spaces and using that as the indentation of my new line.So the bug is: why is this reading my HTML Editor settings at all?	hi,I tested it just now,pdt reads Preferences->PHP->Code Style->Formatter.This is no way to handle a ticket. I included the version information and o/s of ecipse and pdt. Listed the steps to reproduce the problem, and yes, I'm still having this problem. The follow-up comment was "works for me." then you mark it 'resolved' and 'fixed'? This is ridiculous. At the very, very least, it's "WORKSFORME" rather than "FIXED". If it is actually fixed, what version is it fixed in? What version of pdt/eclipse did you test with? Was your php file entirely php? Or did it include a mix of html tags and php?I'm reopening this until I can learn something about about what just happened.So the bug is: why is this reading my HTML Editor settings at all?my version is Indigo and it does not read my HTML Editor settings at all...ah,sorry,my fault,it should be "WORKSFORME",and are you ok with this?I would say no, I'm not ok with this."Indigo" is not a version of PDT, it's a version of eclipse. It's also not the version of eclipse I was running when I reported this ticket (I'm on Helios in Linux using Oracle's 1.6.0_23 jdk). Similarly, I have yet to hear anything about the file you were editing, what version of PDT you were using, what OS you're on, or how you ensured that this is not a bug. "I tried editing a php file and things are fine" is pretty inadequate.In case my original "steps to reproduce" are not clear:* I have a .php file that contains both HTML markup and php blocks* the html blocks are indented using tabs* window -> preferences -> php -> code style -> formatter has "tab policy" set to "tabs"* window -> preferences -> web -> HTML files -> editor has "indent using spaces" and "indentation size" set to "2"When I open my .php file (which is associated with "PHP Editor") and insert a carriage return at the end of a line indented with at least one Tab, the next line is indented with n*2 spaces, where n is the number of tabs of indentation in the previous line.This is the bug I'm seeing. I can confirm it is still happening for me.Eclipse: Helios Service Release 2 20110218-0911PDT: PHP Development Tools (PDT) SDK Feature 2.2.1.v20101001-2300-53184QAN4JBQgLYPWMLcXn6Na9OdI will likely have time to upgrade eclipse and test after this upcoming weekend, and it very well be that this bug has been fixed. But I'm really not ok with this ticket being closed with next to no due diligence. I took the time to report the ticket, the steps to reproduce, and necessary version information, and I would expect the same from your side before this can be considered resolved.yes,I only tested it in php file that only contains php,thanks for your reporting and explain,I will have a look at it again asap,thanks again:)	6.0
id=319795	REOPENED	PDT	Debugger	unspecified	PC Windows XP	P1 normal	PHP UI	2010-07-13 18:40 EDT by	James McCall	2010-10-19 11:26 EDT (	0 users	Build Identifier: 20100617-1415I have recorded a screen capture and commentary and posted it to Youtube here:Running a remote debug of server side PHP script on Apache. XDebug version 2.1.0 is in use.I put a breakpoint in my code then step towards an "include( )" function call.It steps into the included file on the line before the include statement.The library has been refreshed and the web server restarted.It seems to be a symptom of a deeper problem because if I put a breakpoint inside the included file and "Resume (F8)" from the first breakpoint, rather than stepping into, then the second breakpoint isn't hit at all. In fact the web app. just seems to hang in some lost/suspended state. Reproducible: AlwaysSteps to Reproduce:Not sure how I would reproduce this on any code but that which I am running. However the video posted to YouTube () shows it quite clearly and I'm happy to help, within my newcomer abilities.	Thanks for the you tube video, that was very interesting.The behaviour does appear to be odd, so here are some things that are worth checking.1. Double check that the files in your eclipse project are the exact same versions as those running on the web server, just in case.2. could you try using xdebug 2.0.5 and see if you get the same problems3. We will need to capture an xdebug log of the failing scenarios (It would be great if you could also annotate in the log each of the scenarios). So this way we can see how PDT and xdebug are interating. To generate the log add the following to you php.ini file.xdebug.remote_log=c:\xdebug.logstoring the file in an appropriate location on the file system of course.4. check your path mappings for your server. (These can be found when you configure your server in the path mapping tab. You can configure your server from the debug configuration you have). You may want to clear any path mappings in case they are old.Thanks.unable to recreate and no feedback from bug reporter. Marking as resolvedThis is not resolved. I was waiting for a response from you guys. I had done all you asked and sent the results.Sorry where did you post the results ? This bugzilla entry doesn't have anything after my append to request more info.Sorry(In reply to)I have installed a brand new web server and now have a chance to take a look at this again.First of all the step-into thing is a complete red-herring. It is simply because it is a single statement which is split across two lines, the second line is not within braces.The big problem is the second part, with breakpoints. It is more succinctly shown in this video:Basically if there is a breakpoint set in an included file then all breakpoints are ignored.Even with a brand new installation on a new computer I get the same behaviour. Note that the included files are not in a subdirectory of the web project root - they have been included in the project as libraries, added as an external source folder (ie. opened the project properties, when to the Libraries tab and clicked the [Add External Source Folder …] button).Thanks again,James	5.0
id=264442	REOPENED	PDT	Code Assist	2.0.0	PC Windows XP	P1 normal	Zhongwei Zhao	2009-02-10 18:36 EST by	Tom Walter	2010-11-05 00:46 EDT (	6 users	Build ID: M20080911-1700Steps To Reproduce:<?phpdefine('AGlobalConst', 1);class AClass{ const AClassConst = 1;}class Test{ protected $var = A|; // <- cursor}?>Expect to have code assist suggest:'AClass''AGlobalConst'Actual:'No completions available' error in status bar.More information:	CreatedpathcThe patch will cause testClassStatement1.pdtt and testClassStatement2.pdtt fail.CreatedCode assist bug when assigning class properties to constantsHi RonenThanks for your patch!It seems that your patch is the same as mine,there was unit test failure ,but now it disappears:)Contributed by Ronen!The patch could be improved so constants are not suggested in the following case:class A { |}but only in a right-hand side of an assignment expression:class A { something = |}Hi MichaelThanks for your suggestion.And we can have:class A { echo CONSTANT;}So do you mean CONSTANT should not be the first word?Still reproducible for PDT-2.2.0.v20100616The same behavior is looking at this PDT buildNo completion availableReopen this issueIf will have the fix for next build please resolved for themReopened byTeodor Kirkovworks nowTested on 2.2.1.v20100829Using the example in the bug description:AGlobalConst is suggested but AClass is NOT.I have a question,if class AClass does not contain any constant do we need to show 'AClass'?and further,we have the following content:<?phpdefine('AGlobalConst', 1);class AClass{const AClassConst = 1;public static $field;}class Test{protected $var = AAClass::|; // <- cursor}?>do we need we only to show 'AClassConst'?for performance reasons I would not show only the classes that have const but all classes.CreatedpatchStill issues of namespace1. The namespace AA is listed and the generated code is broke.<?phpnamespace AA;define('AGlobalConst', 1);class AClass{ const AClassConst = 1;}class Test{ AA\:: }?>2. Select the class AClass, the generated code is broke.<?phpuse AA\AClass;namespace AA;define('AGlobalConst', 1);class AClass{ const AClassConst = 1;}class Test{AClass::}?>Hi QS for 1st case,it is not special for this bug,and I have committed code that fixes it.for 2nd case,I could not reproduce it,I updated to the latest code(head).I'm using the latest code from 7.3 and haven't tried the head code.I assume that you plan to port the patch back to 7.3, otherwise no review needed at all. The original code is as below.<?phpnamespace AA;define('AGlobalConst', 1);class AClass{ const AClassConst = 1;}class Test{AClas | // CA here.}?>(In reply to)instead insert "use AA\AClass;",I got an exception,and I think the problem is we should not propose anything at '|' as Michael said.I will think about this later:)Createdpatch(In reply to)There is no need to insert the use statement, this patch can fix the issueThe patch looks all right. Can you please add unit test for it?(In reply to)The problem is we should not show any proposal at the above location.I have reverted my patch and my patch will cause tests failing.Xu's patch is based on my wrong patch,sorry for this.	19.0
id=301220	REOPENED	AspectJ	Build	unspecified	PC Linux	P2 major	aspectj inbox	2010-01-29 03:26 EST by	Konstantin Boudnik	2010-10-08 01:30 EDT (	2 users	Starting with at least AspectJ 1.6.5 the following problem has been discovered: unpacked aspectjtools.jar file has classes and directories with 0-0-0 permissions. E.g.---------- 1 xxx xxx 1432 2007-10-23 18:07 about.htmld--------- 2 xxx xxx 30 2009-06-17 20:42 ant_tasks/-rw-r--r-- 1 xxx xxx 8181 2009-02-28 13:15 aspectj_1_5_0.dtd---------- 1 xxx xxx 804 2007-10-23 18:14 CDC-1.0_Foundation-1.0.profile---------- 1 xxx xxx 938 2007-10-23 18:14 CDC-1.1_Foundation-1.1.profileAn attempt to build an RPM package for a product with AspectJ dependencies is apparently failing because once the file is unpacked there's very little can be done with such files.Another jar file from the same distribution (aspectjrt.jar) doesn't have that problem.Please fix if if possible.	I'm trying to look into this, I'm on Windows/Mac. jar -tvf won't show me the permissions so I did a jar -xvf to unpack aspectjtools.jar - in my expanded folder the files are all 644 (rw-r--r--). I'm not saying there isn't a problem here, I'm just trying to find a nice way to confirm there is. What tool were you using on linux to show jar permissions?i was going to build a little jar explorer to show me the permissions of the entries, but I can't actually see where the permissions are stored inside the file ....Actually, I've been using 'unzip' utility and I can confirm that 'jar'works property and I don't see incorrect permission after 'jar xf'command execution.Apparently, this isn't an issue with aspectj* jar files - this is alimited or incompatible implementation of unzip program.Please don't build that jar explorer :) and feel free to close the bug.thanks for getting back to me :)Can we re-open this? Looks like the aspectjtools jar still has lots of files w/o permissions set. jar xf will set permissions even if they're not set, while unzip preserves the permissions in the jar file. Re-packing tools used by rpm use unzip so we have to disable jar re-packing in order to work around this. common1 (trunk)$ mkdir tempcommon1 (trunk)$ cp build/hadoop-common-0.22.0-SNAPSHOT/lib/aspectjtools-1.6.5.jar temp/temp (trunk)$ unzip aspectjtools-1.6.5.jar temp (trunk)$ ls -al...drwxr-xr-x 5 eli eli 4096 2009-06-17 20:42 org-rw-r--r-- 1 eli eli 26 2009-06-17 20:42 org.eclipse.jdt.core-empty---------- 1 eli eli 731 2007-10-23 18:14 OSGi_Minimum-1.0.profile---------- 1 eli eli 751 2007-10-23 18:14 OSGi_Minimum-1.1.profile---------- 1 eli eli 715 2007-10-23 18:07 plugin.properties---------- 1 eli eli 1337 2007-10-23 18:07 plugin.xml---------- 1 eli eli 794 2007-10-23 18:14 profile.list---------- 1 eli eli 890 2007-10-23 18:14 systembundle.propertiesd--------- 2 eli eli 4096 2009-06-17 20:42 testdataok, feel free to reopen.I don't have that option since I'm a normal user and didn't create the bug.Per Eli's requestActually, I agree that the problem is valid: we have worked it around by exactly turning off RPM repackaging. However, if having an RPM package for Hadoop distro is the must requirement then the problem needs to be fixed 'cause otherwise use of aspectjtools.jar becomes an issue.	9.0
id=89009	REOPENED	AspectJ	Runtime	DEVELOPMENT	PC Windows XP	P2 enhancement	Adrian Colyer	2005-03-24 12:23 EST by	Ramnivas Laddad	2013-06-24 11:06 EDT (	4 users	Often, there is a need to keep per-join point (static part, usually)information. While using hashmaps works, it is inefficient in many situations.While perJoinPoint and perJoinPartStaticPart aspect associations mightwork, I have a simpler proposal to address the need. I will like to add the following APIs: void JoinPoint.StaticPart.setUserObject(Object) Object JoinPoint.StaticPart.getUserObject()And, for symmetry, void JoinPoint.setUserObject(Object) Object JoinPoint.getUserObject()Then I will be able to store profile information as follows:Object around() : profiled() { long startTime = getTime(); Object ret = proceed(); long endTime = getTime(); ProfileInfo jpStats = (ProfileInfo)thisJoinPointStaticPart.getUserObject(); if(jpStats == null) { thisJoinPointStaticPart.setUserObject(new ProfileInfo()); } jpStats.record(endTime-startTime);}	We had such a concept in AWNot just an object but a map so that more than one object can be associated tothe jp.Note that the StaticPart version will not be thread safe. Given your sample, iexpect that the "record" method is doing the locks etc..Further on, what would happen with inlining (when there is no closure).(In reply to)I think the default implementation should provide no thread safety. User can, if warranted, make such access thread safe by either:- Explicitely taking locks around get/setUserObject and/or accessing/modifying the user object.- Using a user object of type that is thread safe (HashTable, for example). In this case, get/setUserObject worn't be thread-safe, but accessing and modigying the underlying user object will be.Re: InliningEven when inlined, thisJoinPoint and thisJoinPointStaticObjects are created.Right? If so, inlining should pose no problem.We're not going to get to this in AJ 1.5.0. Marking as "LATER" for considerationin 1.5.1 and future release planning.I would really like to have this reconsidered for 1.5.1 ... it is motivated by the same kind of efficiency concerns as pertypewithin aspects, e.g., where you want to cache information and calculate data at each shadow advised (e.g., for monitoring, error handling, etc.). JBoss AOP provided a perjoinpoint aspect instantiation model to address the same goals...I have had some thoughts on this. The user object could be kept in the StaticJoinPoint instance. However you need one for each aspect otherwise you cannot rely upon it. There could be one object per aspect, not aspect instance, which would be very efficient. However we need to make per-aspect access transparent and possibly protected to prevent inadvertent corruption.One solution is to allocate a user object array in the StaticJoinPoint instance with one entry for each aspect that affects the target class. The index is the implied or defined aspect precedence for that class i.e. the one with the highest precedence is 0. The object is accessed from advice using thisJoinPoint.get/setUserObect(). The transient JoinPoint object passed to the advice is instantiated with the aspect index. The downside with this approach is the need to us thisJoinPoint.A simple implementation would allocate a user object for each aspect declared to the weaver but this would cause unnecessary bloat to StaticPartImpl instances which we have recently streamlined to reduce heap footprint in“Reduce footprint of JoinPoint.StaticPart objects”. An optimization would only allocate user objects for join points whose associated advice actually used the feature (in a similar way to detecting static only access to thisJoinPoint). A further enhancement would use a StaticPartImpl subclass for the new “userObects” array reference to save space when the feature is not used at all.I will post a patch to runtime when I have something working.The reason I like this approach is that thisJoinPoint is used as a localized, transient “ticket” granting an aspect access to its data. The user data has the same scope as thisJoinPointStatic part i.e. it can only be access in advice but passed to others if necessary. I would like to make access harder by avoiding changes to the public JoinPoint.StaticPart interface. One option is a UserObjectHolder a reference to which is passed to a JoinPoint on construction.Implementation ideas with increasing levels of performance (and complexity):1. Allocate an Object[] in StaticPartImpl whose size is the total number of aspects. Bloated.2. Allocate an Object[] whose size is the number of aspects affecting the class i.e. 0-N where N is the total number of aspects. This is more complex as the aspect # would be different for each class.3. Allocate an Object[] whose size is the number of aspects affecting the class iff at least on of them uses get/setUserObject(). Probably the sweet spot.4. Allocate an Object[] whose size is the number of aspects affecting the class iff advice associated with the join point uses get/setUserObject().5. Allocate an Object[] whose size is the number of aspects that have advice which is associated with the join point and uses get/setUserObject(). This is even more complex as the aspect # would be different for each join point in a given class.6. Allocate a StaticPartImpl subclass for those join points whose associated advice using get/setUserObject(). This would mean zero cost is systems where the feature is not used.What about abstract aspects, do they get their own slot or do they share it with sub-aspects?Can we think of an efficient implementation that would allow a user object per aspect instance or is the current model more appropriate?Renewed interest.review this for 1.6.0I'm thinking about implementing this but am having a few problems.Currently thisJoinPointStaticParts have no knowledge of the aspect that caused them to come into existence. They are shared amongst any advice that needs them at a particular shadow in the code.The initial thought would be:public void setUserObject(Object data) {}public Object getUserObject() {}But, as discussed in this bug, that breaks down because there are multiple aspects around, you might get back something that another aspect decided to store against the jp object. I don't know how you would generate an int id for an aspect that was robust across compile time weaving and later possible reweaving with a different set of aspects. So, let's change the methods to store against a key - reducing the collision chance because differing aspects are unlikely to be using the same keys:public void setUserObject(Object key, Object value) {}public Object getUserObject(Object key) {}But where is the data stored? Well each staticpart object holds a map instance - that would unfortunately increase the tjp object size by 4bytes (from 12 to 16 - which is quite a lot when you have a tracing aspect using 1000s of these things). And what type of map would it be to avoid problems with concurrent thread access?So we could introduce a new kind of jp to address the size issue - StatefulStaticPart (as outlined in (6) in the previous comment). But that means throughout the whole codebase we have to modify all the code dealing with joinpoints to do the right thing with this new kind of jp, and that is a big piece of work.I'm hoping there is a much simpler way... but can't quite see it at the moment.I understand the motivation for changing to a map, but it almost completely invalidates my desire for this feature: efficiency.The only change to my current aspect would be not creating my own map, but using this one instead.The scenario I'm working in is:* use an annotation on a field (perhaps multiple per class)* use an aspect to 1) associate a java.util.concurrent.atomic.AtomicMarkableReference with each field, 2) around get for these fields atomically check the markable reference (and do stuff).The aspect I've already implemented is constructing a ConcurrentHashMap to map from field to AtomicMarkableReference. It's lookups in this map that slow down everything considerably. (If you're curious see)The two solutions I see are:1) (Somehow) implement the original setUserObject/getUserObject signtatures to be array indexes or field access for efficiency.2) Extend the aspect instantiation model to include perfield.I don't know how to do that somehow part either, that why I voted for this bug! ;)Hi,we are working on an in-house monitoring tool utilizing aspectj and came across the same issue. What we want to achieve is to provide an annotation based API which can be used to identify methods in the code which needs to be measured. With annotations we can fully decouple the capturing part from the implementation part. Ideally the code would be weaved in in production applications and monitoring can be turned on/off at runtime on demand. If i weren't use aspectj the following code would be written:class A{ StopWatch stopWatch=...; void methodNeedsToBeMeasured(){ stopWatch.start(); //doStuff stopWatch.stop(); }}With the current AspectJ implementation this is the nearest i can get:class A{ //Injecting this field to the class through ITD Map<String,StopWatch> signatureToStopWatchMap; void methodNeedsToBeMeasured(){ StopWatch stopWatch= // lookup the current stopwatch from the map based on the signature name passed in to the JoinPoint stopWatch.start(); //doStuff() stopWatch.stop(); }}The lookup in the map slows down things considerably(like mentioned in this Jira issue) and makes us thinking whether this slow down is acceptable in a production environment which questions the usefulness of the annotation API.I would like to ask if this Jira is considered to be fixed in the foreseeable future, given that there is another use case which requires it ;-)I had a quick look at JBoss AOP which has implemented this feature by providing a per joinpoint instantiation model and wonder why this has been missed out from Aspectj. I have 2 guesses here: a) because JBoss aop is proxy based - as far as i know- b) instantiating an aspect at every join point has a bad performance impactIn any case i would like to here your opinion about this.Thanks you for your time and answer in advance!Kind Regards,Zoltan SzelHi Zoltan,As discussed in, it is currently blocked on trying to come up with a design that is not simply a map internally as that will have the same performance issue as maintaining your own map.let me put some brain power into seeing if there is a sensible design that we could use in the short term.Achieving a performant implementation of perjoinpoint() or even perjoinpointstaticpart() seems tough. In the former case would we create instance fields in the affected target for every advised joinpoint? If we didn't do that then we would be reduced to maintaining a map from joinpoint>aspect instance - and map lookups is the whole thing we are trying to avoid here.A perjoinpointstaticpart() seems more achievable because we already have a field in the affected target for every JoinPointStaticPart - but as mentioned earlier in this bug, they are shared - there is not one per aspect affecting the type. This means we couldn't just extend what we have to add an aspect instance to the existing JoinPointStaticPart field, because if there was more than one aspect, they'd clash.Maybe the use cases for large scale crosscutting (tracing) and small scale crosscutting (profiling) don't overlap and so I'm worrying too much about the problem of having one instance field in the target type per joinpoint per aspect instance, since in the scenarios where the instantiation model is useful there are not thousands of advised join points.How many places are you advising with your profiling aspect, for example?It does seem that a way to reduce the map size for these kinds of aspect is to also use the pertypewithin() instantiation model. Instead of a singleton aspect with a huge map of all thisJoinPointStaticPart instances to StopWatches, it would be one map per advised type that only included tJPSPs from that advised type.I spoke with Ramnivas who agreed that the pertypewithin(*) lifecycle for an aspect would really help limit the size of the maps involved (and so speed up lookup time).However, I've also spent the day thinking about perjoinpoint and perjoinpointstaticpart. There might be something we should do for these instantiation models that would offer great performance - but the trade off would be larger class files, and possibly files that are tooo big for a highly pervasive aspect attempting to use them, so we'd have to police how many joinpoints are being advised within a particular type.However, adding a new instantiation model is not cheap because we need to do it properly and write an army of testcases. Whereas a very basic set/get userobject for thisjoinpointstaticpart looks like it would address every reasonable use case I have seen and is far less effort (just an API change rather than a language change). I might think about this small change for 1.6.4.Hi Andy,thank you for putting this much effort into this, really appreciate it.In my use case the number of affected classes would not be more than a couple of hundreds.I do not need to use the pertypewithin instantiation model because i can work around it by injecting the map into the advised object and use it directly from there which avoids having a huge map in a singleton aspect. All i need is a single unique identifier(from a reasonable range) of joinpoints. With that identifier i can inject an array into the advised object and lookup my stopWatch from that based on this identifier.Doing array lookups instead of field lookups is not much of a big deal and seems to me the closest we can get.The fallback of this approach arises when we want to use more than one thing for profiling. In this case for every "profiler" we have to inject a field to the advised class even if that class does not use let's say accessCounter.What's your thought on this approach?ZoltanYep, sounds good, that is just about the same thing as pertypewithin(*) would give you. (pertypewithin is really just implemented as holding the aspect instance as a new field in the target types).It sounds reasonable to me. As long as you don't have too many profilers I guess there won't be too many extra fields in the target objects. If I add just the:void JoinPoint.StaticPart.setUserObject(Object);Object JoinPoint.StaticPart.getUserObject();do you think that would be entirely sufficient for you? I suppose you'd use it to hold the unique identifier generated from the thisJoinPointStaticPart info? And keep the range down so it can be the array index.That would be a minimal amount of work for me and achievable in a few days. If it was required on the individual JoinPoint level, that would be a much larger piece of work which I couldn't manage in 1.6.4 and it would be unlikely in 1.6.5/1.6.6.I think the initial thing I'm proposing here is how I'd like to proceed and then collect feedback on it and perhaps grow it into perjoinpointstaticpart/perjoinpoint aspect models sometime later.Adding those API's to the StaticPart is problematic because of the thing mentioned in this issue: The StaticParts are shared among aspect's, if i consume that space for my lib i am closing everyone else out.I have checked the code in the generated classes and found that the static part fields are named as ajc$tjp_0,ajc$tjp_1 ... ajc$tjp_N. If those order numbers were to be exposed, i would be able to build my logic around that and get rid of the map lookup completely. What about adding the following API:int JoinPoint.StaticPart.getOrderNumber();How feasible is this proposal?Taking this thought forward implementing the perjoinpoint aspect model would be much easier:1) You can inject an array of aspects into the advised object.2) At every joinpoint you can lookup the aspect instance from the array based on the order and execute the required function on that.What do you think?yep, you are closing everyone else if you use the slot, unless it is made into a Map, each aspect keying what it is using in there. And we'd be back to map lookups - and they'd be slow. I knew this was a limitation of that solution but if it addressed a common use case, it seemed reasonable. But it does move all the responsibility to the aspect writer. It sounds like you don't want this, so I'll shelve it again for now. Since I've been thinking more about perjoinpoint/perjoinpointstaticpart - they seem a better solution to this problem of state.>Hmmmmm, relatively easy to implement but there are no guarantees that the numbers will remain the same across builds. If a single new joinpoint were to be advised and it resulted in a new field, it would be inserted at some point in the list, not at the end. I think getOrderNumber() suggests the ordering is more reliable than it really is. In your situation you possibly don't really care about the number changing across builds so long as it remains the same across multiple invocations. But really I'm not too keen on externalizing a value we can't give an accurate definition to, it feels a bit hacky.And for two thisJoinPointStaticParts in different files, it would return the same value, so it is not a unique number across the system - that may surprise some users, so maybe it would need qualification ... getIdWithinAffectedType(). I guess you are ok with that because of the injected map being type specific but that is also perhaps a factor against the general usefulness of a change like this.>I'm afraid for (2) - we don't have fields for joinpoints, they are conjured up on demand on the stack because every time they are encountered they are likely to be different. We only have fields for joinpointstaticparts since that information (line number/etc) is unchanging (you can see the type of the ajc$tjp objects is 'JoinPoint$StaticPart'. So going down this road the only quick-ish solution would be for a perjoinpointstaticpart instantiation model (since adding fields for all join points would be a very large piece of work). Now that may be a sensible stop-gap on the road to supporting perjoinpoint, but I can't fit it into 1.6.4. I do like your idea of the tjp static part number indexing the instance (since the number can then just be an 'internal' thing, which the user is never aware of, and it potentially changing across builds will then not matter).But then what would be the signature for the aspectOf() method for perjoinpointstaticpart/perjoinpoint instantiation model? It can't be aspectOf(orderNumber) because the number may change across compiles and the user cannot rely on it. It is these surrounding issues that need solving for an entirely new language feature like this. Would we even need an end user version of aspectOf() and hasAspect()? I've not thought about it enough, but we have them for every other kind of instantiation model so it feels odd if they were missing.this is some good discussion and is slowly teasing out some new language features and their design :)More thinking...Given that a join point is an event that occurs during the execution of a program, they are all different (even though if you think quickly about it, some may appear to be the same). So a perjoinpoint instantiation model, in the purest sense, would run every piece of advice on a new aspect instance. That isn't so useful. So I think the best solution is perjoinpointstaticpart, but I still can't crack what aspectOf()/hasAspect() take as parameters. If I could crack that, we'd be in good shape.Oh and let me also reference another related bug, this one covers supporting a custom joinpoint factory so the user could specify the factory for joinpoint objects and do whatever they wish in their creation:I guess the signature for it is reallyaspectOf(JoinPoint.StaticPart) but of course I'd been getting ahead of myself because how would the user ever be able to determine the object to pass from some arbitrary context. This made me think of a simple (possibly generally useful) API to return the joinpoint static parts for a typeJoinPoint.StaticPart[] joinpointsIn(Class)So if a user realllllllly realllly needed to call aspectOf, they had everything they need to do it. Of course internally the aspectj implementation would be highly optimized to get straight to the aspect in question.aspect CleverStuff perjoinpointstaticpart() { private Object importantThing; before(): execution(* Foo.*(..)) { if (importantThing==null) { importantThing = createImportantThing(); } // use importantthing }}then each time the joinpoint is reached we would use the same importantThing.Under the coversclass Foo { CleverStuff[] ajc$instances; JoinPoint.StaticPart ajc$tjp_0; JoinPoint.StaticPart ajc$tjp_1; JoinPoint.StaticPart ajc$tjp_2; JoinPoint.StaticPart[] ajc$allJPs; static { ajc$instances = new CleverStuff[3]; ajc$tjp_0= make the first joinpoint ajc$tjp_1= make the first joinpoint ajc$tjp_2= make the first joinpoint } CleverStuff optimizedAspectOf(int i) { if (ajc$instances[i]==null) { ajc$instances[i]= new CleverStuff(); } return ajc$instances[i]; } JoinPoint.StaticPart[] joinpointsIn() { // created on demand for the 3 join points } // Advised method public void m() { optimizedAspectOf(0).ajc$before$Advice(); }}class CleverStuff { // similar for hasAspect public CleverStuff aspectOf(JoinPoint.StaticPart jpsp) { return Foo.optimizedAspectOf(jpsp.internalId); } public void ajc$before$advice() { }}the use of a more optimal aspectOf in the target type would be similar to what happens for pertypewithin, and there are no map lookups.I was always bad at naming :-) getIdWithinAffectedType() sounds much betterI totally agree with that, creating an aspect at each execution of a joinpoint is useless and can be already achieved with the existing features(just create an adivse for that joinpoint and create the state which would be stored in the aspect by yourself). In my dictionary i have the following definition for the perjoinpoint instantiation model: It will instantiate 1 aspect for each joinpoint which instance's lifecycle spans among all joinpoint execution at that given point in code. One thing which needs to be mentioned here is having an Aspect instance per joinpoint in the advised class as a static member will beat the purpose of this instantiation model, because at every execution of a given advise i have to look up the state of the current object at the current joinpoint, which would involve the map lookup again. Let me share my original thought:aspect CleverStuff perjoinpoint() { private Object importantThing; //Here the jpsp can be optional, but it could be used to load the state of this aspect instance.(Also adding the this object to the constructor would be nice) public CleverStuff(JoinPoint.StaticPart jpsp){ importantThing = createImportantThingBasedOnTheStaticPart(jpsp); } before(): execution(* Foo.*(..)) { // use importantthing }}would transform to the following class:class CleverStuff{ public interface Advised{ CleverStuff[] getAspects(); } public static boolean hasAspect(Object object){ return object instanceof Advised; } public static CleverStuff[] aspectOf(Object object){ if(!hasAspect(object)){ throw new AspectNotBoundException(); } return ((Advised)object).getAspects(); } private Object importantThing; public CleverStuff(JoinPoint.StaticPart jpsp){ importantThing = createImportantThingBasedOnTheStaticPart(jpsp); } public void ajc$before$advice() { }}and then under the cover:class Foo implements CleverStuff.Advised{ CleverStuff[] ajc$instances; static JoinPoint.StaticPart ajc$tjp_0; static JoinPoint.StaticPart ajc$tjp_1; static JoinPoint.StaticPart ajc$tjp_2; static{ ajc$tjp_0= make the first joinpoint ajc$tjp_1= make the first joinpoint ajc$tjp_2= make the first joinpoint } { ajc$instances = new CleverStuff[3]; ajc$instances[0] = new CleverStuff(ajc$tjp_0); ajc$instances[1] = new CleverStuff(ajc$tjp_1); ajc$instances[2] = new CleverStuff(ajc$tjp_2); } public CleverStuff[] getAspects(){ return ajc$instances; } // Advised method public void m() { ajc$instances[0].ajc$before$Advice(); }}With this approach we can guarantee that at every joinPoint a piece of state can be attached to the joinPoint, which state is not shared between different objects. This approach has some fallbacks: 1) Supporting the pre-initialization and initialization pointcuts would require adding a static aspect instance to the field 2) The same for pointcuts matching on static functions, they would also require a static aspect instance field, to guarantee the same instance of aspect will be used at every joinpoint execution.Given that this kind of instantiation model at it's current state can be almost achieved with the existing language features i do not think it worth having the burden of implementing it at the language level.(If the internal id of the static part is reachable than i can store the state what i would store in the aspect instance in the advised class and look it up from there + having a nice javadoc for getIdWithinAffectedType())But if we want to make the above solution perfect then we have to inject extra static fields. But if we have to do that then we can choose a slightly different approach: Inject an aspect field to the advised class for each joinpoint, which can be static if the underlying pointcut requires it. The aspect implementation would not change just the woven class:class Foo implements CleverStuff.Advised{ //This join point is a static initialization joinpoint and it requires to run before any other initialization steps is made. static final JoinPoint.StaticPart ajc$tjp_0; static final CleverStuff ajc$cleverStuffAspect_0; //This join point matches on a static function/field or for pre-initalization /initialization joinpoints static final JoinPoint.StaticPart ajc$tjp_1; static final CleverStuff ajc$cleverStuffAspect_1; //No comes the joinpoints for instance members static JoinPoint.StaticPart ajc$tjp_2; CleverStuff ajc$cleverStuffAspect_2 static JoinPoint.StaticPart ajc$tjp_3; CleverStuff ajc$cleverStuffAspect_3 CleverStuff[] ajc$instances; static{ ajc$tjp_0= make the first joinpoint ajc$cleverStuffAspect_0 = new CleverStuff(ajc$tjp_0); ajc$tjp_1= make the first joinpoint ajc$cleverStuffAspect_1 = new CleverStuff(ajc$tjp_1); ajc$tjp_2= make the first joinpoint ajc$tjp_3= make the first joinpoint } { ajc$instances = new CleverStuff[4]; ajc$instances[0] = ajc$cleverStuffAspect_0; ajc$instances[1] = ajc$cleverStuffAspect_1 ajc$instances[2] = ajc$cleverStuffAspect_2 = new CleverStuff(ajc$tjp_2); ajc$instances[3] = ajc$cleverStuffAspect_3 = new CleverStuff(ajc$tjp_3); } public CleverStuff[] getAspects(){ return ajc$instances; } // Advised method public void m() { ajc$cleverStuffAspect_2.ajc$before$Advice(); }}This indeed increase the size of the woven class, but the use cases which would use it wouldn't mind it.(If i want to write a trace aspect than i wouldn't use this instantiation model ). And also i can imaging it would take much more work than implementing the getIdWithinAffectedType() method.If we were implementing the perjoinpoint instantiation model as described above, than the need for joinpoint factory would disappear: You would get an aspect instance/joinpoint/object and you can store any kind of state/logic in there instead of hacking that state/logic into the joinpoint itself(which is created on the fly several times)We are getting there :-)And one more thing: I am really bad at naming, feel free to change any names in the code i have written. :-)What do you think about this approach? Is it feasible?I have a full design for perjoinpoint which seems to work - I have written the generated code as 'real code' to test it works as expected (it is rather similar to the pertypewithin approach, in terms of the architecture of what methods go where). It is a lot of effort though and also hinges on joinpoint static parts having an ID. So, as a precursor to that which will address this enhancement request in the short term, I'm on the verge of adding getId() to joinpoints (I prefered a very simple name in the end), a simple id you can use it as an array index. Javadoc for getId() is currently:/** * Return an id number for the join point static part. All join points * advised in a target type are assigned an id number, starting from 0. * This number is guaranteed to remain constant across repeated executions * of a program but may change if the code is recompiled. In each affected * type the id numbers start from 0 so two join points advised in different types * may have the same number. The benefit in having an id is for rapid access * to per joinpoint state through an array lookup rather than using the * joinpoint object itself as a key in a map lookup. however, because * the numbers are not unique across types, any maintained state must be * maintained per type (either by using an ITD or the pertypewithin * instantiation model). * * @return the id of this joinpoint */The last stumbling block is me deciding if this is ok from a language point of view.---For reference, the working perjoinpoint code is here.import java.lang.reflect.InvocationTargetException;import java.lang.reflect.Method;import org.aspectj.lang.JoinPoint;import org.aspectj.lang.NoAspectBoundException;import org.aspectj.lang.JoinPoint.StaticPart;import org.aspectj.runtime.reflect.Factory;public class C { private static AspectX[] ajc$AspectX$instances; private static JoinPoint.StaticPart[] ajc$AspectX$joinpoints; // created on demand as probably not used very often private static final int ajc$AspectX$maxJps; private static final org.aspectj.lang.JoinPoint.StaticPart ajc$tjp_0; private static final org.aspectj.lang.JoinPoint.StaticPart ajc$tjp_1; static AspectX ajc$AspectX$localAspectOf(int id) { if (id >= ajc$AspectX$maxJps) { return null; } return ajc$AspectX$instances[id]; } static JoinPoint.StaticPart[] ajc$AspectX$getJoinpoints() { if (ajc$AspectX$joinpoints == null) { ajc$AspectX$joinpoints = new JoinPoint.StaticPart[ajc$AspectX$maxJps]; ajc$AspectX$joinpoints[0] = ajc$tjp_0; ajc$AspectX$joinpoints[1] = ajc$tjp_1; } return ajc$AspectX$joinpoints; } static { Factory f = new Factory("C.java", C.class); ajc$AspectX$maxJps = 2; ajc$tjp_0 = f.makeSJP(0, "method-execution", f.makeMethodSig("1-m-C----void-"), 33); // 33 is line number ajc$tjp_1 = f.makeSJP(1, "method-execution", f.makeMethodSig("1-n-C----void-"), 38); ajc$AspectX$instances = new AspectX[ajc$AspectX$maxJps]; ajc$AspectX$instances[0] = AspectX.ajc$createAspectInstance(ajc$tjp_0); ajc$AspectX$instances[1] = AspectX.ajc$createAspectInstance(ajc$tjp_1); } public void m() { // jpsp is only passed because it is used in the advice, it isn't necessary for perjp to work ajc$AspectX$instances[0].ajc$before$AspectX$1$3444dde4(ajc$tjp_0); System.out.println("m running"); } public void n() { // advice calls are as fast as can be, a swift array access and call ajc$AspectX$instances[1].ajc$before$AspectX$1$3444dde4(ajc$tjp_1); System.out.println("n running"); } public static void main(String[] args) { new C().m(); new C().n(); new C().m(); new C().n(); new C().m(); new C().n(); JoinPoint.StaticPart[] jpsps = AspectX.joinpointsIn(C.class); System.out.println("number of joinpointstaticparts in class C because of AspectX " + jpsps.length); JoinPoint.StaticPart jp1 = AspectX.joinpointsIn(C.class)[0]; JoinPoint.StaticPart jp2 = AspectX.joinpointsIn(C.class)[1]; System.out.println("Aspect instance for " + jp1 + " is " + AspectX.aspectOf(jp1)); System.out.println("Aspect instance for " + jp2 + " is " + AspectX.aspectOf(jp2)); }}class AspectX { int i = 0; private StaticPart ajc$jpsp; static AspectX aspectOf(JoinPoint.StaticPart jpsp) { AspectX instance = ajc$getInstance(jpsp); if (instance == null) { throw new NoAspectBoundException(); } return instance; } static boolean hasAspect(JoinPoint.StaticPart jpsp) { AspectX instance = ajc$getInstance(jpsp); return instance != null; } public static AspectX ajc$createAspectInstance(StaticPart jpsp) { // depending on whether the user specified a ctor that takes a jpsp, call: AspectX ax = new AspectX(); // or // AspectX ax = new AspectX(jpsp); ax.ajc$jpsp = jpsp; return ax; } public JoinPoint.StaticPart getJoinpoint() { return ajc$jpsp; } public static JoinPoint.StaticPart[] joinpointsIn(Class c) { try { Method m = c.getDeclaredMethod("ajc$AspectX$getJoinpoints"); return (StaticPart[]) m.invoke(null); } catch (IllegalArgumentException e) { return null; } catch (SecurityException e) { return null; } catch (IllegalAccessException e) { return null; } catch (NoSuchMethodException e) { return null; } catch (InvocationTargetException e) { return null; } } private static AspectX ajc$getInstance(JoinPoint.StaticPart jpsp) { try { Method m = jpsp.getSignature().getDeclaringType().getDeclaredMethod("ajc$AspectX$localAspectOf", Integer.TYPE); return (AspectX) m.invoke(null, jpsp.getId()); } catch (SecurityException e) { return null; } catch (NoSuchMethodException e) { return null; } catch (IllegalArgumentException e) { return null; } catch (IllegalAccessException e) { return null; } catch (InvocationTargetException e) { return null; } } public void ajc$before$AspectX$1$3444dde4(JoinPoint.StaticPart jpsp) { System.out.println("advice running at " + jpsp + " loc=" + jpsp.getSourceLocation()); System.out.println("i=" + i); i++; }}There will not be any API alongside it to ask 'getIdMax()' or anything - is that a problem for you?(In reply to)No, i can handle the size of the array without the need of getIdMax().Checking through your perjoinpoint implementation it seems to me it is more like a per_class_joinpoint instantiation model as defined by JBOSS Aop, while my proposal seems to be nearer to the per joinpoint model: Copied from JBOSS AOP doc():"PER_CLASS_JOINPOINT: An instance of an aspect will be created per advised joinpoint. The aspect instance is shared between all instances of the class (for that joinpoint).PER_JOINPOINT:An instance of an aspect will be created per joinpoint advised. If the joinpoint is a static member (constructor, static field/method), then there will be one instance of the aspect created per class, per joinpoint. If the joinpoint is a regular non-static member, than an instance of the aspect will be created per object instance, per joinpoint."Based on these is there any chance to add an aspect/joinpoint/object instantiation model in the (near) future? If yes, which could be the target release?The getId() API seems to be the golden path for now. Do you have an ETA for it?Thank you again for your continuous effort on this, it was a pleasure for me brainstorming on this issue.Thanks for digging that out from the Jboss doc.Yes, this is what jboss call per_class_joinpoint - which is what I've been calling all along 'perjoinpoint staticpart' or 'perjoinpoint shadow' - it is per thing that is constant across all instances of a join point. It seems unfortunately have been slightly at cross purposes in the discussion because of the difference in terminology. This model (perjoinpoint shadow) is more feasible (as in much easier to implement in the short term) than perjoinpointperinstance because of how much infrastructure is already around in the advised classes.perjoinpointperinstance is something I've not put any thought into, and I'd need some compelling use cases to explore it further (I'll look through your handwritten generated code again when i get time). I wonder how far it can be achieved already with a combination of pertypewithin/getId for the static components and perthis/getid for the non-static components.Not really on my radar right now without some compelling use cases, but not in 1.6.4.might do it today.yes, enjoyed it - shame we were a little at cross purposes due to a difference in terminology though.Great design discussion.I wanted to check if the current plan would provide support for instance field level manipulation.In mybelow () I refer to Dash Obtain that lazy-loads fields in instances.Would the proposed near-term solution support the following:1) Given:public class Foo { @Obtain DataSource dataSource; @Obtain ISomeService someService;}2) Using ITD:Introduce a per-instance AtomicMarkableReference[] array into any class that hasfield(@Obtain *).3) Would the following pointcut get a unique id _per field_, or a single unique id?pointcut obtain_get(): get(@Obtain !static * *);4) Lookup the correct AtomicMarkableReference by array index (and appropriate synchronization), then do actual stuff.Thanks,John HeintzI have spun off two enhancement requests for:perjoinpointstaticpart/perjoinpointshadow/perclassjoinpoint -perjoinpointperinstance/'perjoinpoint' -The former is more well formed in my mind, whilst the latter needs some good use cases. In both cases they are kind of achievable using existing constructs - and achievable in a performant way when getId() is added.Now to think about John's situation. With getId() there is a unique id for each join point static part - the problem is that accessing the same field from different places would be considered different join points (as John imagines in his point (3))These are four different join point (shadows):...someinstance.accessFieldAsomeinstance.accessFieldBsomeinstance.accessFieldAsomeinstance.accessFieldB...so each has its own ID, even though only two fields are accessed. I don't think perthis or pertarget will help. Still thinking... (I don't imagine either of the two new enhancement requests will help either). I'm currently wondering if there is a way to write an aspect such that it is costly to initially sort out the references but then fast afterwards due to array lookups. Here is the brain bender so far:aspect BrainBender { interface Marker {} declare parents: hasfield(@Obtain * *) implements Marker; // Array used for fast lookup, lazily initialized. Not one entry per field - // there are possibly multiple entries for the same field, but under // different ids (they will share the same AtomicMarkableReference). AtomicMarkableReference[] Marker.amr = new AtomicMarkableReference[100]; // Hideous map used when we haven't initialized the array for a // particular join point id Map<Marker,Map<String/*FieldName*/,AtomicMarkableReference>> map = new HashMap<Marker,Map<String,AtomicMarkableReference>>(); before(Marker m): get(@Obtain * *) && target(m) { // if this succeeds - zoom AtomicMarkableReference amr = m.amr[thisJoinPointStaticPart.getId()]; // otherwise very costly if (amr==null) { int idx = thisJoinPointStaticPart.getId(); // Find it out the expensive way String fieldName = thisJoinPointStaticPart.getSignature().getName(); System.out.println("Field access of "+fieldName+" on instance "+m); Map<String,AtomicMarkableReference> instanceMap = map.get(m); if (instanceMap == null) { map.put(m,instanceMap=new HashMap<String,AtomicMarkableReference>()); } else { amr = instanceMap.get(fieldName); } if (amr==null) { amr = new AtomicMarkableReference(); instanceMap.put(thisJoinPointStaticPart.getSignature().getName(),amr); } m.amr[idx] = amr; // will be fast next time } System.out.println("Accessing a field, joinpoint id = " +thisJoinPointStaticPart.getId()+" amr="+amr); }} Less than perfect (does it even meet your needs?), but once the arrays are setup it is as fast as can be. It means multiple references will be kept to an AtomicMarkableReference in the array, one reference for each joinpoint index that is accessing the same field. The map I use in the slow case to initialized the array sounds a bit like your (from) 'The aspect I've already implemented is constructing a ConcurrentHashMap to map from field to AtomicMarkableReference'A possible enhancement of perfield() will need more thought and its own enhancement request - what it means currently isn't completely clear in my mind.Andy, that latest BrainBender proposal should work. The code you wrote would need a little synchronized voodoo, but certainly doable.I like the _clever_ trick of storing the "multiple references will be kept to anAtomicMarkableReference in the array", that would optimize the normal lookup path and only cause pain during first reference.I even have a brain-dead performance test in Dash Obtain to prove out the implications of different strategies,Here's a bit of that code: // throw away first results... getLoopTiming(createDirectConsumers(1), 1); getLoopTiming(createAtomicConsumers(1), 1); getLoopTiming(createIndexedAtomicConsumers(1), 1); getLoopTiming(createFieldObtainedConsumers(1), 1);The last one is the AspectJ code, it runs about an order of magnitude slower than the first three. With your suggested code the performance should be about the same. The startup time would be measurable, but heck I'm getting objects from Spring and properties file! Who cares! :)Cheers,JohnThe change is in. The dev builds later today will include thisJoinPointStaticPart.getId(). Please try it out.Going to have 50 zillion bugs reported against 1.6.4 now because people are using getId() but not running with an up to date aspectjrt.jarIt worked, and it's quite a bit faster. (Given a trivial looping test...)The new timings are:...sequential: [java] Do timings for 1000 consumers over 5000 iterations. [java] Initial creation timings: [java] Control is Direct Consumer at 51 [java] Atomic Consumer is 1 [69] [java] Indexed Consumer is 1 [79] [java] Field Consumer is 7 [376] [java] [java] Looped access timings: [java] Control is Direct Consumer at 64 [java] Atomic Consumer is 1 [73] [java] Indexed Consumer is 1 [94] [java] Field Consumer is 2 [154] [java] What that means:* "Field Consulmer is 2": Looped access timings are only 2X the cost of a pure Java solution with direct field access. That sounds pretty darn good for AOP intercepted access.* Initial processing time was 7X the other strategies. This number isn't really a big deal, as the time measured here will be swamped by actually loading Spring objects for example.Here is the timing run from the old code that used a giant shared ConcurrentHashMap:sequential: [java] Do timings for 1000 consumers over 5000 iterations. [java] Initial creation timings: [java] Control is Direct Consumer at 173 [java] Atomic Consumer is 1 [193] [java] Indexed Consumer is 1 [185] [java] Field Consumer is 9 [1668] [java] [java] Looped access timings: [java] Control is Direct Consumer at 167 [java] Atomic Consumer is 1 [177] [java] Indexed Consumer is 1 [186] [java] Field Consumer is 9 [1559] [java] This was essentially an order of magnitude slower for the common case of lookups (not counting intialization) and seemed to costly to me.Thanks all for driving this progress and a workable solution.unsetting the target field which is currently set for something already released	34.0
id=234045	REOPENED	Target Management	RSE	3.0	PC Windows XP	P2 normal	David McKnight	2008-05-26 18:41 EDT by	Martin Oberhuber	2012-11-19 04:41 EST (	0 users	Connect "FTP Only" to Windows "FileZilla Server".This FTP Server doesn't support the CHMOD command.Setting a file to Read-only leads to following output on FTP console: SITE CHMOD 444 /antenna/LICENSE 504 Command not implemented for that parameterBut users are not informed about the error. It looks like some FTPClient.isPositiveCompletion()or similar call is missing.	CreatedPatch fixing FTPAttached patch fixes the problem in FTP, but there are more problems e.g. in SystemFilePermissionsPropertyPage all exceptions are silently swallowed.Patch committed: [234045] FTP Permission Error HandlingAssigning DaveM to fix the remaining issues.I've added handling for when we catch exceptions (either displaying the error message in dialog via setMessage() or by logging (in the case of unexpected things).I think that the fix is not sufficient because1.) When I change permissions and then press OK on the Property Page, I'm not informed that my change of properties didn't actually work. I'd like to see an error dialog in this case.2.) When I press Apply and it fails, the message on the Properties Dialog looks like a normal title and has no error indicator.3.) When I press Apply and it fails, the incorrect properties which I specified (but could not be set) are still displayed. The dialog should reset to the real properties of the remote file in that case.Reopening to address.Createdpatch for display error and resetting defaultsThis patch calls setErrorMessage() which prevents okay from closing the dialog and displays the message as an error. After that, I reset the values to the defaults. In order to remove the error and enable ok/apply, the user needs to change something though. Do you think something like this is okay?I find the patch's behavior very unintuitive, especially because I cannot switch to another property page; the dialog claims that it has "invalid values" which is not true, because it already shows the defaults again!I see two options for improving:(a) On error, set the Property Page's error message, but do not reset the flags to the defaults. That way, user can press the "Restore Defaults" button to clear the error and switch to other pages.(b) Instead of setErrorMessage, open a seaprate error dialog with the exception. This has the added advantage that a details message (which could contain more information from the file system why the command failed) is readable by the user. When user accepts the subdialog with OK, the properties are restored to defaults automatically so the dialog is "clean" again.I personally like (b) better because it's more intuitive to use. It also makes the selection listener unnecessary.(In reply to)For (b), are there any Eclipse best practices guidelines for error dialogs within dialogs?CreatedPatch fixing SSHHere is what I think is a correct patch for SSH -- It adds another sanity check in SshHostFile, to ensure that all "Rootfiles" actually have a "null" parentPath just as the IHostFile API requires it.But, with this patch, if I try to expand the "/" node on an SSH connection it runs into the IllegalArgumentException, because the FileServiceSubSystem tries to query the root with a parent path of "" -- which is different than null and seems odd:FileServiceSubSystem#updateRemoteFile(IRemoteFile, IHostFile, IProgressMonitor){ // now newHostParent file passed in so we'll assume it wasn't returned if (newHostParent == null){ String parentParentPath = parent.getParentPath(); if (parentParentPath == null){ parentParentPath = ""; //$NON-NLS-1$ } newHostParent = getFileService().getFile(parentParentPath, parent.getName(), monitor);}Why do you replace the (correct) "null" parentPath with an "" parentPath here? Does the SftpFileService need to be prepared for this, and automagically replace it back to a "", or is this a bug in the FileServiceSubSystem?Even if it may be incorrect, I'd be a little afraid of changing this in 3.0.1 since it might break clients who (incorrectly) don't like null parent paths in their input. What do you think?Don't know, but when you try switching to a different property page you get exactly such a dialog so it can't be that bad.Feel free to E-mail theif you want to know for sure, or look at their Wiki pages atMy personal opinion is: by pressing the "Apply" button you ask Eclipse to perform some work, and it's ok to get the result of such work in a subdialog ... just like when you press a "browse" or "Edit" button somewhere.FYI, when I'm in the Resource Perspective, select a file of a project (on windows) and right-click > properties; the Property page allows me to change the Read-Only flag.If I try that on a file where I removed all access permissions by means of NTFS Security, then I press apply, then the property page just silently resets its values to the defaults without showing me any error message.I personally don't like that because I'd like to know why it failed. I'm still more in favor of (b). But that's what Eclipse does. Most likely, because java.io.File.setReadOnly() doesn't return any error message or exception so they don't have anything to display. But we do.CreatedScreenshot of Windows Explorer PropertiesWindows Explorer also shows a subdialog with the error from its property page, see screenshot.(In reply to)I asked theBulk moving 3.2.x bugs to 3.3Bulk moving 3.3 deferred items to 3.3.1Clearing target milestone.I think the desired behavior would be (1) loading the real permissions as per, and (2) showing a message dialog with the error as per.	16.0
id=202439	REOPENED	PDT	Debugger	2.0.0	PC Windows XP	P2 minor	PHP Debug	2007-09-06 09:24 EDT by	Toshihiro Izumi	2012-01-02 04:30 EST (	6 users	'Change Value' on a variable in Expressions view causes nothing (in case of ZendDebugger).1. Create following PHP code.<?php$obj = array(1,2,array("a","b","c"));var_dump($obj);?>2. Debug as PHP Web Page with Zend + Break at First Line3. Select "$obj" and add watch.(rightclick->watch, show view->Expressions)4. Do StepOver. $obj appears in Expressions view.5. Change value $obj[0] ((int) 1) for example. The value won't be changed.6. Change value $obj[2][0] ((string:1) a) for example. The value won't be changed and value pane shows wrong(entered) value.In case of Xdebug, 'Change Value' causes error message-box. It says>	For xdebug, it would seem that xdebug refused the request to change the value from PDT. So this might be a feature of xdebug rather than a bug in PDT.DBGpVariable in Expressions View doesn't have fullname value even if it is a php variable.For xdebug, I have disabled the ability to change a value in an expression. It would only make sense if you were watching just a variable. The facility to change variable contents is available from the variables pane.This however doesn't apply to the zend debugger.Addressed in XDebugSame goes for the Zend debugger ,but we need to add a relevant message OR disable this action.Reproducible in PDT 2.0.0 as well using ZendDebuggerTested on Wix XPEclipse SDKVersion: 3.4.1Build id: M20080911-1700debugger - org.zend.php.debug_feature-I20081127pdt - N20081201dltk-core-sdk-I-I200811251145-200811251145-incubation[Kalin Yanev]Can't re-create.I go to Variables View, change value of $obj[0], press F8 - and I see new value in the Debug Output View.The value changed after F6 pressed. There is no changed after pressing OK on "Change Value" window.Still relevant.Reopening, moving to 2.2.0M1CreatedpatchThis patch can fix it in "Variables" view.But in "Expressions" view, I find it also can't refresh the value when I change it in JDT.So I think it's a bug of platform.	9.0
id=249422	REOPENED	PDT	PHP Explorer & Projects management	2.0.0	PC Windows XP	P2 minor	Roy Ganor	2008-10-01 21:00 EDT by	Toshihiro Izumi	2010-05-26 08:42 EDT (	1 user	Created.logSource Folder has context menu 'Configure Inclusion / Exclusion Filters', however this doesn't work.Steps to reproduce:1. Create PHP Project2. Add external source folder3. Right-click on the source folder (or source folder under 'PHP Language Library')4. Select 'Build Path'5. Select 'Configure Inclusion / Exclusion Filters' and click it=> Nothing happen.Extra:3. Right-click on the project4. Select 'Build Path'5. Select 'Configure Inclusion / Exclusion Filters' and click it=> This is OK. (dialog pops up)Versions:Eclipse SDK 3.4.1WST 3.0.2DLTK I200809251012PDT I20080924	Createdpatchfixed, Contributed by Zhao, Qiangsheng W and Xu.thanks!Context menu on the external source folder under the Include Path -> Build Path -> No actions available.Is it supposed to be like that?(works OK for source folders inside the project, not external)[Sylvia Tancheva -]	3.0
id=252363	REOPENED	PDT	Outline Views	2.0.0	PC Windows XP	P2 normal	PHP UI	2008-10-28 10:09 EDT by	Sylvia Tancheva	2010-08-02 05:38 EDT (	1 user	CreatedScreen-shot PDT 2.0Right-click a class in the PHP Project Outline view and see the context menu.It is more like PHP Explorer menu. Should be like in 1.0.3See the screen-shot	Hi,SilviyaIt seems this bug has been fixed already:)mark as fixedNo. There are still options like New, Import, Export, Include Path, Build Path, etc. ... things that are relevant to PHP Explorer and not to PHP Project Outline.The options should me more like in the Outline and not like in PHP Explorer.Reopening	3.0
id=311874	REOPENED	PDT	PHP Explorer & Projects management	unspecified	PC Windows XP	P2 normal	PHP UI	2010-05-06 09:10 EDT by	gossi	2016-03-02 10:29 EST (	4 users	Build Identifier: Eclipse: 20100218-1602, PDT (SDK): 2.1.1v20090707-1108, PDT: 2.1.3v20090914-1400 (Eclipse EPP PHP Package) AND Eclipse: 3.5.2, build: M20100211-1343, PDT (SDK): 2.1.1v20090707-1108, PDT: 2.1.3v20090914-1400Image the following project outline (just some top level folders):- src- js- templates- images- cssNow under src there are my php files. I added src to my "Source" Folders in the project properties.When I turn on the setting "group by namespaces", my top level representation changes to this:- namespace\one- namespace\two- namespace\tree- ...I can only access my php files, all others are hidden. Instead, please just group the namespaces, that are in a "Source" folder recognized by the project properties dialog. According to the example above, this would be:- src-- namespace\one-- namespace\two-- namespace\trhee- js- templates- images- cssSo I am able to access other files of my project, while I have a namespace concentrated view on my php files. At the moment, the "group by namespace" setting is totally unusable. Keep in mind, less projects are working with php files only.A little other thing: Wouldn't be the "package" icon more suitable, instead of the big, fat, green N which pulls every attention from the user, it could get, everytime? For me this would lead to a more consistent UI overall.Reproducible: Always	add something to here:"A little other thing: Wouldn't be the "package" icon more suitable, instead ofthe big, fat, green N which pulls every attention from the user, it could get,everytime? For me this would lead to a more consistent UI overall."... or probably the package icon with a "P" or a "P" with the package icon or any other combination. For the UI consistentency: other source editing plugins like Java or JavaScript also use the package icon, this is where my thought was coming from.Hi RoyCan you make decision for the "group by namespaces" structure and the namespace image?At the moment, the group by namespace option removes the source folder the project explorer and adds all found namespaces to the root level.I'd suggest a similar option as this is in java. Like grouping the namespaces under the source folders.Something like this:- source folder-- Name\space--- MyClass--- MyInterface-- Another\Name\Space--- MyClass--- MyInterface- source folder 2-- <global>--- getStuff()-- second\name\space--- MyClass- other- folders- in- my- projectI want refresh this task.I implemented grouping by source paths, to make "grouping by namespace" more usable for larger projects.But this function is still have some bugs:1. Resources are still hidden2. Namespaces doesn't refresh during developing3. Link to editor not workBesides, scrolling in explorer on large projects can be painfull ;)Due php dynamic nature, I think we should make PHP Explorer (and maybe project layout settings) more extendable.Example use cases/problems:* PSR-0 and PSR-4 grouping* Grouping per module for Symfony, Drupal, Kohana, Zend or Magento projects* Resources (html,css,yaml..) inside buildpathPHPExplorerContentProvider extension should:* Report grouping type (unknown, none, namespace or custom) on IContainer* Deliver custom elements, if any* Deliver label provider for custom elementsThoughts?Yes!I opened an issue for the composer-plugin lately:which actually refers to this bug ;)I think the biggest issue for PDT itself is the missing metadata, that plugins can provide.The other is a little more research on where and how a possible grouping can be done within the php explorer. Some frameworks (I think zend, however I never used and worked with it) has the application folder + some folders for models, views and controllers. Other frameworks have different folder structures. It would be great to give framework plugin authors a possibility to easily tweak the php explorer view and highlight them. Also what would be nice, is to say, ok this project is a symfony/zend whatever project (from a plugin perspective). Like a good way to extend php projects (maybe Facets is a solution, I don't know that technic well enough).Maybe discuss it at a larger scale? PDT/PEX mailing list - this is also where PDT plugin authors are.PEX mailing list can be used to send invitation to this bug.Each feature request could be helpful while developing api, I have experience only with several frameworks/systems.PHP-Fi memebers?From Symfony 2 side, we need ability to report bundles (modules) and resources (configs, doc, public, i18n, and more).I think its about finding general patterns that are used across different frameworks. Those that come to my mind:- Decorations: 'custom' folders and projects- Specific operations on these 'custom' folders and projects- Modifying source path entries in the php explorer ()- Tools-Support: Installed via Composer () or CLI respectively (Using Apache Commons to execute them, currently in PEX, I extracted them to- Specific PHP Project operations (decorations, tools)While a lot is already covered through eclipse APIs. PEX mailing list and PHP-FI are surely worth a try.I recently retried this in pdt 3.5 - I guess this can be closed? just by its original idea. However discussion led somewhere else towards the end.This is an old bug of mine which is fixed in recent PDT version. I'm happy to close this.It's still not fixed. Resources aren't hidden if are outside build, or are part of first level in build path.Example:app/src/ AppBundle/ Controller/ Resources/If you set buildpath to src/, resources from src/AppBundle/Resources aren't available.Awww, what a pity. I reopened this one.Maybe I also found another one, which kinda is related.Example:src/res/tests/ fixtures/ FooBar.php ControllerTest.phpIf group by namespaces is on, even stuff in tests/fixtures/ is shown, which basically is totally unrelated to my code. Maybe there should be something like exceptions on source folders, which are both automatically detected but also manually selectable?	11.0
id=279070	REOPENED	PDT	Editor	unspecified	Macintosh Mac OS X - Carbon (unsup.)	P2 normal	PHP UI	2009-06-04 04:40 EDT by	John Smith	2010-10-05 17:24 EDT (	3 users	I've created some additional php filetypes, when I add task tags in files of these types they aren't recognised as task tags.	Can not be reproduced.Do you associate the file name/extention with the PHP Content Type?If you can reproduce this bug ,please reopen it.After more investigation about this issue found the following:- If extension is added before file import - Task tags are defined like expected- If add extension after you already imported to project - It is necessary to close and after that open again project and after that to put task tags- See and some strange behavior - at some times and close/open project did not help to be recognized after adding it at PHP Content Type after import file to project - only icon at PHP Explorer is changed, but no functional working.General decisions is to Restart PDT and after that everything is working like expected(In reply to)Posted by Teodor KirkovI think this bug is not pdt special.After I debug deep into the code,I think one reason cause this is after you add the file extension to the php content type,and then IFile.getContentDescription() return null,but I think IFile.getContentDescription() should not return null.I will create a bug for eclipse platform.What's the status on this bug?I'm having the same issue on helios + pdt 2.2 on Linux 64 bits.Somehow I can't get .module files to be parsed for task tags, only .inc files are processed (don't have many .php files).File extension is associated with php content type via the Drupal plugin ().Closing/Opening project does not do anything.Closing all projects and restarting eclipse does not help either.Previous comment seems to indicate an eclipse bug to be reported.Has it been reported and can we link to it?BTW, this bug seems to be a duplicate of(In reply to)False alert: the Drupal plugin does not add new PHP file extensions but rathernew types of PHP content.Manual association of *.module file with PHP content type make tasks appear intask view.Going to the General->Editors->Structured Text Editors->Task Tags preference page and clicking on the "Clean and redetect Tasks" button should already handle this.	7.0
id=333322	REOPENED	PDT	Editor	2.2.1	PC Windows XP	P2 normal	PHP UI	2010-12-29 19:59 EST by	Toshihiro Izumi	2016-05-02 10:53 EDT (	3 users	'Deprecated members' for exampleSteps to reproduce:1. Reset syntax coloring (Restore Defaults)2. Edit php script as|<?php|/**| * @deprecated| */|class Foo {}|?>(now you can see "Foo" with strikethrough)3. Open Preferences>PHP>Editor>Syntax Coloring4. Enable 'Classes' (select 'Classes' and check 'Enable')5. Check 'Bold'6. Click 'OK' to close preference=> Now you can see "Foo" in bold, not with strikethrough [NG]7. Delete "@deprecated"8. Undo delete=> Now you can see "Foo" with strikethrough [OK]9. Edit script as|class Foo {-}10. Undo edit (revert to "class Foo {}")=> Now you can see "Foo" in bold, not with strikethrough [NG]	The main reason is...1. "Foo" has "Classes" and "Deprecated members" highlightings.2. org.eclipse.wst.sse.ui.internal.style.SemanticHighlightingReconciler ignores existed same highlighting.step2 above, Foo has [Deprecated] => Deprecatedstep6, Foo has [Classes]+[Deprecated(=previous Deprecated)] => reconciler rejects [Deprecated] because same one existed => Classesstep8, Foo has [Classes(!=previous Classes)]+[Deprecated] => Deprecatedstep10, Foo has [Classes]+[Deprecated(=previous Deprecated)] => reconciler rejects [Deprecated] because same one existed => ClassesWorkaround?org.eclipse.wst.sse.ui.internal.style.SemanticHighlightingReconciler.addPosition(Position, HighlightingStyle, boolean) private void addPosition(Position position, HighlightingStyle highlighting, boolean isReadOnly) { boolean isExisting = false; // TODO: use binary search/* delete loop since this doesn't care priority of multi highlightings */// for (int i = 0, n = fRemovedPositions.size(); i < n; i++) {// HighlightedPosition highlightedPosition = (HighlightedPosition) fRemovedPositions.get(i);// if (highlightedPosition == null)// continue;// if (highlightedPosition.isEqual(position, highlighting)) {// isExisting = true;// fRemovedPositions.set(i, null);// fNOfRemovedPositions--;// break;// }// } if (!isExisting) { fAddedPositions.add(fJobPresenter.createHighlightedPosition(position, highlighting, isReadOnly)); } }This was fixed in latest SSE (luna release):I can still reproduce the last case (points 9 and 10):9. Edit script as|class Foo {-}10. Undo edit (revert to "class Foo {}")=> Now you can see "Foo" in bold, not with strikethrough [NG]I need do close-reopen the file to see it back with strikethrough (nightly from 27.05.2015). Reopening the bugNew Gerrit change created:Gerrit changewas merged to [master].Commit:Merged patchcorrects only a part of the problem, this bug report also depends onand can be closed once patch fromwas merged.Thierry.	6.0
id=250559	REOPENED	PDT	Code Assist	2.0.0	Other All	P2 major	Michael Spector	2008-10-12 09:19 EDT by	Gadi Goldbarg	2016-06-16 03:11 EDT (	3 users	When we open the Type Hierarchy view we see text explaining that we can D&D elements. it is not functional	***has been marked as a duplicate of this bug. ******has been marked as a duplicate of this bug. ***It seems that we could not D&D elements.Right?I don't see any D&D text in Type Hierarchy view. Probably it was related to old implementation.CreatedScreenshotMichal, I attach a screenshot of the mentioned text. It can be seen when you open the view prior to selecting any type to be shown.Let me know what we should do	6.0
id=336647	REOPENED	PDT	Editor	unspecified	PC Windows XP	P2 normal	PHP UI	2011-02-08 14:59 EST by	Jens G	2012-04-06 18:34 EDT (	4 users	Build Identifier: 20100917-0705 (PDT 2.2.1.v20101001-2300-53184QAN4JBQgLYPWMLcXn6Na9Od)Insert Spaces for Tabs should calculate the number of spaces to the next tab column and only insert that amount. But the PHP Editor doesn't wants to and is always inserting, as in my case, 4 spaces.Reproducible: AlwaysSteps to Reproduce:1. Configure PHP Code Style Formatter to Tab Policy = Spaces2. Try to e.g. align some assignments, using tab key	Voted for this bug. It seems that PDT formatter calculates the number of spaces to the next tab only for intendation (from begining of line), but not inside the line (e.g. in array('a'=>[TAB]'b') the [TAB] will always constantly). It would be more useful to calculate the number of spaces to the next tab always in any place of line.It seems the plugin fromfixes this problem completely, it would by nice to embed that plugin as oficial fix to the next PDT update. Thanksduplicate of 326250*** This bug has been marked as a duplicate of***Verified.I don't see how this may be a duplicate of #326250, but maybe an internal technical relationship.Nevertheless, THIS bug still occurs in the current (I guess it's a release) version (3.0.2.v2011102768).Perhaps this was misconception. I meant the number of spaces, that is inserted when pressing the tab key, is constant. There is no tab character inserted, as described in the other bug.Hi Jens,I do not understand you,can you show some examples?With pleasure :)Code before trying to align with tab key:<?phpclass NewTestClass{ public function __construct() { // real tab position before // $letsSee = 'some string'; $dfgd = 'another string'; }}?>Code after:<?phpclass NewTestClass{ public function __construct() { // real tab position before // $letsSee = 'some string'; $dfgd = 'another string'; }}?>You see, the tab position is completely ignored, the editor just inserts 4 spaces.I have used last PDT 3.0.2 and can confirm that this problem still exists and I continue using 3th party plugin as I wrote before.CreatedAdds logic for calculating the indent size, for spaces, so that the "tab" visually lines up with the literal tab character.	9.0
id=409587	REOPENED	PTP	RDT.sync	7.0	PC All	P2 major	Project Inbox	2013-05-31 09:28 EDT by	Brian Watt	2013-06-07 10:07 EDT (	4 users	On the latest Kepler Master branch. Client: Red Hat Enterprise Linux Server release 6.2 (Santiago)Server: Red Hat Enterprise Linux Server release 6.4 (Santiago)1. I created a new synchronized project to a hello_world program.2. When the creation was finished I noticed that the C/C++ Indexer was running in the message area at the bottom right corner of the screen.3. So I opened the progress view and was surprised to see the C/C++ Indexer running constantly and the "Discover compiler built-in language setting (waiting)" occurring over and over and over. See attached image. For the next 5+ minutes as I entered this bug it has not stopped, but continues to span new ones.	CreatedImage showing Porgress view with C/C++ Indexer running over and overNote: If I try stopping [red square on right] the various tasks then new ones appear and take their place. I cannot ever get it to purge all of these tasks and quiesce. I consider this an important error to fix.Second Note: If I then try to do a clean or a build, the Clean or Build task takes a long time to complete because it is Build Project (Blocked: The user operation is waiting for "Discover compiler built-in language settings" to complete)Maybe related the log has:!ENTRY org.eclipse.cdt.managedbuilder.core 4 0 2013-05-31 08:34:39.678!MESSAGE Problem running CDT Scanner Discovery provider org.eclipse.ptp.rdt.sync.core.SyncGCCBuiltinSpecsDetector!SUBENTRY 1 org.eclipse.cdt.managedbuilder.core 4 4 2013-05-31 08:34:39.679!MESSAGE Error running Builtin Specs Detector!STACK 0java.lang.NullPointerException at org.eclipse.ptp.internal.remote.remotetools.core.RemoteToolsFileStore.getExecutionManager(RemoteToolsFileStore.java:455) at org.eclipse.ptp.internal.remote.remotetools.core.RemoteToolsFileStore.getRemoteItem(RemoteToolsFileStore.java:499) at org.eclipse.ptp.internal.remote.remotetools.core.RemoteToolsFileStore.fetchInfo(RemoteToolsFileStore.java:184) at org.eclipse.core.filesystem.provider.FileStore.fetchInfo(FileStore.java:280) at org.eclipse.ptp.internal.rdt.sync.cdt.core.SyncGCCBuiltinSpecsDetector.getSpecFile(SyncGCCBuiltinSpecsDetector.java:277) at org.eclipse.cdt.managedbuilder.language.settings.providers.AbstractBuiltinSpecsDetector.resolveCommand(AbstractBuiltinSpecsDetector.java:306) at org.eclipse.cdt.managedbuilder.language.settings.providers.AbstractBuiltinSpecsDetector.startupForLanguage(AbstractBuiltinSpecsDetector.java:543) at org.eclipse.cdt.managedbuilder.language.settings.providers.AbstractBuiltinSpecsDetector.runForEachLanguage(AbstractBuiltinSpecsDetector.java:495) at org.eclipse.cdt.managedbuilder.language.settings.providers.AbstractBuiltinSpecsDetector$1.runInWorkspace(AbstractBuiltinSpecsDetector.java:430) at org.eclipse.core.internal.resources.InternalWorkspaceJob.run(InternalWorkspaceJob.java:38) at org.eclipse.core.internal.jobs.Worker.run(Worker.java:53)The above may occur because I was banging cancel/stop numerous times on various tasks and they were shutting-down/stopping at weird places. If I stop Eclipse and restart it NO back traces are present until I start canceling/stopping the tasks. When the back traces occur they can be other failures than NPE.CreatedImage showing Progress view when submitting a job while C/C++ Indexer running over and overSet Importance to P2 majorGoing into Window > Preferences > C/C++ > Indexer I get "Could not Accept Changes: The currently displayed page contains invalid values". If I press OK and then reattempt to select Indexer now I get the Indexer Preference page with nothing set (no checkboxes checked, no indexer choice selected). If I press OK the Indexer task stops running. Now only the "Discover compiler build-in language settings" task is running over and over.CreatedImage of Progress view after Indexer is stoppedHow many other projects do you have in your workspace? Last night I fixed, so that the sync scanner discovery now runs. So it could be that it is running discovery on all of your projects because it detects that none of them have yet been run. The C/C++ indexing also takes a long time, even on small projects, which would explain the backup of tasks.One project, the hello world one with hello_world.c of 5 lines.Just deleted the workspace (runtime-Eclipse) and restarted Eclipse. Created the hello_world synchronized project again afresh and the C/C++ Indexer & Discover scanner started again running over and over.What is weird is that the Indexer is grossly misstating things like "Indexing: 334/341 sources, 22 headers: parsing hello_world.c (/test_hello_world_Linux_x86_64)" and the hello_world.c program consists of:/* * hello_world.c * * Created on: May 8, 2013 * Author: bwatt */#include <stdio.h>#include <unistd.h>int main(int argc, char **argv) { char name[256] = ""; gethostname(name, 256); printf("Hello World from %s!\n", name); sleep(600); return 0;}Definitely seeing"However, removing this causes the scanner discovery/indexer to get into an infinite loop."For me the sync discovery doesn't run at all when the project is created. I have to invoke it manually as described in. Then it runs once followed by the indexing. How exactly are you creating the project? What project type and toolchains do you select and what files, if any, are on the remote? Also, what version of CDT are you using?(In reply to)How exactly are you creating the project? Right click on Project Explorer area > "New" > "Synchronized C/C++ Project". Enter project name: "test_hello_world_Linux_x86_64".Under "Remote directory" "Connection name": select "k7.pok.ibm.com" from list or create it "New" if connection doesn't exist. Under "Remote directory" "Remote directory": select "Browse" and find "/home/bwatt/test_client/remote_projects_linux/test_hello_world_Linux_x86_64". The remote system contains all the files: hello_world.c and Makefile. If already built it also contains hello_world.o and hello_world executable.Under "Project Type" expand "Makefile project" and select "Empty Project".Under "Remote Toolchain (select 1 or more)" select "Linux GCC".Do not select a "Local Toolchain"Press "Finish"Also, what version of CDT are you using?Eclipse C/C++ Development Tools SDK Version: 8.2.0.201305061014I haven't tried this out, but I noticed on the last page of the project creation there are some sync setting dropdown menus with nothing selected by default. Could this be causing an issue?Again deleted the workspace (runtime-Eclipse) and restarted Eclipse. Created the hello_world synchronized project again afresh, but this time WITHOUT specifying any "Remote Toolchain (select 1 or more)". And the Indexer/Discovery Scanner are NOT running over and over. So I can make progress this is a workaround I'll use for the time being until this is fixed.(In reply to)I don't think so, because those settings only affect which build configuration is selected, and in this case there is only one.I'm seeing a similar issue. I would expect there to be a significant number of header files processed, since system headers include other headers, etc. However, I left the indexing running for a couple of hours, and it is now up to over 9,500 source files and 2,500 headers while indexing shallow/main.c. It does appear that there is some kind of looping problems.I added a lock to prevent multiple threads from running scanner discovery at the same time. Please test and see if this helps.So I pulled the latest master code, and then I followed the aforementioned scenario after deleting the project from my workspace. The behavior is no different. That is, the C/C++ Indexer begins to run. Over time the Indexing of the sources starts at 0/3 and progress over several minutes to about 360/367 (numbers not exact). Then it resets back to zero and starts all over again. Another time it went even longer and got over 1000/1008 before I finally gave up and stopped Eclipse.To make sure I have pulled the latest master code to test please tell me the plugin that was affect by your latest change so I can verify that the change in the the history.Yes, the behavior is still the same for me.For the org.eclipse.ptp.rdt.sync.cdt.ui the last change I see is:commit 62692b3596547594489e95eef1ba4a10691ce789Author: John Eblen <> 2013-05-30 18:47:55Committer: John Eblen <> 2013-05-30 21:07:40Parent: c40f9df113d0c2b8a34e548e290728425c52938a (- Without toolchain selection, New Sync project gives NPE)Branches: master, origin/master- Sync GCC Builtin Compiler Settings not workingAlso includes improvements to sync scanner discovery:1) Do not sync before or after discovering built-in compiler settings2) Do not share providers between projectsOK, I see it, for org.eclipse.rdt.sync.cdt.core, I seecommit 3980a80c249e726acd14b5fb22105bdba330b373Author: John Eblen <> 2013-05-31 13:59:18Committer: John Eblen <> 2013-05-31 14:07:22Parent: 62692b3596547594489e95eef1ba4a10691ce789 (- Sync GCC Builtin Compiler Settings not working)Branches: master, origin/masterAdd lock to prevent multiple sync scanner discovery jobs running atthe same time. See bugs 409479, 409587, and 409609.Yes, that is the commit. I think there are two issues: the runaway indexing and the constant adding of new discovery jobs. This commit targets the latter problem. Do you still see lots of discovery jobs in the queue? If so, are there fewer now than before? Unfortunately, I'm not able to reproduce the problem, so I can't see the results for myself.(In reply to)John, I have not been focusing on the discovery jobs, so I cannot reply to your question since I don't know if there are more or less now. Sorry.(In reply to)In earlier comments you said that the long list of discovery jobs, which queue behind the indexing job, kept regenerating and that you were unable to purge all of the jobs (). Does that still occur? My hope is that now there is only one discovery job or at least a finite number, say 7 or 8, and that they do not continually regenerate.(In reply to)So here is what I see now. 1. The indexer task is running 48/51 sources...51/54 sources...54/47 sources...2. There are N discovery task beneath the indexer. Where N is upwards to 10-15 of them (see)3. Over time the discovery tasks complete. 4. When all discovery tasks complete the indexer is reset to 0/0 sources and N more discovery tasks are created where might be more this time, and the whole things starts over again.I'd be more than willing to call you and also set up a web conference so you can watch it.CreatedImage of Progress View with recently regenerated discover tasksI see similar behavior to Brian. I created a new workspace, then a new synchronized C/C++ project using a remote project that already existed.1. It looks like the indexer may have started before the synchronization was completed. Not sure if this has any effect.2. I see the indexed job, then about 10 Discover jobs. Each Discover job completes in turn until they are all done, then another 10 or so appear.3. The indexer says Indexing: 0/10 sources, then by the time the 10 jobs are done it says something like 4/10 sources. When the second lot of 10 jobs are done, it is now indexing 15/29 sources.4. The number of sources just keeps increasing. For interest, I let it run all day over the weekend and it got to about 60,000 sources indexed before running out of heap space.I can refer toand. If somebody can provide reduced reproducible example, I would take a look at looping from CDT side.Also,might be of interest.BTW, I am running Eclipse C/C++ Development Tools Version: 8.2.0.201305291013John, I wonder if we should revert this change? Sync projects kill my whole workspace currently.Workaround: Created the synchronized project, but WITHOUT specifying any "Remote Toolchain (select 1 or more)". As a result the Indexer/Discovery Scanner DO NOT run over and over.(In reply to)I presume this is because the remote build configuration is not created, so no scanner discover is run. I guess the other workaround is to manually disable the Sync scanner discovery provider in the Preprocessor Include Paths property page.(In reply to)No, a remote toolchain is still created. The sync scanner discovery is only added when the toolchain contains the GCC scanner discovery (the latter is removed). So any non-GCC toolchain will not have the sync scanner discovery.(In reply to)Yes, if we are unable to fix this problem. Fortunately, it should be easy to alter the code to simply not add the sync scanner discovery, no need to revert commits, and it would still be available for the user to add after the project is created.Will you do this for RC3? It needs to be done today if possible.Okay, sync scanner discovery providers are no longer enabled by default.Just pulled down the latest code, created a new synchronized project to a hello_world program, and specified Under "Project Type" expand "Makefile project" and select "Empty Project" along with under "Remote Toolchain (select 1 or more)" select "Linux GCC". I am no longer seeing the C/C++ Indexer running constantly and the "Discover compiler built-in language setting (waiting)" occurring over and over and over. All fixed. Closing.Brian, I'd like to keep this open. John has just changed the sync config so that the sync scanner discovery is not enabled by default. This should be enabled by default, so the root cause of the problem still needs to be determined.Greg, sure, that's your choice. I just wanted to properly respond the immediate comment and issue versus your desire to later address the greater problem. So that's fine by me.	44.0
id=271071	REOPENED	PDT	Debugger	2.0.0	Macintosh Mac OS X - Carbon (unsup.)	P2 normal	Michael Spector	2009-04-02 21:29 EDT by	Jacob Weber	2013-02-28 13:10 EST (	17 users	At seemingly random times, I get an alert saying "Incompatible debugger version. The remote debugger version might not match the expected protocol version (2006040705)."The thing is, I haven't tried to launch the PHP debugger. In fact, I sometimes get this message when I'm not doing anything at all with Eclipse.For what it's worth, I have the debugger set to Xdebug, port 9000. I don't have any PHP servers configured, other than the default one. I'm using Eclipse 3.4.2 and Mac OS 10.5.6.	I would think this is the zend debug component in PDT that is reporting this. This will be listening by default on port 10000, maybe something on your network is connecting to the zend debug port and trying to pass unexected data ?I don't think anything's connecting to port 10000, but now that you mention it, I do have something else listening on port 9000, which is what xdebug is set to. That's probably what caused it.Actually, you were right. It was the usual random people trying to hack in to my machine. If I telnet to localhost:10000, I get the error in Eclipse. I guess there's no way to prevent it.I'm reopening this issue - we should be able to detect this case somehow.I set my debugger from Zend Debugger to XDebug and telneting to 10000 still pops up the error. (Sometimes it pops up in a modal window behind the main window, which can be frustrating to figure out.) I would like to disable Zend completely but there appears to be no way to do that. Can it be made to stop listening for the Zend Debugger when XDebug is chosen as the debugger?Could it have the option that XDebug does to control JIT debugging? (i.e. to disable listening when not in debugger)I would also like to see this issue resolved. My company runs vulnerability scans very frequently against computers on the network, which are scanning all open ports. This scan causes the "Incompatible debugger version" error message to popup several times a day. Is there anyway the debugger can be disabled so it isn't actively listening on any ports?I would also like to request that there be a way to turn off whatever is listening on port 10000. If nothing else, just log the error to the eclipse error log rather than popping up a dialog. Thanks.I agree with Hal, when not actually attempting to use the debugger, just a one-time log would be sufficient.When this issue occurs for me, which is quite random, it renders Eclipse unusable do to a continuous stream of these popups that I can barely keep up with (which gives me flashbacks of the old days with IE).I downloaded Eclipse for the first time yesterday and everything was working normally. Today when I started it up, I was experiencing this bug. It happened consistently about 10-12 tries of restarting Eclipse. Based on the comments here, I simply disconnected my computer's ethernet cable to see if the problem went away; it didn't. So, I opened up TCPView (from sysinternals) to watch for other traffic on the debugger's ports and this seemed to make the bug go away. (Additionally, there was no other traffic on those ports).One point I noticed that may be relevant is that my cursor was in a variable name when the program last exited (thus highlighting all other uses of the variable). After opening TCPView, this condition didn't cause the bug to return.Note that I don't have to keep TCPView open to keep the bug away - it seemed to "magically" fix it by running once, somehow.CreatedScreen shot of the popped up dialog. This is the screen shot of the 15 dialogs which popped up during the weekend when I was away from the machine. Eclipse was running. ThankssguhaRed Hat Enterprise Linux Server release 5.1 (Tikanga)uname -aLinux XXXXXXXX 2.6.18-92.1.18.el5 #1 SMP Wed Nov 5 09:00:19 EST 2008 x86_64 x86_64 x86_64 GNU/LinuxOver the weekend it popped up 15 error dialogs, screen shots are attached. Also attaching eclipse configuration dump and error log. ThankssguhaCreatedError log obtained from Configuration tab (View Error Log button) of installation detailsError log obtained from "Configuration" tab (View Error Log button) of "Eclipse platform installation details" dialog.sguhaCreatedConfiguration details of Eclipse 3.5 on Linux 64, RHEL 5.1Configuration details of Eclipse 3.5 on LinuxI am using Eclipse on windows where this popup keeps coming up regularly. I have changed the port for PHP debug and so far have not got this error message...The bug seems to fix itself when you close ALL projects in the workspace and then reopen whichever you need.I do not know whether to add this here or create a new bug, however.....I am running Eclipse on an XP machine with XAMPP installed, I get the pop-up every 30 seconds when I am running IE6 simultaneously. Now, please don't tell me that my two main problems are XP and IE as I know that, however this is the corporate environment and the 'preferred' browser. This bug is rendering Eclipse useless as there is not much you can do in 30 seconds before the next pop-up appears and requires attention. I made the mistake of going to lunch with both apps running. It took 15 minutes to clear the pop-ups. If I could simply leave the pops in the background and get on with working, I could almost live with that, but you must attend to the warning before you can continue work. And as IE is the nastiest browser to work with, I tend to like testing each block as I get it running.Help, advice or a new MacBook Pro 15 inch would be appreciated.Chris HFYI - I stopped this reoccurring error message by closing IE 8 on my machine. Pretty sure IE doesn't like being in the same playground.Hi! I just had this exact same problem, and finally found the cause: i had recently installed µtorrent, which installed its own toolbar in firefox without my knowledge. As soon as i removed that toolbar, the problem was GONE!I got same problem when I installed BitTorrent and it automatically attached BitTorrent toolbar to my Chrome and FireFox browsers. Removed the BitTorrent toolbar and restart the browsers fixed it.***has been marked as a duplicate of this bug. ***Thanks , The problem is with IE , when its closed , the nasty popup dissapeared.	21.0
id=59041	REOPENED	CDT	cdt-core	2.0	PC Windows 2000	P3 normal	Alex Chapiro	2004-04-19 05:25 EDT by	Klaus Falser	2007-02-14 15:59 EST (	2 users	I need to build my C project with rather old command line tools (DOS).Together with a make and the cygwin environment this worked very fine.Using the last eclipse M8 and cdt M8 it still works, but the compiling is maybe 100 times slower. From the Task Manager one can see that the NTVDM process consumes nearly 99 % of the processor time.Did something change in the invocation of the make command? Thanks Klaus	Tried to replace "Starter.exe" and "spawner.dll" with old versions from branchcdt_1_0_1, and it improved the situation greatly.From the task manager it can be seen that the NTVDM box, where the DOS commandsare run, consumes nearly 100% processing power, but the DOS command itself workvery slowly. From the sources I have seen that in the reading function read0(), used formonitoring the output of the compilation process, some event handling wasadded. Could it be that NTVDM spends lot of time sending events instead of doing something usefull?Regards Klaus FalserPR was not targeted to any particular release. Changing target milestone to 2.1We've improve this, please reopen if the performance is not satisfactory.I checked this with CDT 2.1 RC2 and the build process is still 10-20 timesfaster when I replace "Starter.exe" and "spawner.dll" with their old versionsfrom branchcdt_1_0_1.KlausAlex can you take a look at this numbers10-20 times is a lot, did we miss something ?Actually, during build spawner launches make just once, so even it does it tooslow, it should not impacts overall time. So the only suspicious place is Read(particulary open/close event handle). But I cannot reproduce it so far. Itested it on Windows XP machine, 2.8g with 512m RAM. My project consisted of 66C++ files. I ran full rebuild using CDT2.1 spawner, CDT 1.0.1 spawner and nospawner at all. Rsults are the same - 45c. Any idea how to reproduce it would beapreciated.CreatedCompiler + C files for showing problemIn the attached ZIP-File there are 3 directories. In the directory TestCasePerformance there is a C-File and needed headerfiles,as a makefile and a BAT-File.The build does nothing else then to compile the same C-file 7 times.I'm normally using the cygwin environment, but by building using the BAT-Fileone can see the same performance penalty.In the directory Compiler is the DOS-based compiler and in the directory"Starter" are the versions of "Starter.exe" and "spawner.dll" from CDT 1.0 which enhanceperformance greatly.On my system, which is a german XP SP2, xeon 1.4GHz, the build needs 115 secwith the original "Starter.exe" and 5 sec with the old ones.I hope this helps to reproduce the phenomina.RegardsKlausFor your example event handle open/close operations are not a good explanationbecause there is almost no output to stdout/stderr. The worst thing is that Icannot reproduce the problem on your test case as well. In all configurations(old spawner, new spawner, no spawner, run as a batch file) I've got one and thesame number - 3c. Could it be a problem of your Windows installation? Did youtry to build this project on other computers?I would also appreciate if somebody else tries this test case for examle in twoconfigurations: new spawner or no spawner.After playing with this with 3 machines(XP) we could repoduce it on 1/3, the others seems to be fine. It seems related to the factyou compile is a DOS application, as you pointed out.Try to reduce you PATH environment variable length, according toa some feedback we got from MS database, that may help !!!I'm moving this 3.0 milestone, we can not delay CDT-2.1 because only of this.Please let me know if reducing the length of the PATH variable didhave an effect.No, sorry.Shortening the path variable to < 100 char had no effect, but deletingspawner.dll had.At this point it is not clear for me why spawner.dll is needed, but a bug data base is probabely not the right place to discuss this.I could live with this bug (??) without problems, if I can always work around by either replacing spawner.dll and starter.exe with there older versionsor by deleting spawner.dll completly. For me, the bug can be closed.Alex any progress on this, if not please mark as fix or move it to futureCannot reproduce it any more.I'm seeing this bug with Eclipse 3.2RC7 and CDT 3.1.0.200605290500, on Windows XP SP2. Filemon fromshows NTVDM spending most of its time reading from \\.\Pipe\stdin<long number> and getting a PIPE DISCONNECTED error, over and over. Using Process Explorer, I see that both ntvdm.exe and Eclipse's javaw.exe have the stdout and stderr named pipes open, but only ntvdm.exe has stdin open.This would seem to be a bug in NTVDM, but it's one that CDT will have to work around. Is there any way to pass a handle to NUL instead of a closed pipe, or to leave the stdin pipe open until the program is finished?My workaround for now is to change the build command to: ${env_var:COMSPEC} /c start /min /wait redir -o build.log -eo maketo run the build in a new console window, which runs much faster.To #13Could you please send an example. I understand what you mean and I believe that it can be fixed easily, but I need to method how to reproduce the problem (i don't have any doubt that this problem exist, but so far I was unsuccessful to reproduce it).I get this with any C or C++ program compiled on my PC using DJGPP from. I have this installed in the normal location, C:\DJGPP\. My PC used to be running Windows 2000 SP4, but it has been upgraded to Windows XP SP2 with all current fixes.If it makes any difference, I'm running Norton Antivirus. I also have VMware Server installed.My testing has been with a simple Hello world: #include <stdio.h> int main() { puts("Hello, world!"); return 0; }and a corresponding Makefile.I'll attach the saved File Monitor log files, although it appears to get swamped by the broken pipe errors. The faster build was generated with this build command: ${env_var:comspec} /c < nul make -kCreatedSysinternals File Monitor output of fast and slow DOS buildsCreatedPatch that fix the problemUsing DJGPP I easyly reproduced the problem. Great thanks for cooperation.I have the last version of the CDT 3.1.1.200609270800 installed and there seems to be no improvement.I still have to replace spawner.dll and starter.exe with the older versions.RegardsKlausSetting back to '--' until we get it re-triaged.	19.0
id=99133	REOPENED	AJDT	Core	1.2.0 RC2	PC Windows XP	P3 normal	AJDT-inbox	2005-06-09 07:49 EDT by	Andrew Clement	2010-04-28 19:20 EDT (	0 users	RC2 has a problem in that it sometimes doesnt build depending projects when youmake a change to a project. If B depends on A, and you make a change to A suchthat B should notice, B was not being built - this is due to incorrect deltaprocessing in AJBuilder.build() when building B.	Fix is to the delta processing - when building project B we should look at thedelta for B *and* the delta for A - if there was a source code change in A weshould call the compiler for B.Also improved the logic that examines deltas to avoid processing unnecessarychanges in the 'bin' folder of a project.Tests for this bug can now be found in org.eclipse.ajdt.core.tests.Test.These have been put both into the AJDT1.2 and AJDT 1.3 streams.Reopenning this bug because with the latest changes to incremental compilation, the tests related to this bug are failing.Actually, can't reopen. Maybe someone else can.Createdpatch that fixes the failing testsThe tests were failing because the timestamp of the last change of an aspect and the timestamp of last build of a project that depends on the aspect were too close together.AjState assumes that if timestamps of a class file and the last build timestamp of a project that depends on it are within 1 second (ie- the class file was touched up to 1 second *before* the build completed), then the class file is considered to have changed since the last build.Now that we are able to complete builds faster, successive builds of dependent projects may run into this limit.In these tests, I have added a one second delay between the creation of the first and second projects. In the real world, this may happen sporadically and may be difficult to track down.All this would mean is that there will be some full builds occurring when there doesn't need to be.Will open an AspectJ bug to track this.patch from c5 applied - tests reactivatedstill work to doNo longer slated for the next release.	8.0
id=316847	REOPENED	AJDT	UI	unspecified	Macintosh Mac OS X - Carbon (unsup.)	P3 normal	AJDT-inbox	2010-06-14 23:25 EDT by	Andrew Eisenberg	2010-12-08 19:59 EST (	0 users	It should be possible to create a new aspect type from within the pull out refactoring wizard. Exactly how this mechanism should work is still open for discussion in my mind.	Now available.Reopenning. Not working yet.	2.0
id=275180	REOPENED	AJDT	UI	1.6.3	PC Windows XP	P3 minor	AJDT-inbox	2009-05-06 12:48 EDT by	Kendall	2010-04-28 19:20 EDT (	1 user	An aspect, Bar.aj, created with only the following code fails to build in eclipse.public aspect Bar { private static final String junk = "...."}There is no error reported, and any other code added to the aspect, no matter how correct, does not get applied. However, there is no indication in the problems view or the editor that anything has gone wrong. This is most annoying, as this can be missed in a quick search of a larger file.	From my message on the mailing list:It almost sounds like the compiler isn't running.Are you seeing this for full builds or incremental only?When you open the AJDT Event trace view (and select all filters) and make an edit/save in the file, what do you see?I have just tried this in my own workspace and I am seeing the expected syntax error in the editor and problems view. So, I think something else is going on.A couple of more questions:Is Bar.aj the only source file in the project?You also might want to update to the latest dev version. We have fixed quite a few bugs since 1.6.3. This may be one of them.Yes, this is the only file in the project. However, this happened with a larger file in a larger project as well.I posted build logs on the mailing list, but for reference:Making a change and doing a build, I get the following in my log:9:58:0 Preparing for build: planning to be an incremental build9:58:0 Starting incremental compilation loop 1 of possibly 59:58:0 AJC: compiling source files9:58:0 Timer event: 109ms: Time to first compiled message9:58:0 AJC: compiled: C:\kmerrima\Java_Dev\Java\AspectBreak\src\Bar.aj9:58:0 AspectJ reports build successful, build was: INCREMENTAL9:58:0 AJDE Callback: finish. Was full build: falseCleaning the project and doing a build, I get this:9:59:52 Preparing for build: not going to be incremental because nosuccessful previous full build9:59:52 AJC: compiling source files9:59:52 Timer event: 110ms: Time to first compiled message9:59:52 AJC: compiled: C:\kmerrima\Java_Dev\Java\AspectBreak\src\Bar.aj9:59:52 AspectJ reports build successful, build was: FULL9:59:52 AJDE Callback: finish. Was full build: trueUnfortunately, I can't update to the latest release version, due to a regression bug in that one. As for the dev version, that could be possible. I'll try it later today, hopefully.(In reply to)Please describe the regression.(In reply to)It is a regression that is fixed in dev, related to an exception when there are multiple projects that have the same classpath.(In reply to)Is there a bug open for this? I am not aware of fixing this problem.(In reply to)Apparently, I'm crazy, as no one else here can reproduce this either. I still think there is something wrong, but until I can reproduce it consistently on machines other then my own, I guess this issue can be closed. I'll reopen it if I can get it to happen more consistently.Ok, I found out that the bug happens only when jdt weaving is disabled. If you want to reopen the bug, it is still a bug.Reopening bug, but marking as low severity because we recommend running with the weaving service enabled.No longer slated for the next release.	11.0
id=163233	REOPENED	AJDT	Core	1.4.0	PC Windows XP	P3 enhancement	AJDT-inbox	2006-11-02 11:33 EST by	Wolfgang Frech	2010-12-08 19:59 EST (	2 users	It is possible to compile an aspect in an aj-sourcefile with a "wrong" package directive with respect to the file's position within the source folder root.A java source file with a "wrong" package directive is flagged by the JDT.Example (short)// file A.aj in package/folder src/abc where src is a source folder. package abc.test;aspect X {}This compiles, and the aspect can be referenced by its name abc.test.X.I did not check if this might be an AspectJ feature, contrasted to a pure AJDT issue. Even if it this behavior is correct AspectJ, the AJDT should at least warn.	This is a long-standing bug in the compiler - ajc does not match javac's enforcement of package structure - see.Warnings are issued by the compiler so this cannot be addressed in AJDT.*** This bug has been marked as a duplicate of***I agree that this should be discussed in the context of the AspectJ language spec and ajc's spec of a compilation unit. I rephrase the issue in terms of an enhancement request to AJDT:no warning when moving or copying an aj-file to another package.I moved a aj-file and the apsect from one package to anaother package.Parallel in JDT: the package statement is adjusted to the new location.The AJDT does not, because the language spec does not require this modification.So what I really want is: refactoring "move aj-file/aspect to another package" in AJDT.Or, for the AspectJ language spec being as it is, a warning that moving aj-files might not have the expected result.To be specific: the warning should not come from ajc as a result of the file position/package directive mismatch, but as part of the move or copy user action/dialog, thus from AJDT.Sorry for insisting and reopening, I tried to lower the priority, but bugzilla would not have it.I agree that AJDT should behave like JDT in this regard and update the package statement if an aspect (in a .aj file) is dragged from one package to another.This does in fact work for me. As a test I created the "TJP Example" project using the New wizard and created a new package called "package2" then dragged the GetInfo.aj file from the "tjp" package to "package2", and the package statement in GetInfo.aj correctly updated to "package2". Could you try this to see if it works for you? If so, what's different about the case where this doesn't work for you?I think I did not move the aspect/aj-file, but I copied it, and deleted the original.The scenario with drag and drop works for me, with two remarks (2a, 2b).Copy and Paste works differently than in JDT. See steps 6 - 8.Details:Starting with two aspects, Base and Derived, Derived extends Base, both in package repro, both within there own compilation unit, that is aj-file, both in the same "regular" folder.Step 1) Create new package other with context menu New...>Package. OKStep 2) Move Base.aj two other, by drag and drop.-> Move Wizard Dialog2a) Expected: Refactored Source shows modified package statementActual: ... shows original package statement.2b) Expected from JDT behavior: Derived.aj should get a new import statement for Base.Actual: Derived is not changed.2c) Expected from JDT behavior: Base.aj has modified package statement.Actual: OKStep 3) Refactor > Undo: OKStep 4) Repeat 2) with Drag and Drop of aspect Base (not aj-file).Same result as 2)Step 5) Undo: OKStep 6) Copy and Paste file Base.aj from package repro to package other.Expected from JDT: (silently) modified package directive.Actual: original package directive with "repro".Now there are two aspects with the same name, defined in two different aj-files.AJDT reports correctly "type Base already defined".Step 7) Delete new aj-file; OKStep 8) Repeat Step 6) with Copy and Paste of aspect (not aj-file)Expected: same as in 6)Actual: package explorer shows Base.aj, but not aspect (as child of compilation unit.Step 9) Delete new aj-file: OK-- Trivial Code:Base.aj in package/folder repro---package repro;public abstract aspect Base {}---Derived.aj in package/folder repropackage repro;public aspect Derived extends Base {}---This is still an issue. I am trying two things and both are failing in different ways.1. Copy a .aj file (with or without an aspect) and paste it to a new folder inside the package explorer.Result--> new aspect exists, but package declaration has not changed (presumably, import statements need to be changed as well.2. Drag and drop a .aj file (with or without an aspect) to a new package in the package explorer.Result--> ArrayStoreException when clicking OK (see stack trace below).java.lang.ArrayStoreException: org.eclipse.jdt.internal.core.PackageFragmentat org.eclipse.jdt.internal.core.refactoring.descriptors.JavaRefactoringDescriptorUtil.getJavaElementArray(JavaRefactoringDescriptorUtil.java:345)at org.eclipse.jdt.core.refactoring.descriptors.MoveDescriptor.<init>(MoveDescriptor.java:179)at org.eclipse.jdt.internal.corext.refactoring.reorg.ReorgPolicyFactory$MoveFilesFoldersAndCusPolicy.createRefactoringDescriptor(ReorgPolicyFactory.java:1303)at org.eclipse.jdt.internal.corext.refactoring.reorg.ReorgPolicyFactory$FilesFoldersAndCusReorgPolicy.getDescriptor(ReorgPolicyFactory.java:866)at org.eclipse.jdt.internal.corext.refactoring.reorg.JavaMoveProcessor$1.getDescriptor(JavaMoveProcessor.java:120)at org.eclipse.ltk.core.refactoring.CompositeChange.getDescriptor(CompositeChange.java:489)at org.eclipse.ltk.core.refactoring.CreateChangeOperation.getChange(CreateChangeOperation.java:150)at org.eclipse.ltk.ui.refactoring.UserInputWizardPage.performFinish(UserInputWizardPage.java:155)at org.eclipse.jdt.internal.ui.refactoring.reorg.ReorgMoveWizard$MoveInputPage.performFinish(ReorgMoveWizard.java:109)at org.eclipse.ltk.ui.refactoring.RefactoringWizard.performFinish(RefactoringWizard.java:622)at org.eclipse.ltk.internal.ui.refactoring.RefactoringWizardDialog2.okPressed(RefactoringWizardDialog2.java:446)at org.eclipse.jface.dialogs.Dialog.buttonPressed(Dialog.java:472)at org.eclipse.jface.dialogs.Dialog$2.widgetSelected(Dialog.java:624)at org.eclipse.swt.widgets.TypedListener.handleEvent(TypedListener.java:228)at org.eclipse.swt.widgets.EventTable.sendEvent(EventTable.java:84)at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1561)at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1585)at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1570)at org.eclipse.swt.widgets.Widget.notifyListeners(Widget.java:1360)at org.eclipse.swt.widgets.Display.runDeferredEvents(Display.java:3474)at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3064)at org.eclipse.jface.window.Window.runEventLoop(Window.java:825)at org.eclipse.jface.window.Window.open(Window.java:801)at org.eclipse.ltk.ui.refactoring.RefactoringWizardOpenOperation$1.run(RefactoringWizardOpenOperation.java:144)at org.eclipse.swt.custom.BusyIndicator.showWhile(BusyIndicator.java:70)at org.eclipse.ltk.ui.refactoring.RefactoringWizardOpenOperation.run(RefactoringWizardOpenOperation.java:156)at org.eclipse.jdt.internal.ui.refactoring.actions.RefactoringStarter.activate(RefactoringStarter.java:37)at org.eclipse.jdt.internal.ui.refactoring.reorg.ReorgMoveStarter.run(ReorgMoveStarter.java:79)at org.eclipse.jdt.internal.ui.packageview.SelectionTransferDropAdapter.handleDropMove(SelectionTransferDropAdapter.java:273)at org.eclipse.jdt.internal.ui.packageview.SelectionTransferDropAdapter.performDrop(SelectionTransferDropAdapter.java:212)at org.eclipse.jdt.internal.ui.dnd.JdtViewerDropAdapter.drop(JdtViewerDropAdapter.java:242)at org.eclipse.jface.util.DelegatingDropAdapter$3.run(DelegatingDropAdapter.java:211)at org.eclipse.core.runtime.SafeRunner.run(SafeRunner.java:37)at org.eclipse.core.runtime.Platform.run(Platform.java:880)at org.eclipse.ui.internal.JFaceUtil$1.run(JFaceUtil.java:48)at org.eclipse.jface.util.SafeRunnable.run(SafeRunnable.java:175)at org.eclipse.jface.util.DelegatingDropAdapter.drop(DelegatingDropAdapter.java:209)at org.eclipse.swt.dnd.DNDListener.handleEvent(DNDListener.java:90)at org.eclipse.swt.widgets.EventTable.sendEvent(EventTable.java:84)at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1561)at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1585)at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1570)at org.eclipse.swt.widgets.Widget.notifyListeners(Widget.java:1360)at org.eclipse.swt.dnd.DropTarget.dragReceiveHandler(DropTarget.java:412)at org.eclipse.swt.dnd.DropTarget.DragReceiveHandler(DropTarget.java:240)at org.eclipse.swt.internal.carbon.OS.TrackDrag(Native Method)at org.eclipse.swt.dnd.DragSource.drag(DragSource.java:351)at org.eclipse.swt.dnd.DragSource$1.handleEvent(DragSource.java:166)at org.eclipse.swt.widgets.EventTable.sendEvent(EventTable.java:84)at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1561)at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1585)at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1570)at org.eclipse.swt.widgets.Widget.notifyListeners(Widget.java:1360)at org.eclipse.swt.widgets.Display.runDeferredEvents(Display.java:3474)at org.eclipse.swt.widgets.Control.sendTrackEvents(Control.java:3105)at org.eclipse.swt.widgets.Control.kEventControlTrack(Control.java:2104)at org.eclipse.swt.widgets.Widget.controlProc(Widget.java:375)at org.eclipse.swt.widgets.Display.controlProc(Display.java:862)at org.eclipse.swt.internal.carbon.OS.CallNextEventHandler(Native Method)at org.eclipse.swt.widgets.Tree.kEventMouseDown(Tree.java:2599)at org.eclipse.swt.widgets.Widget.mouseProc(Widget.java:1326)at org.eclipse.swt.widgets.Display.mouseProc(Display.java:2925)at org.eclipse.swt.internal.carbon.OS.SendEventToEventTarget(Native Method)at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3047)at org.eclipse.ui.internal.Workbench.runEventLoop(Workbench.java:2382)at org.eclipse.ui.internal.Workbench.runUI(Workbench.java:2346)at org.eclipse.ui.internal.Workbench.access$4(Workbench.java:2198)at org.eclipse.ui.internal.Workbench$5.run(Workbench.java:493)at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:288)at org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:488)at org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:149)at org.eclipse.ui.internal.ide.application.IDEApplication.start(IDEApplication.java:113)at org.eclipse.equinox.internal.app.EclipseAppHandle.run(EclipseAppHandle.java:193)at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:110)at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:79)at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:382)at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:179)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)at java.lang.reflect.Method.invoke(Method.java:585)at org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:549)at org.eclipse.equinox.launcher.Main.basicRun(Main.java:504)at org.eclipse.equinox.launcher.Main.run(Main.java:1236)With JDT weaving enabled, things work a little better (ie- no exceptions are thrown), but there are still problems:1. Sometimes, drag and drop will copy compilation unit to new folder, but original CU in original folder is still around. This seems to occur when there is a class that depends on the class being moved. When no other classes refer to the one being moved, drag and drop works fine.2. Package statement *is* updated, but imports are not. Neither in CU being moved, nor in CUs that refer to it.Still some work to do.Try to solve for 2.1.0.Determining what will be tackled for 2.1.1 release.OK...most of the problems here appear to be solved.One last thing that I notice. When moving an aspect, references to classes that will need an import statement after the move, are not found.Eg:package a;public aspect A { declare parents : Sub extends Super;}package a;public class Sub { }package a;public class Super { } Now, move aspect A to package b, and there should be 2 import statements, but there are not. However, if Sub and Super are referenced as regular variables, then import statements are properly added:package a;public aspect A { declare parents : Sub extends Super; Sub s; Super s2;}becomespackage b;import a.Sub;import a.Super;public aspect A { declare parents : Sub extends Super; Sub s; Super s2;}The problem is that the Move refactoring uses an ImportRewriter to update the import statements on move. This class cannot add or remove import statements for references inside of AJ-specific code.Possible solutions:1: create an AJ-aware form of import rewrite2: walk all AJ-declarations and looks for references that may need to have imports added or removed and do so manually.	10.0
id=277852	REOPENED	Linux Tools	RPM	unspecified	PC Linux	P3 normal	Alexander Kurtakov	2009-05-26 09:14 EDT by	Alexander Kurtakov	2016-05-06 06:45 EDT (	2 users		No time for 0.3.Re-opening as I suspect Alex mistakenly closed it.This bug hasn't had any activity in quite some time. Maybe the problem got resolved, was a duplicate of something else, or became less pressing for some reason - or maybe it's still relevant but just hasn't been looked at yet.If you have further information on the current state of the bug, please add it. The information can be, for example, that the problem still occurs, that you still want the feature, that more information is needed, or that the bug is (for whatever reason) no longer relevant.--The automated Eclipse Genie.This bug hasn't had any activity in quite some time. Maybe the problem got resolved, was a duplicate of something else, or became less pressing for some reason - or maybe it's still relevant but just hasn't been looked at yet.If you have further information on the current state of the bug, please add it. The information can be, for example, that the problem still occurs, that you still want the feature, that more information is needed, or that the bug is (for whatever reason) no longer relevant.--The automated Eclipse Genie.	4.0
id=39001	REOPENED	CDT	cdt-core	2.0	All All	P3 enhancement	Alain Magloire	2003-06-17 04:18 EDT by	Oyvind Harboe	2009-01-09 14:53 EST (	0 users	I'd like CDT to automatic builds in the background.This is part of regaining creature comforts lost when I switched from JDT to CDT.The information below is a bit off topic:I want the automatic, incremental builds that JDT has in CDT. To that end I've created a makefile that:- automatically enumerates and compiles .cc files in the project- automatically figures out dependenciesinclude $(INSTALL_DIR)/include/pkgconf/ecos.makOUTPUT = ../output/$(APPNAME)LINKFILES = $(patsubst %.cc,$(OUTPUT)/%.o,$(shell ls *.cc))XCC = $(ECOS_COMMAND_PREFIX)gccXCXX = $(ECOS_COMMAND_PREFIX)g++XLD = $(XCC)CFLAGS = -I$(INSTALL_DIR)/includeCXXFLAGS = $(CFLAGS) $(ECOS_GLOBAL_CFLAGS) -fexceptionsLDFLAGS = -nostartfiles -L$(INSTALL_DIR)/lib -Ttarget.ld.PHONY : clean all bumpversion $(OUTPUT) all: bumpversion $(OUTPUT) $(OUTPUT)/$(APPNAME).bin$(OUTPUT): mkdir --parents $(OUTPUT)clean: echo Cleaning rm -rf $(OUTPUT)GENOPT = -MP -MT '$(OUTPUT)/$*.o' -MT '$(OUTPUT)/$*.d'.SILENT: $(LINKFILES) $(LINKFILES:.o=.d) $(OUTPUT)/$(APPNAME).bin$(OUTPUT)/%.o: %.cxx$(OUTPUT)/%.o: %.cc echo -- compiling $*.cc $(XCXX) $(GENOPT) -MD -c -o $(OUTPUT)/$*.o $(CXXFLAGS) $<$(OUTPUT)/%.d: %.cc mkdir --parents $(OUTPUT) echo -- dependencies $*.cc $(XCXX) $(GENOPT) -M -MF $(OUTPUT)/$*.d $(CXXFLAGS) $*.cc$(OUTPUT)/%.bin: echo -- linking $(XLD) $(LDFLAGS) $(ECOS_GLOBAL_LDFLAGS) -o $(OUTPUT)/$*.elf $^ arm-elf-objcopy -O srec $(OUTPUT)/$*.elf $(OUTPUT)/$*.srec arm-elf-objcopy -O binary $(OUTPUT)/$*.elf $(OUTPUT)/$*.bin arm-elf-size $(OUTPUT)/$*.elf echo -- Done!-include $(LINKFILES:.o=.d)bumpversion: rm -rf $(OUTPUT)/version.o$(OUTPUT)/$(APPNAME).bin: $(LINKFILES)	To do that we need support from Eclipse/Platform.There is plan to add the framework for this in Eclipse-3.0See Eclipse-3.0 draft planLATER/REMIND are deprecated. Changing to reopened milestone '--'	2.0
id=245409	REOPENED	PDT	PHP Search	unspecified	PC Windows XP	P3 enhancement	Alon Peled	2008-08-27 12:13 EDT by	Alex	2016-06-16 04:47 EDT (	2 users	Right now, the "Open PHP Element" can open classes, functions and constants, but not class methods. It would be nice if we could have an extra option to include methods. Say you have class like this:class Cat { function meow() { //meow } function purr() { //purr }}The user should be able to type "meow" (or "m..." etc) in the "Open PHP Element" window, and the list should show "Cat::meow in /path/to/cat.php".This feature is quite important for instance when working with an MVC framework, where action names are all methods. To jump to an action, you now need to first open the class and then the action (via quick outline). This could be one operation.An even nicer implementation could be the way Netbeans 6.5 is doing it:Type "Cat" =>- Cat (class)Type "Cat::" =>- Cat::meow (method)- Cat::purr (method)Type "::meow" =>- Cat::meow (method)	Hiwhere is the "Open PHP Element" ?I think it's about Open Declaration action. It supports also methods.Actually it is not. Once upon a time I think there was an option in Navigate menu called "Open PHP Element". Then it was divided into Open Method and Open Type. Obviously Open Method will open methods :)The only thing we miss is opening methods prefixed by the class name - that is currently you can find "meow" if you start typing it but not Cat::meow.Let me know if this is nice to implement as well or we should close it.	3.0
id=381907	REOPENED	Linux Tools	RPM	unspecified	All Linux	P3 enhancement	Alexander Kurtakov	2012-06-06 15:15 EDT by	Corey Ashford	2013-11-08 15:58 EST (	3 users	Build Identifier: M20120208-0800If I'm editing a spec file, I would like to easily be able to navigate to patch file that is referenced from within the spec file.For example, if there is a line like this:Patch5244: bug-52844-remove-fzl.patchdouble-clicking on the patch file name should open up a view of that patch file.Reproducible: Always	I think you can Ctrl-click on the filename and it'll open the patch file. If you Ctrl-click on references to that patch (ie. instances of %patchN), it should bring you to the declaration of it above (I think).Thanks for the quick reply, Andrew!I tried control-click on the file, but I get nothing. There doesn't seem to be anything to indicate that I can do something with the file. All of the context menus seem to be relative to the window, rather than the file.I should mention that there are no %patch references to this or any other patch file in the spec. Instead, there is a function in the spec file that applies the patches. Could the lack of a %patch line keep the editor from recognizing the patch file?The version of the spec file editor that I have is0.4.3.201203221532(In reply to)I haven't looked at this code in a while but I'm pretty sure the parser finds Patch##: <filename>. Whether or not %patch## is present shouldn't affect that.Maybe I was dreaming about being able to open the actual patch file :) Since it doesn't work, we should implement it. Thanks for the bug.(In reply to)Just as an experiment, I tried adding a %patch## to the file, but as you suspected, it didn't make any difference.I don't know, but suspect this may not be too hard to implement.[1] and [2] allow navigating to patch file as well as creating/downloading it if it does not exist and/or is a URL.----------[1][2]I just now tried the nightly-build, and either the change isn't in there yet, or I don't know how to use it, because I don't see any change of behavior.The plugin version I have is: RPM Import/Export/Building and Editing Tool 1.0.0.201311061924I just tried the nightly build as well and the specfile editor seems to create a new patch file if it doesn't exist and open it with the default editor. The patch file also handles URLs with valid protocols.How I tested it was: 1) Create new specfile from template into a project 2) Add "Patch0: test.patch" (without quotations) 3) Ctrl+left click on "test.patch"This should result in "test.patch" being created in the project and immediately opening it with the default editor for .patch files.For URLs: 1) same step 1 as above 2) Add "Patch1:" 3) Ctrl+left click on ""This should result in displaying an option box on what to do. More information in the user guide.Here is the user guide for it:Using: RPM Import/Export/Building and Editing Tool v1.0.0.201311061924OK, I think I've discovered why it wasn't working for me.The plugin appears to require that the spec file resides in the SPECS subdirectory. I tried moving my spec file from the top level to SPECS, and then everything seems to work as you described.Is that how it should work?(In reply to Corey Ashford from)Hmm...I don't think it should be working that way.I just tested it again but with the {BUILDS,RPMS,SOURCES,SPECS,SRPMS} directory structure with cases where the .spec file is at the top level or inside the SPECS folder, and both in both situations, it seems to create a patch within the SOURCES folder. I also tried this with 2 projects: 1 project with an rpm nature (RPM Project) and 1 without (general eclipse project).However, I did find that downloading URLs only work with http://, but does not work with https://. And that downloading a patch from a URL (when the .spec file is at the top level) will place the patch at the top level. However, placing the .spec file in one of the RPM build layout directory folders would place downloaded patches into SOURCES (what was intended).I am not sure what may be wrong, but if you have any more details on it, feel free to reply. I may have to look at this patch again.Ok, sorry, I need to be more clear. If the spec file is at the top level, I am able to create a new patch, but I cannot examine existing patches. control-left-click on a patch file does not bring it up in the editor if the spec file (alone) is at the top level, and the patches are in the SOURCES directory.In fact, I get nothing when I ctrl-left-click the file, except the underscore disappearing.(In reply to Corey Ashford from)Ah I see...sorry for misunderstanding, I finally got it to reproduce how you explained it.I have not considered in it acting that way because a .spec file would usually be located in the SPECS directory anyway if using an RPM Build directory layout (BUILDS, RPMS, SOURCES, ... etc.). However, there is probably the scenario where a user is using a flat layout and putting a .spec file at the top level and creating a SOURCES directory with the patch(es) in it. But then again, that is what the RPMBUILD layout is for.For what it's worth, placing the .spec file in any other folder but the top level would open the patch file from the SOURCES folder if it exists.I don't think it would be that important to add that feature in as it is not using the layouts as intended, but I will take a look into it in the future (I'd keep it reopened to remind me). Thanks for clarifying what was actually going on :)Ok, thanks for looking into that :-)This just happens to be the way our packages are stored in our SCM system, but I don't exactly know why we are deviating from the standard format of placing spec files in the SPECS directory. We only seem to have the SOURCES directory controlled, and the spec file is sitting at the top level.For the record, I tried creating a soft link from SPECS/<package>.spec to the <package>.spec file in the top level directory, and that works too. So this is a work-around for anyone that runs into this issue.	12.0
id=310992	REOPENED	CDT	cdt-debug-dsf	7.0	All All	P3 normal	Anton Leherbauer	2010-04-29 06:44 EDT by	Anton Leherbauer	2010-09-10 11:15 EDT (	3 users	I noticed that the DelayedStackRefreshUpdatePolicy flushes the cached data of the execution context for a suspended event which leads to a stack depth retrieval from the service when computing the delta for the event.This should be avoided for optimal stepping performance.See also Ken's mail on cdt-dev:	CreatedFixThis seems to fix it.Pawel, would you review before I commit? I am not sure about potential side-effects.The only other side effect that I can think of is that the thread's label and icon will not update until the full stack refresh event. Having this update meant that the thread icon was often flashing between running and suspended states. Eliminating this behavior is actually a positive change though.(In reply to)I wonder what triggers the label update of the thread. Is this a result of the EXPAND delta?Related to that, would it make sense to have an update flag to update all properties? This would correlate to the STATE delta.Committed to HEAD.(In reply to)The resume event handling? All this really begs for some controlled tests...Yes! It may even make sense to allow flushing of only select properties, at least that's the only way I can think of to implement.I believe this fix causedwhere stack frames are missing. One may have to turn off the "Limit stack frames" option to see the problem.The fix for this has caused issues, e.g., therefore I backed out the changes.I am marking this invalid, because with the current cache behavior there is no way to relax the flushing rules.(In reply to)If it's OK with everyone, I'd like to keep this bug opened and try to address it again past 7.0. We'll likely need to extend the cache API to support the optimal optimization ;-), but more importantly we'll need to have a good regression test suite also.*** cdt cvs genie on behalf of aleherbau ***- [vm][cache] Unnecessary cache flushing of thread children on suspended event[*] DelayedStackRefreshUpdatePolicy.java 1.3	9.0
id=346301	REOPENED	CDT	cdt-debug	8.0	PC All	P3 normal	Alvaro Sanchez-Leon	2011-05-18 12:54 EDT by	Winnie Lai	2013-06-17 11:26 EDT (	4 users	Build Identifier: 3.7 M7Current actions for add/remove/edit/restore register group in registers viewassume the 'debug target' is IDebugElement and ICDebugTarget. These assumptions do not fit into dsf gdb, thus there is a need to let other cdt gdb (non-cdi) debugger based registers view to override these actions.Reproducible: Always	Winnie, do you have some implementation of register groups for DSF?(In reply to)I have the concept of nested register groups. No magic - I simply allow a register group dm context can have (0..*) register group dm context on service side; and a similar concept on view model side - a group node can have a group node and a regiser node.The hierarchy is determined by both the hardware model and the software side. The sw side is more or less making a simple grouping, say any group having >100 registers will be grouped -- nothing elegant.After the nested group is implemented, it won't be hard to allow user driven grouping - just an extension of sw grouping logic.Accidentally marked as fixed, so it's now re-opened	3.0
id=306708	REOPENED	CDT	cdt-build	7.0	All All	P3 normal	Andrew Gvozdev	2010-03-22 09:16 EDT by	Emanuel Graf	2010-06-11 10:46 EDT (	1 user	Building a project call IScannerInfoConsoleParser.startup() even if nothing changed in the project. On some systems the call g++ -E -P -v -dD specs.cpp takes some seconds.	I was just about to create a bug like that. The problem is that ScannerConfigBuilder is set up as a separate project builder (in properties->Builders) and it is being run on every build event. I think it needs to be configured to be activated on FULL_BUILD event only. Perhaps even that is too often and it should have some additional logic to skip the event if compiler specs were fetched already.CreatedThe patchCommitted on HEAD (7.0). This will take effect on new projects. Old projects still can be configured in Project->Properties->Builders->Scanner-Configuration-Builder->Edit. Voodoo by disabling all events except "After a Clean".(In reply to)This may not be the case, but just checking...Does this prevent all scanner info parsing from happening on Incremental build? If so does this mean that scanner discovery won't pick up new paths / symbols if -Is and -Ds are added to the external makefile?Or does this change only affect the discovery of built-ins?Just tested this change. It looks like scanner info is now only picked up on the first build after a clean. So adding a -D to a makefile, run an incremental build, doesn't cause the discovered defines to be updated.I have hard time figuring out how that can be. ScannerConfigBuilder is a separate builder running a separate command (to fetch built-in specs). It has no access to regular build output. Regular build output is parsed by BOP parser which is not a builder but mere a line parser which is connected to parse output of CommonBuilder. If you enable all the events in properties, does it start working? Or maybe you use customized scannerInfoProvider?(In reply to)I'm just trying in my HEAD runtime. (In my product I only use scanner discovery for the built-ins -- I use a DwarfParser for makefile projects...).What I did using a clean head: - Create HelloWorld managed project - Create empty makefile project - Copy the source and Debug directories from the managed project to the makefile project - Change the makefile project build directory to makefileproject/Debug - Build the makefile project - Add some -D's to the makefile, touch hello.c, build. + Before the patch the -Ds are correctly shown in the Symbols page, afterwards they don't seem to be picked up.(In reply to)(I had to create a new project to pick up the changed builder as detailed by).I was under the impression, which could be wrong, that while the BOP runs inline with the make, the paths and symbols are contributed back by the scanner info builder running after the make.OK, I can see the problem. Let me figure it out.Createdadditional patch(In reply to)You are right. I think that is counter-intuitive and it prevents disabling built-in specs re-discovery on incremental builds. Here is a patch to contribute the entries in CommonBuilder after build output parsing is done.Is there a good reason for the if in:if (kind == INCREMENTAL_BUILD || kind == FULL_BUILD || kind == AUTO_BUILD) { // Update project model with scanner info...?If on CLEAN_BUILD we cleared all the scanner info state, this would fix all those other bugs on not being able to remove builtins...I don't really have any preference as to whether this runs as its own builder or not. But at a first glance the patch looks good to me.One other question: is the ScannerConfig call in the right place in CommonBuilder? Shouldn't it be in #build(int kind, CfgBuildInfo bInfo, IProgressMonitor monitor) to pick up scanner config on referenced configurations?(In reply to)I do now have a preference -- this is a better approach. It looks like ScannerConfigBuilder doesn't run correctly for the configurations which were just built. It updates the settings on the des.getDefaultSettingConfiguration(), which may not be what was built: see CommonBuilder#build(int kind, Map args, IProgressMonitor monitor) :s(In reply to)I agree with you and I want to look at that next. It is just that for now ScannerConfigBuilder is not able to do any cleaning and we do not really want to save scanner info collected from clean output. I think we may likely introduce another flag which will instruct ScannerConfigBuilder to clean discovery info and for that we would need to insert in the code if(kind == CLEAN_BUILD) anyway.(In reply to)ScannerConfig saves all scanner info collected before. It was placed in separate builder presumably for efficiency as it persist collected data on disk. If we put it in #build(int kind, CfgBuildInfo bInfo, IProgressMonitor monitor) we place it inside "for" loop. Regarding referenced configurations they are also built via calling #build(int kind, IProject project, IBuilder[] builders, boolean isForeground, IProgressMonitor monitor, MyBoolean isBuild) - where the call is placed - aren't they?Yeah, I thought that that could be a problem looking at the code too(In reply to)Yes you're right: this function calls itself recursively via buildReferencedConfigs.OK, I committed second patch on HEAD (7.0) too.Reopening as Doug backed the change, see.	16.0
id=324240	REOPENED	AJDT	UI	2.1.0	PC Windows 7	P3 major	Andrew Eisenberg	2010-09-01 15:33 EDT by	Jojo	2010-12-08 19:59 EST (	1 user	Build Identifier: 20100617-1415Hi all,following problem:I have one project with aspects and another one with pure java classes.If I use declare parents to advice all classes in a different project, there is no code completion for the additional field added per intertype dec. in the effected class.Following Code with "IAspIntertyping" only as marker interface(No declaration inside):-------------------------------------------------package com.bugzilla.ajdt;public interface IAspIntertyping {}package com.bugzilla.ajdt;public aspect IntertypeAspect { declare parents : com.bugzilla.test.* implements IAspIntertyping; //Add a public field LOGGER to all effected classes: public BugLogger IAspIntertyping.LOGGER = new BugLogger(); public pointcut interfacePC() : get(public BugLogger *..*.LOGGER) && !within(com.bugzilla.ajdt.*); BugLogger around(): interfacePC() { //Some other implementation... BugLogger LOGGER = new BugLogger(); return LOGGER; }}The effected class:package com.bugzilla.test;public class SingleClass { public SingleClass() { LOGGER.debug("SingleClass"); //<-- No code completion here }}----------------------------------------------------------------------------- When i use the java-editor in Eclipse sometimes an Error is shown: LOGGER cannot be referenced...- When i use the aspectj/java editor no Error is shown, all advice markers still displayed, but also no code completion is working.In both cases the programm works correct. LOGGER.debug("...") is invoked each time. But without code complition is hard to develope software, when i cant see which methods are available, in this case LOGGER. (BugLogger.java) doesnt suggest debug(msg).Both projects are aspectj projects. Project "com.bugzilla.test" has added com.bugzilla.ajdt on its aspect path. So all aspects in ...adjt are woven in as they should in ...test.IF I advice a class in the same project where the aspects lie, then whole 'cc' is available...(But not applicable for huge projects)So maybe i got something wrong with those path-specific configuration stuff like aspect path, inpath, which project knows other... If not and my configs are correct, there is bug for cross-project aspects.regards JohannesI attach a Test-Project!Reproducible: Always	This is an AJDT bug.This bug is a duplicate. Please seefor a workaround.*** This bug has been marked as a duplicate of***Hi Andrew, first thanks for the very fast reply!I have reopend this ticket because my problem is a bit different.So first: My 2 projects are both aspectj-projects, oner with aspects inside, the other one with only java files!!!!!!!!If I use the workaround example and convert the java-project also to an aspectj-project instead adding the nature in .project, then eclipse complains that .message -> "The field JavaClassInAJProject.message is not visible". Maybe you can explain this.But my problem is, if in my java-project I only change the nature, no ITD is done from Aspectj-project(ProA) into java-project(ProB). So in my example LOGGER is no more referenced and therefor I got an compile error. So in my thought, i have to convert my java-project into an aspectj-project. Now aspects form ProA are woven in ProB.To get this working i only do the converting and in ProB, I add to the aspect-path ProA. So the aspectj-project has no references to other projects, but the java-project(ProB) has a reference to the aspectj-project(ProA). Please correct me if I'm doing something wrong here.The main difference between the workaround and my problem is, that I'm not using an aspectj manipulated object (in the example "JavaClassInAJProject") in my java-project. What I do is, I ITD's an interface with a field called LOGGER. Than an aspect (called IntertypeAspect) will effect all classes/abstracts or other interfaces in the java-project by adding following code:declare parents : com.bugzilla.test.* implements IAspIntertyping;This 'declare parents' statement has only effects if my java-project has also converted into an aspectj project! Maybe you know a better way to achive that...So if I do it my way, eclipse does not complain and also no compilation errors exists. BUT IF I WANT TO ACCESS THE INTERTYPED FIELD (in my case LOGGER) no code completion works and also no javadoc informations are displayed.The wired thing is, if my effected class or interface in the java-project is a super class, than code completion works in the subclass, but in the superclass not.E.g.:Project Aspj -> With an aspect for ITD's other java-projects.Project Java (with aj convertion!):- SuperClassA is ITD from Project Aspj <--- here no code completion there- SubClassB extends SuperClassA <-- here code completion is workingThis is a confusing behavior and maybe you have a workaround for this bug, too?If I got something wrong with my path-settings please tell me that. If I explaind my problem to unexact, tell me that, I've got a small Test-Project I will attech that makes everthing clear!So thanks again!JohannesCreatedTest-Project for not supported code completionThanks for the test project. I can see the issues you are describing. I don't know if I'll be able to get to this for 2.1.1.I have a fix for the navigation and content assist issues in your sample projects. I need to do some more testing before committing. This should be able to make it into 2.1.1.The compilation error you have looks like it may be an aspectj bug. I forwarded it to the AspectJ team and they are looking at it now.I created a few test cases to make sure that everything's working now. And it seems like there is at least one more AspectJ problem that is described in but 327057.I will commit the pieces that I have fixed. This will at least allow you to get content assist and navigation for ITDs across projects.* Declare annotation is still not working.* The spurious compile problem you describe is still not fixed.I am committing the fix on the 3.6 branch. Are you on 3.6 or 3.5?I'm using 3.5 but if there is too much trouble getting the fix into 3.5, I'll use 3.6 in future.Thanks again for fixing the code-completion stuff, this was the main reason for the release-delay of my logging-framework. But now, juhu...	8.0
id=261976	REOPENED	CDT	cdt-build	5.0.1	PC Windows XP	P3 normal	Andrew Gvozdev	2009-01-22 04:12 EST by	Adrian	2012-03-18 05:52 EDT (	0 users	Build ID: M20080911-1700I am using A NIGHT BUILD CDT 5.0.2 Build I200901160801 but maybe it's related with 5.01 as well.Steps To Reproduce:1.Create a new target with something like: make -ODist"1 2 3" all2.When rebuild it will display it with out the quotes: make -ODist1 2 3 allMore information:This bug is related to another one I reported several months ago, but then both the display and the result of the building were indicating me the the make command was working with out quotes. Now it seems that only the display is wrong.	Added printing enclosing quotes for arguments of build command which have spaces, quotes or backslashes. Double-quotes and backslashes are printed escaped by backslash. Committed to master CDT 8.1.0.*** cdt git genie on behalf of Andrew Gvozdev ***: Console does NOT display quoted command line options.[*]*** cdt git genie on behalf of Andrew Gvozdev ***: CommandLauncher to report about $PATH problems and related clean-up[*]*** cdt git genie on behalf of Andrew Gvozdev ***: Externalize strings[*]Reopen to fix also ParallelBuilder.	5.0
id=400382	REOPENED	CDT	cdt-core	8.1.1	PC Linux-GTK	P3 normal	Andrew Gvozdev	2013-02-09 06:42 EST by	Martin Oberhuber	2013-05-03 12:37 EDT (	3 users	There is a new test failure (regression) in cdt-8.1.2 build 404 (Feb 9, 2013).LanguageSettingsManagerTests.testConfigurationDescription_ProvidersThe failure was not in build 403 and the change between 403 and 404 seems unrelated, so I assume that the failure is transient; still it might be related to recent changes inand. It should be investigated for potential regression !junit.framework.AssertionFailedError: Expected number (0) of non-OK status objects in log differs from actual (1). Resource '/' does not exist. Resource '/' does not exist. at org.eclipse.cdt.core.testplugin.util.BaseTestCase.runBare(BaseTestCase.java:193) at junit.framework.TestResult$1.protect(TestResult.java:110) at junit.framework.TestResult.runProtected(TestResult.java:128) at junit.framework.TestResult.run(TestResult.java:113) at junit.framework.TestCase.run(TestCase.java:124)	It is not failure of test LanguageSettingsManagerTests.testConfigurationDescription_Providers but a message in the log about failure of previous testThe failure was transient since it didn't repeat in build.(In reply to)Being transient does not mean that it is OK. We still need to fix those. The intermittently failing tests on Hudson are a major headache.The stack trace provided in the description is a bit short and does not give relevant details. Assuming that it is the same as in build 408, I fixed that on master with commitHere is the stack trace for reference:junit.framework.AssertionFailedError: Expected number (0) of non-OK status objects in log differs from actual (1). Resource '/' does not exist. Resource '/' does not exist. at org.eclipse.cdt.core.testplugin.util.BaseTestCase.runBare(BaseTestCase.java:193) at junit.framework.TestResult$1.protect(TestResult.java:110) at junit.framework.TestResult.runProtected(TestResult.java:128) at junit.framework.TestResult.run(TestResult.java:113) at junit.framework.TestCase.run(TestCase.java:124) at org.eclipse.cdt.core.testplugin.util.BaseTestCase.run(BaseTestCase.java:210) at junit.framework.TestSuite.runTest(TestSuite.java:243) at junit.framework.TestSuite.run(TestSuite.java:238) at junit.framework.TestSuite.runTest(TestSuite.java:243) at junit.framework.TestSuite.run(TestSuite.java:238) at junit.framework.TestSuite.runTest(TestSuite.java:243) at junit.framework.TestSuite.run(TestSuite.java:238) at junit.framework.TestSuite.runTest(TestSuite.java:243) at junit.framework.TestSuite.run(TestSuite.java:238) at org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:83) at org.apache.maven.surefire.junit4.JUnit4TestSet.execute(JUnit4TestSet.java:53) at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:123) at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:104) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at java.lang.reflect.Method.invoke(Method.java:597) at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:164) at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:110) at org.apache.maven.surefire.booter.SurefireStarter.invokeProvider(SurefireStarter.java:175) at org.apache.maven.surefire.booter.SurefireStarter.runSuitesInProcess(SurefireStarter.java:123) at org.eclipse.tycho.surefire.osgibooter.OsgiSurefireBooter.run(OsgiSurefireBooter.java:84) at org.eclipse.tycho.surefire.osgibooter.HeadlessTestApplication.run(HeadlessTestApplication.java:21) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at java.lang.reflect.Method.invoke(Method.java:597) at org.eclipse.equinox.internal.app.EclipseAppContainer.callMethodWithException(EclipseAppContainer.java:587) at org.eclipse.equinox.internal.app.EclipseAppHandle.run(EclipseAppHandle.java:198) at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:110) at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:79) at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:353) at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:180) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at java.lang.reflect.Method.invoke(Method.java:597) at org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:629) at org.eclipse.equinox.launcher.Main.basicRun(Main.java:584) at org.eclipse.equinox.launcher.Main.run(Main.java:1438) at org.eclipse.equinox.launcher.Main.main(Main.java:1414)Caused by: C Model Exception: Core Exception [code 368] Resource '/' does not exist. at org.eclipse.cdt.internal.core.model.SetPathEntriesOperation.updateProjectReferencesIfNecessary(SetPathEntriesOperation.java:117) at org.eclipse.cdt.internal.core.model.SetPathEntriesOperation.executeOperation(SetPathEntriesOperation.java:52) at org.eclipse.cdt.internal.core.model.CModelOperation.execute(CModelOperation.java:341) at org.eclipse.cdt.internal.core.model.CModelOperation.run(CModelOperation.java:607) at org.eclipse.core.internal.resources.Workspace.run(Workspace.java:2344) at org.eclipse.cdt.internal.core.model.CModelOperation.runOperation(CModelOperation.java:638) at org.eclipse.cdt.internal.core.model.PathEntryManager.setRawPathEntries(PathEntryManager.java:618) at org.eclipse.cdt.internal.core.model.PathEntryManager$2.runInWorkspace(PathEntryManager.java:1435) at org.eclipse.core.internal.resources.InternalWorkspaceJob.run(InternalWorkspaceJob.java:38) at org.eclipse.core.internal.jobs.Worker.run(Worker.java:54)Caused by: org.eclipse.core.internal.resources.ResourceException: Resource '/' does not exist. at org.eclipse.core.internal.resources.Resource.checkExists(Resource.java:341) at org.eclipse.core.internal.resources.Resource.checkAccessible(Resource.java:215) at org.eclipse.core.internal.resources.Project.checkAccessible(Project.java:147) at org.eclipse.core.internal.resources.Project.getDescription(Project.java:428) at org.eclipse.cdt.internal.core.model.SetPathEntriesOperation.updateProjectReferencesIfNecessary(SetPathEntriesOperation.java:66) ... 9 moreHmm, this fix just pushed the problem elsewhere. Now the stack is:junit.framework.AssertionFailedError: Expected number (0) of non-OK status objects in log differs from actual (1). Project:is closed or inaccessible! Project:is closed or inaccessible! at org.eclipse.cdt.core.testplugin.util.BaseTestCase.runBare(BaseTestCase.java:193) at junit.framework.TestResult$1.protect(TestResult.java:110) at junit.framework.TestResult.runProtected(TestResult.java:128) at junit.framework.TestResult.run(TestResult.java:113) at junit.framework.TestCase.run(TestCase.java:124) at org.eclipse.cdt.core.testplugin.util.BaseTestCase.run(BaseTestCase.java:210) at junit.framework.TestSuite.runTest(TestSuite.java:243) at junit.framework.TestSuite.run(TestSuite.java:238) at junit.framework.TestSuite.runTest(TestSuite.java:243) at junit.framework.TestSuite.run(TestSuite.java:238) at junit.framework.TestSuite.runTest(TestSuite.java:243) at junit.framework.TestSuite.run(TestSuite.java:238) at junit.framework.TestSuite.runTest(TestSuite.java:243) at junit.framework.TestSuite.run(TestSuite.java:238) at org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:83) at org.apache.maven.surefire.junit4.JUnit4TestSet.execute(JUnit4TestSet.java:53) at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:123) at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:104) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at java.lang.reflect.Method.invoke(Method.java:597) at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:164) at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:110) at org.apache.maven.surefire.booter.SurefireStarter.invokeProvider(SurefireStarter.java:175) at org.apache.maven.surefire.booter.SurefireStarter.runSuitesInProcess(SurefireStarter.java:123) at org.eclipse.tycho.surefire.osgibooter.OsgiSurefireBooter.run(OsgiSurefireBooter.java:84) at org.eclipse.tycho.surefire.osgibooter.HeadlessTestApplication.run(HeadlessTestApplication.java:21) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at java.lang.reflect.Method.invoke(Method.java:597) at org.eclipse.equinox.internal.app.EclipseAppContainer.callMethodWithException(EclipseAppContainer.java:587) at org.eclipse.equinox.internal.app.EclipseAppHandle.run(EclipseAppHandle.java:198) at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:110) at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:79) at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:353) at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:180) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at java.lang.reflect.Method.invoke(Method.java:597) at org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:629) at org.eclipse.equinox.launcher.Main.basicRun(Main.java:584) at org.eclipse.equinox.launcher.Main.run(Main.java:1438) at org.eclipse.equinox.launcher.Main.main(Main.java:1414)Caused by: C Model Exception: Core Exception [code 0] Project:is closed or inaccessible! at org.eclipse.cdt.internal.core.model.PathEntryManager.saveRawPathEntries(PathEntryManager.java:991) at org.eclipse.cdt.internal.core.model.SetPathEntriesOperation.executeOperation(SetPathEntriesOperation.java:55) at org.eclipse.cdt.internal.core.model.CModelOperation.execute(CModelOperation.java:341) at org.eclipse.cdt.internal.core.model.CModelOperation.run(CModelOperation.java:607) at org.eclipse.core.internal.resources.Workspace.run(Workspace.java:2344) at org.eclipse.cdt.internal.core.model.CModelOperation.runOperation(CModelOperation.java:638) at org.eclipse.cdt.internal.core.model.PathEntryManager.setRawPathEntries(PathEntryManager.java:618) at org.eclipse.cdt.internal.core.model.PathEntryManager$2.runInWorkspace(PathEntryManager.java:1435) at org.eclipse.core.internal.resources.InternalWorkspaceJob.run(InternalWorkspaceJob.java:38) at org.eclipse.core.internal.jobs.Worker.run(Worker.java:54)Caused by: org.eclipse.core.runtime.CoreException: Project:is closed or inaccessible! at org.eclipse.cdt.internal.core.settings.model.ExceptionFactory.createCoreException(ExceptionFactory.java:22) at org.eclipse.cdt.internal.core.settings.model.CProjectDescriptionManager.getProjectDescriptionStorage(CProjectDescriptionManager.java:888) at org.eclipse.cdt.internal.core.settings.model.CProjectDescriptionManager.getProjectDescriptionInternal(CProjectDescriptionManager.java:436) at org.eclipse.cdt.internal.core.settings.model.CProjectDescriptionManager.createProjectDescription(CProjectDescriptionManager.java:629) at org.eclipse.cdt.internal.core.CConfigBasedDescriptorManager.createProjDescriptionForDescriptor(CConfigBasedDescriptorManager.java:380) at org.eclipse.cdt.internal.core.CConfigBasedDescriptorManager.findDescriptor(CConfigBasedDescriptorManager.java:350) at org.eclipse.cdt.internal.core.CConfigBasedDescriptorManager.getDescriptor(CConfigBasedDescriptorManager.java:241) at org.eclipse.cdt.core.CCorePlugin.getCProjectDescription(CCorePlugin.java:743) at org.eclipse.cdt.internal.core.model.DefaultPathEntryStore.setRawPathEntries(DefaultPathEntryStore.java:107) at org.eclipse.cdt.internal.core.model.PathEntryStoreProxy.setRawPathEntries(PathEntryStoreProxy.java:111) at org.eclipse.cdt.internal.core.model.PathEntryManager.saveRawPathEntries(PathEntryManager.java:988) ... 9 more	5.0
id=121700	REOPENED	AspectJ	Compiler	DEVELOPMENT	PC Windows XP	P3 enhancement	aspectj inbox	2005-12-21 03:13 EST by	Ron Bodkin	2006-06-29 09:18 EDT (	1 user	I have found this class to be quite helpful as a way of using load-time weaving to run inside an IDE. This nondelegating classloader weaves into any classes on the system classpath, making it work well as a drop in load-time weaving option with a single command -Djava.system.class.loader=org.codehaus.ajlib.util.classloader.AlwaysWeavingURLClassLoader This avoids the difficulty of changing how IDE's like IntelliJ set up their classpath. For that matter, how does the Eclipse load-time weaving configuration work? It seems like it won't weave things on the classpath either and would benefit from this class as well. It didn't allow me to weave any classes in my test project, whereas this does.	Createdalways weaving nondelegating classloaderto integrate this into the code base it would be better to refactor to eliminate duplicated private methods from the WeavingURLClassLoader...CreatedPrebuilt jar containing a compiled version of the classloader, which works with AspectJ 1.5.0 (and later I believe)Thanks for the example, Ron. Given the AJDT support for a load-time weaving configuration, I'm not sure this is still required as an AspectJ offering (and I'm reluctant to promote nondelegating class loaders). But it does seem worth publishing for other IDE's and users; do you want to publish it yourself? Please reopen if you disagree.stalebugI think it's still useful for two classes of users:- those using IntelliJ- those using Java < 5 (as I understand it the AJDT support for load-time weaving using -javaagent)While I agree that nondelegating classloaders have their problems, I think it'd be better to include this as part of AspectJ.Some comments:I don't believe we include any IDE-specific support in AspectJ (anymore)We use -Djava.system.class.loader for 1.4. There is no reliable mechanism for 1.3They are an evil hack	5.0
id=333014	REOPENED	Target Management	RSE	unspecified	PC Linux	P3 normal	Anna Dushistova	2010-12-21 08:45 EST by	Samuel Lampa	2012-05-22 15:03 EDT (	1 user	Build Identifier: 20100617-1415I'm tryng to execute a command on a remote system via SSH and read the output.The problem: If running the readLine() function of an SimpleCommandOperation object in a loop with no or almost no sleep between the iterations, the function gives empty results for most of the iterations, and only occasionally returns another line of the stdout content. When introducing a sleep of a few ms, the number of empty results decreases, and around 15-25 ms, it seems like a correct result is returned for every iteration.At some stage I did also get an exception telling that "pipe closed", when running the iteration without sleep, though I haven't been able to reproduce it later.I'm running 32bit Ubuntu 10.10 (kernel 2.6.35-23-generic), with java-6-sun-1.6.0.22, on a 1.3 GHz Dual-Core laptop.The remote system is running 64bit Scientific Linux (kernel 2.6.18-194.17.4.el5)Reproducible: AlwaysSteps to Reproduce:1. Open an SSH connection to a remote Linux/Unix host2. Run some code like the following (replacing "[the-host-name-of-your-host]" with your host, and the "projinfo" command with something which is available on your system): ISystemRegistry reg = SystemStartHere.getSystemRegistry(); IHost[] hosts = reg.getHosts(); if (hosts.length == 0) { System.out.println("No host names found!"); } for (IHost host : hosts) { String hostAlias = host.getAliasName(); if (hostAlias.equals("[the-host-name-of-your-host]")) { IRemoteCmdSubSystem cmdss = RemoteCommandHelpers.getCmdSubSystem(host); SimpleCommandOperation simpleCommandOp = new SimpleCommandOperation(cmdss, new RemoteFileEmpty(), true); try { allOutput = ""; temp = ""; simpleCommandOp.runCommand("projinfo", true); for (int i=0;i<100;i++) { temp = ""; temp = simpleCommandOp.readLine(false); if (temp == null) { System.out.println("Temp is nul&#314;!"); } else if (temp.equals("")) { System.out.println("*** readLine returned empty result!"); } else { System.out.println("Temp: " + temp); allOutput += temp + "\n"; } try { Thread.sleep(100); } catch (Exception e4) { e4.printStackTrace(); } } System.out.println(allOutput); } catch (Exception e3) { // TODO Auto-generated catch block e3.printStackTrace(); } break; } }3. Watch for an excess of "*** readLine returned empty result" output.4. Modify the line "Thread.sleep(0);", with values between 0-25 (or so), and see how the amount of empty results change.	SimpleCommandOperation.readLine() takes a boolean argument that indicates whether to wait for output or not. In some cases, output is assumed to already be available (without any wait) - those are the times where the use of the false argument makes sense. However, if you need to wait for output, you can pass in true instead as is done with a modified version of your example code here: .... for (int i=0;i<100;i++) { temp = ""; temp = simpleCommandOp.readLine(true); // changed this from false to true if (temp == null) { System.out.println("Temp is nul&#314;!"); ...Ok, tried this now, and I realize that this is where I get the "pipe closed" exception, if using no sleep (works fine with 25 ms sleep). From the error log:java.io.IOException: Pipe closed at java.io.PipedInputStream.read(PipedInputStream.java:291) at java.io.PipedInputStream.read(PipedInputStream.java:361) at sun.nio.cs.StreamDecoder.readBytes(StreamDecoder.java:264) at sun.nio.cs.StreamDecoder.implRead(StreamDecoder.java:306) at sun.nio.cs.StreamDecoder.read(StreamDecoder.java:158) at java.io.InputStreamReader.read(InputStreamReader.java:167) at java.io.BufferedReader.fill(BufferedReader.java:136) at java.io.BufferedReader.read(BufferedReader.java:157) at org.eclipse.rse.internal.services.shells.TerminalServiceShellOutputReader.internalReadLine(TerminalServiceShellOutputReader.java:60) at org.eclipse.rse.services.shells.AbstractHostShellOutputReader.handle(AbstractHostShellOutputReader.java:74) at org.eclipse.rse.services.shells.AbstractHostShellOutputReader.run(AbstractHostShellOutputReader.java:180)(In reply to)I tried this out with dstore and local shells and was not able to reproduce the exception. It only seems to occur when using SSH/Terminals, despite the fact that TerminalServiceShellOutputReader is essentially the same code as it's local counterpart.I believe that was fixed with the. Please reopen if that is not the case.Marking as RC2 since we didn't formally release RC1.Is this maybe related to?(In reply to)I tried this now, and this Exception (exactly same call stack) still occurs for me. Only when I put 15-25 ms sleep between the consecutive readLine() calls, I can avoid the "pipe closed" Exception.Forgot to add version details:RSE End-User Runtime: 3.3.0.v20110601...RSE Core: 3.3.0.v20110601...RSE SSH Services: 3.0.300.v20110601...(In reply to)Clarification: This initial problem with empty lines from readLine(), I am not been able to reproduce now. Only the "pipe closed" one remains.(In reply to)Some more testing revealed that the "Pipe closed" exception has nothing to do with the sleep time between the readLine() calls. It occurs every time, if the runAsShell parameter is set to true.As Anna mentioned on, I think that this is related towhich got fixed only after 3.3.Please upgrade to the latest and retry -Downloads:Update Site:(In reply to)Ah, sorry didn't realize I had to use this other update site (was using)Same error though, with:RSE Core 3.3.1.R33x_v201106281309-7a7JFZ1F9Dyo8ynwUvjic3wHaNTRSE SSH Services 3.0.301.R33x_v201106281309-7A3F9xAGGB5k0C7KEATN92641(In reply to)Well, doesn't seem like I get the same version from the update site (20110628 vs 20110722) ...(In reply to)But, the error is still there even if I download and install manually.	14.0
id=126556	REOPENED	AspectJ	Compiler	DEVELOPMENT	PC Windows XP	P3 major	aspectj inbox	2006-02-06 08:58 EST by	Yoav Landman	2006-06-02 20:04 EDT (	0 users	ITD ignores methods from the declared interface implementation if they are already implemented in the super class of the aspected class.A test case is attached:Method a() will never be generated into B, since it already implemented in the super class A.	Createdaop-test.zipThis looks like another case of @AJ decp not behaving like it would if you did it in code style.Under code style the implementation on the subtype is via ITDpublic void B.a() { System.out.println("---a---"); }and if you do it that way, it works as expected - with the introduced method overriding that in the supertype.Unfortunately my client is not using Eclipse, so the only option for him is to use @AJ...I didn't say it wasnt a bug - it is and it needs fixing if thats possible within the current design of @decp.Remember that @DeclareParents has declare ... implements semantics, not declare ... extends. With implements, the given method declaration is treated as a default implementation to be used if the target type does not provide its own.So the test case is analoguos to the following aspectj program:public class TestDP extends Super { public static void main(String[] args) { new TestDP().a(); }}class Super { public void a() { System.out.println("Super.a"); }}aspect DP { interface I { void a(); } public void I.a() { System.out.println("DP.a"); } declare parents : TestDP implements I;}Which raises an interesting semantics issue. The program above fails to compile (!) warning that the ITD conflicts with existing member Super.a(). I don't believe this should be the case - it is not a conflict as we have declare ... implements semantcis. So there is still a bug here...fwiw, I believe Adrian's code sample *is* a conflict, as defined by the semantics appendix section on point: "Conflicts may occur from ambiguously inheriting members from a superclass and multiple superinterfaces." It would not be a conflict if the existing implementation were in the target class (target class wins over inherited interface implementation) or if the declaration were on the target class (declaration overrides supertype implementation). It should also be a conflict if there are declarations of the same member in multiple interfaces implemented by the target class.I noticed that this bug raises semantic debates, so it has not been assigned yet.On the practical side, many (arguably, poorly written) 3rd party frameworks, including the framework I needed to use, use null implementations that need be overridden by the developer. I was looking to automate this overriding process with AJ.Adrian's point of view wrt "implements" semantic seems logical to me since it behaves like normal java code. This is also the approach taken by AspectWerkz mixins (which I eventually ended up using).Works as expected in 1.5.1_aMy bad (ran wrong tests). Still mismatch between @aj and code style.	9.0
id=121805	REOPENED	AspectJ	Compiler	DEVELOPMENT	PC Windows XP	P3 normal	aspectj inbox	2005-12-21 20:13 EST by	Ramnivas Laddad	2014-01-18 06:20 EST (	3 users	I tried the project reported originally as a part ofwith the latest release (AspectJ 5). While the compiler doesn't crash anymore, I am getting the following error:ambiguous binding of parameter(s) entity across '||' in pointcut UIEntityManagementAspect.ajHere are the aspects:public abstract aspect AbstractEntityManagementAspect { public abstract pointcut entityAccessor(CommonEntity entity); ... advice to the pointcut...}public aspect UIEntityManagementAspect extends AbstractEntityManagementAspect{ public pointcut entityAccessor1(CommonEntity entity) : (execution(* CommonEntity+.add*(CommonEntity+)) || (execution(* CommonEntity+.remove*(CommonEntity+)))) && within(CommonEntity+) && args(entity) && if(entity != null); public pointcut entityAccessor2(CommonEntity entity) : execution(ManageEntity.new(CommonEntity+, ..)) && within(ManageEntity) && args(entity, ..) && if(entity != null); public pointcut entityAccessor(CommonEntity entity) : entityAccessor1(entity) || entityAccessor2(entity); declare parents: Entity implements CommonEntity;}Since entityAccessor1() and entityAccessor2() do not share a selected join point, the collected context should not be ambiguous. This bug is still preventing me from implmenting an elegant solution (without having to repeat the advice) reported as a part of.	The place to fix this is in BcelWeaver.couldEverMatchSameJoinPoints(Pointcut,Pointcut)but here be dragons... it's very easily to return false from this test in too many cases (ie. you think they could never match the same join points, but there's a case you've forgotten). A careful improvement to this algorithm would reduce the number of time we report ambiguous binding when we strictly didn't need to.Well I was going to look at this ... so I wrote this program:class CommonEntity { public void add(CommonEntity ce) {} public void remove(CommonEntity ce) {}}class ManageEntity { ManageEntity(CommonEntity ce) { }}abstract aspect Y { abstract pointcut entityAccessor(CommonEntity entity); before(CommonEntity entity): entityAccessor(entity) {}}aspect X extends Y { public pointcut entityAccessor1(CommonEntity entity) : (execution(* CommonEntity+.add*(CommonEntity+)) || (execution(* CommonEntity+.remove*(CommonEntity+)))) && within(CommonEntity+) && args(entity) && if(entity != null); public pointcut entityAccessor2(CommonEntity entity) : execution(ManageEntity.new(CommonEntity+, ..)) && within(ManageEntity) && args(entity, ..) && if(entity != null); public pointcut entityAccessor(CommonEntity entity) : entityAccessor1(entity) || entityAccessor2(entity);}it only fails at AspectJ 1.5.0:Complex.java:36 [error] ambiguous binding of parameter(s) entity across '||' in pointcut: entityAccessor1(entity) || entityAccessor2(entity); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^at either AspectJ 1.5.1a or AspectJ1.5.2 - it compiles fine (who knows what accidentally fixed it... possibly the fixes in pointcut rewriting...)Join point 'constructor-execution(void ManageEntity.<init>(CommonEntity))' in Type 'ManageEntity' (Complex.java:10) advised by before advice from 'X' (Complex.java:17) [with runtime test]Join point 'method-execution(void CommonEntity.add(CommonEntity))' in Type 'CommonEntity' (Complex.java:3) advised by before advice from 'X' (Complex.java:17) [with runtime test]Join point 'method-execution(void CommonEntity.remove(CommonEntity))' in Type 'CommonEntity' (Complex.java:4) advised by before advice from 'X' (Complex.java:17) [with runtime test]please reopen if you still have similar problems Ramnivasnot sure what on earth is going on now ... this is one of those cases where when run as a set of tests (Ajc153Tests) it fails, when run standalone it works... so reopening this for now until we get to the bottom of the wierdness.is this still misbehaving?(In reply to)Looks like it is still misbehaving, perI believe this may be a case of recording the problem against something other than the current unit being processed - that is why it doesn't always get correctly reported and appears to come and go.Any updates on this bug? I am still facing this issue in eclipse indigo using aspectjI'd recommend splitting up your pointcut into pieces to workaround it.Splitting up pointcut is still not working when I use a single advice and have something like (pointcut1(m) || pointcut2(m))So only option I had is use to use two different advices altogether and have both the advices call another common method.Would appreciate if anyone can provide a workaround using single advice onlyunsetting the target field which is currently set for something already releasedI've found that it is still actual for version 1.7.4.Sample code is:public privileged aspect TestAspect { pointcut checkMethodBecauseOfClass(TestAnn access): execution(* *(..)) && @within(access) && if(in(access, ElementType.METHOD)); pointcut checkMethod(TestAnn access): execution(@TestAnn * *.*(..)) && @annotation(access); before(@NotNull TestAnn ann): checkMethodBecauseOfClass(ann) || checkMethod(ann) { final boolean needStack = ann.stackTrace(); logMethod(thisJoinPoint, needStack); }......}And the compiller's error is:ajc: ambiguous binding of parameter(s) ann across '||' in pointcut	11.0
id=252787	REOPENED	AspectJ	LTWeaving	1.6.1	PC Linux	P3 normal	aspectj inbox	2008-10-30 12:11 EDT by	Wim Deblauwe	2009-07-07 11:08 EDT (	3 users	When using LTW you can get this exception:I am using LTW and I get this exception: [WebappClassLoader@1478a43] warning parse definitions failed -- (SAXParseException) Premature end of file.[INFO] [talledLocalContainer] Premature end of file.[INFO] [talledLocalContainer] org.xml.sax.SAXParseException: Premature end of file.[INFO] [talledLocalContainer] at org.apache.xerces.parsers.AbstractSAXParser.parse(AbstractSAXParser.java:1183)[INFO] [talledLocalContainer] at org.aspectj.weaver.loadtime.definition.DocumentParser.parse(DocumentParser.java:108)[INFO] [talledLocalContainer] at org.aspectj.weaver.loadtime.ClassLoaderWeavingAdaptor.parseDefinitions(ClassLoaderWeavingAdaptor.java:211)[INFO] [talledLocalContainer] at org.aspectj.weaver.loadtime.DefaultWeavingContext.getDefinitions(DefaultWeavingContext.java:121)[INFO] [talledLocalContainer] at org.aspectj.weaver.loadtime.ClassLoaderWeavingAdaptor.initialize(ClassLoaderWeavingAdaptor.java:137)[INFO] [talledLocalContainer] at org.aspectj.weaver.loadtime.Aj$ExplicitlyInitializedClassLoaderWeavingAdaptor.initialize(Aj.java:262)[INFO] [talledLocalContainer] at org.aspectj.weaver.loadtime.Aj$ExplicitlyInitializedClassLoaderWeavingAdaptor.I was using this aop.xml:<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE aspectj PUBLIC "-//AspectJ//DTD//EN" ""><aspectj> <weaver options="-verbose -showWeaveInfo"> <include within="com.mycomp.domain.message.event.hibernate.*"/> </weaver> <aspects> <aspect name="org.springframework.beans.factory.aspectj.AnnotationBeanConfigurerAspect"/> <aspect name="org.springframework.transaction.aspectj.AnnotationTransactionAspect"/> </aspects> </aspectj>The error went away with removing the xml declaration and the DTD declaration.	take a look for 1.6.3 - are we using the parser correctly?I can't recreate this - can you? I am on Java6 (1.6.0_06-b02). If I add those initial lines it works fine. If I remove them it works fine. if I add them and make a mistake in the DTD name, it fails as expected.A google for the SAX problem indicates this can happen if there is a network issue preventing correct download of the DTD. I wonder if this was happening at the time you were having the problem? Can you just retry it now, or perhaps grab the DTD and put it in a local file then change the URL in the DOCTYPE element to point to the local version to see if it helps.closing as works for me - may have been an intermittent network glitch to the eclipse.org servers. please reopen if still a problem.This bug also appears for me. I use aspectj 1.6.2 and Java 1.6.10. Also tried it with aspectj 1.6.4 and with Java 1.6.13 and the same exception is thrown. If I try to take the file locally, I get the same exception.Marius - you need to reopen it, not just cc on a closed bug :)I'll reopen it.I just tried again on 1.6.5 dev builds with java 1.6.0_13 and using the aop.xml file you sent me:---<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE aspectj PUBLIC "-//AspectJ//DTD//EN" ""><aspectj> <aspects> <aspect name="Aspect"/> <include within="package..*"/> </aspects></aspectj>---it worked just fine. Do you *really* need to include the dtd reference in the xml file?I had a similar problem when having 2 aop.xml files in my project (a project with multiple subprojects in maven).Moving all information into one aop.xml file fixed the problem for me.Natan's comment is interesting. In AspectJ 1.6.5 I fixed. That was where the caching of the DTD caused a problem if it was reused (by loading a second aop.xml file for example). It might be that fix addresses this issue too.	7.0
id=385156	REOPENED	AspectJ	Compiler	1.7.0	PC Linux	P3 major	aspectj inbox	2012-07-16 05:13 EDT by	Ivica Loncar	2012-07-17 04:26 EDT (	1 user	Build Identifier: Version: Indigo Service Release 2 Build id: 20120216-1857 AJDT version info:Version: 2.2.0.e37x-RELEASE-20120704-0900AspectJ version: 1.7.0.20120703164200Error log contains:Internal compiler error: java.lang.ClassCastException: org.aspectj.weaver.MissingResolvedTypeWithKnownSignature cannot be cast to org.aspectj.weaver.ReferenceType at org.aspectj.weaver.BoundedReferenceType.parameterize(BoundedReferenceType.java:109)Dialog has a bit more info:java.lang.ClassCastExceptionat org.aspectj.weaver.BoundedReferenceType.parameterize(BoundedReferenceType.java:109)at org.aspectj.weaver.ResolvedType.parameterize(ResolvedType.java:2434)at org.aspectj.weaver.ResolvedMemberImpl.parameterize(ResolvedMemberImpl.java:872)at org.aspectj.weaver.ResolvedMemberImpl.parameterizedWith(ResolvedMemberImpl.java:764)at org.aspectj.weaver.ResolvedMemberImpl.parameterizedWith(ResolvedMemberImpl.java:717 ... Compile error: ClassCastException thrown: org.aspectj.weaver.MissingResolvedTypeWithKnownSignature cannot be cast to org.aspectj.weaver.ReferenceTypeReproducible: AlwaysSteps to Reproduce:The project in which error happens is quite complex and I don't know what causes the exception.	I've cloned git repo and stepped through code.This is stack trace:<pre>Thread [Worker-12] (Suspended (exception ClassCastException)) BoundedReferenceType.parameterize(Map<String,UnresolvedType>) line: 109 ReferenceType(ResolvedType).parameterize(Map<String,UnresolvedType>) line: 2434 BcelField(ResolvedMemberImpl).parameterize(UnresolvedType, Map<String,UnresolvedType>, boolean, World) line: 872 BcelField(ResolvedMemberImpl).parameterizedWith(UnresolvedType[], ResolvedType, boolean, List<String>) line: 764 BcelField(ResolvedMemberImpl).parameterizedWith(UnresolvedType[], ResolvedType, boolean) line: 717 ReferenceType.getDeclaredFields() line: 621 ResolvedType$FieldGetter.get(ResolvedType) line: 284 ResolvedType$FieldGetter.get(Object) line: 282 Iterators$4$1.hasNext() line: 213 Iterators$6.hasNext() line: 288 Iterators$4.hasNext() line: 230 HasMemberTypePattern.hasField(ResolvedType) line: 64 HasMemberTypePattern.matchesExactly(ResolvedType) line: 49 HasMemberTypePattern(TypePattern).matchesStatically(ResolvedType) line: 132 DeclareParents.match(ResolvedType) line: 63 DeclareParents.findMatchingNewParents(ResolvedType, boolean) line: 358 AjLookupEnvironment.doDeclareParents(DeclareParents, SourceTypeBinding) line: 886 AjLookupEnvironment.weaveInterTypeDeclarations(SourceTypeBinding, List<ConcreteTypeMunger>, List<DeclareParents>, List<DeclareAnnotation>, boolean, int) line: 736 AjLookupEnvironment.weaveIntertypes(List<SourceTypeBinding>, SourceTypeBinding, List<ConcreteTypeMunger>, List<DeclareParents>, List<DeclareAnnotation>, int) line: 424 AjLookupEnvironment.completeTypeBindings() line: 261 Compiler.internalBeginToCompile(ICompilationUnit[], int) line: 755 Compiler.beginToCompile(ICompilationUnit[]) line: 381 Compiler.compile(ICompilationUnit[]) line: 426 AjBuildManager.performCompilation(Collection<File>) line: 1028 AjBuildManager.performBuild(AjBuildConfig, IMessageHandler, boolean) line: 272 AjBuildManager.batchBuild(AjBuildConfig, IMessageHandler) line: 185 AjdeCoreBuildManager.performBuild(boolean) line: 105 AjCompiler.buildFresh() line: 100 AJBuilder.build(int, Map, IProgressMonitor) line: 255 BuildManager$2.run() line: 728 SafeRunner.run(ISafeRunnable) line: 42 BuildManager.basicBuild(int, IncrementalProjectBuilder, Map<String,String>, MultiStatus, IProgressMonitor) line: 199 BuildManager.basicBuild(IBuildConfiguration, int, IBuildContext, ICommand[], MultiStatus, IProgressMonitor) line: 239 BuildManager$1.run() line: 292 SafeRunner.run(ISafeRunnable) line: 42 BuildManager.basicBuild(IBuildConfiguration, int, IBuildContext, MultiStatus, IProgressMonitor) line: 295 BuildManager.basicBuildLoop(IBuildConfiguration[], IBuildConfiguration[], int, MultiStatus, IProgressMonitor) line: 351 BuildManager.build(IBuildConfiguration[], IBuildConfiguration[], int, IProgressMonitor) line: 374 Workspace.buildInternal(IBuildConfiguration[], int, boolean, IProgressMonitor) line: 513 Workspace.build(IBuildConfiguration[], int, boolean, IProgressMonitor) line: 432 BuildAction$1.runInWorkspace(IProgressMonitor) line: 305 BuildAction$1(InternalWorkspaceJob).run(IProgressMonitor) line: 38 Worker.run() line: 54 </pre>The offending ReferenceType is actually com.mysema.query.types.ExpressionBase<ApplicationInfo>meaning it's trying to do something with QueryDSL generated classes.The scenario is something like this:- we use "security" aspect which declares common parent on secured objects, and inserts required methods and fields- same objects could be JPA entities, which are processed by the QueryDSL (apt processor which is invoked separately from CLI - we've learned that apt doesn't work well with AJDT)If I manually remove source folder with generated QueryDSL classes AJDT compilation suceeeds.I suspect that QueryDSL generated class triggers this error.Please ignore.The issue was:- querydsl generated classes were not removed properly on Project -> Clean- aspectj (AJDT) found old classes and we got exceptionI have manually deleted querydsl generated classes, regenerated querydsl classes, and AJDT compilation suceeds.OTOH, it would really help us if there were clear integration between AJDT, apt processors and maven.I see more and more maven projects that querydsl in combination with AJDT and while on paper it seems like a match made in heaven, in practice it requires too much error prone configuration magic.I'm reopening this bug to see if there is something we can do here. It might be that querydsl is generating byte-code that AspectJ cannot handle. There are two possibilities, either this is an annotation processor problem, or it is a byte code problem.Were you seeing this error only inside of Eclipse or also when running mvn on the command line? Inside of Eclipse AspectJ is used to compile all source code and Java6 style annotation processors are not supported. From maven, java code is compiled by javac and aspect code by ajc. And the java classes are subsequently woven by aspectj. This means that we can get away with annotation processors that do not affect aspects and new kinds of byte code that is not affected by the weaver.So, if there is anything we can do, it would be on the aspectj side of things.Converting this to an AspectJ project. Ivica, if you can describe a way to reproduce, then we may be able to look at it.Hi Andrew.I generated QueryDSL classes from command line.In the meantime somebody refactored original code and moved some of the JPA entities into a different package.I have updated the code and just regenerated QueryDSL Q classes (notice that I didn't run maven clean or removed previously generated classes).Old version of classes were left untouched in the folder with manually generated sources. Now I had old classes and new classes.When AJDT compiler kicked in I got CCE.I guess that aspectj view of the world was in inconsistent state and it couldn't tell me that I had old code in the source folders.When I say "generate classes" I really mean "generate source code".	6.0
id=350758	REOPENED	AspectJ	IDE	1.6.11	PC Linux	P3 normal	aspectj inbox	2011-06-29 21:46 EDT by	Setya Nugdjaja	2011-07-05 17:20 EDT (	2 users	Hi,After installing AJDT 2.1.2 I've encountered the following exception upon Eclipse restart:org.aspectj.weaver.BCException: Unable to continue, this version of AspectJ supports classes built with weaver version 6.0 but the class org.eclipse.contribution.jdt.IsWovenTester is version 7.0 at org.aspectj.weaver.bcel.Utility.readAjAttributes(Utility.java:83) at org.aspectj.weaver.bcel.BcelObjectType.ensureAspectJAttributesUnpacked(BcelObjectType.java:355) at org.aspectj.weaver.bcel.BcelObjectType.<init>(BcelObjectType.java:146) at org.aspectj.weaver.bcel.BcelWorld.buildBcelDelegate(BcelWorld.java:371) at org.aspectj.weaver.bcel.BcelWorld.resolveDelegate(BcelWorld.java:366) at org.aspectj.weaver.ltw.LTWWorld.resolveDelegate(LTWWorld.java:107) at org.aspectj.weaver.World.resolveToReferenceType(World.java:384) at org.aspectj.weaver.World.resolve(World.java:278) at org.aspectj.weaver.bcel.BcelWeaver.addLibraryAspect(BcelWeaver.java:158) at org.aspectj.weaver.loadtime.ClassLoaderWeavingAdaptor.registerAspects(ClassLoaderWeavingAdaptor.java:432) at org.aspectj.weaver.loadtime.ClassLoaderWeavingAdaptor.registerDefinitions(ClassLoaderWeavingAdaptor.java:267) at org.aspectj.weaver.loadtime.ClassLoaderWeavingAdaptor.initialize(ClassLoaderWeavingAdaptor.java:159) at org.eclipse.equinox.weaving.aspectj.loadtime.OSGiWeavingAdaptor.initialize(Unknown Source) at org.eclipse.equinox.weaving.aspectj.AspectJWeavingService.ensureAdaptorInit(Unknown Source) at org.eclipse.equinox.weaving.aspectj.AspectJWeavingService.preProcess(Unknown Source) at org.eclipse.equinox.weaving.adaptors.WeavingAdaptor.weaveClass(Unknown Source) at org.eclipse.equinox.weaving.hooks.WeavingHook.processClass(Unknown Source) at org.eclipse.osgi.baseadaptor.loader.ClasspathManager.defineClass(ClasspathManager.java:575) at org.eclipse.osgi.baseadaptor.loader.ClasspathManager.findClassImpl(ClasspathManager.java:550) at org.eclipse.osgi.baseadaptor.loader.ClasspathManager.findLocalClassImpl(ClasspathManager.java:481) at org.eclipse.osgi.baseadaptor.loader.ClasspathManager.findLocalClass_LockClassLoader(ClasspathManager.java:469) at org.eclipse.osgi.baseadaptor.loader.ClasspathManager.findLocalClass(ClasspathManager.java:449) at org.eclipse.osgi.internal.baseadaptor.DefaultClassLoader.findLocalClass(DefaultClassLoader.java:216) at org.eclipse.osgi.internal.loader.BundleLoader.findLocalClass(BundleLoader.java:393) at org.eclipse.osgi.internal.loader.BundleLoader.findClassInternal(BundleLoader.java:469) at org.eclipse.osgi.internal.loader.BundleLoader.findClass(BundleLoader.java:422) at org.eclipse.osgi.internal.loader.BundleLoader.findClass(BundleLoader.java:410) at org.eclipse.osgi.internal.baseadaptor.DefaultClassLoader.loadClass(DefaultClassLoader.java:107) at java.lang.ClassLoader.loadClass(ClassLoader.java:248) at org.eclipse.osgi.internal.loader.BundleLoader.loadClass(BundleLoader.java:338) at org.eclipse.osgi.framework.internal.core.BundleHost.loadClass(BundleHost.java:232) at org.eclipse.osgi.framework.internal.core.AbstractBundle.loadClass(AbstractBundle.java:1197) at org.eclipse.core.internal.registry.osgi.RegistryStrategyOSGI.createExecutableExtension(RegistryStrategyOSGI.java:174) at org.eclipse.core.internal.registry.ExtensionRegistry.createExecutableExtension(ExtensionRegistry.java:904) at org.eclipse.core.internal.registry.ConfigurationElement.createExecutableExtension(ConfigurationElement.java:243) at org.eclipse.core.internal.registry.ConfigurationElementHandle.createExecutableExtension(ConfigurationElementHandle.java:55) at org.eclipse.jdt.core.JavaCore.computeClasspathContainerInitializer(JavaCore.java:2752) at org.eclipse.jdt.core.JavaCore.getClasspathContainerInitializer(JavaCore.java:2728) at org.eclipse.jdt.internal.core.JavaModelManager.initializeContainer(JavaModelManager.java:2688) at org.eclipse.jdt.internal.core.JavaModelManager$11.run(JavaModelManager.java:2613) at org.eclipse.core.internal.resources.Workspace.run(Workspace.java:1975) at org.eclipse.jdt.internal.core.JavaModelManager.initializeAllContainers(JavaModelManager.java:2653) at org.eclipse.jdt.internal.core.JavaModelManager.getClasspathContainer(JavaModelManager.java:1845) at org.eclipse.jdt.core.JavaCore.initializeAfterLoad(JavaCore.java:3463) at org.eclipse.jdt.internal.ui.InitializeAfterLoadJob$RealJob.run(InitializeAfterLoadJob.java:35) at org.eclipse.core.internal.jobs.Worker.run(Worker.java:54)Thanks.Setya	Can you take a look at your plugins folder? Look for the org.eclipse.equinox.weaving.aspectj*.jar bundle. What is the full version number there?Do you have ScalaIDE installed by any chance?Hi,It's 'org.eclipse.equinox.weaving.aspectj_1.0.0.v20100108.jar'NoSetyaYou must have somehow gotten a version of org.eclipse.equinox.weaving.aspectj that was compiled under an older version of AspectJ. Can you try this:1. Uninstall AJDT2. Open your Install manager (Help -> Install new software)3. *Uncheck* Contact all update sites...4. Reinstall AJDTThis should ensure that you get the most recent AJDT and that you only get components from the specified update site. Please let me know if this is working for you.Hi,I've tried your suggestion, initially the problem persisted, but then I realized that some projects contained old Aspectj weaver from Spring, so I replace it with the latest one and the problem is gone. I could not reproduce it ever since.Thanks,SetyaThanks for the reply. I am closing this bug, but feel free to re-open if you see the problem again.Resolving as invalid because the problem was not caused by AspectJ or AJDT.Hi,I'm still experiencing this issue every now and then even after using the latest aspectjweaver.jar in my project.Regards,SetyaHi Setya, if you have moved to a new version, can I check the message and stack trace are the same as they were? What version of the equinox weaving plugin do you have now?Hi,I've tried AJDT with Indigo. It seems the problem is gone, instead I've got lots of messages:[org.eclipse.ajdt.ui] error can't determine superclass of missing type org.eclipse.jdt.internal.junit.launcher.JUnit4TestFinder$AnnotationSearchRequestor [Xlint:cantFindType][org.eclipse.ajdt.ui] error can't determine superclass of missing type org.eclipse.jdt.internal.junit.launcher.JUnit4TestFinder$AnnotationSearchRequestor [Xlint:cantFindType][org.eclipse.ajdt.ui] error can't determine modifiers of missing type org.eclipse.jdt.internal.junit.launcher.JUnit4TestFinder$AnnotationSearchRequestorwhen processing type mungers org.eclipse.ajdt.internal.ui.actions.AddAJNatureActionwhen processing type mungers when weaving [Xlint:cantFindType][org.eclipse.ajdt.ui] error can't determine modifiers of missing type org.eclipse.jdt.internal.junit.launcher.JUnit4TestFinder$AnnotationSearchRequestorwhen processing type mungers org.eclipse.ajdt.internal.ui.actions.AddAJNatureActionwhen processing type mungers when weaving [Xlint:cantFindType][org.eclipse.ajdt.ui] error at org/eclipse/ajdt/internal/ui/actions/AddAJNatureAction.java::0 class 'org.eclipse.ajdt.internal.ui.actions.AddAJNatureAction' is already woven and has not been built in reweavable mode[org.eclipse.ajdt.ui] error at org/eclipse/ajdt/internal/ui/actions/RemoveAJNatureAction.java::0 class 'org.eclipse.ajdt.internal.ui.actions.RemoveAJNatureAction' is already woven and has not been built in reweavable mode[org.eclipse.ajdt.ui] error at org/eclipse/ajdt/internal/buildpath/SaveBCAction.java::0 class 'org.eclipse.ajdt.internal.buildpath.SaveBCAction' is already woven and has not been built in reweavable modeWith Helios, I've tried AJDT that comes with Spring's STS, since then it frequently throws :Exception in thread "Queueing Thread (Spring UAA/1.0.2)" java.lang.OutOfMemoryError: PermGen spaceSetyaThe 'cant find type' messages are 'normal' (irritating but normal) when jdt weaving is running.Maybe increase the permgen for helios based STS if you need to? I can't recall the defaults but they can be seen and modified in the STS.ini file, I typically run 384m permgen.	9.0
id=211768	REOPENED	AspectJ	Build	1.5.3	All All	P3 normal	aspectj inbox	2007-12-03 10:40 EST by	Rob Harrop	2013-06-24 11:06 EDT (	1 user	Upgrade the OSGi manifest entries to Bundle-ManifestVersion: 2. This then requires that Bundle-SymbolicName is supplied.	I must do this, just need to work out what they are - maybe I can steal them from the versions in the bundle repo once 1.6.2 is uploaded there.this is done.err, no its not. The manifests for aspectjweaver/aspectjtools and aspectjrt are all incorrect and are patched up by bundlor when they are uploaded to SpringSource Bundle repo. This bug does not relate to the AJDT plugins, but the aspectj jars.unsetting the target field which is currently set for something already released	4.0
id=129989	REOPENED	AspectJ	Compiler	DEVELOPMENT	PC Windows XP	P3 normal	aspectj inbox	2006-03-01 12:21 EST by	Ramnivas Laddad	2013-06-24 11:02 EDT (	1 user	From javac documentation:"The compiler defaults to the version 5 behavior if the -source flag is not used."ajc should match javac in this regard by defaulting to "-source 5".	We previously discounted doing this because of the changes in pointcut matching caused by features like autoboxing (your pointcuts may match more than they used to if you compile with -1.5) - how horrible would it be if all your do is upgrade from ajc1.2.1 to ajc1.5.0 and your program behaves completely differently. Also we have users targetting aspectjrt.jar 1.2 runtimes and certain compiler optimizations that are only activated if compiling with -1.5 (since it is then assumed you are targetting an aspectjrt.jar 1.5 runtime - and these optimizations only work on a 1.5 runtime).If we can be 100% confident we won't cause people pain, we should consider it again. (LTW defaults to java5 if on a 1.5 vm.)How about using the same logic as LTW i.e. if you are compiling using 1.5 vm, then -source defaults to 5? This would cover the most common scenario, where the same VM is used for compiling and executing.It's a reasonable request. If anything it would change to -1.5, and might also include a version check on the java.* classes. But if this fix were to be made, it should have happened in 1.5.0. Regardless of the merits, it would be disconcerting to change ajc defaults, e.g., in a move from 1.5.1a to 1.5.2. We would get tons of support emails, and we don't want that! stalebugsI kind of see the point, but kind of not :-)May be the real bug here is the asymmetry between the compiler and LTW.It appears that if I use compile time and then switch to LTW (both using 1.5),or vice-versa, the behavior will be potentially different.Perhaps the best way to resolve this is to ask users if changing the default is okay with them. If many users are compiling using 1.5 and want pre-1.5semantics, then we should leave as it is; otherwise this may be a good timeto change, before we get more users through Spring 2.0, once its final releaseis out.I must add that this is more of a demo issue than anything else. On realproject, I don't have big problem setting explicit version in the ant buildscript. During demos, such difference from javac attracts attention to unnecessary details.Another potential solution is to have a ajc.default file (which can be overridden through command-line, of course). Much like the way we have forXLint. That way, I can customize my ajc installation to suit my needs.might be time to join the 21st century...unsetting the target field which is currently set for something already released	6.0
id=196991	REOPENED	ATF	Mozilla	unspecified	Macintosh Mac OS X - Carbon (unsup.)	P3 normal	Inbox	2007-07-18 13:31 EDT by	Eugene Ostroukhov	2007-09-14 07:53 EDT (	1 user	1. Open some looped JavaScript.2. Set the breakpoint in the JS so it is hit on each loop cycle.3. Start that JS script in debugger.4. When the breakpoint is hit for the first time toggle "Skip all breakpoints" button.5. Resume the script.6. Untoggle the "Skip all breakpoints"."Progress information" dialog with generic "Operation in progress" message will be shown as soon as breakpoint is hit. The dialog won't complete and Cancel button won't close it. I found to way to access UI after this dialog is shown.Disabling/Enabling or Removing/Adding the breakpoint while script is running won't reproduce the problem.	We cannot reproduce this (tested on Win32 and Mac OS X). If you are still seeing this issue with the latest ATF milestone, please provide the exact test case that you are using.Closing this bug as WORKSFORME. Eugene, if you can provide us with a small testcase that still demonstrates this issue, then please reopen this bug and attach the testcase.CreatedZipped test projectI can reproduce it in 0.2.3 v2007091016501. Set a breakpoint in script.js#42. "Debug in Mozilla" page.html3. When the breakpoint is hit, toggle "Skip All Breakpoints" on the Breakpoints view toolbar.4. Continue the application.6. Give it 15-30 seconds to run and untoggle "Skip All Breakpoints".This is not 100% reproducible but I can reproduce it approx. once for 3 runs.	4.0
id=340658	REOPENED	Buckminster	Core	unspecified	PC Windows XP	P3 major	buckminster.core-inbox	2011-03-22 09:56 EDT by	Jakob Braeuchi	2011-12-20 02:38 EST (	1 user	Build Identifier: Plugin1 depends on Plugin2. A prebind action is defined in the cspex of Plugin1.This Action has a Prerequisite to the bundle.jar Action of Plugin2.When i resolve my Query using an empty Workspace (only Plugin1 resides in the Workspace) all plugins are correctly resolved and my prebind action is called.When the same query is resolved again, the following error occurs:ERROR [0001] : CSpec org.eclipse.datatools.connectivity.db.generic:osgi.bundle$1.0.1.v200908130547 has no action, group, or local artifact named bundle.jarthe attached zip-file contains plugin1 and it's artifacts.Reproducible: AlwaysSteps to Reproduce:1. import plugin1 into an empty workspace2. resolve the query My.query -> prebind action is called as expected3. resolve the query My.query again -> ERROR	CreatedExample Pluginchanged to major because restarting eclipse after running a query is very annoyingA prebind action is called just prior to when a project is bound to the workspace. That's not the case the second time the query runs. If you don't want to restart your IDE, you can simply remove the project for which the prebind should execute. You don't need to remove the actual files, just the project. As a result, the project will be re-bound to the workspace the next time you run a cquery and that will trigger the prebind action.(In reply to)This sounds reasonable. But i do not understand why it works after a restart of the IDE. The project is already in the workspace and the action works as expected.as thomas said, i removed the project with the prebind action and rexecuted the query and the error popped up again.the only thing i can do in this case is restart the workspace.buckminster does not complain about the project with the prebind action itself,the problem comes from a prerequisite that seems to loose it's bundle.jar action when running the query again.	5.0
id=209483	REOPENED	ATF	Mozilla	unspecified	PC Linux	P3 normal	Inbox	2007-11-12 08:05 EST by	Andrew Gaydenko	2009-08-25 17:24 EDT (	5 users	Reason why "blocker" are:- the arch is officially supported by the Eclipse platform,- it is the most widespread arch in current market (well, at least around me),- there *is* possibility to install standalone xulrunner under the arch.	You should be able to run the 32bit XULRunner on a 64bit machine. You need make sure to use a 32 bit Java when running eclipse. Specifying a blocker priority for the bug will not get the XULRunner built. I'm lowering the priority of the bug. My initial reaction when I saw the priority was to close the bug, because I want to make it clear that we do XULRunner builds for the needs of ATF and the team is not in the business of providing XULRunner builds. The fact that you specify in your description "there *is* possibility to install standalone xulrunner under the arch", is a reason for me to close the bug. I understand that the embedded browser support which was moved into the platform is useful, but the builds that ATF provieds are for ATF users. When we do build for other teams/groups it is because we are trying to be helpful, not because it is required. I going to leave this open for now, while I see if I can find someone who can do a 64 bit build. We are looking for people to contribute a 64 bit build. It is time for the community to step up and start providing some of these builds.Robert,OK, I see and understand.Is it too complicated task to build the 64 bit version? I mean, being on 64bit arch, I can do the task if steps can be formalized by somebody :-) I have the Eclipse v.3.3.1 with PDT installed (i.e. built from sources).The XULRunner build uses the Mozilla "make" build system. One of the biggest issue with doing a Linux 64 bit build is setting up a "lowest common denominator" linux configuration for doing the build. We probably can't just do the build on your configuration, because the resulting build would may only run on configurations with the same or later version of the libraries that XULRunner was linked with. Getting the "lowest common denominator" for 32 bit was easy, since it was already determined by Mozilla. We simply copied the configuration of their build machines and built a VMWare image. Since Mozilla isn't building 64bit, we don't have a easy way of determining the best configuration to use. We would also need to package a 64bit JavaXPCOM to go with the 64bit XULRunner build. JavaXPCOM is built as part of XULRunner, but ATF packages it as a separate plugin. I'm going to discuss these issues with some of the other members of the team. We never tried to build a 64 bit version of XULRunner, because we don't have a 64 bit machine. Since the embedded browser support moved out of ATF into the platform, the ATF team has gotten a number of requests for different XULRunner builds or to fix XULRunner problems. The team doesn't have the resources to be the XULRunner build team.I'm not sure what Robert means by "lowest common denominator" on Linux there really isn't a lot of choice. GCC3 or GCC4 linkage, I believe the SWT interface supports both and most Eclipse Mozilla usage I have seen is biased to GCC3 (since systems which use GCC4 natively also support GCC3 through compatibility libraries which are usually installed).As for the rest of the built time options the 64bit version just followed the _SAME_ options as the 32bit version. Sure if you need your own specific version then you need to start doing things yourself (but that situation is the same for the 32bit version too, since there is only one 32bit build as well).So there really is no voodoo with 64bit builds, It is just a case that that the active people working on ATF just don't have access to a 64bit machine, or are not primarily Linux users or simply don't have enough time to do it.(In reply to)I think, Robert means Linux/64bit users still form a small part of overall Eclipse users....Aha, at case there isn't any 64bit-specific magic, I can hope :-)What I meant by "lowest common denominator" is that if you build XULRunner on a newer version of Linux, it won't necessary run on previous version of Linux. At least this is what I have been told by Mozilla. The 32 bit builds were built on Red Hat Enterprise Linux 3. Some people at Redhat have done a 64 bit build of XULRunner and they admit that it doesn't run on all 64 bit version of Fedora core. RedHat has agreed to figure this all out and do the 64 bit build. The ATF team has agree to provided them with the source for the version of XULRunner for the CQ we have submitted to eclipse IP.Closing the issue - it is not more interesting for me (reporter) and, probably, for developers also.Actually it is still interesting and there has been some work done on this.Following is the answer why there's no official Mozilla xulrunner builds for x86_64:Because arguments sound valid and reasonable (better performance and QA), ATF is going to stay with their choice.I'm going to mark this as WONTFIX.And to answer original question, it's possible and recommended to install gtk.linux.x86 build on x86_64 machine.Ok, it's not going to be WONTFIX that fast.Now there's bugopen to bring official support for x86_64. Let's see how it resolves.	11.0
id=351928	REOPENED	Buckminster	Core	unspecified	PC Windows 7	P3 normal	buckminster.core-inbox	2011-07-13 05:12 EDT by	Adolfo Sanchez-Barbudo Herrera	2011-07-29 09:08 EDT (	1 user	As commented in the the forum thread [1], it would be good that at the presence of any kind of error during the qualifier replacement step, buckminster scaled up the exception to notify said error, for instance, to hudson.I've blocked the following build [2] because there are some buckminster warnings related to this issue due to the lack of a proper p2 repository in the artifacts of the lastSuccessfulBuild (in the times the build was executed) so that there was not any repository reference to compare with. The build was successful, however no qualifier replacement took place[3]. From this build I understand that the reference.repository plays some kind of role, indeed.On the one hand, I still full of doubts about how the qualifier replacement works, does it need a repository reference to compare with ? Does the source code management system also participate in somehow during said replacement step ?On the other hamd, I see a couple of actions:1. The easy one: Turning said buckminster warnings into errors, to make hudson build fail.2. The hard one: Investigating if there are other places where any kind of exception may be caught. (Why did I have some plugins qualifier segments replaced and others were not replaced? - Sorry the faulty builds commented in the forum were lost, as soon as the replacement started to work again - )[1][2][3]Regards,Adolfo.	The short story:A missing reference repository from the last build should not have any effect on the qualifier generation. A warning should be printed but nothing more since this is a normal condition. The repository will not exist the first time the build is executed.The fix for this is to catch the ProvisionException, print a (one line) warning, and continue. The version qualifier has already been computed when that exception is thrown so the generator will then succeed.The fix is committed:Since you wanted more details on how things work, here's the long story:The version qualifier will first consult the SCM (cvs, svn, or git) to find the latest modification pertaining to the project. It then tries to figure out if a bundle with the exact same version (with qualifier) can be found in the last successful build. If that's the case, and if that component has a generated build.id stored as a property then some further action needs to be taken.Only plug-ins with an about.mappings file will have receive this property. The about.mappings file is generated by the build and it contains the build.id so when the build.id changes the version qualifier must also change. The current build.id and the stored build.id is therefore compared and if they differ, then the qualifier is regenerated using the current date rather than the timestamp of the latest source modification.Thomas. Thanks for the info...It sounds very interesting and enlightening... So I understand that both reference repository and SCM info are used to generate qualifiers.I guess that when you say "can be found in the last successful build", you mean the reference repositor( which usually we configure to be used by our last hudson sucessful build)... Things start to make sense to me, now... thanksMore comments in line below.(In reply to)But if there is a missing repository, how will the qualifiers be replaced ?. Will the current date be used ? Will the timestamp of last modification be used instead ?. If it's the former case, I think it's better to raise and error and tell the user to use a proper repository or no using anyone, instead of silently generating undesirable qualifiers replacement...I'll do some experiments in local after updating my local Eclipse installation with the new version of buckminster. To ensure that no providing reference repository, it properly generates qualifiers.This also explains why in spite of not making any change to the source code (I'm doing releng changes), some plugins qualifiers are being replaced with the current date of the build... which I find it an inconvenience, and I'll try to explain that.These suspicious plugins are the tipical plugins which work as branding plugins (used by the features), containing the about information (which includes about.mappings with the build.id). This build information is quite useful to see in our features, and I understand that if the buildId changes, then the plugin is different, then we should change the qualifier to use the current build date. However changing the qualifier, when doing a future update, make P2 to download no-necessarily a lightweight plugin again, just for updating a simple buildID. IMHO, an inconvenience from the point of view of an updating process.Some solutions:1- No including build information in our features.2- Splitting out the about information in a different branding plugin, so that it's just a lightweight branding plugin which gets downloaded during an update process.3- Making this qualifier replacement behaviour, configurable from buckminster. Although I'm not sure that this is the right solution...4- Living with overhead in the update process ;PAn interesting discussion to have with my project leader, probably with more cross-project-dev listCheers,Adolfo.(In reply to)The latter.I would advocate #2. Use a dedicated branding plug-in. #3 is not an option since it's extremely bad practice to retain the same qualifier when the bits change.(In reply to)Thinking a little bit more on this issue, the latter may also produce undesirable qualifiers... Think on a plugin with such about.mappings so that with every build its qualifier is replaced with the current date1. first build (no reference repository), lets say v20110303 (timestamp of the last modification)2. second build (we have reference repository), we would have v20110714 (current date, because the buildId in the about.mappings file gets updated).3. third build (no reference repository, we miss it by somehow), we would have v20110303 again.This would imply an undesirable qualifier downgrade in a plugin of our generated repository. It's also true, that the problem would be fixed with the next build (with a valid reference repository), however we would have "silently" (to me a warning, it's not revealing, specially in automated environments) producing incorrect p2 repositories... Perhaps, making the build process fail because we want to provide a reference repository, and the repository is missing or it's corrupted, could be more revealing for the release engineer...Anyway, it's just an opinion, and I understand that this may be considered a "breaking" change, and I guess I could live without it... so it's up to you to adopt it ;)Cheers,Adolfo.BTW,Buckminster -still shows the update from Tuesday. Waiting for Wednesday one to verify the fix.Cheers,Adolfo.(In reply to)Ideally, we could trap the reason why the repository is unavailable. If we were 100% sure that the repository was in fact missing, then that could render a warning while all other causes for not being able to access the repository would be an error. That way, we would support the normal use-case (the very first build is missing the reference repository) while also throwing exceptions on other types of errors. Unfortunately, I don't think we can extract the reason in a safe enough manner to do that.So the choice is between always throw an exception if the reference repository cannot be loaded, and thereby invalidating the normal "first build" use-case, or to print a warning when that repository cannot be accessed. I chose the latter.They are simply opinions... As a modest release engineer, I prefer having an error in my first build, and in every one in which a non-proper reference repository is used, instead of silently generating undesirable qualifiers, therefore p2 repositories... Anyway, it's OK to me ;)BTW, my last build (on master server) produced the abnormal qualifier replacement again:I don't have any idea about why this happens. My feelings, some kind of server fault provokes some buckminster abnormal behavior. Cheers,Adolfo.Thommas,I haven't been able to verify this. In my local Eclipe installation using the last buckminster 3.7 (Buckminster Core - v1.4.0.v20110712-1350 ):I've included the following property in the properties file I'm going to use:buckminster.reference.repository=C:/temp Providing that the folder is empty, after executing the action which produces my p2.repository the following occurs (I'll attatch an screenshot):- Features don't get the forth segment qualifier version replaced. Some feature sources get the qualifier segment replaced.- Plugins don't get the forth segment qualifier version replace. Some plugins sources get the qualifier segment replaced.A lot of "Unable to qualify version" errors appear in the console. For example:[start org.eclipse.ocl:osgi.bundle$3.1.0.qualifier#manifest]Unable to qualify version[end org.eclipse.ocl:osgi.bundle$3.1.0.qualifier#manifest][start org.eclipse.ocl:osgi.bundle$3.1.0.qualifier#about.mappings][end org.eclipse.ocl:osgi.bundle$3.1.0.qualifier#about.mappings][start org.eclipse.ocl:osgi.bundle$3.1.0.qualifier#bundle.jar][end org.eclipse.ocl:osgi.bundle$3.1.0.qualifier#bundle.jar]If I remove that property, all qualifier are properly generated.Regards,Adolfo.CreatedDemonstrating screenshotI nearly forget the SS :)	9.0
id=294142	REOPENED	Buckminster	Core	unspecified	All All	P3 enhancement	buckminster.core-inbox	2009-11-03 19:44 EST by	Ralf Ebert	2012-10-03 11:20 EDT (	15 users	User-Agent: Mozilla/5.0 (X11; U; Linux x86_64; de; rv:1.9.1.4) Gecko/20091028 Ubuntu/9.10 (karmic) Firefox/3.5.4Build Identifier: Provide a simple command and hudson tooling to execute a build as described inwith almost no configuration.Goal: Configure a build for the RCP mail app in an existing Hudson installation in 5 minutes.I'll contribute this till the end of the year.Reproducible: Always	<helindbe> all that is needed is a headless command that takes some input parameters and creates a build model out of itjust like it had read a fileIt can be written as a headless commandthen you would use buckminster's API to create inmemory artifacts corresponding to the files you wrote manually, and then feeding the inmemory artifacts to buckminster for executionrmap and mspec can be done using ecore(In reply to)I'm responsible for the hudson plugin, so once you know what kind of tooling support you need on that side, let me know, and we'll see how we can achive that.Your tutorial came out great btw.With the Eclipse move to Tycho I close that bug. If someone has plans to work on this feature please reopen this bug.With the Eclipse move to Tycho I close that bug. If someone has plans to work on this feature please reopen this bug.Although I don't think anyone plans to work on this feature in the foreseeable future - this is a Buckminster feature and touches on the Buckminster/Hudson integration. This combination is used by many outside of eclipse.org and has nothing to do with any decisions to use Tycho.Afaik, the proposal is still a good idea, but I am not sure if some/all of it is already possible.Reopening. If this issue should be closed it is up to the Buckminster project.	5.0
id=357506	REOPENED	Buckminster	documentation	unspecified	PC Windows 7	P3 normal	buckminster.core-inbox	2011-09-13 10:44 EDT by	Christian Pontesegger	2011-09-16 05:32 EDT (	3 users	Build Identifier: I20110613-1736The installIU parameter of the director application is described the following way:-installIU: a comma separated list of IUs to install. Each entry in the list is in the form <id> [ '/' <version> ].When trying to install a product and a feature by passing-i productID,myfeature.feature.groupI get an error!ENTRY org.eclipse.equinox.p2.core 4 0 2011-09-13 16:38:38.323!MESSAGE Unknown option myfeature.feature.group. Use -help for a list ofknown options.I am able to install both IUs one after the other. It also works when passing-i productID -i myfeature.feature.groupReproducible: Always	This works for me both in Eclipse 3.7 and in the latest builds. Here is the command-line that I am using:./eclipse -application org.eclipse.equinox.p2.director -nosplash -r file:///Users/equinox/export.filters -i fff.feature.group,fff.macosx.feature.groupAre there additional command-line arguments that you have which might be causing problems?(In reply to)My full commandline is:director -consoleLog -r "file:///C:/Build/UpdateSite" -d "C:/Build/Example RCP installed" -i com.example.myfeature.feature.group,com.example.rcp.core.myproduct -p2.os win32 -p2.ws win32 -p2.arch x86I tried moving the -i parameter to the end, but still see the same error(In reply to)Should have read your post more carefully. I am using a standalone director and did not call eclipse with director app.The standalone director uses a batch file to create the command line args for the director app. When prefixing the last line of the batch file with an echo I get:Command:C:\UserData\Build\director>director -consoleLog -r file:///C:/Build/UpdateSite -d C:/Build/ExampleRCPinstalled -p2.os win32 -p2.ws win32 -p2.arch x86 -i com.example.rcp.core.myproduct,com.example.myfeature.feature.groupEcho output:java -jar "C:\UserData\Build\director\plugins\org.eclipse.equinox.launcher_1.2.0.v20110502.jar" -consoleLog -r file:///C:/Build/UpdateSite -d C:/Build/ExampleRCPinstalled -p2.os win32 -p2.ws win32 -p2.arch x86 -i com.example.rcp.core.myproduct com.example.myfeature.feature.groupwhich clearly explains why it is not working.When using eclipse as launcher it works as expectedThanks for double-checking.Closing.(In reply to)The standalone director app seems to be an official download from eclipse:... and it's not working as expected. So this bug might be moved to buckminster but in my opinion it should be fixed, not closed.Yep, I'll move it to Buckminster. I had though the stand-alone app was a script that you had created and didn't realize that it was provided by an Eclipse.org project.As this is a windows problem, I would very much appreciate a patch to the .bat file.(In reply to)Cannot come up with a patch. Seems like windows treats a comma as a natural parameter delimiter.But what works is quoting the list of IUs. So my original parameter need to be modified to-i "productID,myfeature.feature.group"to make it work.If it cannot be patched otherwise maybe this could be documented so that other do not run into this anymore.Agree. I'll move this to documentation.In the docs about headless invocation there needs to be a special note for windows users that comma separated lists must be quoted.	9.0
id=490147	REOPENED	Buildship	General	1.0.12	All All	P3 normal	Project Inbox	2016-03-21 21:54 EDT by	EPP Error Reports	2017-02-07 02:55 EST (	2 users	The following incident was reported via the automated error reporting: code: 0 plugin: org.eclipse.buildship.ui_1.0.5.v20150922-2202 message: Cannot execute command 'org.eclipse.buildship.ui.commands.runtasks'. fingerprint: e96fc811 exception class: org.eclipse.core.commands.NotEnabledException exception message: Trying to execute the disabled command org.eclipse.buildship.ui.commands.runtasks number of children: 0 org.eclipse.core.commands.NotEnabledException: Trying to execute the disabled command org.eclipse.buildship.ui.commands.runtasks at org.eclipse.core.commands.Command.executeWithChecks(Command.java:484)[REQUIRED, TOPMOST] at org.eclipse.core.commands.ParameterizedCommand.executeWithChecks(ParameterizedCommand.java:486) at org.eclipse.e4.core.commands.internal.HandlerServiceImpl.executeHandler(HandlerServiceImpl.java:210) at org.eclipse.ui.internal.handlers.LegacyHandlerService.executeCommand(LegacyHandlerService.java:343) at org.eclipse.ui.internal.handlers.LegacyHandlerService.executeCommand(LegacyHandlerService.java:330) at org.eclipse.buildship.ui.view.task.TreeViewerDoubleClickListener.run(TreeViewerDoubleClickListener.java:56)[REQUIRED] at org.eclipse.buildship.ui.view.task.TreeViewerDoubleClickListener.doubleClick(TreeViewerDoubleClickListener.java:45) at org.eclipse.jface.viewers.StructuredViewer$1.run(StructuredViewer.java:832) at org.eclipse.core.runtime.SafeRunner.run(SafeRunner.java:42) at org.eclipse.ui.internal.JFaceUtil$1.run(JFaceUtil.java:50) at org.eclipse.jface.util.SafeRunnable.run(SafeRunnable.java:173) at org.eclipse.jface.viewers.StructuredViewer.fireDoubleClick(StructuredViewer.java:829) at org.eclipse.jface.viewers.AbstractTreeViewer.handleDoubleSelect(AbstractTreeViewer.java:1470) at org.eclipse.jface.viewers.StructuredViewer$4.widgetDefaultSelected(StructuredViewer.java:1263) at org.eclipse.jface.util.OpenStrategy.fireDefaultSelectionEvent(OpenStrategy.java:252) at org.eclipse.jface.util.OpenStrategy.access$0(OpenStrategy.java:249) at org.eclipse.jface.util.OpenStrategy$1.handleEvent(OpenStrategy.java:311) at org.eclipse.swt.widgets.EventTable.sendEvent(EventTable.java:84) at org.eclipse.swt.widgets.Display.sendEvent(Display.java:4481) at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1327) at org.eclipse.swt.widgets.Display.runDeferredEvents(Display.java:3819) at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3430) at org.eclipse.e4.ui.internal.workbench.swt.PartRenderingEngine$4.run(PartRenderingEngine.java:1127) at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:337) at org.eclipse.e4.ui.internal.workbench.swt.PartRenderingEngine.run(PartRenderingEngine.java:1018) at org.eclipse.e4.ui.internal.workbench.E4Workbench.createAndRunUI(E4Workbench.java:156) at org.eclipse.ui.internal.Workbench$5.run(Workbench.java:654) at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:337) at org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:598) at org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:150) at org.eclipse.ui.internal.ide.application.IDEApplication.start(IDEApplication.java:139) at org.eclipse.equinox.internal.app.EclipseAppHandle.run(EclipseAppHandle.java:196) at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:134) at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:104) at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:380) at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:235) at sun.reflect.NativeMethodAccessorImpl.invoke0(NativeMethodAccessorImpl.java:-2) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:497) at org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:669) at org.eclipse.equinox.launcher.Main.basicRun(Main.java:608) at org.eclipse.equinox.launcher.Main.run(Main.java:1515) at org.eclipse.equinox.launcher.Main.main(Main.java:1488) General Information: reported-by: anonymous-id: 6bdc2b14-48ae-49ac-a3f1-07bf0d6c00b3 eclipse-build-id: 4.5.0.I20150603-2000 eclipse-product: org.eclipse.epp.package.jee.product operating system: Linux 3.13.0 (x86_64) - gtk jre-version: 1.8.0_51-b16The following plug-ins were present on the execution stack (*): 1. org.eclipse.buildship.ui_1.0.5.v20150922-2202 2. org.eclipse.core.commands_3.7.0.v20150422-0725 3. org.eclipse.core.databinding.observable_1.5.0.v20150422-0725 4. org.eclipse.core.databinding_1.5.0.v20150422-0725 5. org.eclipse.core.runtime_3.11.0.v20150405-1723 6. org.eclipse.e4.core.commands_0.11.0.v20150422-0725 7. org.eclipse.e4.ui.workbench_1.3.0.v20150531-1948 8. org.eclipse.e4.ui.workbench.swt_0.13.0.v20150504-0621 9. org.eclipse.equinox.app_1.3.300.v20150423-1356 10. org.eclipse.equinox.launcher_1.3.100.v20150511-1540 11. org.eclipse.jface_3.11.0.v20150602-1400 12. org.eclipse.swt_3.104.0.v20150528-0211 13. org.eclipse.ui_3.107.0.v20150507-1945 14. org.eclipse.ui.ide.application_1.1.0.v20150422-0725 15. org.eclipse.ui.ide_3.11.0.v20150510-1749Please note that:* Messages, stacktraces, and nested status objects may be shortened.* Bug fields like status, resolution, and whiteboard are sent back to reporters.* The list of present bundles and their respective versions was calculated by package naming heuristics. This may or may not reflect reality.Other Resources:* Report:* Manual:Thank you for your assistance.Your friendly error-reports-inbox.This bug was created on behalf of st.oehme@xxxxxxxxxxxx.	For some reason (even though they have the same logic in isEnabled()), the run task command sometimes is disabled when called from the doubleclick listener*** This bug has been marked as a duplicate of***Still a problem in 1.0.12	3.0
id=401306	REOPENED	PTP	RM	7.0	All All	P3 enhancement	Brian Watt	2013-02-20 07:31 EST by	David Wootton	2013-06-04 15:14 EDT (	2 users	I used the class creation wizard to create the control and model classes for the org.eclipse.ptp.rm.jaxb.control.ui.widget extension point.The generated control class incorrectly contained the linepublic class QueryControl implements Control {instead of public class QueryControl extends Control {The generated model class had an import statement for org.eclipse.ptp.rm.jaxb.control.core.ui.IUpdateModel;that could not be resolved. I think the correct import statement should be org.eclipse.ptp.rm.jaxb.control.ui.IUpdateModel;	I've updated the extension point API and documentation.Add some information from an e-mail exchange...The widgetClass' appinfo meta.attribute specifies that the kind is "java" and it is based on ":org.eclipse.swt.widgets.Control" (note the colon) which I think means that it is based upon the interface "org.eclipse.swt.widgets.Control". Oops. So instead I think the metadata should specify "org.eclipse.swt.widgets.Control" (no preceding colon). Also when I run under Kepler I don't see this error [that is, it works right] which means they might have changed the code to scan all entries and regardless of their order figure out which one is the class and which are the interfaces.I've committed a modified the schema so that the widget must extend AbstractWidget rather than Control. This solves a couple of problems:1. The Control class should not be subclassed and is marked as noextend. Clients should subclass Composite instead.2. By providing an abstract base class, it is possible to ensure that the correct constructor is declared.I've tested creating classes from the extension point as Dave describes, and it seems to work ok now. I've also updated the EMS plugin to use the new class.Closing this as fixed. Please reopen if you have concerns or run into problems.Sorry to do this, but I'm reopening...It might now make sense to change the update model class to have a slightly different constructor, that is, instead of passing Control as the last parameter we should pass in an AbstractWidget which, now with your above changes, matches everything type-wise. Also we should change the AbstractUpdateModel constructor to be passed three parameters (the last one being of type AbstractWidget). This should do the same as what you just did for AbstractWidget, that is, by providing an abstract update model base class, it is possible to ensure that the correct constructor is declared.(In reply to)Makes sense. Feel free to make these changes.Reassigning to myself so I don't forget to do it	6.0
id=108085	REOPENED	CDT	cdt-build	3.0	PC Windows XP	P3 normal	cdt-build-inbox@eclipse.org	2005-08-26 04:41 EDT by	steven gay	2005-09-16 20:51 EDT (	2 users	Hello,I am using Eclipse to compile a C++ open-source project (Ogre).A subproject uses a .c file which is not recognised by the "Managed C++ Project"as a file to compile.I must manually configure it to compile with gcc and not g++ !Look at the paragraph "6.1.4 - Compiling glprocs.c" on the instructions I wrote :-_Compile_Ogre_with_EclipseBTW, I discussed this point on the forum :?id=8104&group=eclipse.tools.cdt#8104Furthermore, the Managed Build doesn't recognise .rc files.(see 5.3.2 - Compiling win32 resources (OgreWin32Resources.rc))but I know that there is a feature request for this point.Thanks	The Managed Build System was changed in CDT 3.0 to use Eclipse content-types for defining the inputs to build tools. The positive aspect of this change is that a user can change the set of file extensions that are considered to be part of the content-type. g++ uses the C++ Source file content-type. This does not, by default, include the .c extension. You can modify the content-type for a workspace or for a project. To modify for a project, open the project properties and select "C/C++ File Types". Select "Use project settings" and create a new entry the *.c as a C++ source file.If there is already a feature request for windres, I will close this bugzilla.(In reply to)Wrong. g++ (at least a modern one) recognise .c files and compiles it correctly by automatically calling gcc. Try it with this superb sample :// main.c#include <stdio.h>int main( void ) { printf("Hello World!\n"); }As said in the forum it doesn't work.CreatedC++ project with .c source fileYou need to specify "*.c", not ".c".***has been marked as a duplicate of this bug. ******has been marked as a duplicate of this bug. ***As someone else seems to have a similar problem, it could interest you to know that I still have my problem.Of course, it used "*.c". It was in the bug message that I forgot to put the "*". This doesn't help.Mixing C and C++ in a small, simplistic program works. But not a more complex with countless #define.If you want to try I put a link in my first message.Note that this tutorial was used by hundreds programmers and AFAIK none found a solution !ByeCan you send us the program? We can't fix the problem unless we can reproduce it.CreatedProject containing a .c file which is not recognised.As asked I send you a subproject containing the incriminating .c file.(I removed from the zip the Eclipse workspace because of the 2Meg limit)The project must be compiled in Release.The problem is with the file "DEBUG\RenderSystems\GL\src\glprocs.c".If you "Disable Custom Build Step" I was not able to compile the project.If you need the whole project you can find it (as said several time) on this wiki :See the chapter "6.1 - Build RenderSystem_GL".There is a problem with your project, because you created your custom build step for the .c source file before adding the *.c file extension. That is why I hadn't seen the problem in any other projects.There are two parts to the problem. One part has to do with generating the makefiles. I have checked in the fix for that. The second part has to do with editing file properties for a file where the file properties were edited before the file extension was associated with a tool. I don't have time to fix that part now, so we'll leave this report open. I'm changing the Summary to be more specific. Note for later: The problem is that the resource configuration code does not expect the build tool associated with a source file to ever change once the ResourceConfiguration is created.I'm attaching a hand-modified .cdtbuild file that should work better for you. You can leave your .c file using the custom build step, or remove the custom build step.CreatedRenderSystems\GL\.cdtbuild	11.0
id=146827	REOPENED	CDT	cdt-build	3.1.1	PC Windows XP	P3 major	cdt-build-inbox@eclipse.org	2006-06-13 10:05 EDT by	Tiziano Leidi	2007-09-19 16:24 EDT (	1 user	1) Managed Build C Projects Proj1, Proj2, Proj32) Proj1 import Proj2, Proj2 import Proj3, Proj3 import Proj13) do something in the workspaceevery operation in the workspace (even outside Proj1/Proj2/Proj3, even on files that have nothing todo with CDT) causes autobild to start compilation.	There were some major changes and enhancements made in the Managed Build System build/rebuild mechanism and I can not reproduce the issue you describe with the current CVS HEAD CDT sources, so I'll mark this as fixed for now.Please re-open if you see this issue happen with one of the latest CDT 3.1 nightly builds or with the CDT sources from CVS HEAD.NOTE: CDT 3.1 requires eclipse 3.2MikhailThis bug is still present in CDT 3.1.1 !if there is a cyclic import between two projects, Autobuild get nervous and react to most of workspace changes.If the cyclic import is removed autobuild behaviour gets back to normality.	2.0
id=199280	REOPENED	CDT	cdt-build	4.0	PC Windows XP	P3 normal	cdt-build-inbox@eclipse.org	2007-08-08 12:20 EDT by	Mikhail Sennikovsky	2009-10-02 08:56 EDT (	1 user		I guess we should enable the Build Output Parser mechanism (parsers specified via the Discovery Profile mechanism) to be used with the Internal Builder invocation es well as for the make builder invokationSince the Internal Builder is used for the Managed builds only, I don't think it is necessary to have a console parser functionality since includes/symbols information gets picked from option values for the "managed" mode.I'll mark it as INVALID for now..(In reply to)Right now the Managed Builder uses scanner discovery to determine all the built-in includes and symbols for GCC by doing a fake build on a specs.cpp file and putting the compiler in verbose mode. GCC then spits out -I and -D output for all the includes and macros used in the compilation, and this is parsed back.It's difficult to specify via hidden "builtIn" option values all the macro defines because they are typically very platform dependent, and thus the number of permutations (especially for a compiler so prevalent as GCC) becomes too many to manage.(In reply to)I'm not talking about replacing the "builtin" calculation via option's builtIn values, but rather about the way the build output is parsed during the build, i.e. about the explicit -I option values, which are picked up by the Managed Build system automatically. Why would you need the build output parsing for the internal builder?(In reply to)I was just saying that if you don't have scanner discovery, then the only way to represent the built in macros and includes is via the options, which is cumbersome. I wasn't saying that I thought you were changing the option builtIn mechanism.In a typical scenario I don't see MBS needing to parse back the output of the regular build, but I am saying that MBS under the hood needs to be able to invoke its own secret fake build and parse that back, so the mechanism still needs to exist.Also, users are allowed to put whatever they want in the "other options" text boxes. If they put -I or -D directives in there, then without scanner discovery these will be missed.	5.0
id=195208	REOPENED	CDT	cdt-build	4.0	PC Windows XP	P3 normal	cdt-build-inbox@eclipse.org	2007-07-02 23:12 EDT by	li.longjiang	2010-05-19 14:05 EDT (	1 user	Build ID: Eclipse SDK 3.3.0 RC4 I20070608-1718Steps To Reproduce:after set exclude from build in secon level directory of a MBS project,the second level directory disppeared. when the elipse restart,the disppeared directory appeared again, and the directory image show error status(show as exclude).1.create a MBS project,it include a directory named src1,and the src1 include a sub directory name src11.2.set src11 exclude from build.3.the src11 disppeared in C/C++ proejct view.More information:	I use cdt cdt-master-4.0.0-I200706261300.Createdsample projectCreatedbefore set excludeCreatedset_src11_excludeCreatedafter_set_excludeCreatedset_src11_not_excludeCreatedsrc11_disppearedCreatedafter_restartfrom the Attachment images ,we could see the reproduce method in detail.thanks.This is probably related to the CModel problems we're getting elsewhere. Althought in those cases, we're getting duplicate folders, not removed folders.I currently can't reproduce this on CDT HEAD (4.0.1). I'll keep trying...I do not see this problem in HEAD. We've did some work in the final week of CDT 4. Please try with the final bits and see if you can still reproduce this. I'm mark as fixed in 4.0 for now.hi,Doug Schaeferthanks your reply.I'll validate this bug in cdt 4.0.1.When will the cdt begin build 4.0.1 and provid the binary plugin's download link?We should start any day now. I see now that you were using the final CDT 4. I'll reopen this bug to take a deeper look.hi,Doug Schaeferthanks your reply.BTW,in the attachment--after restart image,we could see a small bug--the folder status has error.thanksli.longjianghi, Doug SchaeferI'm sorry to disturb you.When would you fixed this bug?Thanks,li.longjianghello,I've verified the bug in the latest cdt 4.0.1. the bug of second level directory disppeared after set exclude from build in secon level directory of a MBS project seem to fixed. but i found the directory image of the folder show error status seem to not be fixed.1.I found that the folder initial status did not show exclude status.2.after set exclude checkbox the sourcefolder image changed to common fold image.Createdbefore set excludeCreatedafter set excludeI also found that the project couldn't build properly after the source folder status in error status.so now i think the problem is not a small bug,i hope CDT Core member could pay more attention to this bug.thanks.li.longjiang(In reply to)Current status of that bug:+ Doubles and disappearance of folders seems to be fixed. I do not see any of that in CDT 7.0 on HEAD.+ As I understand, after setting exclude status the folder stops being source folder and so its image changes to common- Excluded status of folders on second level is not persistent.- Currently excluded folders are not marked in the view with the overlay at all (and the code in CProjectDescriptionManager.baseSettingsCustomized() is commented out)Changing subject line to reflect remaining problem	21.0
id=108207	REOPENED	CDT	cdt-build	3.0	PC Linux-GTK	P3 major	cdt-build-inbox@eclipse.org	2005-08-27 21:06 EDT by	None	2008-02-02 11:08 EST (	1 user	I am attempting to run Eclipse v.3.1 on an AMD Athlon64 with kernel 2.6.13-rc5and Gentoo. I have attempted to run both the Sun JDK 1.5.0 and 1.6.0 beta (both64 bit versions), and both exhibit the same behavior. The most noticeableproblem for me is that I receive a typical "Out of Memory" dialog after buildinga few times. When this happens, I also receive the message posted at the end ofthis report. I have attempted a few different sets of vmargs, and all behavesimilarly. Most recently, I have run it with the args:-vmargs-Xms1024m-Xmx1024m-d64(I also tried this omitting the -d64 flag)I even doubled my RAM to 2GB to see if the problem would go away. Good excusefor a RAM upgrade I guess. :-)java.lang.UnsatisfiedLinkError: no spawner in java.library.path at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1682) at java.lang.Runtime.loadLibrary0(Runtime.java:821) at java.lang.System.loadLibrary(System.java:992) atorg.eclipse.cdt.utils.spawner.ProcessFactory.<init>(ProcessFactory.java:35) atorg.eclipse.cdt.utils.spawner.ProcessFactory.getFactory(ProcessFactory.java:47) atorg.eclipse.cdt.utils.spawner.EnvironmentReader.getEnvVars(EnvironmentReader.java:49) atorg.eclipse.cdt.core.CommandLauncher.getEnvironment(CommandLauncher.java:67) at org.eclipse.cdt.make.core.MakeBuilder.invokeMake(MakeBuilder.java:147) at org.eclipse.cdt.make.core.MakeBuilder.build(MakeBuilder.java:76) atorg.eclipse.core.internal.events.BuildManager$2.run(BuildManager.java:593) atorg.eclipse.core.internal.runtime.InternalPlatform.run(InternalPlatform.java:1044) at org.eclipse.core.runtime.Platform.run(Platform.java:783) atorg.eclipse.core.internal.events.BuildManager.basicBuild(BuildManager.java:168) atorg.eclipse.core.internal.events.BuildManager.basicBuild(BuildManager.java:202) atorg.eclipse.core.internal.events.BuildManager$1.run(BuildManager.java:231) atorg.eclipse.core.internal.runtime.InternalPlatform.run(InternalPlatform.java:1044) at org.eclipse.core.runtime.Platform.run(Platform.java:783) atorg.eclipse.core.internal.events.BuildManager.basicBuild(BuildManager.java:234) atorg.eclipse.core.internal.events.BuildManager.basicBuildLoop(BuildManager.java:253) atorg.eclipse.core.internal.events.BuildManager.build(BuildManager.java:282) atorg.eclipse.core.internal.events.AutoBuildJob.doBuild(AutoBuildJob.java:139) at org.eclipse.core.internal.events.AutoBuildJob.run(AutoBuildJob.java:200) at org.eclipse.core.internal.jobs.Worker.run(Worker.java:76)Warning: Could not get charToByteConverterClass!Unhandled event loop exceptionReason:unable to create new native thread	I apologize, I somehow ended up pairing up too old a version of CDT with Eclipse3.1. I'll reopen this if the problem reoccurs.This bug is still present in v.3.0 of CDT. The only difference is that I nowreceive this message immediately upon startup:Warning: Could not get charToByteConverterClass!And, the message I receive after the out of memory condition has been shortenedto this:Unhandled event loop exceptionReason:unable to create new native threadIf someone has a 64-bit x86 box and wants to test and debug this we could use the help. Otherwise I don't think this will be resolved any time soon.are you adding this to eclipse.ini?or the JVM Setting in "Installed JRE" within eclipse...adding this "-Xms256m -Xmx1024m" as "Default VM Arguments" worked for an out of memory problem i had recently.	4.0
id=214324	REOPENED	CDT	cdt-build	4.0.1	All All	P3 major	cdt-build-inbox@eclipse.org	2008-01-04 05:19 EST by	Andras Varga	2010-10-09 14:06 EDT (	3 users	Build ID: M20070921-1145Most code in the CDT lacks Javadoc comments, or any kind of helpful comments at all. This is in sharp contrast with other Eclipse projects I've seen, where public APIs are usually well documented.Lack of comments is a very high barrier for anyone who wants to contribute to CDT or integrate with it.	100% agree... But, I think this bug will be completely ignored.Yeah, it would be hard to judge when it's fixed. When more than half of the CDT is less than totally undocumented? I think half the classes have at least one comment so this may already be fixed. Please advise.BTW, jokes aside, this is a well known issue and we are actively looking for solutions. None are easy, though.(In reply to)On the surface the solution seems pretty darn simple: everyone just start writing comments! ... But the difficult problem isn't the lack of comments, its a lack of motivation to write them.This is a difficult problem. In a community of non-documentation-writers a sole documentation-writer will be at a disadvantage. Time spent documenting is time taken away from coding. The documentation-writer would be making a sacrifice while the other committers would get more work done.The problem here is the definition of "work done". Currently in CDT land "work done" is defined as having some working code with a few JUnits. We need to redefine "work done" so that it includes high quality API and source level comments, and additional design docs or wiki docs for larger features/components. (I also think we should be doing more code review.)How do we enforce this? I'm not entirely sure it can be strictly enforced. The word "community" gets thrown around a lot, so instead of enforcement writing docs needs to be part of the culture of the community. It should be something we all do just because its the right thing to do. Like saying please and thank you is the accepted thing to do in polite society. Maybe that's the motivation we need, a general acceptance of certain community values. For example, there is no law enforcing politeness, but if you act rude then you will be frowned upon and won't get invited to parties. Similarly writing docs should be the "polite" thing to do, and if you don't do it you risk losing the approval and respect of your peers.Unfortunately right now writing documentation is not a shared value in the CDT community.The comments I miss most are the class-level comments of interface classes (ISomething) and very central manager classes like ManagedBuildManager and CoreModel -- that would already be an immense help for all new to CDT.If I know what a class is for, and what relationship it has to other classes (like, IManagedBuildInfo --> "managed by ManagedBuildManager, holds configurations, and is live data structure loaded/saved via ICProjectDescriptions"), then figuring out methods is already much-much easier. So if there's **really** a willingness to improve, that's what I'd suggest to start with: class-level comments for all ISomething classes and a handful of other, very central classes.I can try and help, but it would be better if original authors or current maintainers of classes would take some minutes/hours of their times to do it. Despite having studied parts of CDT and writing up dome of my experiences at, I don't feel I'm qualified enough. Well, for a start I could try putting down what I currently know, if CDT team members are willing to revise and expand it. I also think that documenting the code would have benefits for the developers too:1) less traffic of stupid questions in [cdt-dev]. If it's documented, it won't be asked (or and replies can be shorter, possibly just RTFC)2) help fellow developers build upon my code, and with less misunderstandings. Like, who the hell knows what ICSettingEntry.RESOLVED means, and whether I need to set it if I create a CSettingEntry on my own??? I need to spend half a day hunting for occurrences in the source code, in order to deduct what it can be possibly used for; and in the end there's still a good chance that I misunderstood something. And maybe then my code will mislead other developers too, and so the plague spreads....3) this may sound strong, but on the long term, it may just be vital to the survival of the CDT code. There are already multiple generations (2.x, 3.x, 4.x) of data structures intertwined, with heaps of code doing mapping between them, possibly involving "tweaks" (think IConfiguration and ICConfigurationDescription, and all the code to keep the two consistent), lots of utility and "manager" classes, etc. Do REALLY all CDT team members know 100% what class is for what, what's the old/deprecated way and what's new/preferred, how to keep things consistent, etc.....? Documenting things would help staying on top.Today's post on cdt-dev:| Subject: [cdt-dev] Need info on CPPUnknownClass|| Hi Andrew, Bryan and Doug,| For understanding issues related toI need background information| on ICPPInternalUnknown, CPPUnknownClass, CPPUnknownScope and few related| classes.| 1. What do CPPUnknownClass and CPPUnknownScope classes represent? What is| the basic idea behind them? What purpose do they serve? | 2. Why are there no PDOM equivalents? Should they be added?| 3. Why does CPPTemplateTypeParameter implement ICPPInternalUnknown, but| PDOMCPPTemplateTypeParameter does not?| 4. Why doesn't CPPTemplateTemplateParameter have a PDOM equivalent? Should | it be added? | Any insight will be highly appreciated.|| -sergeyAs if he was posting it exactly to support my points... 1. so it indeed *does* happen that CDT developers themselves are not sure what purpose some class serves -- docu would benefit them too 2. what he misses (esp. in bullet 1) is exactly what should have been written down in the class-level doc of those classes in the first place. This seems to confirm that documenting should begin with class-comments of interface classes and a few central classesNow he cannot continue for a few days, until he actively gathers all information he needs. This delay and wasted effort could have been spared (but at least reduced) by the author of those classes spending 10 minutes on writing a useful class comment.(In reply to)See, thats the thing, I don't believe there is a willingness to improve. We get comments all the time that are related to lack of docs and the policy hasn't changed. Some of the newer APIs in CDT are commented, like the IIndex API. But the vast majority of the code is undocumented.Absolutely, this happens all the time. Also, having docs makes it much easier and faster for new contributors to get up to speed. When I first started on CDT it took me a long time to get even a bit comfortable with the core.I agree, sure you can save ten minutes by not commenting your code, but you are causing several other developers to waste more then ten minutes each trying to understand the code. Documentation can be thought of as an investment in overall team productivity.In my opinion this is a major issue. There are a couple very active commiters on the CDT core and I wonder what would happen if any one of them decided to quit working on CDT. Certain individuals have a lot of intimate knowledge of CDT internals, but that knowledge hasn't been written down. If a key individual left it would create a major stall in development. The developers that would take over would have nothing but a huge heap of undocumented code to deal with.There is a willingness to improve and as I mentioned we are actively looking for solutions. As with all projects, the CDT is strapped for resources and we appreciate all help in cleaning this up. But whatever you do, please don't interpret the lack of progess on willingness.(In reply to)>You do need to understand the history and structure of the CDT. We are all CDT developers. The fact that you are looking at the code makes you a CDT developer too. As you learn about the code you are reading, and given your enthusiasm for the issue, I should be able to expect patches with new documentation from you, no?Second, the code Sergey is talking about was written in haste to meet deadlines by developers that no longer work on the CDT. It would be a hell of a lot easier if we didn't have turnover or fixed deadlines, but that is the fact of life that we have to endure on the CDT and what makes solutions even more difficult.(In reply to)If there really was willingness then there wouldn't even be a problem. In fact the real problem here is exactly the lack of willingness, the lack of motivation. How are we actively looking for solutions? What potential solutions have been considered?I have done exactly this in the past. I wrote up a wiki page describing how the DOM parsers work, then I posted a link to the dev list. That dev list post got zero replies. Not one correction to the docs, not one single reply saying "thanks for writing documentation". So you can see why I personally believe that the documentation issue is being ignored.And wouldn't it make much more sense for the author of the code to write the docs, especially when its fresh in his mind.This is a very weak argument. This is like saying that you can't jog a mile because the earth's atmosphere doesn't contain enough oxygen. Deadlines are an environmental constant, they will always be there, they are not unique to CDT, and they are not an excuse.Furthermore, as I have pointed out, documentation has the potential to *increase* productivity. And turnover becomes less of an issue if you have docs because new developers can get up to speed quicker. It seems to me that docs would actually help improve the issues you mention here.And really, how long does it take to put in a simple "this is what this class is for" description.(In reply to)Well, Mike, it sounds like you're motivated. I look forward to any solutions you come up and your efforts to achieve buy-in from the CDT community. I will certainly support you on this.In the meantime, I intend to follow through with the committment I made at the CDT Summit to get the ISV docs going in CDT 5.0.Doug, Nobody's in a better situation to actually do something than you. You are the CDT Project Lead. If you publicly say documentation is important, people will listen.If you say, that, for example, by CDT 5.0 you'd like to see all public interface classes to be documented on class level, it may actually happen. For the next milestone, you may ask X to document interface classes in package org.eclipse.cdt.blah (class level comments only), ask Y to document classes in package org.eclipse.cdt.blahblah, and so on. That's maybe 2-3 hours of their time? Won't kill them. They've all wasted much more time in the past, on figuring out undocumented classes written by someone else.It's all on you. If you need to be convinced that it's worth it, re-read previous comments. If you don't act, that will be also a testament of something.Exactly.(In reply to)I have and that is what I'm referring to with the ISV docs I've committed to get going. We did have a good discussion on this at the CDT Summit. The committers are aware of it. But it will take time to get together, especially given that I'm trying to get up to speed on my new job.Doug,Writing CDT documentation for ISVs is very welcome and going to be very useful. However, it sounds like standalone docs -- how is that going to solve the problem of missing source code comments? What are you as Project Lead going to do about missing source code comments?Encouragement? Policy? Goals? Deadlines?(In reply to)Well, much of the ISV docs will be generated from Javadoc, we'll at least get comments for the APIs.I've already encouraged. The CDT committers are all professional developers. They already know the value of code documentation. And to be honest, the code you are complaining about was written by people no longer contributing to the project, so there's not much I can do there.And to be further honest, we really do have bigger issues than the shortage of code comments that need my attention in the short term. That is why I am looking for help from the community to drive this issue.(In reply to)Clearly some don't because if they did they would be writing it. If this were true we wouldn't be having this discussion (or flame war, I'm not sure anymore).This is probably true for existing code that isn't commented. Many of us don't have time to go back and dig through old code at this point in the cycle. But after the 5.0 release would be a perfect time to take a breath, relax, then go on a refactoring and documentation frenzy over the summer. This is an example of a potential solution that we should be discussing here instead of arguing back and forth. New code thats being written right now is different. Everyone should be commenting their code as they go, starting right now. I find its really not an issue at all to write comments as I code. Sometimes I'll be in the middle of describing my solution and I'll realize that I forgot a corner case. Writing docs as you go forces you to think twice about your solutions, and that leads to better code.And frankly it seems to me that you just want this issue to go away. Thats not going to work, we need to do something. We need to work together, arguing is not helping.We should still try to go back and do something at some point. In fact its the older code thats the worst offending in many respects. Again, I suggest a major refactoring pass when the heat is off. Taking a break from writing new features and just focusing on improving existing code for a bit would help greatly. (In fact I think cleaning up the code itself is even more important than comments.)Right, the community is the key here.Doug, if you really want me to take the lead on this I will. But frankly I don't think I have enough clout in the CDT community to make much of a difference. But if you say you will back me up then I'll try. All I can think of right now is to to create a discussion on the cdt-dev list, get the community to work together to come up with a set of official CDT best practices, and perhaps take a vote on it. I guess it would be unofficial but if we actually followed it that would be a big win for CDT.Well its been a week since I posted what I thought was a real potential solution, and there has been no replies.Screw it, I'm not going out on a limb for this. I would need backup from you Doug anyway, and your lack of reply means I can't count on you for that, even though you said you would support me, I just don't believe it.Besides, new documentation policies are not my job, its your job as project lead. And if you don't see the problem here, then so be it. CDT will remain mostly undocumented, and that will be the official policy. Case closed.I will continue to fully comment my own code, but I'm not wasting any more of my time discussing this issue.Closing this bug as WONTFIX.Reopening because the problem still exists, and it is a real problem.	17.0
id=235328	REOPENED	CDT	cdt-build	5.0	PC Linux-GTK	P3 normal	cdt-build-inbox@eclipse.org	2008-06-03 09:28 EDT by	CDE Administration	2009-08-19 11:13 EDT (	6 users	<response_by> Mostafa Ali at 2008.06.02.17.52.48 </response_by>OS: LinuxBuild date: 0601Component/Function name: CDTLanguage: ArabicTester Name: Mostafa AliSteps to recreate the problem:In the C/C++ Projects view, right click on project xlc and select Properties.Select C/C++ Build -> Settings.On the Tool settings tab, select Input Control under XL C++ Compiler.Verify the highlighted areas are translated (scroll down to verify all strings).Problem description:There are several reversed parentheses, plus, the drop down menu items are not translated<response_by> John Ryding at 2008.06.03.08.06.17 </response_by>This article was reassigned from Category:''TVT/Testing,Inbox''.	Created05.001930.jpg<cde:tctdetail>Testcase: 05.001930Project: WSW34Component: Xfer - CDT/cdt-buildPriority: 2Subject: The parentheses are reversed, and the menu items are not translatedArticle ID: 704Originator:</cde:tctdetail>The untranslated strings are fixed in*** This bug has been marked as a duplicate of***<response_by> Mostafa Ali at 2008.06.09.08.34.46 </response_by>Hi,The closing parenthesis problem is fixed, but the strings are missed up. What I want is to keep the order of the strings as they were and just correct the closing parenthesis direction.Attached is an example of the missed up strings.ThanksMostafaCreated05.001930_b.jpgThis might be related to.<response_by> John Ryding at 2008.06.12.11.29.26 </response_by>This has been deferred. It will be considered for the 3.4.1 service pack.*** This bug has been marked as a duplicate of***reopen. this is the reserved paratheses problem.The status of the article and the state of the corresponding problem may be out of sync.](In reply to)Hi Felipe, I'm already using the TextProcessor API to process the string as seen in 05.001930_b.jpg but I'm still not getting the correct ordering. Do you have other suggestions for me? Kit mentioned that this might be occurring because there is an English string in the middle of the BIDI string.Sorry, I didn't read the whole report last time around.This can be a dup of.What is the String ? Does it start with an English word ?This is the string and it does not start with any English word:Option.cinc=\u0627\u062F\u0631\u0627\u062C "C" {} \u062E\u0627\u0631\u062C\u064A \u0641\u064A \u0645\u0644\u0641\u0627\u062A \u0627\u0644\u062A\u0636\u0645\u064A\u0646 \u0627\u0644\u0645\u062D\u062F\u062F\u0629 (-qcinc)works for me. I set this string as it is in a Label, Text, and StyledText and it works fine.Are you sure this string is set exactly like that ? Doesn't the TextProcessor change the string ?In the case of this string the bidi algorithm needs help.But, IMO, TextProcessor API is not what you want, see my comments in.IMO this string should be fixed the the catalog file, the right form should be:"\u0627\u062F\u0631\u0627\u062C \"C\" {} \u062E\u0627\u0631\u062C\u064A \u0641\u064A \u0645\u0644\u0641\u0627\u062A \u0627\u0644\u062A\u0636\u0645\u064A\u0646 \u0627\u0644\u0645\u062D\u062F\u062F\u0629 (\u202A-qcinc\u202C)";-> the english text in this case needs to be surrounded with a left-to-right embeding mard and a pdf. Please, have a hebrew/arabic translator to confirm this.In another words: this is a bug in the translation not in the code.Hello,if you mean left-to-right marker, I already tried this during the TVT and it didn't work. It is written in your response (left-to-right embeding mard), but I guess this means marker.I don't understand what you mean by (a pdf) in the text? Does it mean to convert the string to pdf or what? I am not sure what you are pointing to here.Finally, I don't think this is a translation problem because there are a lot of similar cases in other components and they are displayed correctly.ThanksI really meant:U+202A: LEFT-TO-RIGHT EMBEDDING (LRE) U+202C: POP DIRECTIONAL FORMATTING (PDF) I think the mark you are talking about is something different:U+200E: LEFT-TO-RIGHT MARK Try the string I paste in, doesn't that work good in LTR and RTL ?Can that string be store in the catalog ?Please, ask somebody else with lots of experience with the bidi algorithm if what we are doing here is the right thing. The smartest guy I know in this area is probably Matitiahu Allouche. Tomer Mahlin is also pretty good.Strictly speaking the problem discussed here does not belong to "Message with placeholder" type of complex expression since the message does not include any placeholder replaced by run time data. In other words the entire message is coming from resource file. From this perspective I agree with Felipe (see) that the problem should be resolved in translateion, not in the code. In other words using of TextProcessor is not going to resolve anything in this case. Having said that I do see the issue closely related to the problem of complex expressions of type "Message with placeholder". This is for a very simple reason - all messages mentioned in this defect have translated and not translated portions. All pieces of text which are not translated can be viewed as placeholders replaced with Latin data. For those pieces of data LTR direction should be enforced. This method (enforcing direction for placeholder in a text message) is described in following defects:* Design articulated by Bidi architect - Mati can be found in section 3.8 "Message with placeholders" at:* The implementation and best practices (aka algorithm) for using thisimplementation for resolution of similar issues were suggested inSome basics:------------- To enforce direction of a piece of text regardless direction of possibly present surrounding text use following method: a. To enforce LTR direction: myText = LRE + LRM + myText + LRM + PDF b. To enforce RTL direction: myText = RLE + RLM + myText + RLM + PDFHow this method should be applied to the examples discussed in this thread ?----------------------------------------------------------------------------Example 1: Please see attachement infor illustration. One of the messages in this case is as follows: Compile any file as a c++ file (-+) I believe that in the translated form it should look as follows: (-+) ELIF c++ A SA ELIF YNA ELIPMOC To achive this display you need to enforce the direction of "(-+)" and "c++" to LTR. This means that using mentioned above method you should have in the resources something like this: COMPILE ANY FILE AS A <LRE><LRM> c++ <LRM><PDF> FILE <LRE><LRM> (-+) <LRM><PDF>Example 2: Please see attachement infor illustration. Another message in this case is as follows: Insert extern "C" {} in the specified include files (-qcinc) In my humble opinion in the translated form it should look as follows: (-qcinc) SELIF EDULCNI DEIFICEPS EHT NI extern "C" {} TRESNI Please notice that the word "extern" should not be translated since it is part of the directive which is suggested for insertion. Using mentioned above method you should have in the resources something like this: INSERT <LRE><LRM> extern "C" {} <LRM><PDF> IN THE SPECIFIED INCLUDE FILES <LRE><LRM> (-qcinc) <LRM><PDF>Example 3: Please see attachement infor illustration. The message in this case is as follows: Specify an additional search path for #include s(-I) I believe that in the translated form it should look as follows: #include s(-I) ROF HTAP HCRAES LANOITIDDA NA YFICEPSUsing mentioned above method you should have in the resources something like this: SPECIFY AN ADDITIONAL SEARCH PATH FOR <LRE><LRM> #include s(-I) <LRM><PDF>Example 3: Please see attachement infor illustration. The message in this case is as follows: Control the interopertaion of and subsequent generation of code for asm statement (-qasm) I believe that in the translated form it should look as follows: (-qasm) TNEMETATS asm ROF EDOC FO NOITARENEG TNEUQESBUS DNA FO NOITAREPORETNI EHT LORTNOC Using mentioned above method you should have in the resources something like this: CONTROL THE INTEROPERATION OF AND SUBSEQUENT GENERATION OF CODE FOR asm STATEMENT <LRE><LRM> (-qasm) <LRM><PDF>PS. <LRE> = U+202A<LRM> = U+200E<PDF> = U+202C If you wonder why you need to use both LRE/LRM (or RLE/RLM) for enforcing a direction of text token (according to UBA using of LRE (or RLE) is sufficient), please notice that this is due to known limitation of presentation engine used by OS.Which OS/version ? can you give me an example where the OS fails without the extra LRM (or RLM) ?Thank youTomer, I feel that this problem can't benefit from proposed enhacements for TextProcessor ().The solution here, in my opnion, is to fix the translation. Do you agree ?I'd say that is not only the simplest solution but also the only one possible.Would you also recommend to them to fix the translation ?In response to. Yes, I agree that the problem can be resolved only on the resources level. TextProcessor works in the code and is useless here. Resolving the problem in the code is possible but much more expensive (since it involves analyzing the translated message, parsing it and isolating the tokens for which direction should be enforced to LTR) and by all means is not justified in the discussed here cases.In response to. I personally discovered the problem for the first time on Windows OS. Please notice that when the string (direction of which you want to enforce) is not surrounded by any additional text usage of LRE + PDF (or RLE + PDF) is sufficient. The sample using which I discovered the issue was as follows: " (*.java) " This string has LTR direction. I wanted the *.java to be displayed the same way when the direction of the whole string is changed from LTR to RTL. If I follow UBA and use: " (<LRE>*.java<PDF>) " I get: " (.*java) " Please notice the relative position of dot and star. Following the method described in: " (<LRE><LRM>*.java<LRM><PDF>) " I get correct display. You can try this example using Notepad. Please also notice that in input fields in IE adding LRE/PDF is sufficient since in that case a slightly different implementation of presentation engine is used.***has been marked as a duplicate of this bug. ***	24.0
id=243841	REOPENED	CDT	cdt-build	5.0	Other Linux	P3 normal	cdt-build-inbox@eclipse.org	2008-08-12 03:21 EDT by	Torkild Resheim	2009-11-16 13:37 EST (	1 user	Build ID: I20080617-2000Steps To Reproduce:When for instance org.eclipse.cdt.managedbuilder.internal.core.Tool is unable to create an instance of the "commandLineGenerator" specified in the Tool element of the toolchain declaration a CoreException is thrown which is ignored silently.Instead an event should be logged for debugging purposes.	CreatedPatch for logging exceptions when instantiation failsThe PLUGIN_ID member variable of ManagedBuilderCorePlugin has been made public and all CoreExceptions thrown when attempting to create instances using instances from the toolchain declaration (in org.eclipse.cdt.managedbuilder.internal.core) are handled using: StatusManager.getManager().handle(e,ManagedBuilderCorePlugin.PLUGIN_ID);(In reply to)I agree that exceptions should be recorded but why do you use StatusManager if everywhere else in the plugin errors are reported via ManagedBuilderCorePlugin.log()?It's been a while and the patch does not apply clean anymore.Closing as there is no response from submitter. Please reopen if still want to proceed with this.Sorry about not answering. I missed your reply. I agree that ManagedBuilderCorePlugin.log() should be used instead. It's been a while since my original request to have this fixed so I cannot remember my original motivation to use the StatusManager. I think the problem was that using the CDT logger would just add an entry to the log and not pop up an UI also I think the error log view was still a part of PDE at that time. So that most users will never be aware of a problem unless they actually have PDE installed (unlikely) and checked the view.I have not taken a look the newer code so I don't know if the problem is still there. Reopening for now. I'll see if I can find the time to submit a new patch soon.Returning to the pool until new patch provided.	5.0
id=285350	REOPENED	CDT	cdt-build-managed	6.0	All All	P3 normal	cdt-build-inbox@eclipse.org	2009-07-31 22:48 EDT by	Andrew Gvozdev	2010-08-08 01:34 EDT (	0 users	ManagedBuildCoreTests20.testProjectrename() occasionally failing on my Windows XP system onassertTrue(definedSymbols.containsKey("DEBUG"));	I do not observe the issue described inanymore but if the test is run separately - getting NPE due to null "info":Doesn't happen if run as a part of the test suite. But happens with other tests in the suite like testConfigurations. Possible dependency on another test case.Looks like the test suite was designed that way, testProjectCreation() will create the project for other tests. WONTFIX.Reopening task:CDT 7.0M7,testProjectRename Error N/Ajava.lang.NullPointerExceptionat org.eclipse.cdt.managedbuilder.core.ManagedBuildManager.getPathForResource(ManagedBuildManager.java:4102)at org.eclipse.cdt.managedbuilder.core.ManagedBuildManager.getBuildLocation(ManagedBuildManager.java:4064)at org.eclipse.cdt.managedbuilder.internal.envvar.MbsEnvironmentSupplier.getConfigurationVariable(MbsEnvironmentSupplier.java:56)at org.eclipse.cdt.managedbuilder.internal.envvar.MbsEnvironmentSupplier.getVariables(MbsEnvironmentSupplier.java:82)at org.eclipse.cdt.managedbuilder.internal.dataprovider.BuildEnvironmentContributor.getVariables(BuildEnvironmentContributor.java:69)at org.eclipse.cdt.internal.core.envvar.BuildSystemEnvironmentSupplier.getVariables(BuildSystemEnvironmentSupplier.java:188)at org.eclipse.cdt.internal.core.envvar.EnvironmentVariableManager.getVariables(EnvironmentVariableManager.java:274)at org.eclipse.cdt.internal.core.envvar.EnvironmentVariableManager.getVariables(EnvironmentVariableManager.java:290)at org.eclipse.cdt.internal.core.settings.model.CBuildSettingCache.initEnvironmentCache(CBuildSettingCache.java:48)at org.eclipse.cdt.internal.core.settings.model.CConfigurationDescriptionCache.loadData(CConfigurationDescriptionCache.java:104)at org.eclipse.cdt.internal.core.settings.model.CProjectDescription.loadDatas(CProjectDescription.java:196)at org.eclipse.cdt.internal.core.settings.model.xml.XmlProjectDescriptionStorage.loadProjectDescription(XmlProjectDescriptionStorage.java:472)at org.eclipse.cdt.internal.core.settings.model.xml.XmlProjectDescriptionStorage.getProjectDescription(XmlProjectDescriptionStorage.java:231)at org.eclipse.cdt.internal.core.settings.model.CProjectDescriptionManager.getProjectDescriptionInternal(CProjectDescriptionManager.java:414)at org.eclipse.cdt.internal.core.settings.model.CProjectDescriptionManager.getProjectDescription(CProjectDescriptionManager.java:396)at org.eclipse.cdt.managedbuilder.core.ManagedBuildManager.findBuildInfo(ManagedBuildManager.java:2847)at org.eclipse.cdt.managedbuilder.core.ManagedBuildManager.getBuildInfo(ManagedBuildManager.java:3113)at org.eclipse.cdt.managedbuilder.core.ManagedBuildManager.getBuildInfo(ManagedBuildManager.java:3068)at org.eclipse.cdt.managedbuilder.core.tests.ManagedBuildCoreTests20.testProjectRename(ManagedBuildCoreTests20.java:650)ManagedBuildManager.getPathForResource() line 4102 could have 2 possible NPE on it, so split the statement to troubleshoot more accurate next time.Got following in weekly buildsThat looks like original problem reported in description:junit.framework.AssertionFailedError: nullat org.eclipse.cdt.managedbuilder.core.tests.ManagedBuildCoreTests20$1.changeNotification(ManagedBuildCoreTests20.java:293)at org.eclipse.cdt.internal.core.settings.model.ScannerInfoProviderProxy.notifyInfoListeners(ScannerInfoProviderProxy.java:51)at org.eclipse.cdt.internal.core.settings.model.ScannerInfoProviderProxy.postProcessProviderChange(ScannerInfoProviderProxy.java:142)at org.eclipse.cdt.internal.core.settings.model.AbstractCExtensionProxy.checkUpdateProvider(AbstractCExtensionProxy.java:121)at org.eclipse.cdt.internal.core.settings.model.AbstractCExtensionProxy.doHandleEvent(AbstractCExtensionProxy.java:166)at org.eclipse.cdt.internal.core.settings.model.AbstractCExtensionProxy.handleEvent(AbstractCExtensionProxy.java:153)at org.eclipse.cdt.internal.core.settings.model.CProjectDescriptionManager.notifyListeners(CProjectDescriptionManager.java:2170)at org.eclipse.cdt.internal.core.settings.model.AbstractCProjectDescriptionStorage.fireLoadedEvent(AbstractCProjectDescriptionStorage.java:268)at org.eclipse.cdt.internal.core.settings.model.xml.XmlProjectDescriptionStorage.getProjectDescription(XmlProjectDescriptionStorage.java:255)at org.eclipse.cdt.internal.core.settings.model.CProjectDescriptionManager.getProjectDescriptionInternal(CProjectDescriptionManager.java:416)at org.eclipse.cdt.internal.core.settings.model.CProjectDescriptionManager.getProjectDescription(CProjectDescriptionManager.java:398)at org.eclipse.cdt.managedbuilder.core.ManagedBuildManager.findBuildInfo(ManagedBuildManager.java:2731)at org.eclipse.cdt.managedbuilder.core.ManagedBuildManager.getBuildInfo(ManagedBuildManager.java:2992)at org.eclipse.cdt.managedbuilder.core.ManagedBuildManager.getBuildInfo(ManagedBuildManager.java:2947)at org.eclipse.cdt.managedbuilder.core.tests.ManagedBuildCoreTests20.testProjectRename(ManagedBuildCoreTests20.java:708)at org.eclipse.test.EclipseTestRunner.run(EclipseTestRunner.java:376)at org.eclipse.test.EclipseTestRunner.run(EclipseTestRunner.java:209)at org.eclipse.test.UITestApplication$2.run(UITestApplication.java:195)at org.eclipse.swt.widgets.RunnableLock.run(RunnableLock.java:35)at org.eclipse.swt.widgets.Synchronizer.runAsyncMessages(Synchronizer.java:134)at org.eclipse.swt.widgets.Display.runAsyncMessages(Display.java:3515)at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3162)at org.eclipse.ui.internal.Workbench.runEventLoop(Workbench.java:2624)at org.eclipse.ui.internal.Workbench.runUI(Workbench.java:2588)at org.eclipse.ui.internal.Workbench.access$4(Workbench.java:2422)at org.eclipse.ui.internal.Workbench$7.run(Workbench.java:670)at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:332)at org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:663)at org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:149)at org.eclipse.ui.internal.ide.application.IDEApplication.start(IDEApplication.java:115)at org.eclipse.test.UITestApplication.runApplication(UITestApplication.java:138)at org.eclipse.test.UITestApplication.run(UITestApplication.java:60)at org.eclipse.test.UITestApplication.start(UITestApplication.java:210)at org.eclipse.equinox.internal.app.EclipseAppHandle.run(EclipseAppHandle.java:196)at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:110)at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:79)at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:369)at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:179)at org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:619)at org.eclipse.equinox.launcher.Main.basicRun(Main.java:574)at org.eclipse.equinox.launcher.Main.run(Main.java:1407)at org.eclipse.equinox.launcher.Main.main(Main.java:1383)at org.eclipse.core.launcher.Main.main(Main.java:34)*** cdt cvs genie on behalf of agvozdev ***: split statement to troubleshoot NPE[*] ManagedBuildManager.java 1.132	6.0
id=301448	REOPENED	CDT	cdt-build	6.0	PC Windows Vista	P3 minor	cdt-build-inbox@eclipse.org	2010-02-01 13:24 EST by	Lev Minkovsky	2010-04-20 06:12 EDT (	3 users	Build Identifier: I20090611-1540The function CConfigBasedDescriptorManager::doHandleEvent() fromthe org.eclipse.cdt.internal.core package throws an NullPointerException if its event parameter has a null project property.It should be coded more defensively to handle this case. Similarly, BuildStateManager::removeProjectInfo() from org.eclipse.cdt.managedbuilder.internal.buildmodel should simply return if its project parameter is null.Reproducible: Always	CreatedProposed patch for BuildStateManager.javaCreatedProposed patch for CConfigBasedDescriptorManager.javaI touched this code last, so I'll bite...Quick question: why? How are you generating ProjectDescriptionEvents without a project?In general user/ISV code should not be generating these events, instead they're always generated by the configuration model as the result of some internal change. AFAICS all the sites that use this pass in a cfgdesc as required. Can you post a backtrace of where you're seeing this go wrong?We are not generating these events directly. The problem happensin application-specific code that creates several CDT projects andsets up their settings and dependencies. When we try to call Configuration::createFolderInfo() function, it throws a NullPointerException that we were able to trace back to two internal CDT functions. The proposed patches simply make thesefunction more robust so that they would not throw the exception.It is unclear why they are being called with null projects inparameters. I attach a backtrace of the problem.CreatedThe error log fragment with a call stackOk, thanks. What's interesting in your backtrace is that you're calling setProjectDescription from within your IManagedOptionValueHandler. I don't think this is a legal thing to do - especially as the value handler is called back when the user changes option in the UI without pressing apply...Furthermore I think that the Project should _never_ be null during these events. Adding null checks may maks the problem, but in my opinion is not the correct fix. Do you see the problem if you code doesn't do this / have you ever made CDT itself do this?As per, I think the way you're using the API is incorrect.Please reopen if you can reproduce the issue in CDT proper, or you think you've spotted an underlying issue. AFAICS adding null checks is not a valid fix in this case.Sorry it took me a while to get back to this. We removed the setProjectDescription() call from the our IManagedOptionValueHandler instance, and the createFolderInfo() call no longerthrows NullPointerExceptions. I see three distinct problems here however, each worthy of attention.The first problem is the rules when ISVs should and shouldnot call setProjectDescription() are AFAIK not documented anywhere.We discover that this call is required to make option changes persistent,but have no way of knowing that this is not the case inside IManagedOptionValueHandler callbacks. Adding some usage guidelines tothe JavaDoc comment of setProjectDescription() would be very helpful.The second problem is that a setProjectDescription() call with validparameters can cause CDT internals to generate ProjectDescriptionEventswith null project properties. This is a "CDT itself" problem, and as we observed it can be difficult to isolate and to deal with.The third problem is two functions I proposed to patch have insufficientor nonexistent parameter validation. I agree that if their parameters by design should always point to valid projects, simply to return in case if a null project would not be a good fix. To let Java runtime throw a NullPointerException however is even worse. I think the right approach would be to do a null project check and either write to the error log or throw a meaningful exception or both.(In reply to)Granted.The problem, to reiterate, is that it's wrong to setProjectDescription in this call-back. The call-back's javadoc clearly states: * This interface represents an option value handler in the managed build * system. It is used to enable a tool integrator to use the MBS configuration * GUI, while linking to an alternative back-end.Note that when a user presses apply / OK the UI causes a setProjectDescription to occur, so you doing similarly will lead to a race and one set of settings may not be persisted.The API usage is wrong, that's why you got the NPE. This bug only occurs as a result of your callback, right?I agree assertLegal(project != null) would be a better fix, but the NPE is an indication that something has gone badly wrong.This is why I closed the bug INVALID / NOT_ECLIPSE: it's an invalid use of the API. The NPE exposed a bug in the way the API was being used. I do agree we could assertLegal or some such, but silently handling the null is the wrong fix.If you want to submit a patch to sanity check the arguments I'd be happy to take a look.	9.0
id=314844	REOPENED	CDT	cdt-build	7.0	PC All	P3 enhancement	cdt-build-inbox@eclipse.org	2010-05-28 07:29 EDT by	Axel Mueller	2010-09-23 03:00 EDT (	1 user	Build Identifier: The new build console has two buttons to jump to the next and previous error/warning. It would be very helpful to have a button to jump to the very first error. Very often, the first error (e.g. missing semicolon or include) leads to dependent errors.Reproducible: Always	After the build is finished pressing "Next" button navigates to the first error (problem marker). Is it good enough?(In reply to)I did not know. It is not really obvious :( But I can live with it.After thinking a little bit aboutand using it I guess we can close this bug. I am fine with the workflow.I will reopen this bug because I noticed that having a button that jumps to the first *error* is very helpful. As mentioned inthe Next button navigates to the first problem marker. But if your application generates a lot of warnings *before* the first error the Next button is pretty useless.I agree and I would argue that it would be useful to use Next/Previous buttons to jump on errors only. For example we could have 3 options with a switch on the toolbar:1. Jumping between errors only2. Jumping between errors and warnings3. Jumping between all markers (errors, warnings and inros)See alsorequesting to highlight them differently on the console.(In reply to)Just to clarify things. We need two things:1) an additional button to jump for the first error2) a kind of filter for the Next/Previous buttons (as described above)(In reply to)Not sure if this is what you mean, but it could work like the Next/Previous Annotation buttons.(In reply to)That sounds good for me.Perhaps I will find some time in the next weeks to have a look at this (if no one else wants to do this, of course).	8.0
id=360989	REOPENED	CDT	cdt-build	8.0	PC Windows XP	P3 normal	cdt-build-inbox@eclipse.org	2011-10-14 11:42 EDT by	John Cortell	2011-10-14 13:22 EDT (	1 user	They should be interpreted as (duh) warnings.To reproduce:1. Create c:\somedir\makefile and give it the following content$(warning The Redcoats are coming!)all : echo "Done"2. File > New > Makefile Project with Existing Code3. Provide: project name, c:\somedir\makefile and choose Cygwin GCC toolchain (MinGW support is broken)4. Build the project.Note the error in the Problems view. Should be a warning.	Generally speaking, error parser parsing console output won't be able to tell the difference between gcc compiler error messages and arbitrary warnings from makefile like that. I suggest to format your messages in makefile to indicate severity, i.e. $(warning warning: The Redcoats are coming!) or adjust error parser patterns to recognize them in Preferences->C/C++->Build->Settings->[Error Parsers] tab -> select GNU C/C++ Error Parser and add or edit patterns. See also. If you have any other suggestions I am listening.*** This bug has been marked as a duplicate of***Thanks, Andrew. Makes sense. In my head I was starting to wonder how we could even distinguish the output of ($warning) and was starting to write a follow up post when you beat me to it. Qualifying the text of the message is definitely a reasonable solution.You know what, I got an idea how we could do it. We can customize GNU Make Error Parser to check a content type on the file and if it is "Makefile" type then assign 'warning' severity.Here is output on the console for reference:build/GNUmakefile:1: The Redcoats are coming!(In reply to)Do you mean GCCErrorParser? That's what the comments insay is doing the parsing. Regardless, providing a different default behavior for messages with file:linenumber for makefiles sounds reasonable to me. In the end, I will still qualify the messages with {info|warning|error} since $warning is not used exclusively for warning, but also for informational tracing.	4.0
id=363203	REOPENED	CDT	cdt-build	8.1.0	PC Windows 7	P3 normal	cdt-build-inbox@eclipse.org	2011-11-08 11:54 EST by	Josh Davidson	2012-04-03 18:07 EDT (	3 users	CreatedScreenshotEclipse IDE for C/C++ DevelopersVersion: Indigo Service Release 1Build id: 20110916-0149"Builder configuration for the indexer" is set to "Use active build configuration"My workspace includes a project "Simics" that is not stored in the workspace, or "default" directory. Instead, the project is stored somewhere else on my hard drive. This seems to break the indexer when I add workspace relative include paths. As you can see in the screenshot below, everything is configured correctly and builds, but the indexer seems to assume that /Simics is directly under my workspace directory instead of using the actual project configuration.Since the internal builder is smart enough to replace <workspace_loc> with the actual root directory of the "Simics" project, the indexer should be as well.	(In reply to)Well after leaving Eclipse running for nearly an hour, the indexer did pick up those headers. Very strange. Previously, I had refreshed the workspace and rebuilt the index multiple times in conjunction with closing and opening both the source file and Eclipse, but nothing worked.Translation of build configuration to absolute paths is done by the build system.The translation is being done by build system correctly. I tested with non-default location of the project and it works fine.Is it possible that in your setup the configuration being indexed (and presented in UI) is not Active (as it would be by default)? What configuration is specified in project preferences->Indexer->"Build Configuration for the indexer"?No response from submitter, assuming it is the configuration problem.(In reply to)As I mentioned in the OP, it was set to to the active configuration. Also, mentioned in my follow up that the indexer did start working after a long period of idle time, so I don't think this is a problem (at least not as framed in the OP).(In reply to)Sorry that I missed that in the description. Still, it is not a problem with relative includes.But, Markus, I've seen issues like that myself when index get lost fully or partially on some unknown event - even if my projects do not use scanner discovery. It looks like there is a black hole between MBS and indexer where language settings get occasionally lost. Let me keep this task open.(In reply to)For the given issue it is not relevant whether the index is complete or not. The editor shows that the includes cannot be resolved. The most likely explanation for that is, that the include search path is not passed to the parser. Josh, to nail that down, please create a parser log for simics.c (in a situation where the includes are not resolved). You can create the log from the context menu of the file in the project explorer - Index - Create Parser Log.	7.0
id=400742	REOPENED	CDT	cdt-build	8.0.2	Other Linux	P3 blocker	cdt-build-inbox@eclipse.org	2013-02-13 17:27 EST by	Ellen Kang	2013-04-15 12:28 EDT (	2 users	I got NullPointerException error when setting up build env in CDT 8.0.2 for Eclipse Indigo, which is downloaded from, after un-compressing the file, also installed GEF and clearcase Team Explorer. To reproduce1. create a clearcase view and load the source files2. in C/C++ perspective, click File - New -- Makefile project with existing code3. choose the source folder from the view created, click ok, project created4. right click project name in project explorer, select properties5. click C/C++ build, get java.lang.NullPointerException	Can you provide a stack trace for the NPE? Normally it can be found in file .metadata/.log in your workspace.No response from submitter, closing bug.Here is the .log. I noticed this happens when Clearcase Team explorer is installed. No this error with the same local files if I uninstalled clearcase Team Explorer. !ENTRY org.eclipse.jface 4 2 2013-02-26 12:08:46.807!MESSAGE Problems occurred when invoking code from plug-in: "org.eclipse.jface".!STACK 0java.lang.NullPointerException at org.eclipse.cdt.managedbuilder.ui.properties.BuilderSettingsTab.updateButtons(BuilderSettingsTab.java:140) at org.eclipse.cdt.managedbuilder.ui.properties.BuilderSettingsTab.updateData(BuilderSettingsTab.java:310) at org.eclipse.cdt.ui.newui.AbstractCPropertyTab.setVisible(AbstractCPropertyTab.java:243) at org.eclipse.cdt.managedbuilder.ui.properties.BuilderSettingsTab.setVisible(BuilderSettingsTab.java:339) at org.eclipse.cdt.ui.newui.AbstractCPropertyTab.handleTabEvent(AbstractCPropertyTab.java:551) at org.eclipse.cdt.ui.newui.AbstractPage.setVisible(AbstractPage.java:810) at org.eclipse.jface.preference.PreferenceDialog.showPage(PreferenceDialog.java:1323) at org.eclipse.ui.internal.dialogs.FilteredPreferenceDialog.showPage(FilteredPreferenceDialog.java:674) at org.eclipse.jface.preference.PreferenceDialog$10.run(PreferenceDialog.java:708) at org.eclipse.swt.custom.BusyIndicator.showWhile(BusyIndicator.java:70) at org.eclipse.jface.preference.PreferenceDialog$9.selectionChanged(PreferenceDialog.java:704) at org.eclipse.jface.viewers.StructuredViewer$3.run(StructuredViewer.java:888) at org.eclipse.core.runtime.SafeRunner.run(SafeRunner.java:42) at org.eclipse.ui.internal.JFaceUtil$1.run(JFaceUtil.java:49) at org.eclipse.jface.util.SafeRunnable.run(SafeRunnable.java:175) at org.eclipse.jface.viewers.StructuredViewer.firePostSelectionChanged(StructuredViewer.java:886) at org.eclipse.jface.viewers.StructuredViewer.handlePostSelect(StructuredViewer.java:1226) at org.eclipse.jface.viewers.StructuredViewer$5.widgetSelected(StructuredViewer.java:1251) at org.eclipse.jface.util.OpenStrategy.firePostSelectionEvent(OpenStrategy.java:262) at org.eclipse.jface.util.OpenStrategy.access$5(OpenStrategy.java:256) at org.eclipse.jface.util.OpenStrategy$3.run(OpenStrategy.java:433) at org.eclipse.swt.widgets.RunnableLock.run(RunnableLock.java:35) at org.eclipse.swt.widgets.Synchronizer.runAsyncMessages(Synchronizer.java:135) at org.eclipse.swt.widgets.Display.runAsyncMessages(Display.java:3563) at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3212) at org.eclipse.jface.window.Window.runEventLoop(Window.java:825) at org.eclipse.jface.window.Window.open(Window.java:801) at org.eclipse.ui.dialogs.PropertyDialogAction.run(PropertyDialogAction.java:158) at org.eclipse.jface.action.Action.runWithEvent(Action.java:498) at org.eclipse.jface.action.ActionContributionItem.handleWidgetSelection(ActionContributionItem.java:584) at org.eclipse.jface.action.ActionContributionItem.access$2(ActionContributionItem.java:501) at org.eclipse.jface.action.ActionContributionItem$5.handleEvent(ActionContributionItem.java:411) at org.eclipse.swt.widgets.EventTable.sendEvent(EventTable.java:84) at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1258) at org.eclipse.swt.widgets.Display.runDeferredEvents(Display.java:3588) at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3209) at org.eclipse.ui.internal.Workbench.runEventLoop(Workbench.java:2701) at org.eclipse.ui.internal.Workbench.runUI(Workbench.java:2665) at org.eclipse.ui.internal.Workbench.access$4(Workbench.java:2499) at org.eclipse.ui.internal.Workbench$7.run(Workbench.java:679) at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:332) at org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:668) at org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:149) at org.eclipse.ui.internal.ide.application.IDEApplication.start(IDEApplication.java:123) at org.eclipse.equinox.internal.app.EclipseAppHandle.run(EclipseAppHandle.java:196) at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:110) at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:79) at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:344) at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:179) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:60) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:37) at java.lang.reflect.Method.invoke(Method.java:611) at org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:622) at org.eclipse.equinox.launcher.Main.basicRun(Main.java:577) at org.eclipse.equinox.launcher.Main.run(Main.java:1410)Is there any update? I cannot use the new clearcase team explorer server which only supports Eclipse Indigo and newer version because of this. The current server is going to be dispelled.Thanks.As far as I know nobody volunteered to work on this yet.The line isbldr = icfg.getEditableBuilder();Not sure how icfg could be null but it would help to have a reproducible case... Any chance that there is a free trial of some sort for that version of ClearCase? Or do I just need to install the Eclipse plugin (link?).Thanks for looking into the issue. The easier way to reproduce this is using Eclipse CDT + clearcase plugin, which can be downloaded fromThere is some speciality with the vob I am using, /vobs/ifmx_qa/rqgunder itbin is an empty dirsrc is dir with a lot of source codeetc is a dir with some config filesGNUmakefile$ cat GNUmakefileall: srcsrc: ALWAYS(cd src ; make)ALWAYS:cleanup:cleanclean:(cd src ; make clean)No this issue if I create project with /vobs/ifmx_qa/rqg/src, I doubt if the error is from bin directoryI didn't have the issue with Eclipse CDT helio, found it during upgrading to Indigo.	8.0
id=346459	REOPENED	CDT	cdt-build	8.0	PC Linux	P3 normal	cdt-build-inbox@eclipse.org	2011-05-19 10:46 EDT by	Ladar Levison	2011-09-18 15:07 EDT (	2 users	I am working with a C project that uses Eclipse generated makefiles. Those same build settings set the compiler to use C99 (or specifically GNU99) and provide several defines like _GNU_SOURCE. However the indexer, and as a consequence the content assistant and semantic validation checks don't function properly. The validation checks don't recognize the bool primitive type so they report it missing.	CreatedScreenshot showing GNU99 enabled...CreatedScreenshot showing defined symbols that be enabling glibc functions.I misspoke above; the content assistant is still showing the alternate function name. But when the syntax highlighter does't show references as external SDK calls.It is unclear to me what kind of problem you are observing. It'd be best to provide steps to reproduce what you are seing and describe what you would expect instead.In C99 'bool' is not a primitive type. You can either use '_Bool', or you need to include 'stdbool.h' which defines the macro '#define bool _Bool'.So the observation, that 'bool' is not recognized is an indication that either your code is wrong, or the include search path for the parser is not setup correctly. Please provide a code snippet + a parser log (context menu of file in project explorer - index - create parser log) and a description what you would expect to behave differently.I've managed to reproduce the issue with the general release version of Indigo. Although the issue seems to only surface intermittently and according to my casual observations after working for an extended period of time.In the parser log I saw:Macro definitions (from files actually parsed):Unresolved includes (from headers in index): file:/usr/lib/gcc/x86_64-redhat-linux/4.4.5/include/stdbool.h is not indexed Unresolved inclusion: freetype/config/ftheader.h in file file:/usr/include/ft2build.hIt could be that the problem is because 4.4.5 is a link back to 4.4.4 on RHEL 6:[ladar@magma /]$ ls -l /usr/lib/gcc/x86_64-redhat-linuxtotal 8drwxr-xr-x. 4 root root 4096 Nov 23 2010 3.4.6drwxr-xr-x. 7 root root 4096 Feb 14 17:16 4.4.4lrwxrwxrwx 1 root root 5 May 19 15:11 4.4.5 -> 4.4.4Attached are screenshots showing the problem inside the IDE, a screenshot of the folder mentioned, and a parser log.CreatedScreenshot showing my_bool as an unresolved symbol.CreatedScreenshot showing gcc linkage on RHEL 6.CreatedParser log.Please check whether stmts.c is actually indexed. For that, try to open it in the Include Browser, for that use 'Show In - Include Browser'.(In reply to)It opens in the include browser and seems to be finding all of the other symbols used in that particular file without issue. Rebuilding the index and restarting Eclipse didn't seem to help.CreatedScreenshot showing include browser.CreatedScreenshot with possible clue.This may indicate the issue. From this screenshot you can see the my_bool type is defined in two places. In looking at the headers, you can see that preprocessor logic is used to ensure the type is only defined once. But for some reason the indexer seems to pick up the deceleration twice.CreatedIndexer settings.My indexer settings. I've asked it to parse unused files so that even symbols/headers I'm not currently using will be available via the content assistant.I presumed that only the symbols actually available at compile time would be used/available. That doesn't appear to be the case here.(In reply to)While the preprocessor can make sure that only one version of my_bool is used per translation-unit, the two versions can still be used by different translation units.In any way, how do the two declarations look like. Can you use them to create a small example that shows the same issue?Createdc source fileI haven't been able to narrow down the problem; so creating a test case project will take some hunting and pecking.I did notice the MySQL viosocket.c file declares functions with a my_bool return type and the return type is followed immediately by a line break and then the function name. The unusual formatting might explain the viosocket.c references in.CreatedScreenshot showing the abnormal formatting.CreatedTest case.The attached workspace will demonstrate the bug. But the bug is fickle about switching on and off.I was in a rush this morning and couldn't fully write out what I found. If I exclude the viosocket.c file from the project's build configuration, the indexer seems to properly handle the my_bool typedef and the waterboard test project passes all of the semantic validation checks. Since I'm building MySQL from the command line and only want the files in my workspace for reference, excluding the file was simpler than reformatting it. I should note that I still can't seem to switch the issue on/off reliably since rebuilding the indexes doesn't seem to take into account the changes I make to the MySQL project's configuration. Any pointers?You might also want to test the indexer against the ClamAV 0.97.1 source code. The parser seems to run into problems with the libclamav/c++/llvm/ sub-directory. I don't know if its the same issue, or something unrelated.Looks like the problem is about parsing viosocket.c. The file + a parser log may reveal why this is the case.CreatedParser log.Attaching a parser log for viosocket.c. The viosocket.c file is from the MySQL 5.1.57 tarball.Any plans to fix this for SR1 release?(In reply to)This looks like a setup issue, the file 'viosocket.c' is parsed without the include search path and the macro definitions that are built into the compiler.Its been awhile since I looked into this, but as I recall one of the problems is the indexer won't properly pickup the my_bool typedef. That particular typedef is defined in two header files. I traced the include files loaded via the mysql.h file and that chain does include both headers. You'll see that the second my_bool typedef should be skipped via preprocessor conditionals but isn't. And based on my limited testing, this symptom would disappear once the viosocket.c file has been excluded from the build configuration. I couldn't figure out what the relationship is between the index parsing error and the header files. If you look at the test project, and locate where I declare a my_bool variable you'll see that the code analysis thinks the type is unresolved. And if you try to open the my_bool declaration you'll be asked whether to visit the mysql.h or my_global.h headers. Like I said above, the my_global.h typedef should be skipped once the mysql.h file is processed.CreatedVideo showing bug reproduction steps.I may have found the culprit. When I add the MySQL project as a referenced project to torture, and then rebuild the index, the parser fails me. If I remove the project reference and rebuild the index it works again.I created a short video to demonstrate the bug in action. The capture omitted video frames where nothing occurred so you may want to slow the playback for easier viewing.(In reply to)This indicates that viosocket.c is parsed incorrectly within the project MySQL. When adding the project reference the wrong declarations from this project cause the problem.--> You need to fix the setup of project MySQL.How is the configuration wrong? The MySQL project builds just fine. Do I need to add specific include files and export them for it to work?(In reply to)The parser log of viosocket.c indicates that you don't have the include search path pointing to the compiler builtin directories. You can try to go to the scanner discovery property page, check the settings, clear the discovered entries and start a build on the project to trigger the discovery. This may generate the correct include paths for the project.CreatedTorture includes...The torture project has the correct includes, even which is why it compiles, and the mysql project seems to be configuring itself using autotools. I also tried setting up the mysql project to 'export' the mysql/include path but that didn't seem to help.CreatedMySQL includes.As you can see the default include paths seem to be auto-discovered...CreatedTest projects as gzipped tarball.Projects exported to gzipped tarball so others can try... and if the bug attachment fails, try:	29.0
id=408541	REOPENED	CDT	cdt-build	8.2	All All	P3 critical	cdt-build-inbox@eclipse.org	2013-05-21 04:12 EDT by	Caroline Klausecker	2014-05-28 11:11 EDT (	3 users	Version: 8.2.0.201303191012When implementing org.eclipse.cdt.managedbuilder.language.settings.providers.ToolchainBuiltinSpecsDetector.getEnvironmentVariables() in a subclass, the following severe performance problem occurs:Compiler inspection seems to run over and over again because of the additional environment variables provided.This seems to get worse the more configurations are configured in the project and the more environment variables are provided.My results:Provided environment variables: 93Number of configurations: 12Time until discovery is completed (until progress view does not show any compiler inspections progress anymore): 7 minutes !!What exactly triggers the listener and the re-discovery here?	That has been fixed a while ago. Please, use newer version.*** This bug has been marked as a duplicate of***Hi Andrew, Unfortunately updating to the newest version which contains your fix does not change the behavior in my project.I am using non-shared built-in specs detectors. Could this make a difference?Thanks in advance!I will reopen this to clarify if the fix is really complete.Please provide reproducible case. If you experience this implementing LSP you can attach sample plugin.Do you still have this issue after update?Unfortunately yes, I still have this issue after updating.The workaround I am using now is to override the following method in my implementation which extends ToolchainBuiltinSpecsDetector:/* (non-Javadoc)* @see org.eclipse.cdt.core.language.settings.providers.LanguageSettingsSerializableProvider#serializeLanguageSettings(org.eclipse.cdt.core.settings.model.ICConfigurationDescription)*/@Overridepublic IStatus serializeLanguageSettings(ICConfigurationDescription cfgDescription) { // no serialization should be done here - does not perform in our project with lots of configs // is there a better way to handle this? CDT does not seem to have that problem return Status.OK_STATUS;}I am not really happy with this since I am not completely sure about the side-effects this could have.I think you gonna have a few problems here. One is that you lose discovered information between restarts. That might cause unnecessary reruns after restarting eclipse. Another is that indexer is not getting notified about changes. User might have to manually reindex every time settings change.If you provide reproducible case I would look at what is going on.Even though I don't think it's exactly the same issue, this is likely to be affected by my proposed fixes for. Caroline, maybe you could test these in your situation and report if they make any difference?	8.0
id=438375	REOPENED	CDT	cdt-build	8.4.0	PC Linux	P3 normal	cdt-build-inbox@eclipse.org	2014-06-27 06:51 EDT by	Konstantin Plotnikov	2014-06-30 10:05 EDT (	2 users	"C/C++ GCC Cross Compiler Support" does not provide settings page for cross compiler.In 8.3 there were configuration of cross tools under "Project properties"->"C/C++ Build"->"Settings". Now it is not there, and nowhere or I'm too stupid to find it.So in 8.4 there are no usable way to configure cross compile, thus it makes this plug-in unusable.	Hello Konstantin. I can't reproduce this in 8.4. How did you create the project? Did you make a Makefile project by any chance? Do you have anything in the error log that could be related?I'm really sorry. My mistake.Lately I'm used to create "Makefile" projects whish does not have such settings (btw why?)And to have those I need to create a project with Eclipse-driven build process.I need to say sorry again =(PS.Still "Makefile" projects have an toolchain select, but no settings for Cross GCC. It is a bit strange. Why?(In reply to Konstantin Plotnikov from)Originally, Cross GCC was also a project template for "managed build", like Executable > Hello world, but it made sense to reuse the toolchain for other templates as well so it was changed to have a custom wizard page whenever you selected the Cross GCC toolchain. I think that's when it started appearing for Makefile > Empty project. I think it would make sense to have it work for Makefile projects as well because that would set the GCC built-ins correctly (Includes, Macros). To do that, the settings would have to be moved out of the "managed build" toolchain settings so that the user can change them in the project preferences. I think that's worth a bugzilla entry, we can reuse this one.	3.0
id=487884	REOPENED	CDT	cdt-build	8.8.0	PC Windows 8	P3 normal	cdt-build-inbox@eclipse.org	2016-02-16 10:13 EST by	John Moule	2016-02-26 06:34 EST (	2 users	If an Executable project references another project using the Eclipse Common References page ((C/C++ Project Properties, Project References:) it does not get built when pressing the LaunchBar launch button. Using the original Build hammer toolbar button does build the projects under these conditions.If the project reference is made using the CDT project references page (C/C++ Project Properties, Paths and Symbols, Project References:) then it does get built as expected.Having 2 project references pages is less than ideal, but it seems there are 2 pages because the CDT page provides extra functionality; supports build configurations. The original build hammer respects references made from either page. The LaunchBar launch button should too.	It depends on launch delegate, on how it handles buildForLaunch, you needto specify what launch configuration types it was, what mode it was etc.I created a C project with linux toolchain. I added references to another project. They both is built now when I press the button.I am using neon M6Thanks for investigating.Attached is a test (-mingw.zip) containing a C executable project, created on Windows for mingw and a static library project. The reference in cproject to staticlib is made project properties > Project References > Project references for 'cproject'. The cproject project also contains a "C/C++ Application" Debug Configuration.Steps to reproduce:1) Import both projects2) Clean both projects3) In LaunchBar Launch Configuration select "cproject Debug" and launch mode as Debug.4) Click LaunchBar launch button Observe: build commences but it fails to build the staticlib. 11:15:40 **** Rebuild of configuration Debug for project cproject **** Info: Internal Builder is used for build gcc "-IC:\\Users\\John\\workspace.drt.3.0release\\staticlib\\src" -O0 -g3 -Wall -c -fmessage-length=0 -o "src\\main.o" "..\\src\\main.c" gcc "-LC:\\Users\\John\\workspace.drt.3.0release\\staticlib\\Debug" -o cproject.exe "src\\main.o" -lstaticlib c:/mingw/bin/../lib/gcc/mingw32/4.8.1/../../../../mingw32/bin/ld.exe: cannot find -lstaticlib collect2.exe: error: ld returned 1 exit status Expected: build should build staticlib project first and then cproject and then launch.If I modify cproject properties > Paths and Symbols > References and select staticlib and OK and then LaunchBar launch button both projects are built and the launch succeeds.Tested on: Windows 8.1 Mars.1 CDT 8.8.0Createdtest containing a C executable project, created on Windows for mingw and a static library project.	3.0
id=347848	REOPENED	CDT	cdt-build-managed	8.0	PC Linux	P3 normal	Project Inbox	2011-05-31 14:55 EDT by	Eugene Ostroukhov	2011-07-13 18:19 EDT (	3 users	Build Identifier: CVSOur toolchain is based on GNU linker and adds some tools and requires the executable to be linked against our libraries.To achive this we created the tool based on cdt.managedbuild.tool.gnu.cpp.linker.exe.debug that has libs and libPaths options with the custom applicability calculator so they do not show up in the linker settings UI but are still included in linker command-line arguments.Those values are still shown on the appropriate tabs of the "C/C++ General"/"Paths and Symbols" preference page.Another problem is that there is a harmless error log entry stating we have several options of the same kind (see BuildEntryStorage.java(v1.19):611.It looks like this storage should check option applicability.Reproducible: AlwaysSteps to Reproduce:1.Declare a custom option of the "libs" type and set its value in the plug-in manifest.2. Run the IDE and check the preference page.3. Library is shown on the page.	There's an easy workaround: - Don't declare your IOption as a lib / libpath type, just declare it as a string list.This will prevent the paths from being sent to cdt.core _and_ prevent them from being dispalyed in the Paths & Symbols page.(In reply to)It's not harmless. Certain options can be set either using API in cdt.core or in mbs.core. There's a mapping between options of the same 'type'. If there's more than one IOption for a given cdt.core language setting entry, then cdt.core will only see some of the options values. This may not matter for libs and libPaths, but it does matter for preprocessor symbols and include search paths.See also.It seems like you don't want cdt.core to know about these paths, so I recommend the workaround above.The problem is that I need cdt.core to use these values when linking the application. I don't want the user to know about them. Isn't it the reason for IOptionApplicability::isOptionVisible method?What I have right now is inconsistent UI - the library is not shown on the linker settings page (that is desirable behavior) but is still shown on the project paths property page that shows values derived from linker settings.That error should not really appear in my scenario as there should be single option editable by user - default linker libs/libPaths. The option I introduced (for provided library) should not be visible to the user and should not be usable - its value is coming from plugin manifest or Java code.(In reply to)Why does cdt.core need to know? MBS does the linking. If you don't want cdt.core to show the options, then don't pass them to it. A string list option will be applied correctly.Well don't define the option as LIBRARIES / LIB_PATHS. Did you try that?cdt.core to show the options, then don't pass them to it. A string list optionwill be applied correctly.Currently our toolchain is a thin layer on top of GNU toolchain hence we are able to reuse makefile generation code from CDT. That code will only discover libraries from the options that have "libs" path. Basically, this issue is the only one that we encountered.Then they will not be passed to linker.(In reply to)Seriously, just create a new option that's identical to CDT's built-in libs options except with a type of string list.Did you try it?Yes.I will close this bug as "wontfix" as we seem to be the only adopters facing this problem and we chose a bit different approach so this issue is no longer a concern for us.If this is a bug lets keep it open even if you are the only adopters. If somebody has a need to rework the code in future, this would be a record of a useful case to consider.(In reply to)If the reporter believes it's a bug then it would be good if they could provide a plugin.xml demonstrating the issue.I don't see how the paths will end up in the core.ui if they use the instructions outlined in.From where I sit, this is wontfix.(In reply to)I don't see how it wouldn't work. There are _very_ few special options which are passed back to cdt.core. All the rest are handled internally to the mbs. There's no reason your mbs option should be any different.	9.0
id=313038	REOPENED	CDT	cdt-build-managed	7.0	PC Windows 7	P3 critical	Project Inbox	2010-05-16 13:12 EDT by	Doug Schaefer	2016-10-01 17:18 EDT (	3 users	What steps will reproduce the problem?1. Create Hello World C++ project, let build and index finish, close down eclipse2. Start up eclipse againWhat is the expected output? What do you see instead?The include path is lost and #include <iostream> shows a warning.I found this first in Wascana:But I can reproduce it launching CDT from my Linux workspace too.	I'm using Wascana 1.0 Beta 1 and I can't reproduce it. Anything in the error log?(In reply to)Have you tried to close and reopen the file after the initial refresh finishes?(In reply to)No logs. And this is reproducible on every machine I tried. Another important point is to start with a fresh workspace.(In reply to)That works fine. It looks like it's lost when we shut down.The scanner discovery info is stored in the .sc file in the metadata. Is it not getting loaded any more?(In reply to)Thanks, that did it.(In reply to)I'm also seeing it.Ugh. I just did the same test in Galileo and it fails there too.First thing I see in the debugger: The first project created in a workspace is broken. All others after are fine.The fMap variable in ScannerConfigInfoFactory2 seems to be incomplete in the first one. There are no 'scannerConfigBuildInfo' records written to the .cproject file.(In reply to)That reminds me ofandNext data point:In CfgScannerConfigInfoFactory2.CfgInfo.createMap() line 180First time through inputType.isExtensionElement is true, i.e. it's the one from the build definition. Thus the info never gets created.Second time through, inputType.isExtensionElement is false, and we're good.Off to the next round of debug stack...Last step for going home for supper.First time through, the NotificationManager is created and the listener set is empty.By the time the second project is created, the ConfigurationDataProvider is registered as a listener who then takes care of updating the inputType for the tool.It gets created and registered later on when the MBSWizardHandler.createProject does a setProjectDescription after the configuration is created which is too late.BTW, what the hell is all this stuff? Why is this thing that's lazily loaded through an extension point responsible for setting up the configuration instance for the inputType of a tool, and why does that cause a mysterious string of supposedly unrelated events that cause the missing scannerConfigBuildInfo, which then causes the missing built-in include path. Ugh!!!!CreatedApplied FixI've committed the attached patch. It moves the init of the config data provider to bundle start time. Doesn't seem to be much data created and it's solely dependent on what extensions are defined so it shouldn't slow start up time noticeably.Please review and comment. I can always revisit the solution.Marking fixed for now.*** cdt cvs genie on behalf of dschaefer ***- Includes path lost on restart. Moved the init of the config data provider to bundle start time so it's ready in time for first project creation.[*] CProjectDescriptionManager.java 1.88[*] CConfigurationDataProviderDescriptor.java 1.6New Gerrit change created:The fix for this bug triggered. Reopened.	16.0
id=399240	REOPENED	CDT	cdt-build-managed	8.2	PC Windows 7	P3 major	Project Inbox	2013-01-28 05:57 EST by	Tamas Csabina	2013-01-29 10:49 EST (	3 users	During custom toolchain creation, the toolChain`s Extension Element Details page should indicate that the toolChain`s targetTool property is required, and cannot be empty.This can be indicated with a * (asterisk) character after the property name, just like it is done with the id property.	This is not a bug in PDE (plugin development environment). However, I can't figure out where it belongs. Closing as INVALID. If you reopen with additional information we can move it to a different component.Hi Curtis,I am not willing to reopen. You have a better grasp on what is a bug an what is not.However I am willing to provide as much additional information as possible and required to fix this. As this little issue caused me to struggle for weeks, without success, with a custom toolChain creation.So please let me know, what information shall I provide.Fixing this should be as simple as checking a box in the schema file for the extension point you reference.The problem is that I have no idea who owns that extension point. The first step would for you to provide the fully qualified name of the extension point you are using. Is this C++ developement? My google search suggests that you might be using Eclipse CDT."org.eclipse.cdt.managedbuilder.core.buildDefinitions" is the extension point I am using.Under this, I`ve created a <projectType>, under that a <configuration>, and under that a <toolChain>, just like the Managed Build System Extensibility Document describes this in Section 6.I am using Eclipse CDT (4.3M3) for the plug-in development.I also found some references on this targetTool property in the above mentioned MBS document:"A tool-chain should specify the targetTool attribute to identify the tool that runs to generate the primary build output. If this is not specified, MBS uses the file extension of the build artifact name supplied by the user. This will work when the user uses one of the extensions expected by the tool, but will not work if they do not."I gave it a try to define the file extension of the build artifact and leave the targetTool property empty (just as the document describes), but I was not able to make this working. Of course I could be mistaken on defining the extension properly, but for me it seems that without the targetTool it is not going to work.Reopening and moving to CDT.	5.0
id=289555	REOPENED	CDT	cdt-build-managed	6.0	PC Linux	P3 normal	Project Inbox	2009-09-16 03:39 EDT by	Jens Seidel	2011-05-12 16:38 EDT (	3 users	User-Agent: Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.13) Gecko/2009082006 Iceweasel/3.0.12 (Debian-3.0.12-1)Build Identifier: 3.5After upgrading autotools to version 0.3.0 I can no longer open Properties -> C/C++ Build -> Tool Chain Editor. I get an exception.The dialog no longer contains any toolchain or current builder, also "Used tools" is empty.eclipse.buildId=I20090611-1540java.version=1.6.0_02java.vendor=Sun Microsystems Inc.BootLoader constants: OS=linux, ARCH=x86_64, WS=gtk, NL=deCommand-line arguments: -os linux -ws gtk -arch x86_64ErrorWed Sep 16 09:39:21 CEST 2009Unhandled event loop exceptionjava.lang.NullPointerException at org.eclipse.cdt.managedbuilder.internal.tcmodification.ConfigurationModification.getBuilderCompatibilityStatus(ConfigurationModification.java:101) at org.eclipse.cdt.managedbuilder.ui.properties.ToolChainEditTab.showErrorMessage(ToolChainEditTab.java:206) at org.eclipse.cdt.managedbuilder.ui.properties.ToolChainEditTab.updateData(ToolChainEditTab.java:187) at org.eclipse.cdt.managedbuilder.ui.properties.ToolChainEditTab.checkPressed(ToolChainEditTab.java:426) at org.eclipse.cdt.ui.newui.AbstractCPropertyTab$2.widgetSelected(AbstractCPropertyTab.java:369) at org.eclipse.swt.widgets.TypedListener.handleEvent(TypedListener.java:228) at org.eclipse.swt.widgets.EventTable.sendEvent(EventTable.java:84) at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1176) at org.eclipse.swt.widgets.Display.runDeferredEvents(Display.java:3493) at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3112) at org.eclipse.jface.window.Window.runEventLoop(Window.java:825) at org.eclipse.jface.window.Window.open(Window.java:801) at org.eclipse.ui.dialogs.PropertyDialogAction.run(PropertyDialogAction.java:157) at org.eclipse.jface.action.Action.runWithEvent(Action.java:498) at org.eclipse.jface.action.ActionContributionItem.handleWidgetSelection(ActionContributionItem.java:584) at org.eclipse.jface.action.ActionContributionItem.access$2(ActionContributionItem.java:501) at org.eclipse.jface.action.ActionContributionItem$5.handleEvent(ActionContributionItem.java:411) at org.eclipse.swt.widgets.EventTable.sendEvent(EventTable.java:84) at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1176) at org.eclipse.swt.widgets.Display.runDeferredEvents(Display.java:3493) at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3112) at org.eclipse.ui.internal.Workbench.runEventLoop(Workbench.java:2405) at org.eclipse.ui.internal.Workbench.runUI(Workbench.java:2369) at org.eclipse.ui.internal.Workbench.access$4(Workbench.java:2221) at org.eclipse.ui.internal.Workbench$5.run(Workbench.java:500) at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:332) at org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:493) at org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:149) at org.eclipse.ui.internal.ide.application.IDEApplication.start(IDEApplication.java:113) at org.eclipse.equinox.internal.app.EclipseAppHandle.run(EclipseAppHandle.java:194) at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:110) at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:79) at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:368) at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:179) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at java.lang.reflect.Method.invoke(Method.java:597) at org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:559) at org.eclipse.equinox.launcher.Main.basicRun(Main.java:514) at org.eclipse.equinox.launcher.Main.run(Main.java:1311) at org.eclipse.equinox.launcher.Main.main(Main.java:1287)Reproducible: Always	Is it possible to attach your .cproject?CreatedCDT project file with bogus make command(In reply to)Ahm, no, at least not the faulty one. I got this NPE multiple times with slightly different stack traces and some times I was even unable to open the C/C++ Build settings (IIRC it only displayed the Configuration: combobox without "Builder Settings", "Behaviour" settings) without getting this exception.Nevertheless after playing with nearly all possible configuration settings I was able to get it working again. During these attempts I noticed that the whole Properties dialog is very, very, very fragile. A few examples:In "Builder Settings" I selected "Use default build command". Once I reentered this dialog the checkbox was unchecked. Checking it again (by clicking on it :-)) didn't worked!!!! The box stayed unchecked. I think this happened only if multiple configurations (debug, release in my case) exists. I had to change to the "Internal builder" and switch back to "External builder" to get it selectable again. In the "Behaviour" settings I always disable "Build in resource save" but all the time it was enabled again. This is still true!But that it really not all. Once I missed my CXXFLAGS and LDFLAGS settings in C/C++ Build -> Environment and had to add it manually again. The same happened with my Run/Debug Settings.The last I did yesterday was adding a new make target "Create API documentation"for the top level directory which calls "make -C doc .doc" (to workaround). Now guess what happened: The C/C++ Build dialog contains now in Builder Settings again an unchecked "Use default build command" box with faulty build command "make -C doc". Grml!!!!!!Sorry, this makes the autotools plugin currently unusable and I increased the importance of this bug (but I'm unable to rename it?).I have my files committed into a Subversion repository and normally check all changes before I commit. You probably know that this is impossible with .cproject as major blocks are moved in the file, and even attributes in a single line XML tag move around. So there is no way for me to verify the changes. I opened once bugs for CDT (e.g.,) but if the Autotools plugin is responsible for this as well please fix!I attached my .cproject with the bogus build command "make -C doc".Please note that I created .cproject and .project from scratch. To avoid old and invalid entries in the project files (such as the old Autotools namespace *.redhat.*) I created a new GNU C Autotools Project and imported my renamed C++ project (without .project, .cproject files). Not sure whether this is important.My system: Autotools Feature (Incubation) 1.0.4.200908180856 org.eclipse.linuxtools.cdt.autotools.feature.group Eclipse C/C++ Development Tools 6.0.0.200907030617 org.eclipse.cdt.feature.group Eclipse C/C++ Development Tools SDK 6.0.0.200907030617 org.eclipse.cdt.sdk.feature.group Eclipse SDK 3.5.0.I20090611-1540 org.eclipse.sdk.ideBefore getting this NPE the first time I found in my log:!SUBENTRY 2 org.eclipse.core.resources 4 567 2009-09-15 19:28:06.855!MESSAGE The project description file (.project) for ${myProject} is missing. This file contains important information about the project. The project will not function properly until this file is restored.!SESSION 2009-09-15 19:31:32.143I removed .project and .cproject to start the project files from scratch. Probably it is better to close Eclipse before :-) (I tried to close it all the time once I work on the files (saved backups after each step, which now no longer exist). Ah, this exception is related to the fact that the project was still part of my workspace and after starting Eclipse it complained).CreatedAnother backtraceCreatedA different backtrace in UI (a different problem?)CreatedAnother backtraceCreatedAnother backtraceHappened now also on another (again autotools based) project while viewing the settings in the properties dialog only. In this project I didn't played with .project, .cproject in the filesystem ...(In reply to)This bug should be against the Linuxtools Autotools component, but in trying to change the product, the bug tool would not refresh the components to Linuxtools ones.I have applied a fix to the Autotools trunk (will appear in nightly build) which should fix this problem. Two tools were removed from the Autotools toolchain (gcc and gpp). When older projects containing these tools in their toolchain are accessed, the Properties view results in errors in the Toolchain editor page and Tool Settings tab among other things.These tools and their settings are not used by Autotools, but they were there to allow the indexer to find C and C++ language ids. There is a better way of doing this and so the tools were removed so they would not show up in the Tool Settings tab and cause confusion.The fix reapplies the toolids back in the toolchain without pointing them to the CDT core tools as superclasses and most importantly, specifies them as unused children of the Autotools toolchain. This removes them from the UI (and .cproject) for any new projects and for old projects, they do not expand and clutter the Tool Settings view. Users can remove the extraneous tools from older projects using the toolchain editor.I am closing this bug. If you still experience problems, please open a new bug against Linuxtools.I'd like to keep this bug open against CDT project model. We should handle even inconsistent toolchains gracefully providing error message with friendly advice to the toolchain implementer.***has been marked as a duplicate of this bug. ***(In reply to)I'm replying still here, hope it is OK.Got this bug again after a long time with the nightly builds of autotools: 2.0.0.200911241428The first time the toolchain editor is opened it creates the NPE and displays nothing (so I cannot remove gcc and gpp). Changing the buildmode from release to debug (what's the workaround if only one buildmode exists?) I get a proper toolchain window. gcc and gpp are not displayed in it and cannot be removed.Once I change the toolchain from Autotools to another one (which requires unsetting "Display compatible toolchains only" as no other is available else) such as Cygwin I get gcc and gpp (which point to Cygwin). Now "Select Tool" can be choosen and I can removed gcc and gpp after activating "Allow all changes".Now it works again and I no longer get a NPE (at least for now) :-)I attached the diff in .cproject which is the result of the steps I performed (the new version works). Looking at it I see many references to the projectRhost.trunk. The current project was created as copy of Rhost.trunk and I changed the project name (outside Eclipse???). So it may be that the bogus settings are the result of using an outdating project name. I hope this helps you.Created.cproject diff, seeThis nasty bug still occurs and I keep getting NPEs.(In reply to)I tried it already multiple times, save the project settings and get this bug again. What config files and config file stanzas are affected? Is there a way to remove a few strings from .cproject directly?(In reply to)Yes, I have done so myself using an editor, but it is definitely "unsupported". One time I did it to remove the gcc and gpp tool references in the .cproject file manually, but I had a new working project to compare with at the time. If you want to post your latest .cproject file and mention which configuration is breaking, I could see if a similar fix would be applicable, but I can't guarantee anything. If you are holding on to an old project which I assume you are, you will be using the compat Autotools plug-in. The new plug-ins (autotools.core and autotools.ui) have a different set-up and base themselves on a Std Makefile project rather than a Managed Make project. The configuration options are stored in a separate file: .autotools which is relatively easy to edit manually. I can't help you to convert old to new and preserve all your configuration data. If you choose to convert to C/C++ Autotools project, you will end up with one default configuration and have to add your data back in again. There also is no pre-build/post-build steps in the new type of project if you were depending on those. Those steps can be replaced relatively easily by adding manual builders.You might want to consider moving at some time as the old version has internal references to the CDT so is very susceptible to being broken by CDT changes whereas the new project has cleaned this all up.For now, it would be helpful to note what versions of CDT and Autotools you have now as you had it working earlier and now you are broken again.(In reply to)OK, I attached my current .cproject file which still is buggy and results in NPE in the dialog.I also attached a patch which results if I try to remove references to gcc and gpp as described in.Strange, in the past it worked for some time. Maybe the problem was reintroduced by another person who has write access to our project. Since it's in general not easy to watch the diff of .cproject it's hard for me to find the guilty person. During my tests the last days I also once missed a few settings tabs such as "Tool Settings", "Build Steps" wheras "Autotools" was available. I reverted this change already.Difficult to say. If I remember correctly I created some time ago a new project from scratch to avoid CDT compatibility issues (old and new behaviour, different dialogs, ...). Would this be the most clean solution to workaround this bug?I do not find "autotools.core" or "autotools.ui" in .cproject.Such a file doesn't exist, either in .settings/ nor my workspace. There exists .settings/org.eclipse.cdt.core.prefs which contains autotool stuff (my CXXFLAGS, ...).OK, will try again from the beginning.You mean it's not possible for you to save in the new format?I currently try CDT 7.0.0 M5 and use autotools 0.4.1.The main problem is that I miss a general guide how to avoid this problem. If you say it's not possible or too hard to automatically fix this issue in the plugin itself it's fine for me to create a new project from scratch. Will do so now (expect new bug reports soon :-))CreatedCurrent config file after trying to remove gcc and gpp references via dialogCreatedDiff describing the affect of removing gcc and gpp (still doesn't work)(In reply to)I'll take a look.Hmm, Build Steps will go away if a new Autotools project is used.>The easiest solution is to fall back to CDT 6.0.1, but for future usage, I would advise switching to the new Autotools project format.Then you have an old-style project that is using the compatibility plug-in.>No, you can't currently just save into the new format. You either stay with the old format or convert to a new fresh Autotools project.This is very likely the problem. As mentioned, the old project is very susceptible to breakage every time the CDT changes. 7.0.0 M5 is cutting edge CDT and the Autotools compat plug-in hasn't been verified to work with it yet. I would advise you either to use CDT 6.0.1 unless there is some particular bug fix or feature in the CDT you specifically are after or else switch to a new-style project.Ok.(In reply to)Hmm.. I don't think we've change anything (/we shouldn't have changed anything) in a non-backwards compatible way which would prevent an old .cproject from working with CDT 7. To be precise we won't have removed or renamed any of the Tool or Option IDs in the built-in toolchains.Could you be more specific on which bits of cdt you're relying on, and how they've changed to cause breakage?(In reply to)I can't say exactly, but I will give a brief history of the Autotools plug-in.The old Autotools plug-in references a number of internal APIs of the CDT. The old style of project is based on a Managed Make project but can't do so without accessing internal bits of the CDT. For example, it has its own builder which inherits from CommonBuilder (internal) and overrides what it needs to so as to force the build directory to be something other than the configuration name (which breaks a normal Makefile created by configure), to allow targets other than "all", "clean" (e.g. install, info), and to make it so the "clean" operation doesn't erase the build directory (which in many cases is the top-level project directory). It lets the CommonBuilder do a lot of the heavy lifting (e.g. run the Makefile and scan the build output), but we have been bitten in the past when the CommonBuilder makes certain things private and we can no longer access them by inheriting from the class.The build definition for Autotools had to refer to gcc and g++ as tools or else indexing/scanner info wouldn't occur properly. We are generating Makefiles using configure so gcc and g++ settings are meaningless and having them show up in the Tool Settings was misleading to users. We tried to make the Build Tool Settings dialog not show gcc and g++ as tools by saying they were unused children. There was a point where they were removed, but the Tools Dialog blew up because it wasn't prepared for an empty list.Every CDT major release, something has broken due to the CDT changing something internally. For example, one time we broke because the CDT stopped looking at the Build Location for a ManagedMake project and decided to hard-wire it to be the Configuration Name regardless of the Build Location setting.I rewrote the plug-in to be clean and such things should happen a lot less often, however, old projects continue to use a compat plug-in which I eventually intend to retire.Jens, I noticed that in one of your previous postings you mentioned changing to another compatibile tool-chain. Due to our old choice of Managed Make project it will offer other Managed Make toolchains that operate in the current environment, however, you can't set our tool-chain to another ManagedMake toolchain and you shouldn't use the Autotools toolchain for a regular ManagedMake project.As well, Jens, can you confirm that the traceback listed is the same traceback for the latest error scenario?(In reply to)Eek, thanks for the detail!I guess the moral of the story is we need better APIs in this area. Perhaps there already are some, but have you thought about filing bugs+patches and promoting the internal bits you need to API? It sounds like things are better in the new plugin, but do feel free to file bugs for CDT issues if you end up needing internal API.(In reply to)I don't fully understand this. Please note that I once changed only temporarily to be able to remove gcc, gpp (see).Now I'm no longer interested in this bug :-) I just created a new project from scratch which uses the new autotools plugin and I haven't seen this error again. There are other minor errors (I reported a few the last 2 days) but nothing critical.Oops, no I can't. I restored temporarily my last error scenario and get two new backtraces once I try to open the autotools preferences:eclipse.buildId=I20100129-1300java.version=1.6.0_17java.vendor=Sun Microsystems Inc.BootLoader constants: OS=linux, ARCH=x86, WS=gtk, NL=de_DECommand-line arguments: -os linux -ws gtk -arch x86ErrorWed Feb 24 18:54:37 CET 2010Exception loading preferences from: /.../.settings/org.eclipse.cdt.managedbuilder.core.prefs.org.osgi.service.prefs.BackingStoreException: Exception loading preferences from: /Rhost.trunk/.settings/org.eclipse.cdt.managedbuilder.core.prefs.at org.eclipse.core.internal.resources.ProjectPreferences.load(ProjectPreferences.java:462)at org.eclipse.core.internal.preferences.EclipsePreferences.create(EclipsePreferences.java:307)at org.eclipse.core.internal.preferences.EclipsePreferences.getChild(EclipsePreferences.java:412)at org.eclipse.core.internal.preferences.EclipsePreferences.internalNode(EclipsePreferences.java:541)at org.eclipse.core.internal.preferences.EclipsePreferences.node(EclipsePreferences.java:669)at org.eclipse.core.internal.resources.ProjectPreferences.deleted(ProjectPreferences.java:111)at org.eclipse.core.internal.resources.ProjectPreferences.deleted(ProjectPreferences.java:162)at org.eclipse.core.internal.resources.Resource.deleteResource(Resource.java:967)at org.eclipse.core.internal.localstore.RefreshLocalVisitor.deleteResource(RefreshLocalVisitor.java:101)at org.eclipse.core.internal.localstore.RefreshLocalAliasVisitor.deleteResource(RefreshLocalAliasVisitor.java:43)at org.eclipse.core.internal.localstore.RefreshLocalVisitor.synchronizeExistence(RefreshLocalVisitor.java:189)at org.eclipse.core.internal.localstore.RefreshLocalVisitor.visit(RefreshLocalVisitor.java:293)at org.eclipse.core.internal.localstore.UnifiedTree.accept(UnifiedTree.java:108)at org.eclipse.core.internal.localstore.FileSystemResourceManager.refreshResource(FileSystemResourceManager.java:804)at org.eclipse.core.internal.localstore.FileSystemResourceManager.refresh(FileSystemResourceManager.java:788)at org.eclipse.core.internal.resources.Resource.refreshLocal(Resource.java:1792)at org.eclipse.cdt.internal.core.pdom.PDOMManager$3.syncronizeProjectSettings(PDOMManager.java:736)at org.eclipse.cdt.internal.core.pdom.PDOMManager$3.run(PDOMManager.java:720)at org.eclipse.core.internal.jobs.Worker.run(Worker.java:55)eclipse.buildId=I20100129-1300java.version=1.6.0_17java.vendor=Sun Microsystems Inc.BootLoader constants: OS=linux, ARCH=x86, WS=gtk, NL=de_DECommand-line arguments: -os linux -ws gtk -arch x86ErrorWed Feb 24 18:55:07 CET 2010Problems occurred when invoking code from plug-in: "org.eclipse.jface".java.lang.NullPointerExceptionat org.eclipse.linuxtools.cdt.autotools.AutotoolsDefaultBuildDirHandler.handleValue(AutotoolsDefaultBuildDirHandler.java:75)at org.eclipse.cdt.managedbuilder.core.ManagedBuildManager.performValueHandlerEvent(ManagedBuildManager.java:3402)at org.eclipse.cdt.managedbuilder.core.ManagedBuildManager.performValueHandlerEvent(ManagedBuildManager.java:3354)at org.eclipse.cdt.managedbuilder.internal.dataprovider.ConfigurationDataProvider.copyCfg(ConfigurationDataProvider.java:257)at org.eclipse.cdt.managedbuilder.internal.dataprovider.ConfigurationDataProvider.createConfiguration(ConfigurationDataProvider.java:230)at org.eclipse.cdt.internal.core.settings.model.CProjectDescriptionManager.createData(CProjectDescriptionManager.java:1118)at org.eclipse.cdt.internal.core.settings.model.CConfigurationDescription.doWritable(CConfigurationDescription.java:152)at org.eclipse.cdt.internal.core.settings.model.CProjectDescription.updateChild(CProjectDescription.java:483)at org.eclipse.cdt.internal.core.settings.model.CDataProxy.checkUpdate(CDataProxy.java:121)at org.eclipse.cdt.internal.core.settings.model.CDataProxy.getData(CDataProxy.java:71)at org.eclipse.cdt.internal.core.settings.model.CConfigurationDescription.getConfigurationData(CConfigurationDescription.java:192)at org.eclipse.cdt.internal.core.settings.model.CConfigurationDescription.getConfigurationData(CConfigurationDescription.java:385)at org.eclipse.cdt.managedbuilder.core.ManagedBuildManager.getConfigurationForDescription(ManagedBuildManager.java:3856)at org.eclipse.cdt.managedbuilder.core.ManagedBuildManager.getConfigurationForDescription(ManagedBuildManager.java:3843)at org.eclipse.cdt.managedbuilder.ui.properties.AbstractCBuildPropertyTab.getCfg(AbstractCBuildPropertyTab.java:54)at org.eclipse.cdt.managedbuilder.ui.properties.ToolChainEditTab.updateData(ToolChainEditTab.java:180)at org.eclipse.cdt.ui.newui.AbstractCPropertyTab.setVisible(AbstractCPropertyTab.java:242)at org.eclipse.cdt.ui.newui.AbstractCPropertyTab.handleTabEvent(AbstractCPropertyTab.java:540)at org.eclipse.cdt.ui.newui.AbstractPage.setVisible(AbstractPage.java:808)at org.eclipse.jface.preference.PreferenceDialog.showPage(PreferenceDialog.java:1323)at org.eclipse.ui.internal.dialogs.FilteredPreferenceDialog.showPage(FilteredPreferenceDialog.java:672)at org.eclipse.jface.preference.PreferenceDialog$10.run(PreferenceDialog.java:708)at org.eclipse.swt.custom.BusyIndicator.showWhile(BusyIndicator.java:70)at org.eclipse.jface.preference.PreferenceDialog$9.selectionChanged(PreferenceDialog.java:704)at org.eclipse.jface.viewers.StructuredViewer$3.run(StructuredViewer.java:864)at org.eclipse.core.runtime.SafeRunner.run(SafeRunner.java:42)at org.eclipse.ui.internal.JFaceUtil$1.run(JFaceUtil.java:49)at org.eclipse.jface.util.SafeRunnable.run(SafeRunnable.java:175)at org.eclipse.jface.viewers.StructuredViewer.firePostSelectionChanged(StructuredViewer.java:862)at org.eclipse.jface.viewers.StructuredViewer.handlePostSelect(StructuredViewer.java:1175)at org.eclipse.jface.viewers.StructuredViewer$5.widgetSelected(StructuredViewer.java:1200)at org.eclipse.jface.util.OpenStrategy.firePostSelectionEvent(OpenStrategy.java:251)at org.eclipse.jface.util.OpenStrategy.access$5(OpenStrategy.java:245)at org.eclipse.jface.util.OpenStrategy$3.run(OpenStrategy.java:419)at org.eclipse.swt.widgets.RunnableLock.run(RunnableLock.java:35)at org.eclipse.swt.widgets.Synchronizer.runAsyncMessages(Synchronizer.java:134)at org.eclipse.swt.widgets.Display.runAsyncMessages(Display.java:3501)at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3148)at org.eclipse.jface.window.Window.runEventLoop(Window.java:825)at org.eclipse.jface.window.Window.open(Window.java:801)at org.eclipse.ui.dialogs.PropertyDialogAction.run(PropertyDialogAction.java:157)at org.eclipse.jface.action.Action.runWithEvent(Action.java:498)at org.eclipse.jface.action.ActionContributionItem.handleWidgetSelection(ActionContributionItem.java:584)at org.eclipse.jface.action.ActionContributionItem.access$2(ActionContributionItem.java:501)at org.eclipse.jface.action.ActionContributionItem$5.handleEvent(ActionContributionItem.java:411)at org.eclipse.swt.widgets.EventTable.sendEvent(EventTable.java:84)at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1223)at org.eclipse.swt.widgets.Display.runDeferredEvents(Display.java:3526)at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3145)at org.eclipse.ui.internal.Workbench.runEventLoop(Workbench.java:2407)at org.eclipse.ui.internal.Workbench.runUI(Workbench.java:2371)at org.eclipse.ui.internal.Workbench.access$4(Workbench.java:2220)at org.eclipse.ui.internal.Workbench$5.run(Workbench.java:500)at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:332)at org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:493)at org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:149)at org.eclipse.ui.internal.ide.application.IDEApplication.start(IDEApplication.java:115)at org.eclipse.equinox.internal.app.EclipseAppHandle.run(EclipseAppHandle.java:194)at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:110)at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:79)at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:367)at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:179)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:616)at org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:611)at org.eclipse.equinox.launcher.Main.basicRun(Main.java:566)at org.eclipse.equinox.launcher.Main.run(Main.java:1363)	24.0
id=421276	REOPENED	CDT	cdt-build-managed	Next	PC Windows NT	P3 major	Project Inbox	2013-11-07 13:25 EST by	Serge Beauchamp	2013-11-11 00:24 EST (	3 users	At the moment, the CDT Managed Builders, either the internal builder, or the external builders call the command line tools directly with the arguments necessary to perform a build, for example:link /debug /nologo /OUT:mscl_project.exe src\src.objA fundamental limitation of this approach is that there is a hard limit in how many characters can be passed. That limit is configurable on Linux by the user (ARG_MAX), but is fixed on Windows (~8191 characters).When large amount of object files or include headers are passed to a command line tool, the build will fail, with leaving the user having to refactor his project, an operation that can be difficult depending on the target platform.	To circumvent this problems, most command line tools (Windows SDK, GCC, etc..) support argument files, or command files, which allow to pass arguments to a tool by writing the arguments in a file, and passing this file as argument to the tool, with a special syntax.The CDT Managed Builder should support argument files, so that the user can build projects independently of how long the command line string end up.CreatedImplementation for the internal builderThis is an implementation of this feature for the internal builder, consisting of:- An addition to the CDT Managed Builder build definition schema, so that tools can specify the argument file format- An addition to the ITool, IBuildCommand2, Tool, so that this information can be retrieved by builders- A change in the CommandBuilder for the Internal Builder so that it uses that information to generate argument files automatically when calling the command line tools.Changes pushed with:Corresponding changes for the external builder are pending.The result of this changes is that when using the internal builder, the console output will display the following:Using argument file argument368255423319774829.args for: /debug /nologo /OUT:mscl_project.exe src\mscl_project.obj link "@C:\\Users\\SERGEB~1\\AppData\\Local\\Temp\\argument368255423319774829.args" Instead of simply:link /debug /nologo /OUT:mscl_project.exe src\mscl_project.obj But it will work for arbitrarily large projects, including (practically) unlimited object files count and include headers.Hi Serge, is this the same as?(In reply to Marc-Andre Laperle from)Oh yes, thanks for pointing it out. The limitation is the same, but the implementation is different.I'll merge this bug into the previous one*** This bug has been marked as a duplicate of***Actually, since this bug resolution is complementary to, and could be a dependency of it instead (since it changes the InternalBuilder and the Managed Builder interfaces), I think it's best to track it independently, and flag it as such.What do you think?(In reply to Serge Beauchamp from)Sounds good!Latest changes include a preference panel setting to enable or disable (defaults to enabled) argument file in the builder	8.0
id=356111	REOPENED	CDT	cdt-build-managed	8.0	Macintosh Mac OS X - Carbon (unsup.)	P3 normal	Project Inbox	2011-08-29 14:19 EDT by	Liviu Ionescu	2011-11-20 14:48 EST (	3 users	I tried to port my GNU ARM Eclipse Plug-in project to 3.7 but either something changed in the way toolchain definitions are parsed, or a bug was introduced on the way.I replaced the references to org.osgi.framework.Version and now the project builds properly.However, when trying to run the plug-in and create a new project based on it, I see the toolchain enumerated, I can select it, but later I get the following error: At least one configuration should be available. Project cannot be created.As expected, there is no Debug/Release configurations presented.According to the SVN, there are no changes in the plugin.xml file.I'm using 3.7 with java 6, on Mac OS X 10.6.8.Any suggestions on how to proceed?Liviu	Related tomaybe?Sounds like the same issue, please reopen if you have evidence proving otherwise.*** This bug has been marked as a duplicate of***I don't think that it is a duplicate of 356864.further more, I heard reports that other plug-ins related to mine do not work on 3.7.please suggest how to proceed, we are almost half year after releasing 3.7, and it is very difficult to explain to my users why they should run 3.6 to use the plug-in.(In reply to)Can I ask why? The symptoms are the same, they both result in the message "At least one configuration should be available."I think we should work on fixing. One thing I would try is to revert the change fromand see if that fixes the problem for XLC and for your plug-in.(In reply to)when I said that, I did a shallow check in the logs and could not find the stack trace mentioned in.now I realised I'm running with the latest updates applied and I checked further in the logs and in some older attempts to run my plug-in I found the same messages:org.eclipse.core.runtime.CoreException: Cannot create managed project with NULL configuration at org.eclipse.cdt.managedbuilder.ui.wizards.MBSWizardHandler.setProjectDescription(MBSWizardHandler.java:561) at org.eclipse.cdt.managedbuilder.ui.wizards.MBSWizardHandler.createProject(MBSWizardHandler.java:537)you're probably rightok, it's fine with me. should I checkout the full CDT from the repo in order to test?any advice will be highly appreciated.LiviuI also checked org.eclipse.ui.workbench/log and found new info:!SESSION 2011-11-17 00:13:19.537 -----------------------------------------------eclipse.buildId=M20110909-1335java.version=1.6.0_26java.vendor=Apple Inc.BootLoader constants: OS=macosx, ARCH=x86_64, WS=cocoa, NL=en_GBFramework arguments: -product org.eclipse.epp.package.cpp.product -keyring /Users/ilg/.eclipse_keyring -showlocationCommand-line arguments: -os macosx -ws cocoa -arch x86_64 -product org.eclipse.epp.package.cpp.product -keyring /Users/ilg/.eclipse_keyring -showlocationThis is a continuation of log file /Users/ilg/My Files/MacBookPro Vault/Projects/Eclipse Workspaces/37 Mac/gnuarmeclipse-test/.metadata/.bak_0.logCreated Time: 2011-11-17 00:13:38.556!ENTRY org.eclipse.osgi 2 0 2011-11-17 00:13:38.556!MESSAGE The activator org.eclipse.cdt.cross.arm.gnu.ARMPlugin for bundle org.eclipse.cdt.cross.arm.gnu is invalid!STACK 0org.osgi.framework.BundleException: The activator org.eclipse.cdt.cross.arm.gnu.ARMPlugin for bundle org.eclipse.cdt.cross.arm.gnu is invalid at org.eclipse.osgi.framework.internal.core.AbstractBundle.loadBundleActivator(AbstractBundle.java:171) at org.eclipse.osgi.framework.internal.core.BundleContextImpl.start(BundleContextImpl.java:679) at org.eclipse.osgi.framework.internal.core.BundleHost.startWorker(BundleHost.java:381) at org.eclipse.osgi.framework.internal.core.AbstractBundle.start(AbstractBundle.java:299) at org.eclipse.osgi.framework.util.SecureAction.start(SecureAction.java:440) at org.eclipse.osgi.internal.loader.BundleLoader.setLazyTrigger(BundleLoader.java:268) at org.eclipse.osgi.framework.internal.core.BundleHost.loadClass(BundleHost.java:236) at org.eclipse.osgi.framework.internal.core.AbstractBundle.loadClass(AbstractBundle.java:1207)org.eclipse.cdt.cross.arm.gnu.ARMPlugin is obviously there, but I do not know why it is not recognised.(In reply to)I downloaded the latest source for your plug-in and it loads the plug-in correctly for me. Maybe double check the plug-ins with the Validate button in the Plug-ins tab in the Run or Debug configuration?(In reply to)did that and only the linux/solaris/win32 plug-ins complain (I'm on Mac).my test environment is currently the latest Eclipse 3.7 RCP with all updates, and in the workspace I have the entire CDT repo, with some projects closed (seefor details), plus my 3 plug-in projects.if I run everything via the embedded Eclipse Application configuration, I do not get any errors in the console, or exceptions in the log, the plug-in is loaded, and it seems I can create the new C++ ARM applications, but later I get the famous "At least one configuration should be available" error and the project is not created.Liviuany other suggestions?if not, I'll try to revert these changes and see if the problem is fixed for my plug-in.Liviu(In reply to)I confirm that reverting CDTConfigWizardPage.java from e7395 to previous 7220a fixes the problem I experienced with my plug-in.James & team, can we decide on how to proceed? Is this patch to be reverted? Should I work on my plug-in to meet the additional requirements of this patch?Liviu(In reply to)further investigations revealed that this additional requirement is to remove the "name" filed of the "projectType" element.according to the "Managed Build System Extensibility Document", 3.2 ProjectType, "You must also provide a meaningful name that will be displayed to the user in the UI and new project wizards"also the Schema in the 3.2.1 table lists the "name" attribute as Required.I don't know what "old style project types" are and I'm not able to follow the reasons behind this additional requirement, but in principle I think that removing the name of an element to mark it somehow different from other elements is not a very fortunate decision.unless very good reasons to not do so, my suggestion is to revert to previous 7220a version and increase the version of org.eclipse.cdt.managedbuilder.ui from 8.1.0 to 8.1.1 so I can check if my plug-in is running in the proper environment.Liviu	11.0
id=159081	REOPENED	CDT	cdt-core	3.1.1	PC Linux	P3 enhancement	CDT-Contrib-Inbox	2006-09-28 03:55 EDT by	xyzmen	2010-11-04 05:03 EDT (	1 user	The values of C/C++ structure and the values of Enum are displayed directly in [C/C++ Index View] of CDT. i use the following products. Linux Kernel 2.4.27 JDK 1.5.0_04&#12288;eclipse 3.2 Linux GTK CDT Ver3.1.1.200609270800	sorry. i took mistake.Structure is OK.Enum is NG.thank you.(In reply to)infomation.CDT Ver3.1.0 is Values of Enum is not displayed.CDT Ver3.1.1 is Values of Enum is displayed direct in [C/C++ index view].uuu....this is a new function ?nobody watch it.LATER/REMIND are deprecated. Changing to reopened milestone '--'Not entirely sure, my interpretation is that you ask for displaying the values of enumerators in the outline view.(In reply to)I came to the same conclusion. Could be a nice feature.With StyledText in we could append " = n" in light grey, where n is the value. Visually this would be not too distractive.Is there an easy, inexpensive way to get those values? Don't want to slow down the outline any further.(In reply to)To obtain the values you need to resolve the enumerators to their binding, which is of type IEnumerator. You can then use IEnumerator.getValue(). The model builder avoids creating bindings where possible. I would think that in most cases creating the binding and computing the value will be trivial.	7.0
id=89172	REOPENED	CDT	cdt-core	3.0	All All	P3 enhancement	Project Inbox	2005-03-26 17:02 EST by	Craig E Rasmussen	2012-08-15 02:07 EDT (	2 users	As a small step toward a more language neutral CDT, I propose that an ICoreModel interface be created and org.eclipse.cdt.core.model/CoreModel implement this interface.Two major problems with using the CDT to create Fortran Development Tools (without copying the entire CDT) is that the CCorePlugin and CoreModel objects cannot be replaced by other language versions. Creating an ICoreModel interface is a simple first step toward allowing a Fortran version.Additional steps that will be needed are to move static methods (ones that are language neutral) in CoreModel and CCorePlugin to other classes (for example, CLCoreModel; CL for common language or compiled language). Static methods that are language dependent should be made normal, non-static methods to allow for polymorphism.At patch (to be supplied) also modifies CCorePlugin.getCoreModel() to return the ICoreModel interface, rather than the CoreModel singleton.	CreatedPatch to implement and use ICorePlugin interfaceAdded to org.eclipse.cdt.core.model package.Oops, this is a bug on CDT, not PTP.	3.0
id=158938	REOPENED	CDT	cdt-core	3.1	PC Linux	P3 enhancement	Project Inbox	2006-09-27 05:05 EDT by	Michael Stather	2010-08-26 02:02 EDT (	2 users	When I select "refactor/rename" to rename a parameter of a c funtion, it isn´t changed in the header.	Parameter names of declarations and definitions are totally independent, paramter names in declarations can even be ommitted. There is no need to rename them.Even if you desire to have the parameter names in sync others may not want to have this. There are many options you have to consider:- parameter name matches (rename it?)- parameter names do not match (rename it?)- parameter name is ommited (add it?)- names in parameter list is a combination of above (change all/some/none?) If you really need this feature, you have to come up with a patch.Sorry I´m no eclipse hacker but anyway I think this could be done better so that all users can benefit.Parameter match->renameParameter doesn´t match->don´t renamePArameter is omitted->don´t do anythingThis is IMHO the only right solution, at least I can´t think of any other which makes sense.If the parameter names don´t match in source and header (and the latter isn´t omitted) there´s something wrong. What sense should this have?Yeah, it's probably not a good idea to mark things WONTFIX just because you don't want to work on the issue. Leave the bug open so we can track it. Maybe someone will come along and give it a try. I actually think this would be a useful feature.Besides leaving a bug open on the inbox with target milestone '--', especially an enhancement request, means no one intends to fix it, at least at the moment.***has been marked as a duplicate of this bug. ***	4.0
id=171193	REOPENED	CDT	cdt-core	8.1.0	PC All	P3 normal	Project Inbox	2007-01-22 03:55 EST by	Axel Mueller	2012-07-12 02:44 EDT (	2 users	In a header file I have the following code:typedef enum{ AE_ON = 0, AE_OFF = 1} Adaptiv_T;The outline view shows me the following:<E> (anon) * AE_ON * AE_OFF<T> Adaptiv_TIt would be more convenient to have something like this:<T> Adaptiv_T <E> (anon) * AE_ON * AE_OFF	This is already fixed in 4.0M4.This bug did reappear. It is in the latest Indigo (CDT 8.0) release. I also checked Helios and Galileo (CDT 7.0 and 6.0, respectively). These versions show the incorrect outline, too.	2.0
id=154563	REOPENED	CDT	cdt-core	4.0	All All	P3 normal	Project Inbox	2006-08-21 12:20 EDT by	Andrew Ferguson	2014-11-30 00:14 EST (	12 users	Where the PDOM maintains B-tree indexes into its content, it needs to delete entries when the corresponding project entity goes awayMost notably PDOMFile objects remain in the index even after the resource has been deleted from the project(Implementation to follow)	Createdbtree delete + unit testhi, please find attached a b-tree deletion routine and associated unit test. I've put some javadoc and comments in with the code.thanks,AndrewI had a quick go at linking the delete routine into various places in the code just to see what issues arose and this seemed to work ok (from just looking at the Index View)Some notes: the only issue that came up that might effect a real patch is that for names attached to bindings, the names are deleted without going through the binding, so that the binding contains a pointer to the original list head (even though the corresponding name may have been deleted and free'd). This didn't stop the isOrphaned() method from returning the correct value (which was then used as a sign the binding could be deleted) but am afraid I don't know whyNote: This bugzilla has been generalized to cover both the deletion routine, and its use in the PDOMThere may be a legal issue with the patch, as the algorithm is taken from a book. Are you sure you have the right to do so?Good point. I was very careful to understand the B-Tree algorithms but write the code myself to avoid copyright issues. The delete is a complicated algorithm which is why I didn't have time to implement it.I'm confident its not a copyright infringement (the pseudo-code was very high-level - not even functionally complete) - i.e. there are no portions of code that are copied from the book.Createdb-tree delete implementation, split expensive b-tree tests into separate classhi, please find attached an updated version of the previous patch. I've split out the expensive performance tests as suggested.thanks,AndrewGreat, I can run the tests now. Please externalize the strings you are using. In case they are for debuggin purposes, add $NON-NLS$ tags.At a few places you are throwing RuntimeExceptions. I don't think this is a good idea. Rather than that you should be throwing an exception that has tobe handled by the caller.Createdexternalize strings, and replace RuntimeException->CoreExceptionnow done :)Thanks Andrew! I have committed the patch.fixed in 4.0 > 20061009.I prematurely closed the bug, there is work left to do. While BTree.delete() is implemented, it is not used anywhere.Yes, this next step is tricky. The idea would be to delete bindings when they are no longer defined, declared, or referenced (isOrphaned() is true). We will need to keep an eye on the performance of incremental indexing when we do this. The whole algorithm may need to change since right now we delete all names in the file that changed, which may lead to removing bindings, and then re-add them which may lead to recreating bindings, which may be a lot more processing that there is now, but then it may not be significant.some discussion has happened in 167396 and 165636in addition to deleting bindings from the linkage index on reindex, I think we'd need to(1) files also need removing from the PDOM file index(2) some IType's need to be deleted e.g. if you have the sequence (i) class A {}; A* c; (ii) class A {}; then at the moment you'll have a floating PDOMCPPPointerType. Maybe subclasses of PDOMCPPVariable should delete the records they reference as types, when its an ITypeContainer (?)(3)in reply to:(methods, fields, etc)I would say no - on the assertion that when its actually valid to delete a PDOMCPPClassType (isOrphaned()) then the member bindings must also be orphaned? PDOMCPPClassType would still be responsible for deleting its data structure that points to the member bindings though.I think parameters from functions/methods would be different though as they are currently not PDOMBindings (and so don't have names attached), and also are themselves linked list nodes.When a project is deleted and all contents also deleted, the PDOM index file in .metadata\.plugins\org.eclipse.cdt.core should also be deleted.(In reply to)This works for me (I tested on Windows against HEAD). Please could you retest/open a new bug with more info (version of CDT, OS)? (This bug is about deletion within the PDOM file)Due to the fix for, IndexBugsTest.test154563() is now passing. However, the bindings are still not removed from the index..Using Windows OS 7. CDT 8.4.0 from 2014-6-11.Yes the PDOM file gets deleted when the project is deleted.PDOM files are not deleted after a project is deleted.Version: Kepler Service Release 2Build id: 20140224-0627(In reply to Sumonto Ghosh from)See.	20.0
id=180784	REOPENED	CDT	cdt-core	4.0	PC Windows XP	P3 normal	Project Inbox	2007-04-03 15:25 EDT by	Bryan Wilkinson	2007-05-16 15:42 EDT (	1 user	PDOM bindings and composite bindings need apprpriate implementations of hashCode() to behave properly in the ObjectSets and ObjectMaps that are used frequently by the parser.ObjectSets and ObjectMaps use equals() for comparison only while their sizes are small. Once they grow larger, a hash table implementation is employed using hashCode() for comparison.	Createdproposed patchFor PDOM bindings, the hash code is calculated based on that of the PDOM's path and the node's record number.Composite bindings return the hash code of their representative bindings.A test case is included checking that both of these types of bindings can be now be used as keys in ObjectMaps.Cool. Patch applied.Oops, forgot to mark fixed.I'm reopening this for discussion.As part ofI've extracted the comparison used by the composite merging routines.This means that the PDOMBinding equals method now is pdom local in the sense that only bindings from a single pdom may be compared. If we have non-pdom implementations of IIndexFragmentBinding, then the current implementations of PDOMBinding.equals, PDOMBinding.hashCode, and possibly CompositeIndexBinding.equals and CompositeIndexBinding.hashCode will have inappropriate semantics for use by ObjectMap and ObjectSet.We also don't have definitions of equals and hashCode behaviour for the AST bindings.Given that all the unit tests are passing as the code is :), I don't see this as of critical importance right now. The two definite failures wil be from (1) non-pdom index fragments (only a theoretical situation for the moment) (2) mixtures of ast bindings and index bindings in ObjectMap and ObjectSet - I'm not sure in what situation this would occur though.Comment onproposed patchPatch has been applied.	5.0
id=189085	REOPENED	CDT	cdt-core	4.0	PC Windows XP	P3 normal	Project Inbox	2007-05-25 03:21 EDT by	Misoullee	2007-06-04 22:57 EDT (	0 users	Build ID: I20070517-1700Steps To Reproduce:hi,Indexer cannot parse for the strcpy get a idenfier 'name' as parameters such strcpy(name,any);2.3.More information:	I don't get it. Please reopen the bug with sample code. It is best to describe whatyou observe and what you expect instead. Thanks.hi, following is a part of my source and it is a sources to develop a small application for ARM embeded linux.//source1.h#include <stdio.h>#include <stdlib.h>#include <string.h>#include <time.h>#include <dirent.h>#include <sys/types.h>#include <sys/stat.h>#include <unistd.h>#ifdef __cplusplusextern "C" {#endif#include <glib.h>#include <glib/gprintf.h>#ifdef __cplusplus}#endif/// source1.cpp#include "source1.h"bool dcm_file_exist(const gchar *path){ return (g_file_test(path, G_FILE_TEST_EXISTS))?true:false;}bool dcm_dir_exist(const gchar *path){ return ( g_file_test(path, (GFileTest)(G_FILE_TEST_EXISTS | G_FILE_TEST_IS_DIR)) ) ?true:false;}bool dcm_check_hidden_file(const gchar * file){ if (file[0] == '.') return true; return false;}bool dcm_check_permission(const struct stat *buf){ if(getuid() == buf->st_uid) { if(buf->st_mode & S_IRUSR) return true; }else { if(getgid() == buf->st_gid) { if(buf->st_mode & S_IRGRP) return true; }else { if(buf->st_mode & S_IROTH) return true; } } return false;}source2.cpp//ommited#include <source1.h>void dcm_scan_rcs(const char* sURI, CDCMId3& dcmid3, CDCMDatabase& dcmdb){ DIR *dir = NULL; struct dirent *dp = NULL; gchar * name = NULL; struct stat buf; char full_path[DCM_MC_URI_PATH_MAX] = {0,}; char root_path[DCM_MC_URI_PATH_MAX] = {0,}; dcm_item_t aitm; strncpy(root_path,sURI,DCM_MC_URI_PATH_MAX); dir = opendir(root_path); while ((dp = readdir(dir)) != NULL) { name = dp->d_name; if (dcm_check_hidden_file(name) == false) { memset(&buf,0x00,sizeof(buf)); memset(full_path,0x00,sizeof(full_path)); g_sprintf(full_path, "%s%s%s", root_path,G_DIR_SEPARATOR_S,name); DEBUGLOG__("\tDebug --------- a file scanned : %s",full_path); if (strlen(full_path) > DCM_MC_URI_PATH_MAX) continue; DEBUGLOG__("\tDebug --------- a file scanned 2"); if (stat(full_path,&buf) == 0) { if (dcm_check_permission(&buf) == false) continue; DEBUGLOG__("\tDebug --------- a file scanned 3"); if (S_ISDIR(buf.st_mode) == true) { dcm_scan_rcs(full_path,dcmid3,dcmdb); } else { DEBUGLOG__("\tDebug --------- a file scanned 4:before extract"); /// extract ID3 from the file. memset(&aitm,0x00,sizeof(aitm)); /// set URI. strcpy(aitm.uri,full_path); //--> OK strcpy(aitm.filename,name); //--> No Indexer can parse this.//..... do something } } } ///< end of no hidden file. } ///< end of loop.}/**Please explain what you mean by no indexer. Furthermore I think you can reduce the problematic code to something like the snipped below. Please provide the definitions of gchar and aitm, I don't know them.// provide definition of gchar??// provide definition of aitm??void testfunc() { char full_path[100] = {0,}; dcm_item_t aitm; gchar* name; strcpy(aitm.uri,full_path); //--> OK strcpy(aitm.filename,name); //--> No Indexer}hi,gchar is a typedef which glib as well known support. that is defined as "typedef char gchar;" in glib.hand aitm is just a variable to the struct type I defined.for example, the type is a similar as below. typedef struct { unsigned long a; unsigned long b; char c[100]; union { struct { union { struct { int aaa; int bbb; } ss1; struct { char ccc[100]; } ss2; }; char dd[20]; unsigned int ee; } s1; struct { unsigned int ff; } s2; } u1; } my_item_t; //tyepdef struct then i defined the aitm as below. my_item_t aitm; (In reply to)I use C standard library or CRT and GLib for ARM gcc.in fact, if i changed from strcpy(any,name) to strcpy(any,any2) then done well and syntax coloring or code completion ..I have thought which CDT don't work copmletely against C++ Template and typedef since I used first CDT 3.x. On becoming today, CDT's Indexer has improved many but not completed yet.I want for this issue to be resolved.thank you.(In reply to)that's fine, but I don't have your headers on my machine, so please provide a small, self-contained example that demonstrates the problem.I can't reproduce the issue, so I can't resolve it.hi,I figured out important what to resolve this issues.So I could know that the reason is not associated with 'name'.please following examples.In success:// test1.c ( C project, for me it's the Makefile Project by other toolchains )#include <stdio.h>#include <string.h>#include <glib.h> // included for gchar, gchar is in glib/gtypes.h // by using GNU GLib 2.0 library (for ARM architecture)int main(void){ gchar * name = "text"; char temp[256] = {0,}; strcpy(buff,name); // OK, CDT Indexer can defect strcpy symbol and coloring good printf("%s",buff); return 0;}// test2.cpp ( CPP Project, for me it's the Shared Library Project using Cygwin Toolchain)#include <stdio.h>#include <string.h>typedef char gchar; // define in fileextern "C" void func(const char* msg){ gchar * name; name = (gchar*)malloc(strlen(msg)*sizeof(gchar)+1); strcpy(name,msg); // OK printf("your message:%s", name);}In Fails:// test2.cpp ( CPP Project, for me it's the Shared Library Project using Cygwin Toolchain)#include <stdio.h>#include <string.h>#include <glib.h> // included for gchar, for me gchar is in glib/gtypes.h.extern "C" void func(const char* msg){ gchar * name; // Colorize good. name = (gchar*)malloc(strlen(msg)*sizeof(gchar)+1); strcpy(name,msg); // Failed, Indexer can't find strcpy symbol and Synt // if you cast explicitly for parameters, it is success. e.g strcpy((char*)name,msg); printf("your message:%s", name);}hi, did this issue solved?I don't receive any comments about whether is resolved.please look at my last comments in 07-05-30.thank you.(In reply to)I still cannot reproduce the problem. Remember I don't have your header files on my machine. It would really help if you put together a self-contained example that demonstrates the problem, thanks.I don't have glib.h, but if I replace#include <glib.h> // included for gchar, for me gchar is in glib/gtypes.h.with typedef char gchar;the example works OK for me.Did you check the include paths? You should see small yellow warning overlays on the include directive icons in the outline view if they could not be resolved by the parser.(In reply to)--> Yeah, as you see second sample codes of my 7'th comments in 2007-05-30, that's no problem and OK for me too. that is, inline typedef for gchar in same a file do works. but such as below if the typedef is in an another file, Indexer is failed. of course my include path for glib.h is well good.In Fails !!!:// test2.cpp ( CPP Project, for me it's the Shared Library Project usingCygwin Toolchain)#include <stdio.h>#include <string.h>#include <glib.h> // included for gchar, for me gchar is in glib/gtypes.h.extern "C" void func(const char* msg){ gchar * name; // Colorize good. name = (gchar*)malloc(strlen(msg)*sizeof(gchar)+1); strcpy(name,msg); // Failed, Indexer can't find strcpy symbol and Synt // if you cast explicitly for parameters, it is success.e.g strcpy((char*)name,msg); printf("your message:%s", name);}--> sure, the include path is right and yellow warning is not indicated in outline view.I don't have toolchains such Cygwin or Mingw in my local windows xp but I am using VmWare tool to host Linux Fedora. This issue seemes to be happened on C++ project type. I have tested with Shared library and Makefile of C++ project. and I selected External toolchain and Cygwin as toolchain in two test.thanks.	12.0
id=104088	REOPENED	CDT	cdt-core	3.0	PC Windows XP	P3 normal	Project Inbox	2005-07-15 15:43 EDT by	John Camelon	2007-08-21 11:00 EDT (	0 users	#include <string>int main() { std::string s; s.b[^SPC] return 0;}basic string is a proposal.	CreatedScreengrab that shows this.Actually, it is valid:#include <string>int main() { std::string s; s.basic_string::begin(); return 0;}The name of a class is inserted into the scope of the class itself (C++ spec9-2). and string is a typedef of basic_string.Generally, for member completions, the class name appears in the list ofproposals when it matches the prefix.class DEF{ int blah;};class XYZ : public DEF{ }; int main() { DEF d; d.//[^SPC] yields DEF but there is nothing it can do. return 0;}(In reply to)-1It's still a valid proposal, although in this case since there are no publicmembers on DEF, there no valid use of DEF::. But that's the anomoly.I'll mark this as future so that we can fine tune the relevance metric in theproposals to make sure these have a low relevance. If people are annoyed by themin the list at all, we could allow them to specify a relevance threshold.Future means you commit to fix it in the Future. Inboxes can't make committments. Moving to '--'.	7.0
id=223652	REOPENED	CDT	cdt-core	5.0	PC Windows Vista	P3 normal	Project Inbox	2008-03-24 10:39 EDT by	Moshe WAJNBERG	2009-01-09 16:30 EST (	4 users	CreatedCapScreenBuild ID: 20080314_1059Steps To Reproduce:1.On a Windows platform with Hebrew Default locale launch Eclipse with the argument -nl iw2. Create a new C/C++ project3. Create a new class with Name in Hebrew look at its name: It appears as :cpp.ABC and h.ABC (where ABC stand for Hebrew letters)The right display should be:ABC.cpp and ABC.h(see the attached screen)More information:	As per Ahmed's comment:This defect is not valid because in mirrored version of eclipse, the correct order for C++ class name is "cpp.ABC" (where ABC represents Bidi characters). In the non-mirrored version of eclipse, the correct order for class name is "ABC.cpp". As per the screenshot, attached with the bug report, eclipse is running in RTL mode thus the correct order of class name should be "cpp.ABC".Closing as invalid.Reopening this defect because at least for Hebrew users the name should be displayed as ABC.cpp (see Tomer's note)	2.0
id=256880	REOPENED	CDT	cdt-core	5.0	PC Windows XP	P3 normal	Project Inbox	2008-11-28 07:09 EST by	saikarthik natesan	2009-08-26 14:36 EDT (	4 users	Build ID: 3.4Steps To Reproduce:1.Full Indexer option was set.2. Created a CPP Project and added a class.3. Selected the class in PE and renamed it using Refactor->Rename.Rename was successful.4. Now again select same class and click on Refactot->Rename.5. A message pops up saying "Selected name cannot be renamed".Only if cpp project is closed and reopened refactor happens for second time.	I can't reproduce this behavior. It's working fine.This one is reproducible when selecting the Class element under the .h in the PE or in the C++ Projects view. If not second time, it happens during third or fourth.The (+) symbol of the Class in PE disappears and the E]elements of the class doesn't get displayed when this happens. The problem goes away if the File is edited and project is recompiled.***has been marked as a duplicate of this bug. ***	3.0
id=261712	REOPENED	CDT	cdt-core	5.0.1	PC Windows XP	P3 enhancement	Project Inbox	2009-01-20 15:11 EST by	Nathan Baker	2009-01-26 10:02 EST (	3 users	Build ID: I20080617-2000Steps To Reproduce:It would be really handy to have a box in the project explorer where I could type a filename or portion of a filename and eclipse would just find it for me (like in cscope). Far more convenient than navigating through a deep hierarchy. (Not 100% sure if this belongs to the CDT folks or the Eclipse folks; sorry if I'm filing this in the wrong place).	Ctrl-F would bring search box. But it is not recursive.Right, I remember seeing that a while back and being happy until I realized it didn't search nodes that weren't expanded.You don't need search box for non-recursive search, just start typing filename. (Btw I get no search box pressing Ctrl-F in Project Explorer.)For recursive search you could use File Search (or Ctrl-H). Leave text empty and provide filename pattern. Enable "Selected Resources". Maybe not too smooth but does the job.I think there are enough methods are provided to achieve this,resolving as "won't fix"Le sigh. Well, if you won't you won't. Dealing with the global search dialog isn't significantly better than manually navigating through the project explorer, though.(In reply to)Don't do that. If someone wants to provide a patch to make this work cleanly, then let them. We can review it then.(In reply to)Ctrl + Shift + RBrings up the Open Resource dialog. It provides the functionality that you are asking for, but in a dialog instead of right in the project explorer.This seems to find .d and .o files as well, but it's certainly better than nothing. Thanks for the suggestion!Nathan	8.0
id=259898	REOPENED	CDT	cdt-core	5.0.1	PC Windows Vista	P3 normal	Project Inbox	2009-01-03 16:25 EST by	J. Rhett Aultman	2010-06-12 12:16 EDT (	3 users	Build ID: M20080911-1700Steps To Reproduce:Using CDT 5.0.1.200809120802 (both with and without GCC toolchain), creating a new C or C++ project freezes Eclipse. The project folder and a .project file is made, but nothing else. I am using Vista and Cygwin is installed correctly and accessible from the command line (i.e. I can run gcc from the command line). There are no "Managed Makefile" projects as per the CDT FAQ, either, but there is an "Example Hello World" under C++ Projects.More information:	***has been marked as a duplicate of this bug. ***Attempted to repeat this on a Windows 2000 machine at work. No problem creating a project there. Could this be something Vista specific? I believe both home and work machines are using JRE 1.6.0Please try to obtain a thread dump of the JVM. Seefor instructions.The <workspace>/.log file might also be helpful. Thanks.CreatedThread dumpThread dump attached. Captured a few seconds after causing the deadlock.I don't see a .log file under my workspace, so I cannot attach that.(In reply to)Thanks for the dump.My bad. The location is <workspace>/.metadata/.log.It looks like the scanner info provider blocks trying to read from the gcc process which it has started to retrieve the compiler specs.If the process is still runnning at the time of the freeze, killing the process should unfreeze the IDE.Could you try running the following command on the command line:gcc -E -P -v -dD <workspace>/.metadata/.plugins/org.eclipse.cdt.make.core/specs.cppGood show. When I ran the command, gcc entered a locked-up state complaining about shared memory problems that were likely the cause of cygwin1.dll version mismatches. I found the one in my cygwin install and kept it and deleted the others. The gcc command started working just fine and Eclipse came unblocked as well. After adding make to my cygwin environment, I can now build and run the "Hello World" project.However, I have some additional concerns. The other cygwin1.dll files were associated with my Processing environment, my Arduino environment, and the WinAVR tools. I simply did away with all of them to be safe, but when I reinstall these, won't I start having the same problem again?(In reply to)Good to hear you solved the problem.I am afraid, there is no guarantee that this won't cause problems again. At least, I don't see a way where CDT could help avoiding them. Maybe using MinGW is an option for you?Marking as NOT_ECLIPSE.Surely the fact that we're running an external tool on the UI thread which, when it blocks, gives the appearance of a deadlocked Eclipse is in fact a bug in CDT?(In reply to)True. That's not nice. There should be at least a way to cancel the wait. Reopening.	10.0
id=265815	REOPENED	CDT	cdt-core	5.0.1	PC Windows XP	P3 normal	Project Inbox	2009-02-23 07:13 EST by	Pavan V	2009-03-04 09:50 EST (	5 users	Whenever a change is made to a CPP source immediately followed by a Save (Ctrl-S) , the save event is notified first by the CDT CModelManager (to all subscribed listeners) followed by the reconcile event. Since the save event (ElementChangedEvent.POST_CHANGE) fired does not contain the change delta, the reconcile event (ElementChangedEvent.POST_RECONCILE) is relied upon to gather the change delta. In the case mentioned above, the last reconcile delta is provided after the SAVE event causing any attached listener/save processor to lose this reconcile change.Please note, if a change is made to a CPP source and a save is fired after a brief interval, this problem is not seen.	This works as expected. Save and reconcile do not depend on each other.What are you trying to accomplish?My app locally stores all the reconcile deltas as and when I get them and processes them on the save event. In the case that a change is made immediately followed by a save, the save event is fired first followed by the reconcile - causing me to lose/not process the last reconcile delta. Save event does not tell me about changes like rename/add/delete of CPP elements made in the source file, I completely rely on the reconcile event for this.Even if the reconcile and save are considered as different operations, the save event is fired first by CDT (always) followed by the reconcile event in the case mentioned above. It does not reflect the actual order of the events right?(In reply to)A reconcile is triggered by the editor with 500ms delay after a change. Whether the save happens before or after that is irrelevant.Therefore your assumption that reconcile always happens before save is not correct.(In reply to)Agree, but I am talking only about the case where a change happens just before a save. As you said, in this case, the editor waits for 500ms and then fires a reconcile. If in that 500ms delay, the save event is already fired, I'll be receiving the fire event before the reconcile.Shouldn't the editor also fire the reconcile when there is a save fired? Can't the click of save be considered as a checkpoint just as a 500ms delay is considered as one?Reconcile and Save may be handled as different threads inside CDT but the event notification for both is done on the same listener (that I have registered) - the sequence of events is important for me to handle these changes(In reply to)Reconcile means parsing the file. This takes time. To synchronize the reconcile operation with the save event we would need to slow down the save (waiting for the file to be parsed). We would get bug reports about that very soon.You need to find a different way to accomplish that. E.g. you can do the following:- when an editor is opened - create a private working copy- upon save - copy the new content into the private working copy- reconcile the working copy(In reply to)This would be a very costly change from our end - considering that performance issues may crop up in our application as well. Can't there be a third type of event created (say SAVE-RECONCILE, containing the reconcile delta in it) solely for this purpose? Only in the scenario that a reconcile event is fired just before save, need this event be triggered. This would mean parsing need not be done for every save but only for the exclusive case mentioned before.(In reply to)Everything Toni says makes sense to me.And I'm not sure how you expect this new event to know that the save "just happened" and corresponds to what the current state of the model according to the reconciler is. Even if we were to add a flag to the ICElementDelta to state whether the working copy was dirty or not at the time the reconcile happened, or track timestamps on when the reconcile started, I don' think we could properly do it. You would end up with a concurrency problem because the save could happen during the reconcile (or vice versa). Then you're back into making one contingent on the other, which means slowing everything down.To complicate things further, it's entirely possible to do multiple saves while the reconciler is running. Then the reconcile finishes and notifies you... if we did it the way you describe, you'd still be in trouble because you would end up thinking the delta came from the last saved content, when it didn't.I think Toni is right, you need to find another way to do whatever it is you're trying to do.	7.0
id=288340	REOPENED	CDT	cdt-build	6.0	PC Linux	P3 normal	Project Inbox	2009-09-02 06:44 EDT by	Christopher Friedt	2009-09-03 12:19 EDT (	1 user	User-Agent: Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.13) Gecko/2009080315 Ubuntu/9.04 (jaunty) Firefox/3.0.13Build Identifier: I20090611-1540Hi, I'm using Eclipse Galileo and the most recent (stable) CDT environment for Linux kernel development. I've set up the project as a 'Makefile Project' and I'm cross-compiling from i686 to ARM.My feature suggestion is to make the 'built-in' headers adjustable (i.e. delete/repriorities) for a CDT Makefile project. In many makefile projects, built-in header files should definitely take priority over the ones that the CDT claims are built-in (especially when the project specificies -nostdinc in the Makefile).Currently, Eclipse will often (almost always) bring up the wrong header file when I Ctrl+click on a struct, include, function, or macro. The reason for this is that I'm using the default 'Linux GCC' configuration, and it will not allow user deletion / prioritizing of the 'built-in' include/header paths, as defined in Project->Properties->C/C++ General->Paths and Symbols->Includes->GNU C . My project-specific include paths are listed in priority from bottom to top. They are all 'workspace paths'. /linux-2-6/include/linux-2.6/arch/arm/include/linux-2.6/arch/arm/mach-pxa/includeHowever, there are 4 'built-in' paths that are of absolutely no use to me, and I cannot delete them or set my include paths to a higher priority (i.e. put them lower in the list-view). /usr/local/include/usr/lib/gcc/i486-linux-gnu/4.3.3/include/usr/lib/gcc/i486-linux-gnu/4.3.3/include-fixed/usr/includeSubsequently, if I Ctrl+click on something that says '#include <linux/i2c.h>' in any file I'm editing, then Eclipse opens /usr/include/linux/i2c.h, rather than /linux-2.6/include/i2c.h (workspace path). They are actually completely different files, which does often happen with kernel development. My build command is make ARCH=arm CROSS_COMPILE=arm-none-linux-gnueabi- I've changed the 'Make build target' to 'zImage modules' as opposed to 'all' for 'Build(incremental build)'. The build works, but the content assist and IDE only offer a marginal amount of usefulness. Likely due to this as well, Eclipse will not properly parse printk(...) siting a syntax error, in spite of defining the __KERNEL__ symbol in the project properties. Perhaps there's somebody with some Linux kernel development experience who can tell me exactly what I'm doing wrong. Reproducible: AlwaysSteps to Reproduce:1. Create a Makefile project2. Check out linux kernel sources3. Add workspace paths4. Add __KERNEL__, CONFIG_PRINTK symbols to project properties5. Open a file that includes <linux/i2c.h> 6. Ctrl+click on linux/i2c.h7. Observer that /usr/include/linux/i2c.h is opened.Really, for Makefile projects, since they're only used for parsing the C source code, 'built-in' include paths should be completely user-manageable.	(In reply to)Sorry, that should read:arg!(In reply to)Woops... I guess this is my bad (you may have guessed with how bad my typing is). I think I may have just forgotten the leading 'l' in /linux-2.6/include, which was probably the most important of the workspace include paths. It seems to be working fine now. Sorry for any inconvenience.Regardless, I think a request to allow more control over built-in entries is legitimate.I agree we need a button to remove/disable "build-ins". "Build-in" In quotes because it is comes from scanner discovery which is not that good. I was fighting to remove some of the entries from the list.End-up editing xml file. They were still coming back sometimes. Yikes.So I will re-open this bug for this purpose (unless we find a duplicate)There are a few bugs around like,,but they do not say remove built-ins explicitly. Arguably they all together could make this one duplicate. The thing is that we need to have control over these entries in UI.	6.0
id=234860	REOPENED	CDT	cdt-core	5.0	All All	P3 major	Project Inbox	2008-05-30 10:34 EDT by	Martin Oberhuber	2012-01-13 12:19 EST (	14 users	The CDT New Project Wizard presents a tree of project types to choose from. The major usability problem here is, that the "container nodes" in this tree also have the meaning of a specific project type.For instance, in order to create a new "Standard Make" project, one needs to select the FOLDER named "Makefile Project". This is totally unintuitive, and I doubt that any CDT newbie will find the correct way of operating this.For reference, see also this mailing list message:which many people agreed on immediately. I'm setting severity Major since I really think this is a big, big hurdle and information about any workarounds that project teams picking up CDT (by extending it) can apply would be highly appreciated.Here are two ideas:(1) Adding a wizard named "Default empty ... project" below each folder node, which performs exactly the functionality that the folder node performs. Is this something that a CDT extender can do without modifying CDT itself?(2) Clean up the tree structure, providing more meaningful container categories and nodes therein. For example, a tree like this, where the items with trailing / are non-selectable folder nodes: Managed Build/ + Executable + Shared Library + Static Library + Empty Project + Examples/ + Hello World C++ Project + Hello World ANSI C Project Makefile Project/ + CDT Makefile Project + Examples/ + Hello World C++ ProjectPointers to relevant documentation, or an FAQ entry, would also help in the Ganymede time frame.Other bugs from bugzilla that are probably related and should be reviewed in this context:,,,	CreatedProposed patchCreatedPart 2I've added the patches we have at CodeSourcery for this issue. Now, the project categories are not selectable, and if you try to select them you are told to select a specific project type. Each project category has a "Empty project" type automatically, that creates a project without using any template. The only issue I know about those patches is that the new strings have to be externalized. Otherwise, I'm not aware of any issues.Neither of these patches applies cleanly to HEAD. Can you regenerate them?CreatedRefreshed patch #1Sorry, it appears the like first patch had our local change in its context. I've refreshed it now, hopefully it's better.I'll refresh the other patch later.(In reply to)Your patch #1 has a problem in that none of the strings are externalized to facilitate national language translations. That will have to be fixed before we can consider committing it.Otherwise the patch looks good and I have no objections to it. I suppose it's arguable as to whether the "feature" should be allowed into 5.0 past the feature freeze, but personally I would argue that the impedance to new users merits this patch's inclusion as a "bug fix". I would be curious to hear the opinions of others on that.I agree with Chris. Should we ask to vote on it on the mailing list?I can externalize string while applying the patch(In reply to)I've already sent a mail to the list.I've assigned the bug to myself so I will take care of the commit once Vlad updates his patch (assuming no one ends up objecting).+1it might be good to(a) setErrorMessage/setMessage(String,int) when a category is selected (to be consistent with other conditions where the user is blocked from continuing)(b) select Executable->Empty Project by defaultThat's what the second patch does. I'll externalize strings in the first patch and refresh the second patch in an hour.CreatedPatch #1, with string externalizesCreatedRefreshed patch #2This patch makes the "Executable" category expanded automatically, and the first child of it selected.Note that the behaviour I observe in CDT5 CVS is somewhat different from the behaviour I had in our product. There, the "Empty Project" element was the first child, and it was pre-selected. In CDT5, the "Empty Project" element, and the selected one is the "C++ Hello world". Apparently, the order depends on the order extensions are traversed in CDTMainWizardPage.updateData. I'm not sure if there's any non-hacky way to get "Empty Project" always be the first child.(In reply to)I'm believe you can do this - the tree items are backed by EntryDescriptors:if (target == null) { TreeItem category= tree.getItem(0); if (category.getItemCount() > 0) { target= category.getItem(0); for(TreeItem item : category.getItems()) { if(((EntryDescriptor)item.getData(DESC)).isDefaultForCategory()) { target= item; break; } } } if(target == null) { target= category; }}CreatedPatch #2, with fixed items orderThis version of the patch makes sure that the "Empty Project" item is always the first child, and make it pre-selected.Andrew,your solution would make the "New Project" item pre-selected, but will not make it appear as the first child. However, the idea is easily adaptible to make it happen, which I did.So, now this issue has two non-obsolete patches, against CVS HEAD, with strings externalized. I'm not aware of any other outstanding issues.I see one remaining problem - the first time you select a category, the error message in the r.h.s. panel doesn't appear (this isn't intermittent for me). If you select it a second time, or resize the dialog, then it appears.seeVlad, can we expect a patch which solves the remaining issues?CreatedPatch #3, to make sure the label appears the first time aroundSorry, I've somehow missed the last comment. I attach a patch, to be applied on top of the other two, that makes the label appear the first time around.I am noticing a problem with the patch(es) : the message about having a category selected shows up if you have other project types defined and you select one of them.How can I reproduce this problem? What are those "other project types"?(In reply to)A quick way is to install the XL C/C++ plugins.One confusing thing for new users is "Managed Build" terminology. It is not quite clear: Does "Managed" mean that you are supposed to manage it or eclipse? Similar confusion is about "Makefile Project": is it about your makefile or eclipse-generated one? Is it possible to eliminate the confusion, for example "CDT Managed Build" or "User Makefile Project"?Thanks.CreatedPatch #4, don't mark old-style projects as 'category'This patch fixes the problem with the old-style projects. ManagedBuildWizard used to create EntryDescriptor instances with 'category' flag set. This does not seem to make sense to me. However, just setting the flag to false broke the 'group old style projects under Other' setting. The problem is that we use to, if we find a EntryDescriptor that is not category and where parent does not have a associated handler, to just skip this EntryDescriptor. This is clearly wrong -- if the EntryDescriptor has a handler itself, we don't care if parent has, or does not have, a handler, so this patch fixes that bit as well.What is the ultimate resolution on this issue?Applied to 5.0.1 and HEAD. Thanks for the patches!(In reply to)The applied patch has some UI issues. The message "Project category is selected. Expand the category and select a concrete project type" is displayed under the Toolchains: label, which is confusing. The message should be displayed in the message area of the top section of the dialog without hiding the Toolchains list.Reopened.I do not agree this UI is wrong. The message is shown exactly where a user expects to see the list of toolchains. Also, we had users regularly overlook messages in the top area of the dialog.(In reply to)Users are even less likely to pay attention to the dedicated message area of dialogs, if every dialog will follow its own rules.If you insist on displaying the message next to the project type selector, the dialog should at least hide "Toolchains:" label together with the control it belongs to.(In reply to)The patch makes it impossible to create XL C/C++ projects. Select "Executable (XL C/C++) as a project type. There is no templates/subitems defined and no "Empty Project" generated so it cannot be expanded. Toolchain cannot be selected and so "Finish" is grayed out even if there is just one toolchain available. I could not care less about XLC project types, but we use our custom toolchain and it got the same problem. I'd say it's pretty critical issue not to be able to create a new project.Also, I find it even more confusing for new users. There is more objects in the window now and it is harder for a new user to get focused. I agree with Sergey that users are less likely to notice the hint under "Toolchain" when they are concentrating hard to figure out what to pick on the left. New users are not even familiar with the "Toolchain" concept.I am trying to do it from the head. 5.0.1.200809120802 looks OK though. Not sure what is going on, let me check.Looks like I picked old one 5.0.1.200808290803. Sorry for the false alert.I think the current message is sufficiently easy to notice. When you select the folder, the entire toolchain area suddenly turns from white to grey, which is bound to draw the user's eye.We could compromise and display the message in both locations.I think this is all very minor and I do not think we should hold up 5.0.1 for this. I will target 5.0.2 for the rest unless someone strenuously objects.Given that the original request has been fixed, wouldn't it be more appropriate to keep this bug fixed (with milestone 5.0.1) and open a new bug (with milestone 5.0.2) for the additional request of modifying the messaging?(In reply to)Waiting first to hear if anyone objects, but yes...(In reply to)I agree that it is minor and would compromise to have one message where it is now rather then have it in 2 places.Actually, I would argue that the message is not necessary at all and causes more confusion than good (i.e. the user has to read it). Just make it so that the folder items are not selectable. Then it would not be necessary to tell the user that they selected the wrong thing.Here's another idea.The tree never has depth greater than two (as far as I can tell). So instead of having a tree we can split it into two separate lists. So there would be three list widgets at the bottom of the wizard. Project Type: Template: Toolchain:+--------------+ +---------------+ +------------+| *Executable* | | Empty Project | | Linux GCC || Makefile | | *Hello World* | | Cygwin GCC || XLC | | | | || | | | | || | | | | |+--------------+ +---------------+ +------------+First the user selects the project type and the available templates are displayed. Then the user selects the template and the available toolchains are displayed.Is it reasonable to assume that we'll only ever have "type"->"template" hierarchy? That is likely not to scale very well.(In reply to)I have an project type contributed by an extension for creating projects based on existing code. The notion of "template" look pretty foreign for that use case.Why are XLC project types not in folders? Shouldn't "Shared Library (XL C/C++)" go to "Shared Library" folder? It is not very populated. How is it different from "Shared Library/Empty Project" with XLC toolchain? Well, if they are strongly "other project types", perhaps as a second best choice they could be kept in "Others" folder - along with any other custom project type.My use case is to create a new project of the same type (custom one) repeatedly. I am pulling them branches from CVS several times per day creating new projects. It would be nice if the last selected project type+toolchain would be remembered and automatically selected next time opening the wizard. Was there a while ago "Preferred toolchain" notion? "Executable/Empty project" is always a wrong choice for me along with the other unnecessary (for me) templates. For my particular workflow (maybe not routine for many) I would rather prefer "Executable" folder collapsed.Returning to the pool.	41.0
id=312298	REOPENED	CDT	cdt-core	7.0	PC Linux	P3 normal	Project Inbox	2010-05-10 12:43 EDT by	Jeff Johnston	2013-03-03 16:34 EST (	8 users	CreatedZip containing autotools project: hello and simple Makefile project: makefileAn Autotools project which is a form of a Makefile project has a build definition which specifies false for supportsManagedBuild. The CommonBuilder is used to perform the make portion of the build.When the project is initially created, a source file will have unknown header files shown in the C/C++ editor. This is expected. After building, the header files will be resolved and can be opened via the Outline View.There are two problems.1. If the workspace is closed and reopened, the header file resolution is lost and the file in the editor will show the header files are unknown until the next build.2. There appears to be no indexing performed automatically. Manually forcing a rebuild of the index does work. Again, this information is lost across a workspace close/reopen.The behaviour above does not occur for a ManagedBuild project.Creating a vanilla Makefile C project and adding a simple Makefile plus source (i.e. non-autotools) results in no header file resolution, even after building is successful. I do not know if the current Makefile project is the old format or uses the CommonBuilder and is closer to an Autotools project definition. If not, then a separate bug should be opened.I will attach the Autotools core plugin.xml for the relevant build definition. I will also attach a zip file containing the Autotools and simple Makefile projects used for testing.	Createdplugin.xml file for Autotools core which contains Autotools project build definitionAdded plugin.xml for autotools core plugin.(In reply to)Update. Indexer seems to be working today for some reason. I can F3 on a C library function and it finds it in the glibc header file correctly. Interestingly enough, it still can't find the header files after close/restart of the workspace but finding the function definition does work (i.e F3 works for puts - a function in stdio.h, but it claims not to know about stdio.h in the outline view).Update for RC2 using the Helios RC2 Package from:If I create a C Project -> GNU Autotools Project -> ANSI Hello Worldthe project will build and the headers are resolved.If one closes the project and reopens it, the headers are marked with warnings even though the indexer works fine on the various C functions used within. Building the project, cleaning the project again does not seem to remove the warnings from the header files.Where is the ScannerDiscovery info going and why isn't it being recalculated?I may have a fix in the pipe. Try the lastest hudson build (>= 193) and see if it fixes your problem too.Is this still an issue?(In reply to)Yes. Closing the project and reopening results in the headers being denoted as not found. The problem can be cleared by rebuilding.The ScannerDiscovery info does not appear to be saved across sessions.(In reply to)Yup, I've seen that too. But the scanner info is saved. It just doesn't get loaded by the project model properly.The odd thing is that my Android projects are getting loaded correctly. But when I create a C++ project with the same toolchain, it doesn't. The bizarreness continues.I'll take a look at this after my vacation and see if I can fix it for 7.0.1. For 8.0, I'd like to hook up the project model directly to the scanner discovery data which I do know is getting persisted properly.(In reply to)Thanks, reassigning to core.***has been marked as a duplicate of this bug. ******has been marked as a duplicate of this bug. ***I have made a fix to the Autotools Wizard to get around this issue. The Autotools build definition includes gcc and g++ compilers in the Autotools toolchain which superclass the gnu gcc compiler and gnu g++ compiler respectively. In project creation, the project description gets set and this eventually kicks off a check of the compiler optimization level of the gcc compiler tool. This option has a default value that changes based on the build type and this causes an option set to occur which triggers a notification which causes a call to getCLanguageDatas(). This in turn gets an instance of the gcc compiler input type with calculated id. Later in this cycle of setting the project description, a call to createMap() for the CfgScannerConfigInfoFactory2 class looks at each tool in the toolchain and creates a context only if the input type is not an extension (i.e. has an calculated id). The save() method of CfgScannerConfigInfoFactory2 is then called which checks the map to see if the scannerBuildInfo should be saved to the .cproject file.For ManagedBuild projects, this works because of the getCLanguageDatas() call such that by the time the call to save() in the CfgScannerConfigInfoFactory2 call occurs, there is an item in the map such that creation of a scannerBuildInfo entry occurs in the .cproject file.For Autotools, the set of the options does not occur and so we don't trigger the notification. This is due to the fact that the options holders do not equal the holders (tools) passed into the propertiesChanged() calls for the tools so the setOption does not occur. My guess is that has to do with the fact that the toolchain is inheriting these options by way of the superclassed gnu gcc tool. By the time the save logic gets invoked for Autotools, there is no context info created as the input type for the gcc compiler tool is still an extension and so no save occurs.After this, Autotools does end up getting the C Language datas, but it is too late because nothing calls the Scanner Config Info Factory to save it. The dirty flag may not even be set at this point.The fix is to override the createProject() method of the Wizard handler and add some logic following the super.createProject() which essentially resets the project description back again. By this time the input types are set and the Scanner Build info gets written to the .cproject file. This code is just emulating what occurs when the C/C++ Discovery Tab is opened and the OK button is pressed.Pressing the OK button is a workaround for older projects where this is occurring as this causes the Scanner build info to be written to the .cproject file and subsequent restarts of Eclipse work fine from then on.You've made a workaround for Autotools but the issue is still there for Makefile projects as evidenced by duplicate bugs. Let me reopen the bug. Thanks for the detailed description.	12.0
id=315540	REOPENED	CDT	cdt-core	6.0	All All	P3 major	Project Inbox	2010-06-03 04:47 EDT by	Alex Blewitt	2015-09-21 08:54 EDT (	3 users	Build Identifier: Code in Linkage.java requires a new hard-coded enum to be added for each new language supported by CDT. This reduces the possibility of adding new languages to CDT.Reproducible: Always	The tools that work on top of an AST have a right to understand what language they are looking at. An enumeration is a clear piece of information compared to some id or a label. Several clients would have to try to guess the language of an IASTTranslationUnit via parsing an id/label.It is not hard to add a constant to the enumeration, see.I have no objection to the tools understanding what language that they are working with. However, an enumeration is (by definition) a closed set and therefore can't be extended without updates to the source code of the base platform. The fact that it's possible to extend the set at a later stage is the key part here - having this represented as a String identifier would permit other languages to build upon it without having to have changes made upstream. There is nothing that would prevent an ADT processor not knowing what a language it knows about with a string identifier, so the comment makes no sense. You either know what it is, or you don't - no need to guess.This is just one of many things which makes extending CDT more difficult than it needs to be. If the goal of CDT is to be actively hostile to such extensions, then please close this as WONTFIX again.On the other hand, if you want to make CDT more extensible and open to other extensions, leave this open.(In reply to)I don't see how the enumeration prevents you from writing an ObjectiveC parser, you already have an enumerator for ObjectiveC. I certainly did not want to express any sort of hostility.(In reply to)Right, but by definition, an enum is a closed set that requires changes upstream before it can be used. So for Objective-C, this may no longer be an issue, but for Next Great C-based Language (Go?) it will be. Furthermore, it essentially locks out the ability to use Eclipse until Eclipse+1 comes out with the new linkage in. I found in the initial stages of ObjectivEClipse that I had to ship patched versions of CDT just so that constant was defined.The reason for raising this (and other bugs) were real problems that I ran into whilst (trying to) develop Objective-C support. It will bite anyone who tries to do another language dependent on the CDT infrastructure. I also don't see a need for such a restriction, when using a generic String instead of an an int would permit an open set of results. One could use "C", "CPP" and "ObjC", for example - and then Go could be added by using "Go" as a string later without having to file a patch and then wait for the next stable (or release) version to come out. And given that Strings are intern'd in Java, it doesn't take up significantly much more memory than an int would (both will have 32 bit instance references, or a compressed OOP for a 64-bit JVM) but it is extensible without having to change the CDT core.My point is that Objective-C could work because you can tweak the existing parsers to add it in.But if you have a new language that requires a new parser, then it's too much work, if not impossible to add it in. The CDT AST infrastructure is very tied to the parsing style we used. And I don't expect other people to write parsers that way.So while I had hoped that we created the CDT DOM (AST, Binding, and Index) so that it can be used by other languages, the optimizations we've done over the years broke that, if it was ever properly built to begin with.So for other new languages, we need to create a new multi-language framework to support them. Xtext could be that but you need the full power of ANTLR to pull of common programming languages. Maybe they'll get there.(In reply to)I think we need to be a lot more clear about what it means to have CDT be extensible for a new language. Firstly I don't think parser extensibility is even close to being the hardest part. I was able to make the LR parser extensible by simply providing reusable grammar files and action classes. Parsing produces an AST from some text, fine, now what do you do with that AST? That's the important question.I'm talking about stuff like the binding resolution algorithms which are incredibly complex. They basically encode most of the semantic rules of C/C++. How do you make something like that extensible? I see two levels...One way would be to plug in at a fine grained level. This might be useful for small language extensions like UPC which tend to only provide a few new things on top of C. If I could just extend a parser with a few grammar rules, add a few semantic rules, a handful of AST nodes etc. Unfortunately I don't think this would work without extensive architectural and algorithmic changes to CDT. And introducing API at that level makes evolving the CDT core much harder.UPC does barely work though. The UPC parser represents UPC constructs in way that is digestible to CDT by "reducing" the new language features to ones CDT already supports. For example the UPC forall loop extends a regular C for loop, which isn't actually correct but makes it work. That's about as far as I got, anything else was big trouble. I even gave up trying to get "shared int" to show up in the outline view. Another example is that the editor help system doesn't even support using a content type other than C/C++. My point is that sweeping changes across the core and UI would be needed to make this work, including introducing tons of API. Is there even demand for such a framework? I think its a non-starter. I could have just added UPC support directly to the core and probably would have gotten a lot farther.The other level would be very high level. Basically you provide an almost complete standalone solution that plugs in only at specific points like ILanguage. You provide a complete parser with binding resolution, AST, index linkage etc. Many parts of CDT could be reusable, specifically the preprocessor/lexer which already buys you a lot. But still there's a ton left to do. And then how do you extend the UI? For the sake of argument say there's some editor trick you could do in Obj-C that doesn't apply to C/C++, how do you extend the existing editor with that? How do you make the call hierarchy extend able to support all kinds of fancy stuff that can't be predicted like multi-methods. Do you have to provide your own editor and type/call hierarchy? All this stuff needs to be thought through.My opinion is that the tooling needs to know a lot about the language in order to provide powerful and useful features. So you're writing at least half an IDE from scratch to add a new language to CDT, if not more.That's why I think Markus is on point. The best approach would be to add objective-c directly to the CDT core as a third officially supported language. CDT is open source, anyone can provide patches, participate in the community, and work towards becoming a committer. I don't see why doing it this way makes CDT closed or hostile. And having ParserLanguage be an enum forces anyone truly serious about supporting a new language to work closely with the CDT community to do it.I suggest that we move the generic discussion of what-makes-it-easier to the parentrather than this one (which is just one instance of the problem).I currently ran into this problem as well. I am working on adding support for IAR language extensions to Standard-C and ANSI-C. I could already add support for the @-operator and IAR-defined keywords by defining my own language, where I configured the scanner and adjusted the parser accordingly. Now I am facing the problem that IAR also provides support for members in nested anonymous unions/structs, as I have outlined here:. I think I need to adjust the linking to deal with that and could finally locate the handling of anonymous members (of top-level structs/unions) inside PDOMCLinkage. I thus could (quite) easily add the respective support if I could replace PDOMCLinkage with my own linkage. The extension points CDT provide assume that this could be done in the context of an own language definition. I.e. my custom language can return a linkage ID, and I can register a PDOMLinkageFactory with the language extension. However, it seems that the relationship between the linkage and my language is never established by the CDT core, as the list of known linkages (that is used by the indexer infrastructure) is limited to those that are "hard-coded" in Linkage.The restriction that Linkage registration is based on a static predefined list seems to be a blocker to my language extension use case (see).While I can contribute my own language, linkage and indexer (to ensure that the linkage is considered during indexing), I am unable to "bind" the linkage to the language because of the implementation within PODM#createLinkage(int linkageID) falls back to the static list of Linkages contained in Linkage.getLinkedName(linkageID), so that the linkage factory will never be used.Without having Linkage evaluate the registered linkages dynamically, the pdomLinkageFactory entry in the language extension point is pretty much useless.	9.0
id=345240	REOPENED	CDT	cdt-core	8.0	PC Linux	P3 minor	Project Inbox	2011-05-10 05:59 EDT by	Thomas Kallenberg	2011-10-04 17:45 EDT (	1 user	Build Identifier: 20110204-0611If I try to resolve the binding for the name (a) func() in the following codevoid func(int i) { }void testFunc() {(a) func();}after i ran a full rebuild of the indexer the binding is a problembinding with two candidates. first it finds the function in the local ast (which is a CPPFunction) and then in the indexer (which is of type PDOMCPPFunction)I think the problem could be in CPPScope function:getBindings(IASTName name, boolean resolve, boolean prefixLookup, IIndexFileSet fileSet, boolean checkPointOfDecl)first the function gets the function from AST with: getBindingsInAST(name, resolve, prefixLookup, checkPointOfDecl) and later it finds it again with:index.findBindings(nchars, filter, null).So, first question: is this behavior correct? Why it reports the same function twice? I cannot see any benefits. Even more, if rely on the number of candidates the behavior is misleading.Thanx ThomasReproducible: AlwaysSteps to Reproduce:1. Write the global free function2. rebuild the indexer manually3. look at the candidates of the problembinding	It's a problem binding because the argument-list does not match the parameters of the function.sure, but the only available candidate of the problembinding is reported twice...(In reply to)Ah, I did not think that this would be an issue.	3.0
id=343510	REOPENED	CDT	cdt-core	8.0	PC Linux	P3 normal	Project Inbox	2011-04-21 06:27 EDT by	Lukas Felber	2011-07-23 12:41 EDT (	4 users	Build Identifier: I20100608-0911When running (not debugging) a program which causes a seg-fault, this is not shown in any way in the eclipse-console (whereas a normal system console does).The feedback is definitely irritating since I cannot see any difference between a correct and none correct running program.I am supervising C++ classes at my university and not reporting a seg-fault causes my students to see CDT as bad product. I suppose that this is not what CDT wants to be!?By the way, I am aware that there is the duplicate. Since the problem was ignored there I deliberately report it again here.Reproducible: AlwaysSteps to Reproduce:1. run the following program:int main() { main();}	I'm going to mark this not eclipse. The seg-fault message comes from the Java VM.(In reply to)I'm not very happy with your "solution". I'm trying to help improve CDT here. If you like to have CDT seen as bad software by newcomers then just leave this bug closed. Is there no interest in having CDT be simple and informative also for new C++ developers?There should be a way to handle that seg-fault coming from Java VW by CDT. Apparently there is such a way since one can see ( -> in CDT ) that a seg-fault occurred when running in debugging via CDT.since the problem is neither "non-eclipse" (in my point of view) nor "solved" in any way, I reopen the ticket.Yes,I agree that this bug can be annoying, especially for university students who often use their terminal for debugging, they won't see it in Eclipse console.	4.0
id=363462	REOPENED	CDT	cdt-core	7.0.2	PC Windows XP	P3 normal	Project Inbox	2011-11-10 08:50 EST by	Marko Tomljenovic	2011-12-12 07:58 EST (	2 users	Build Identifier: 7.0.2If I delete a closed project CModelManager throws the following exception:org.eclipse.core.internal.resources.ResourceException: Resource '/example_c_cpp' is not open. at org.eclipse.core.internal.resources.Project.checkAccessible(Project.java:137) at org.eclipse.core.internal.resources.Project.hasNature(Project.java:511) at org.eclipse.cdt.internal.core.model.CModelManager.resourceChanged(CModelManager.java:890) at org.eclipse.core.internal.events.NotificationManager$2.run(NotificationManager.java:291) at org.eclipse.core.runtime.SafeRunner.run(SafeRunner.java:42) at org.eclipse.core.internal.events.NotificationManager.notify(NotificationManager.java:285) at org.eclipse.core.internal.events.NotificationManager.handleEvent(NotificationManager.java:261) at org.eclipse.core.internal.resources.Workspace.broadcastEvent(Workspace.java:321) at org.eclipse.core.internal.resources.Resource.broadcastPreDeleteEvent(Resource.java:1993) at org.eclipse.core.internal.resources.Resource.delete(Resource.java:771) at org.eclipse.core.internal.resources.Project.delete(Project.java:331) at com.bosch.codenav.testutils.util.TestHelper.deleteProjectAndWait(TestHelper.java:878) at com.bosch.codenav.testutils.util.TestHelper.clearWorkspace(TestHelper.java:1688) at com.bosch.codenav.testutils.profiling.AbstractMemoryTest.finalizeAbstractMemoryTest(AbstractMemoryTest.java:242) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at java.lang.reflect.Method.invoke(Method.java:597) at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:44) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15) at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:41) at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:37) at org.junit.runners.ParentRunner.run(ParentRunner.java:236) at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:49) at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38) at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467) at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683) at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390) at org.eclipse.pde.internal.junit.runtime.RemotePluginTestRunner.main(RemotePluginTestRunner.java:62) at org.eclipse.pde.internal.junit.runtime.UITestApplication$1.run(UITestApplication.java:116) at org.eclipse.swt.widgets.RunnableLock.run(RunnableLock.java:35) at org.eclipse.swt.widgets.Synchronizer.runAsyncMessages(Synchronizer.java:134) at org.eclipse.swt.widgets.Display.runAsyncMessages(Display.java:4041) at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3660) at org.eclipse.ui.internal.Workbench.runEventLoop(Workbench.java:2640) at org.eclipse.ui.internal.Workbench.runUI(Workbench.java:2604) at org.eclipse.ui.internal.Workbench.access$4(Workbench.java:2438) at org.eclipse.ui.internal.Workbench$7.run(Workbench.java:671) at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:332) at org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:664) at org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:149) at org.eclipse.ui.internal.ide.application.IDEApplication.start(IDEApplication.java:115) at org.eclipse.pde.internal.junit.runtime.UITestApplication.start(UITestApplication.java:47) at org.eclipse.equinox.internal.app.EclipseAppHandle.run(EclipseAppHandle.java:196) at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:110) at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:79) at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:369) at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:179) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at java.lang.reflect.Method.invoke(Method.java:597) at org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:620) at org.eclipse.equinox.launcher.Main.basicRun(Main.java:575) at org.eclipse.equinox.launcher.Main.run(Main.java:1408) at org.eclipse.equinox.launcher.Main.main(Main.java:1384)Reproducible: AlwaysSteps to Reproduce:Try to delete a closed project (that is no cdt enabled project).	I tried to reproduce this and I'm a little bit confused. The only way I had this exception is if I removed the try catch block in this partCModelManager.resourceChanged...case IResourceChangeEvent.PRE_DELETE : try { if (resource.getType() == IResource.PROJECT && ( ((IProject)resource).hasNature(CProjectNature.C_NATURE_ID) || ((IProject)resource).hasNature(CCProjectNature.CC_NATURE_ID) )){ this.preDeleteProject((IProject) resource);} } catch (CoreException e) { } break;Also, the line CModelManager.java:890 didn't match to a Project.hasNature call in 7.0.2. Could it be possible that you have a modified version of CDT 7.0.2?(In reply to)I compared "my" version with yours. The only difference is that in my version the catched CoreException is logged where in your version it is simply not regarded at all.This issue can be closed from my point of view. The only question is whether not regarding a CoreException here is the right and specified way.Closing as per last comment. I've seen the trick of ignoring exceptions from closed projects in other places in CDT a well.We just recently tweaked Freescale's copy of platform to throw a specialization of CoreException that we check and ignore. CDT shouldn't be reporting exceptions to the Error log when such exceptions are expected and acceptable. The problem is that the way the exception is thrown in the platform doesn't allow CDT to reliably know if it's one of these harmless exceptions or not. I'll ask Serge Beauchamp to pursue contributing the platform change and I'll contribute the CDT part of it.If you readandstock CDT doesn't report such an exception. A forked (or older) version of CDT does that. But I don't mind if this gets fixed the right way of course. Is there any bug on platform side?(In reply to)Well, eating any CoreExceptions that can happen in that code is definitely not ideal. We only want to eat the core exception that happens as a result of the project being closed. Again, properly making that distinction isn't possible today but if Serge is on board for contributing the change to the platform, then we can improve the situation in CDT. I or Serge will open a platform bug soon.	6.0
id=378009	REOPENED	CDT	cdt-other	Next	PC Linux	P3 normal	Project Inbox	2012-04-28 13:55 EDT by	duncan	2012-05-27 05:55 EDT (	2 users	Build Identifier: Version: Indigo Service Release 2 Build id: 20120216-1857This is a recently introduced bug as this used to work in the previous version of Eclipse.If I define a method like this: __device__ int doSomething (int x, int y, int z) { return x+y+z; };Eclipse does not pick this up as a "foldable" method. If I remove __device__ Eclipse immediately picks up the method and I'm am able to fold it after resetting the structure.I have added the symbol to Project > Properties > C/C++ Include Paths and Symbols.I've included the following section in my code:#ifdef __CDT_PARSER__...#define __device__...#endifI've also included the file in which __device__ is declared in the same source file.I've also done Window > Preferences > C/C++ > File Types > New > Pattern: "*.cu" Type:"C Source File". (This is a CUDA source file - I am aware that there are other issues with these in Eclipse, but the fact that this is CUDA should be irrelevant in this case).I've also closed/opened and rebuilt project (from within and outside of eclipse).This used to work in a previous version of Eclipse, but I recently reinstalled my desktop and installed a newer version only to find the code folding no longer worked.Reproducible: AlwaysSteps to Reproduce:1. Write method2. Reset code folding structure3. Code folds not present	Information about the system if it's relevant:OS: Kubuntu 12.04 up-to-dateEclipse installed by downloading and extracting tarball from eclipse.org (i.e. not installed from Ubuntu Repos). "Eclipse > Help > Check for Updates" says Eclipse is up-to-date.More information:If I open the file in Eclipse, close Eclipse, then reopen eclipse (so that the file opens up when Eclipse is restarted - it must be the focussed tab if it isn't this doesn't work), then the code folds are created correctly. If I then disable and re-enable folding, or reset the structure, then I lose the folds.However, if I restart eclipse with the file closed (or open is an unfocussed tab), and then open the file (or switch to the relevant tab), then the code folds are not present and cannot be enabled.Works for me in CDT 8.1 fromwith __device__ defined in Paths and Symbols page in project properties.I've done some more testing of this issue. For the basic case I initially identified above. things appear to work for me now. I then found if I copied everything out of the "problem file" into a new file, I could get code folding to work.I then systematically removed sections of code from the "problem file" until code folding worked. I found that the order of my includes at the top of my source file affected the code folding. An example except from the top of the "problem file": //#include "my_cuda_file.cu" //code folding doesn't work // CUDA header unnecessarily included to stop eclipse showing errors // for certain CUDA syntax. #include <cuda_runtime_api.h> #include <host_defines.h> #include "my_cuda_file.cu" //code folding worksIf I included "my_cuda_file.cu" before the CUDA headers then code folding breaks when I refresh the structure. If I include "my_cuda_file.cu" after the CUDA headers then code folding works again after I reset the structure.So there is definitely a bug somewhere. However, I understand that it might not be worth the effort to figure out the problem - there are probably more pressing/less obscure issues. So feel free to resolve this as I have found a suitable workaround.(In reply to)Please try to come up with a self-contained example by providing all involved header files. This may require you to further reduce the use case.(In reply to)I think I've worked out what the problem is.In the cuda header files __device__ is defined by:#define __device__ \ __location__(device)But __location__ is only defined by:#if defined(__GNUC__)//__location__ defined in here#elif defined(_WIN32)//__location__ defined in here#endifI assume __GNUC__ and _WIN32 are not defined by the CDT parser. Therefore __device__ is not properly defined and the code parser doesn't know what to do with it and therefore can't definitively say whether it has come across a section that can be folded or not when __device__ is used as a qualifier for a method (possibly by design).In my earlier attempts to get code folding to work , I had defined __device__ to be nothing in a file at the top of my include hierarchy. So if I included my cuda file first, the blank define got overridden with a broken define by the cuda includes. If I included my cuda file after the cuda includes then my define overwrote the broken defines and the code parser could understand things properly.When I upgraded Eclipse, the GUI correctly reported (because Eclipse doesn't know to use nvcc for the *.cu files) a number of new errors that older versions didn't pick up. So to get around these errors I included the cuda header files, which fixed the problem. Unforunately I included them after my usual includes instead of before, which led to me seeing the code folding problem.So this behaviour might be intended - I couldn't know. Regardless, the workaround is to make sure that you add the following after any cuda headers are included:#ifdef __CDT_PARSER__#define __device__#define __host__#define __constant__#define __global__#define __shared__// + any other non-standard notation being used#endif	6.0
id=441674	REOPENED	CDT	cdt-core	8.3.0	PC Linux-GTK	P3 critical	Project Inbox	2014-08-13 06:13 EDT by	Martin Oberhuber	2015-05-29 10:06 EDT (	2 users	CreatedThread dump showing the deadlockBuild ID: CDT 8.3.0 on top of Eclipse 3.8.2 / Linux GTK 32-bitA user has experienced a deadlock in CDT, attached is the Thread dump.Following is my analysis of the problem:1. "main" Thread is executing HyperlinkManager.mouseMove() and tries ASTTranslationUnit.beginExclusiveAccess() which is blocked waiting on 2 below2. "org.eclipse.cdt.internal.ui.text.CReconciler" Thread seams to still be holding a lock on the AST, when CodanMarkerProblemReporter.reconcileMarkers() leads to broadcasting a synchronous workspace change notification3. The workspace change notification inside the reconciler Thread is handled by net.sourceforge.eclipseccase.views.CheckoutsView.resourceChanged() which performs a Display.syncExec()--> But syncExec is blocked because the main Thread is busy as per 1 above.Possible fixes:---------------In (2), I think that the CReconciler Thread must make sure that it either returns the lock on the AST before the Workspace change notification is sent,or it performs the change notification asynchronously.One could argue that net.sourceforge.clearcase must not do Display.syncExec() in response to the change notification, but fact is that one cannot know whatclients may do in response to a notification. Therefore I think the fix shouldbe made in CDT.	net.sourceforge.eclipseccase.views.CheckoutsView.resourceChanged() is at fault, not CDT. Please reopen if you can reproduce without eclipsecase.Sergey, I have to disagree here. As I wrote: I think that the CReconciler Thread must make sure that it either returns the lock on the AST before the Workspace change notification is sent, or it performs the change notification asynchronously.It is not OK to call out to foreign code that you don't own, while holding a lock.IMO this is exactly the kind of issue that breaks CDT's project model elsewhere: allowing change notifications / listeners to run into recursions while locks are held.Sure it's not nice doing Display.syncExec() in a resource listener. But other resource listener clients could be doing more subtle things that may lead to problems ... such as triggering an editor reload or model access that also wants the ASTTranslationUnit. The point is, you don't have under control what the clients do here.CreatedThread Dump showing the deadlock with plain CDTAttached thread dump shows the deadlock with plain CDT (no 3rd party tools involved). This is from Eclipse 3.8.2 + CDT 8.3.0.20140214 .I've now got reports from at least 6 independent users running into the same deadlock. In fact all CDT-related deadlocks seem to boil down to this issue: - Why does the CElementHyperlinkDetector on the main Thread require exclusive access to the AST ? While the AST might be hung in a WorkspaceModifyOperation. - Why does the CReconciler do a syncExec() from its Workspace notification, while workspace is busy in endOperation?These two seem to be the main ingredients to the deadlock. Can we get confirmation that this can no longer happen in latest CDT ? Or can it be fixed ?(In reply to Martin Oberhuber from)I do see net.sourceforge.eclipseccase in the dump:"org.eclipse.cdt.internal.ui.text.CReconciler" daemon prio=10 tid=0x59170400 nid=0x60ef in Object.wait() [0x610fb000] java.lang.Thread.State: TIMED_WAITING (on object monitor) at java.lang.Object.wait(Native Method) at org.eclipse.ui.internal.Semaphore.acquire(Semaphore.java:43) - locked <0x7203d3a8> (a org.eclipse.ui.internal.Semaphore) at org.eclipse.ui.internal.UISynchronizer.syncExec(UISynchronizer.java:168) at org.eclipse.swt.widgets.Display.syncExec(Display.java:4299) at net.sourceforge.eclipseccase.views.CheckoutsView.resourceChanged(CheckoutsView.java:539) at org.eclipse.core.internal.events.NotificationManager$1.run(NotificationManager.java:291)Doh! You are right Toni. I'm checking back with the submitters. Thanks !	5.0
id=327617	REOPENED	CDT	cdt-debug-dsf-gdb	8.0	PC Windows 7	P3 normal	Project Inbox	2010-10-12 19:10 EDT by	Tim Cook	2012-03-05 11:05 EST (	6 users	Build Identifier: M20100909-0800After multiple executions of fprintf(stderr, "some string\n") in user code, the gdb process stderr buffer gets full and further writes to stderr hang gdb.Reproducible: Always	CreatedCDT 7.0.1 patchThe attached patch adds a command processor to read from the gdb process error stream. Stderr output is shown in the Console View.Code to demonstrate problem :#include <stdio.h>#include <stdlib.h>int main(void) { int i = 0; setvbuf(stderr, NULL, _IONBF, 0); for (i = 0; i < 50000; i++) { printf("iteration %d\n", i); // On iteration 14, stepping the following line will leave debugger in run state. fprintf(stderr, "!!!Hello World!!!!!!Hello World!!!\n"); } return EXIT_SUCCESS;}Very similar toin CDI.This works ok on Linux. Maybe because we can use PTYs. I'll try it from home, on a Windows machine.I can see this on Windows. The patch seems to fix the problem, but I find the behavior strange. With the patch, I see each line of output to stderr being printed to the program's console gradually (that is very nice), but I don't see the similar stdout printouts until the very end of the program (which is how stdout is currently behaving on Windows). Why the difference?(In reply to)I've looked at the CDI solution which reads from GDB's error stream and prints to the GDB console.I'm curious to know why CDI chooses to print to the GDB console and not the process console? I couldn't quite find what GDB will print to its error stream, so are we worried that output that is not from the process could be printed there and that is why CDI goes to the GDB console?CreatedCDI patch to use process console instead of GDB consoleNot being sure why CDI chooses to write stderr printouts to the GDB console, I tried it with the process console. This is the patch to do that.This is all so I can decide where DSF-GDB should print input received on GDB's stderr.(In reply to)I don't understand why are you so confused. All GDB io streams go to the GDB console and the process streams to the process console, what's wrong with it?(In reply to)The reason was I was seeing errors from GDB itself coming out GDB's stderr. Target output was being wrapped in MI and going correctly to the correct console. It may be that our GDB behaves differently to native linux gdb in which case there isn't a good reason...(In reply to)On Windows, we cannot use a PTY, so I'm trying out CDI without the option to "Connect process input & output to a terminal".Currently cout << "Hello cout" << endl;this goes to the process console. cerr << "Hello cerr" << endl;this goes to the GDB console.That is because GDB's error stream is used to print the process stderr. I don't know what else GDB's error stream is used for, so, if it is only for the process' stderr, shouldn't we print this to the process console?(In reply to)If GDB uses its stderr for actual GDB errors, then I see the point, and I don't see how to differentiate between GDB error printouts and inferior error printouts.I don't know what GDB uses its stderr for. I'll have to ask.(In reply to)Re-reading my first question, I can see why you didn't see my point, I didn't explain myself well at all.(In reply to)Well I'm not sure whether GDB does do this. However any linked in simulators or target specific bits might just write to the error stream.There's a thread on target stderr vs. stdout:Looks like this patch was committed:mi-interp.c has: ... /* Route target output through the MI. */ gdb_stdtarg = mi->targ; /* Route target error through the MI as well. */ gdb_stdtargerr = mi->targ; ...AFAICS this means that targets stdour and stderr will be wrapped in MI, which may be different from what happens for native debugging...(In reply to)>Right, so target errors will come out with @ in front (maybe not on linux, but we handle it also), and that will be on GDB's output stream.What goes on GDB stderr, I'm still trying to figure outI was able to get GDB to print to stderr using CLI mode, as shown below. The 'display <use a type>' command will do it.GNU gdb (GDB) 7.2.90.20110420-cvs(gdb) l1 struct str {};2 int main() {3 str s;4 return 0;5 }(gdb) startTemporary breakpoint 1 at 0x804849a: file a.cc, line 4.Starting program: /home/lmckhou/testing/a.out Temporary breakpoint 1, main () at a.cc:44 return 0;(gdb) display strDisabling display 1 to avoid infinite recursion.1: str = Attempt to use a type name as an expressionI confirmed it was writing to stderr by redirecting GDB's stderr to a file like so:bashgdb.7.3 testing/a.out 2> ttAnd the string "Attempt to use a type name as an expression" got redirected.When using MI, 'gdb -i mi' and redirecting, that particular stderr printout comes out on stdout instead, with a & prefix. But a cerr or fprintf(stderr, from the inferior does come out on GDB's stderr.This makes me think that it is safe to print GDB's stderr to the inferior console.(In reply to)This may be true for native GDB, but it's not true for target GDB. For target GDB, stdout and stderr for the target will always be in the MI. stderr of the GDB process will therefore only contain stuff that was fprintf(stderr, ...) from within the GDB process itself: i.e. a linked in simulator or target specific architecture bits.It may be true that GDB itself wraps its output in stderr, but it may not be the case that all the things that are linked with GDB wrap their stderr like this. Hence, for non-native targets, it makes sense to send GDB stderr to the gdb console and not to the target console.(In reply to)Makes sense.Considering that DSF-GDB currently ignores GDB's stderr altogether, and that CDI outputs to the GDB console, I think doing the same for DSF-GDB is good enough.CreatedNew thread to read GDB error streamThis patch mimics the solution for CDI of. It creates a new thread to read GDB's error stream and sends the string as an MI event for the AbstractCLIProcess to printout in the gdb console.I had to prefix the string with an '&' to indicate that it is an error printout to AbstractCLIProcess.By not using a PTY, I was able to confirm that inferior stderr printouts are now seen on the gdb console and we no longer have GDB hang when stderr gets full.Committed to HEAD.Thanks for your help James.Can you review the fix?Looks reasonable to me. (In reply to)I wonder if there'd a way to get this right in all cases. i.e.if (PTY || target {sim|...} ) send gdb stderr to GDB consoleelse /* native debugging minus PTY */ send gdb stderr to target consoleI suspect most people using DSF/GDB will be on linux native, so it would make sense for stderr to go to the program console by default. If there was a way to configure where it went that might be an optimal solution?*** cdt cvs genie on behalf of mkhouzam ***: Gdb hangs after user code writes to stderr multiple times[*] AbstractMIControl.java 1.17[*] GDBBackend.java 1.27(In reply to)On linux native we _always_ use a PTY, and in that case, the inferior stderr goes to the PTY (i.e., the target console). So, this bug was really aimed at Windows users. But I'm all for a better solution for Windows, if we can figure something out. I'll leave it alone for now until someone requests it, or some solution is proposed.***has been marked as a duplicate of this bug. ******has been marked as a duplicate of this bug. ***Stderr and stdout should go to the same console on Windows, not stdout to the target console and stderr to the gdb console. My original patch accomplished this on Windows. This works properly on Linux.I'm putting this back in the pool if someone has a solution that allows us to know which output of stderr should go to the process console and which should go to the gdb console.	28.0
id=100185	REOPENED	CDT	cdt-debug	3.0	PC Windows XP	P3 normal	cdt-debug-inbox@eclipse.org	2005-06-15 09:59 EDT by	David Daoust	2007-06-22 12:56 EDT (	0 users	When using RC1 or RC1 of the base platform, there are 9 warnings aboutdescouraged access -- it looks like we are accessing internal bits from theplatform. Since we have been bitten by this in the past, I thought that I wouldraise a defect, and see if we can remove this dependency. ( I will raise aseparate defect on the refactoring package which also does this )Severity Description Resource In Folder Location Creation Time1 Discouraged access: The type SourceLookupUIUtils is not accessible due torestriction on required libraryC:\eclipse\RC2\plugins\org.eclipse.debug.ui_3.1.0.jarAddSourceContainerDialog.javaorg.eclipse.cdt.debug.ui/src/org/eclipse/cdt/debug/internal/ui/sourcelookupline 19 June 13, 2005 2:16:03 PM	The usage of this internal class was suggested by the platform folks. Seefor details.LATER/REMIND are deprecated. Changing to reopened milestone '--'	2.0
id=451929	REOPENED	CDT	cdt-other	8.5	PC Linux	P3 enhancement	Project Inbox	2014-11-17 10:23 EST by	Pascal Rapicault	2015-06-24 14:10 EDT (	8 users	p2 has added a mechanism that allows users to express dependencies on packages (see).This bug captures the desire to use this functionality in CDT so users installing plugins will know that they need to install native packages.	Could someone help me figure out the list of all the CDT plug-ins that have an OS dependency?(In reply to Pascal Rapicault from)What exactly do you need?Off the top of my head, CDT can uses:GDBGCCbut maybe also the C/C++ Unit test framework like Boost.Test, Qt Test, Google Testing FrameworkDo you want the plugins that access those binaries?I would need the id of the plugin that access binaries and the id on ubuntu of the native package(s) used by that plugin.For GDB: org.eclipse.cdt.dsf.gdb uses ubuntu package gdbFor GCC:there are multiple native packages that would satisfy CDT. For instance: gcc (link to one of the below) gcc-4.4 gcc-4.5 gcc-4.6Note that I'm running Ubuntu 12.04, so on say 14.04, there are probably newer packages.Probably 'gcc' is enough.I think I still need clarification of how much detail you need about those packages.I've copied Marc-Andre to hopefully help clarify which plugin we could trigger on for GCC.I've copied Jeff because we also use 'autotools' binaries. The plugin is probably: org.eclipse.cdt.autotools.corebut I'm not sure about the binary packages.Initial contribution atI added native dependencies to the following plugins (plugin-id --> package-id)- org.eclipse.cdt.autotools.core --> autoconf- org.eclipse.cdt.make.core --> make- org.eclipse.cdt.build.crossgcc --> gcc- org.eclipse.cdt.gdb --> gdb- org.eclipse.cdt.dsf.gdb --> gdb- org.eclipse.cdt.qt.core --> qt-sdkPlease let me know if I got them all and if the packages expressed are correct.Closing as fixed since Doug released the provided patch.Ah, dude, from our internal Tycho build:Installation failed.An error occurred while installing the items session context was:(profile=DefaultProfile, phase=org.eclipse.equinox.internal.p2.engine.phases.Install, operand=null --> [R]org.eclipse.cdt.dsf.gdb 4.6.0.201412191314, action=org.eclipse.equinox.internal.p2.engine.MissingAction). No action found for: org.eclipse.equinox.p2.touchpoint.natives.checkAndPromptNativePackage.I've reverted the change.Ok so looking at the release notes for M4, it looks like we need the 0.23 tycho snapshot for this to work. So if we're building linux packages of CDT 8.6, we'll need that snapshot?What's the plan for users when they upgrade from an existing CDT 8.5 to 8.6? They won't have the touchpoint installed in their current environment. Will it not fail?Using this touchpoint action requires Tycho 0.23.0 snapshot. This was part of the original patch. I tried different options of tycho to avoid this (like specifying a different runtime) but this was the only way.Btw, as a general comment, I'm a bit surprised by the practice of removing something from master because *your* internal build is broken whereas everything works in the OSS side. If IBM had done that back in the days, I'm not sure where we would have ended :p(In reply to David Cummings from)The update of tycho has already been done for the EPP packages ().If this is a usecase that matters to you (not judging, I don't know enough the habits of the CDT user community), then IUs using this touchpoint action must specify a meta requirement to get the action into the existing base before the update proceeds. I can provide a patch for this.(In reply to Pascal Rapicault from)Well the difference with CDT is that we actually have vendors trying to build off of master and we strongly encourage it to ensure they find breakages early. I didn't to this for us, I did it for everyone.I'm also not convinced forcing everyone building against the CDT master to use a SNAPSHOT of Tycho is a great community move. Especially without sending a note to cdt-dev first and getting feedback. Or mentioning it in the patch at least. I guess I was too trusting of an old friend ;).(In reply to Pascal Rapicault from)Yes please. Updating from release to release is something we find pretty important.(In reply to Pascal Rapicault from)I think it's an important use case. Correct me if I'm wrong, but for users of the CDT EPP Luna package, when they do an update when Mars rolls out, they'll run into this problem, no?What would be the reason for not setting the meta requirement in the IUs that use this touchpoint? Is there a drawback?Independent of Luna to Mars, CDT 8.6 is Luna SR-2, so this affects upgrading SR-1 to SR-2.(In reply to Doug Schaefer from)Woa, this is news to me! This patch was only intended to be released in the version of CDT to be released with Mars. Definitely not as something for SR2 since the necessary p2 support is only in Luna.Actually I lied. There was no change in the Tycho version.Here is what happens. When you build a plugin or a feature, you can use any version of Tycho since the touchpoint actions are not executed. This explains why when building the CDT plug-ins there were no problem. However when you try to consume the plug-ins inside a product build, the touchpoint actions are being executed (since tycho runs the p2 director to create the product installation and then zip it) and this is where the build will fail if you don't use Tycho 0.23.0-SNAPSHOT.But again I did not think that the version that was in master was to be released for Luna.It is my understanding that most people just download eclipse from scratch again every major release. Nonetheless there will always be people who try the update and for whom the update would fail because of this.Making user's update experience bad? :)Not that I can think of.I will work on a solution that allows for a smooth upgrade. Do you plan on shipping a version different than 8.6 in Mars? When will master be re-opened for Mars?(In reply to Pascal Rapicault from)Cool. Thanks. I know this is not an opinion shared by a few others in the Eclipse community, but whatever we can do to make the lives of Eclipse users by supporting upgrades as much as possible, we should be doing that. I don't remember the last time firefox or chrome made me uninstall to install a new release.And with the CDT in particular, our releases are every four months. There's nothing special about the June releases other than the opportunity to do a Major version bump. Which even then I'd expect CDT users to be able to upgrade to.I have 3 possible solutions:1 - Implement no-op actions. Concretely, this means that we need to create a new plug-in that provides a noop implementation of the touchpoint action. And then the plug-in that uses the new touchpoint action need to meta require this plug-in or the real p2. The end result for the user is that if Luna is being used then CDT is installed and no prompting is done. If Mars is being used then CDT is installed and prompting is done2 - Use a patch to get p2 bundles from Mars into Luna. Concretely, we need to create an IU patch that would allow to install the Luna version of the p2 bundles into Mars. Then the plug-in that uses the new touchpoint action would have to meta require this new IU or the regular p2 IUs. In this case, users migrating from Luna to Mars would be prompted to install the new packages.3 - Move the touchpoint action to a new IU. In the patch that was originally proposed, the plug-in IU directly referenced the touchpoint action which made the install fail on Luna. Given a plug-in P we could create a new IU called P-native whose only role is to deliver the touchpoint action. P-native would have a dependency on the p2 bundles from Luna. P would optionally require P-native. This way, when P is installed on Luna, P-native dependencies can't be satisfied and thus the bundle is not installed and the actions are not executed. Now when P is installed on Mars, P-native dependencies are satisfied and the actions are executed. In a sense the behavior is similar to what we see in #1At this point I would suggest we go with #3 because #2 may be harder to test and maintain if more changes are being done to p2.	21.0
id=327766	REOPENED	CDT	cdt-debug-dsf-gdb	8.0	PC Windows 7	P3 normal	Project Inbox	2010-10-14 09:14 EDT by	Tim Cook	2014-01-25 18:59 EST (	7 users	Build Identifier: M20100909-0800Stepping a line containing printf("!!!Hello World!!!") without a newline terminating the string, leaves the "Debug View" in the running state.Reproducible: Always	Code to demonstrate problem :#include <stdio.h>#include <stdlib.h>int main(void) { setvbuf(stdout, NULL, _IONBF, 0); // Stepping following line leaves debug view in run state. printf("!!!Hello World!!!"); return EXIT_SUCCESS;}CreatedCDT 7.0.1 patchWhen the program is run the following line is emitted to the Console View :!!!Hello World!!!23*stopped,reason="end-stepping-range",reason="breakpoint-hit",bkptno="1",thread-id="1",frame={addr="0x004011f1",func="main",args=[],file="../src/test.c",fullname="/cygdrive/d/user/cook/workspace_cdt_test/test/src/test.c",line="29"}The problem is caused by the users stdout being intermingled with the MI asynchronous message "23*stopped,reason....". The attached patch sub-parses the stdout line and allows RxThread.processMIOutput() to function correctly.This seems to be a problem on Windows only, probably because we don't have a PTY. I'll have to test it from home where I have a Windows 7 machine.I can see the problem on Windows. And it happens for CDI as well.The fix does not seem to work though.My line starts with:!!!Hello World!!!*stopped,reason="The patter used in the patch is:"\\d+\\*stopped,reason="But doesn't that look for digits at the beginning?Also, in some *stopped events, there is no 'reason' flag, so we should match for it.Isn't this a GDB bug? This intermingling of program output breaks the gdb/mi output syntax.(In reply to)Definitely. But we can try to work around it.I'm able to reproduce this bug on Linux when we don't use a PTY. It still happens with GDB 7.2.The problem is that this affects all MI output, not just the *stopped event.For example, in a multi-threaded program I got this:263,335 [MI] 32-exec-continue --thread 1263,338 [MI] 32^running263,339 [MI] *running,thread-id="1"263,339 [MI] (gdb) 263,345 [MI] !!!Hello World!!!=thread-created,id="2",group-id="i1"and the thread created event was lost to us.The problem is triggered by making the stream unbuffered: setvbuf(stdout, NULL, _IONBF, 0);I don't see how we can fix this ourselves.So, I think Toni was right and we can only say that it is a GDB bug.I will follow-up with GDB to get this fixed.If someone has an idea for a workaround, feel free to re-open.I'm even wondering how we can fix this in GDB itself. My guess is that I will be told to use the "set inferior-tty" command to keep the output out of the MI streams.This is what we do for Linux. What is the reason we don't use a PTY for Windows? Is it that we didn't implement it in CDT?I've been googling about this and I don't think this is a GDB bug, but more of a Windows limitation, as said here:Dan refers to the command "set new-console on", which would make the output of the process come out in its own window. This feature has been discussed for DSF-GDB here:and within, and was previously used for CDI (but no more).I'm thinking this is probably our best hope of avoiding the current bug.Note thatwarns that we should make sure that using the new-console feature won't prevent us from interrupting the inferior.It is too late to try this for Indigo.However, you can make use of this already by adding the line set new-console onto a gdbinit file for your launch.In fact, with the new preference to set default gdbinit file, this becomes really easy ()***has been marked as a duplicate of this bug. ******has been marked as a duplicate of this bug. ******has been marked as a duplicate of this bug. ***	13.0
id=79484	REOPENED	CDT	cdt-debug	2.1	PC Windows 2000	P3 normal	cdt-debug-inbox@eclipse.org	2004-11-25 08:21 EST by	Oyvind Harboe	2004-11-30 07:47 EST (	0 users	My debugger stopped working when I stepped out of a fn. I wonder if CDT is getting confused by a tailjump....[1,101,388,634,748] &"step\n"[1,101,388,634,988] ~"Current language: auto; currently c++\n"[1,101,388,634,988]7931^done,reason="end-stepping-range",thread-id="0",frame={addr="0x01049550",fun\c="_GLOBAL__I.49000__ZN17cyg_io_init_classC1Ev_cygdrive_c_cdtworkspace_ecos_repository_ecos_packages\_io_common_current_src_ioinit.cxxqhvkhb",args=[],file="/cygdrive/c/cdtworkspace/ecos-repository/ecos\/packages/io/common/current/src/ioinit.cxx",line="65"}[1,101,388,634,988] (gdb) [1,101,388,634,988] 7932 info threads[1,101,388,634,998] &"info threads\n"[1,101,388,634,998] &"warning: RMT ERROR : failed to get remote thread list\n"[1,101,388,634,998] &"\n"[1,101,388,634,998] 7932^done[1,101,388,634,998] (gdb) [1,101,388,634,998] 7933-stack-info-depth[1,101,388,635,128] &"Previous frame identical to this frame (corrupt stack?)\n"[1,101,388,635,128] 7933^error,msg="Previous frame identical to this frame(corrupt stack?)"[1,101,388,635,128] (gdb) [1,101,388,635,138] 7933-stack-info-depth[1,101,388,635,138] 7934-var-update var10[1,101,388,635,138] 7933^done,depth="4"[1,101,388,635,138] (gdb) [1,101,388,635,198] 7934^done,changelist={}[1,101,388,635,198] (gdb)	Arggghhh....I believe the problem is specific to gdb 6.2.1$ ~/gdbbuild/install/bin/arm-elf-gdb -v GNU gdb 6.2.1With this GDB, it works.$ arm-elf-gdb -vGNU gdb 5.3 (eCosCentric)My older GDB crashes when I try to view registers in CDT. !"¤&#"&"#¤& :-)Choose between two broken GDB's....In retrospect I think the error message from GDB should be reviewed. BrokenGDB's are not going away.ØyvindCreatedThis log contains something that is quite possibly a real CDT bugThese exceptions where generated when debugging the same problem, but thisparticular exception isn't easily reproduceable.java.lang.NullPointerException atorg.eclipse.cdt.debug.internal.core.model.CExpression.getExpressionText(CExpression.java:58) atorg.eclipse.cdt.debug.internal.core.model.CExpression.getExpressionString(CExpression.java:163) atorg.eclipse.cdt.debug.internal.core.model.AbstractCValue.evaluateAsExpression(AbstractCValue.java:48) atorg.eclipse.cdt.debug.internal.ui.CValueDetailProvider$1.run(CValueDetailProvider.java:41) at org.eclipse.swt.widgets.RunnableLock.run(RunnableLock.java:35) atorg.eclipse.swt.widgets.Synchronizer.runAsyncMessages(Synchronizer.java:106) at org.eclipse.swt.widgets.Display.runAsyncMessages(Display.java:2749) at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:2434) at org.eclipse.ui.internal.Workbench.runEventLoop(Workbench.java:1377) at org.eclipse.ui.internal.Workbench.runUI(Workbench.java:1348) atorg.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:254) at org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:141) atorg.eclipse.ui.internal.ide.IDEApplication.run(IDEApplication.java:96) atorg.eclipse.core.internal.runtime.PlatformActivator$1.run(PlatformActivator.java:335) atorg.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:273) atorg.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:129) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) at java.lang.reflect.Method.invoke(Unknown Source) at org.eclipse.core.launcher.Main.basicRun(Main.java:183) at org.eclipse.core.launcher.Main.run(Main.java:644) at org.eclipse.core.launcher.Main.main(Main.java:628)I've verified that GDB is temporarly unable to parse the stackframe.As soon as I step out of the fn, GDB resumes normal operation.Index: Thread.java===================================================================RCS file:/home/tools/org.eclipse.cdt.debug.mi.core/cdi/org/eclipse/cdt/debug/mi/core/cdi/model/Thread.java,vretrieving revision 1.12diff -u -r1.12 Thread.java--- Thread.java 18 Nov 2004 16:07:54 -0000 1.12+++ Thread.java 26 Nov 2004 13:59:38 -0000@@ -181,7 +181,12 @@ } } } catch (MIException e) {- throw new MI2CDIException(e);+ // FIX!!! by commenting out the line below, I was able to show+ // that although GDB freaks out on the corrupt stack frame, the + // GDB debug session recovers as soon as we step out of the + // area.+ // throw new MI2CDIException(e);+ stackdepth=0; } finally { target.setCurrentThread(currentThread, false); }at>org.eclipse.cdt.debug.internal.core.model.CExpression.getExpressionText(CExpression.java:58)Oyvind ... please do not do that ... i.e. do not mixed PR(issues)It makes it very hard for us to follow and come upwith a valid fix. The NPE should been a new PR, see:Why is this patch needed, If you look at the code carefully inThread.getStackFrameCount(). When the first try failswe try a second time and decrement the depth by one ignoringthe corrupt frame, Question why it does not work for you ?Are we looking at the right code/bug ?Why stackdepth = 0 ? you may have other valid frames in the threadJust to clarify. The diff is not patch. It is just some tweaks I did in order to prove that GDB recovered from thistemporary condition.ØyvindI'll try.The problem is that I need to distinguish between writing up problems as I findthem, and diving into them as time permits.Bugzilla does not have a "REPORTING IN PROGRESS" flag.Its not pretty, but forking off PR's have served us so far.ØyvindUnderstood, but the question remains. Why the schemethat we have in Thread.getStackFrameCount() does not work for you ?If the first try failed, we retry a second time and decrementthe stackdepth by one to ignore the corrupt frame.And according to your own trace, it appears to be working.So why did you have to add another catch clause ?More info:- Here is the stack trace *before* I add a watch expression on p[0]3 cyg_hal_invoke_constructors() atc:\cdtworkspace\ecos-repository\ecos\packages\hal\arm\arch\current\src\hal_misc.c:2012 start() 1 start() - add watch expression on on p[0] - step around the application for a bit- the debug session is frozen as in step3.jpg(i.e. step is unavailable)- issuing "stepi" in the GDB console enough times enventually brings GDB/CDTback to a working state again.CreatedLogThe error in the log appeared shortly before CDT reentered a working stateCreatedShows CDT GUI before trouble beginsCreatedshows debugger after watch expression has been addedWorks as expectedCreatedAfter issuing step a couple of times w/p[0] watch expressionIt is no longer possible to step.stepi/step into the GDB console still worksRead this log from the bottom and up. It is untrimmed... :-)[1,101,818,422,527] (gdb) [1,101,818,422,547] 942^done,depth="9"[1,101,818,422,547] (gdb) [1,101,818,423,168] 943 stepi[1,101,818,423,178] &"stepi\n"[1,101,818,423,228]943^done,reason="end-stepping-range",thread-id="0",frame={addr="0x010d1420",func\="Cyg_CList_T",args=[{name="this",value="0xf9fc"}],file="clist.hxx",line="310"}[1,101,818,423,228] (gdb) [1,101,818,423,228] 944 info threads[1,101,818,423,238] &"info threads\n"[1,101,818,423,248] &"warning: RMT ERROR : failed to get remote thread list\n"[1,101,818,423,248] &"\n"[1,101,818,423,258] 944^done[1,101,818,423,258] (gdb) [1,101,818,423,258] 945-stack-info-depth[1,101,818,423,548] &"Previous frame identical to this frame (corrupt stack?)\n"[1,101,818,423,548] 945^error,msg="Previous frame identical to this frame(corrupt stack?)"[1,101,818,423,548] (gdb) [1,101,818,423,548] 945-stack-info-depth[1,101,818,423,548] 946-var-update var1[1,101,818,423,568] 945^done,depth="9"[1,101,818,423,568] (gdb) [1,101,818,423,799] 946^done,changelist={}[1,101,818,423,799] (gdb) [1,101,818,423,799] 947-var-update var2[1,101,818,424,029] 947^done,changelist={}[1,101,818,424,029] (gdb) [1,101,818,424,029] 948-data-list-changed-registers[1,101,818,424,039] 948^done,changed-registers=["13","15"][1,101,818,424,039] (gdb) [1,101,818,424,049] 949-stack-info-depth[1,101,818,424,159] &"Previous frame identical to this frame (corrupt stack?)\n"[1,101,818,424,159] 949^error,msg="Previous frame identical to this frame(corrupt stack?)"[1,101,818,424,159] 949-stack-info-depth[1,101,818,424,179] (gdb) [1,101,818,424,189] 949^done,depth="9"[1,101,818,424,189] (gdb) [1,101,818,424,580] 950 stepi[1,101,818,424,590] &"stepi\n"[1,101,818,424,650]950^done,reason="end-stepping-range",thread-id="0",frame={addr="0x010d1424",func\="Cyg_CList_T",args=[{name="this",value="0x10d0f90"}],file="clist.hxx",line="310"}[1,101,818,424,650] (gdb) [1,101,818,424,650] 951 info threads[1,101,818,424,650] &"info threads\n"[1,101,818,424,650] &"warning: RMT ERROR : failed to get remote thread list\n"[1,101,818,424,650] &"\n"[1,101,818,424,660] 951^done[1,101,818,424,660] (gdb) [1,101,818,424,660] 952-stack-info-depth[1,101,818,424,970] &"Previous frame identical to this frame (corrupt stack?)\n"[1,101,818,424,970] 952^error,msg="Previous frame identical to this frame(corrupt stack?)"[1,101,818,424,970] (gdb) [1,101,818,424,970] 952-stack-info-depth[1,101,818,424,970] 953-var-update var1[1,101,818,424,980] 952^done,depth="9"[1,101,818,424,980] (gdb) [1,101,818,425,231] 953^done,changelist={}[1,101,818,425,231] (gdb) [1,101,818,425,231] 954 stepi[1,101,818,425,231] 955-var-update var2[1,101,818,425,241] &"stepi\n"[1,101,818,425,301]954^done,reason="end-stepping-range",thread-id="0",frame={addr="0x010d1428",func\="Cyg_CList_T",args=[{name="this",value="0x10d0f90"}],file="clist.hxx",line="310"}[1,101,818,425,301] (gdb) [1,101,818,425,551] 955^done,changelist={}[1,101,818,425,551] (gdb) [1,101,818,425,551] 956-data-list-changed-registers[1,101,818,425,561] 956^done,changed-registers=["11","13","15"][1,101,818,425,561] (gdb) [1,101,818,425,571] 957-stack-info-depth[1,101,818,425,671] &"Previous frame identical to this frame (corrupt stack?)\n"[1,101,818,425,681] 957^error,msg="Previous frame identical to this frame(corrupt stack?)"[1,101,818,425,681] (gdb) [1,101,818,425,681] 957-stack-info-depth[1,101,818,425,701] 957^done,depth="9"[1,101,818,425,701] (gdb) [1,101,818,425,711] 958 stepi[1,101,818,425,771] &"stepi\n"[1,101,818,425,841]958^done,reason="end-stepping-range",thread-id="0",frame={addr="0x010d142c",func\="Cyg_CList_T",args=[{name="this",value="0xf9fc"}],file="clist.hxx",line="310"}[1,101,818,425,841] (gdb) [1,101,818,425,841] 959 info threads[1,101,818,425,851] &"info threads\n"[1,101,818,425,851] &"warning: RMT ERROR : failed to get remote thread list\n"[1,101,818,425,851] &"\n"[1,101,818,425,861] 959^done[1,101,818,425,861] (gdb) [1,101,818,425,861] 960-stack-info-depth[1,101,818,426,152] &"Previous frame identical to this frame (corrupt stack?)\n"[1,101,818,426,152] 960^error,msg="Previous frame identical to this frame(corrupt stack?)"[1,101,818,426,152] (gdb) [1,101,818,426,152] 960-stack-info-depth[1,101,818,426,152] 961-var-update var1[1,101,818,426,162] 960^done,depth="9"[1,101,818,426,162] (gdb) [1,101,818,426,412] 961^done,changelist={}[1,101,818,426,412] (gdb) [1,101,818,426,412] 962-var-update var2[1,101,818,426,643] 962^done,changelist={}[1,101,818,426,643] (gdb) [1,101,818,426,643] 963-data-list-changed-registers[1,101,818,426,653] 963^done,changed-registers=["15"][1,101,818,426,653] (gdb) [1,101,818,426,663] 964-stack-info-depth[1,101,818,426,773] &"Previous frame identical to this frame (corrupt stack?)\n"[1,101,818,426,773] 964^error,msg="Previous frame identical to this frame(corrupt stack?)"[1,101,818,426,773] (gdb) [1,101,818,426,773] 964-stack-info-depth[1,101,818,426,803] 964^done,depth="9"[1,101,818,426,803] (gdb) [1,101,818,431,590] 965-interpreter-exec console stepistepi[1,101,818,431,590] &"Undefined command: \"stepistepi\". Try \"help\".\n"[1,101,818,431,590] 965^error,msg="Undefined command: \"stepistepi\". Try\"help\"."[1,101,818,431,600] (gdb) [1,101,818,432,581] 966 stepi[1,101,818,432,591] &"stepi\n"[1,101,818,432,661]966^done,reason="end-stepping-range",thread-id="0",frame={addr="0x010d1430",func\="Cyg_CList_T",args=[{name="this",value="0xf9fc"}],file="clist.hxx",line="310"}[1,101,818,432,671] (gdb) [1,101,818,432,671] 967 info threads[1,101,818,432,671] &"info threads\n"[1,101,818,432,671] &"warning: RMT ERROR : failed to get remote thread list\n"[1,101,818,432,671] &"\n"[1,101,818,432,681] 967^done[1,101,818,432,681] (gdb) [1,101,818,432,681] 968-stack-info-depth[1,101,818,432,972] &"Previous frame identical to this frame (corrupt stack?)\n"[1,101,818,432,972] 968^error,msg="Previous frame identical to this frame(corrupt stack?)"[1,101,818,432,972] (gdb) [1,101,818,432,972] 968-stack-info-depth[1,101,818,432,972] 969-var-update var1[1,101,818,432,982] 968^done,depth="9"[1,101,818,432,982] (gdb) [1,101,818,433,242] 969^done,changelist={}[1,101,818,433,242] (gdb) [1,101,818,433,242] 970-var-update var2[1,101,818,433,482] 970^done,changelist={}[1,101,818,433,482] (gdb) [1,101,818,433,482] 971-data-list-changed-registers[1,101,818,433,482] 971^done,changed-registers=["15"][1,101,818,433,482] (gdb) [1,101,818,433,492] 972-stack-info-depth[1,101,818,433,603] &"Previous frame identical to this frame (corrupt stack?)\n"[1,101,818,433,603] 972^error,msg="Previous frame identical to this frame(corrupt stack?)"[1,101,818,433,603] 972-stack-info-depth[1,101,818,433,613] (gdb) [1,101,818,433,633] 972^done,depth="9"[1,101,818,433,633] (gdb) [1,101,818,433,703] 973 stepi[1,101,818,433,713] &"stepi\n"[1,101,818,433,793]973^done,reason="end-stepping-range",thread-id="0",frame={addr="0x010d1434",func\="Cyg_CList_T",args=[{name="this",value="0xf9fc"}],file="clist.hxx",line="310"}[1,101,818,433,793] (gdb) [1,101,818,433,793] 974 info threads[1,101,818,433,803] &"info threads\n"[1,101,818,433,813] &"warning: RMT ERROR : failed to get remote thread list\n"[1,101,818,433,813] &"\n"[1,101,818,433,813] 974^done[1,101,818,433,813] (gdb) [1,101,818,433,813] 975-stack-info-depth[1,101,818,434,113] &"Previous frame identical to this frame (corrupt stack?)\n"[1,101,818,434,113] 975^error,msg="Previous frame identical to this frame(corrupt stack?)"[1,101,818,434,113] (gdb) [1,101,818,434,113] 975-stack-info-depth[1,101,818,434,113] 976-var-update var1[1,101,818,434,123] 975^done,depth="9"[1,101,818,434,123] (gdb) [1,101,818,434,374] 976^done,changelist={}[1,101,818,434,374] (gdb) [1,101,818,434,374] 977-var-update var2[1,101,818,434,634] 977^done,changelist={}[1,101,818,434,634] (gdb) [1,101,818,434,634] 978-data-list-changed-registers[1,101,818,434,634] 978^done,changed-registers=["3","15"][1,101,818,434,634] (gdb) [1,101,818,434,644] 979-stack-info-depth[1,101,818,434,754] &"Previous frame identical to this frame (corrupt stack?)\n"[1,101,818,434,754] 979^error,msg="Previous frame identical to this frame(corrupt stack?)"[1,101,818,434,754] 979-stack-info-depth[1,101,818,434,774] (gdb) [1,101,818,434,784] 980 stepi[1,101,818,434,794] 979^done,depth="9"[1,101,818,434,794] (gdb) [1,101,818,434,794] 981 info threads[1,101,818,434,794] &"stepi\n"[1,101,818,434,874]980^done,reason="end-stepping-range",thread-id="0",frame={addr="0x010d1438",func\="Cyg_CList_T",args=[{name="this",value="0xf9fc"}],file="clist.hxx",line="310"}[1,101,818,434,874] (gdb) [1,101,818,434,874] &"info threads\n"[1,101,818,434,874] &"warning: RMT ERROR : failed to get remote thread list\n"[1,101,818,434,874] &"\n"[1,101,818,434,884] 981^done[1,101,818,434,884] (gdb) [1,101,818,434,884] 982-stack-info-depth[1,101,818,435,195] &"Previous frame identical to this frame (corrupt stack?)\n"[1,101,818,435,195] 982^error,msg="Previous frame identical to this frame(corrupt stack?)"[1,101,818,435,195] (gdb) [1,101,818,435,195] 983 stepi[1,101,818,435,195] 982-stack-info-depth[1,101,818,435,295] &"stepi\n"[1,101,818,435,335]983^done,reason="end-stepping-range",thread-id="0",frame={addr="0x010d0f80",func\="Cyg_CList",args=[{name="this",value="0xf9fc"}],file="clist.hxx",line="164"}[1,101,818,435,335] (gdb) [1,101,818,435,335] 984 info threads[1,101,818,435,656] &"Previous frame identical to this frame (corrupt stack?)\n"[1,101,818,435,656] 982^error,msg="Previous frame identical to this frame(corrupt stack?)"[1,101,818,435,656] (gdb) [1,101,818,435,666] &"info threads\n"[1,101,818,435,666] &"warning: RMT ERROR : failed to get remote thread list\n"[1,101,818,435,666] &"\n"[1,101,818,435,666] 984^done[1,101,818,435,666] (gdb) [1,101,818,435,666] 985-stack-info-depth[1,101,818,435,676] 985^done,depth="10"[1,101,818,435,676] (gdb) [1,101,818,435,676] 986-stack-list-frames 0 10[1,101,818,435,686]986^done,stack=[frame={level="0",addr="0x010d0f80",func="Cyg_CList",file="clist.\hxx",line="164"},frame={level="1",addr="0x010d143c",func="Cyg_CList_T",file="clist.hxx",line="310"},\frame={level="2",addr="0x010d1410",func="Cyg_ThreadQueue_Implementation",file="mlqueue.hxx",line="12\6"},frame={level="3",addr="0x010d1364",func="Cyg_ThreadQueue",file="/cygdrive/c/cdtworkspace/ecos-re\pository/ecos/packages/kernel/current/src/sync/cnt_sem.cxx",line="73"},frame={level="4",addr="0x0105\a73c",func="Cyg_Condition_Variable",file="/cygdrive/c/cdtworkspace/ecos-repository/ecos/packages/ker\nel/current/src/sync/mutex.cxx",line="540"},frame={level="5",addr="0x010771f0",func="__static_initia\lization_and_destruction_0",file="/cygdrive/c/cdtworkspace/ecos-repository/ecos/packages/io/fileio/c\urrent/src/select.cxx",line="100"},frame={level="6",addr="0x01077268",func="_GLOBAL__I.50000_cyg_tim\eval_to_ticks",file="/cygdrive/c/cdtworkspace/ecos-repository/ecos/packages/io/fileio/current/src/se\lect.cxx",line="453"},frame={level="7",addr="0x0105332c",func="cyg_hal_invoke_constructors",file="/c\ygdrive/c/cdtworkspace/ecos-repository/ecos/packages/hal/arm/arch/current/src/hal_misc.c",line="202"\},frame={level="8",addr="0x01030230",func="start"},frame={level="9",addr="0x01030230",func="start"}][1,101,818,435,686] (gdb) [1,101,818,435,686] 987-var-update var1[1,101,818,435,966] 987^done,changelist={}[1,101,818,435,966] (gdb) [1,101,818,435,966] 988-var-update var2[1,101,818,436,216] 988^done,changelist={}[1,101,818,436,216] (gdb) [1,101,818,436,216] 989-data-list-changed-registers[1,101,818,436,216] 989^done,changed-registers=["14","15"][1,101,818,436,216] (gdb)	17.0
id=156218	REOPENED	CDT	cdt-debug-cdi-gdb	3.1	PC Windows XP	P3 major	cdt-debug-inbox@eclipse.org	2006-09-05 12:00 EDT by	Olav Zarges	2009-01-09 14:20 EST (	0 users	When debugging a multithreaded C++ app I'm unable to see backtrace information or some or all of the threads. Using command line gdb I found that gdb - when it detects a problem while undwinding the stack - gives the user the stack info and then stops with a message like: "Backtrace stopped: frame did not save the PC" or "Previous frame identical to this frame (corrupt stack?)" or ...while Eclipse just throws away the complete backtrace for the corresponding thread.I patched gdb to stop outputting these messages and everything worked fine but I think best would be to let Eclipse show the backtrace and the message as it is provided like gdb does.When setting "org.eclipse.cdt.debug.mi.core/debug=true" you will not see any backtrace for a thread with a message (the "(corrupt stack?)" message is shown as an error).I managed to dump what was sent via gdb/mi and there you could see all the backtrace for the thread.The gdb-developer Daniel Jacobowitz told me, that with older versions of gdb, it was an ^error; while with newer it's a ~"console output message". He would not expect Eclipse to throw away the backtrace if there's a console output message.-----------------------------------------------eclipse debug console output[1.157.461.298.906] 207^done,new-thread-id="4",frame={level="0",addr="0x402c8d60",func="poll",args=[],from="/opt/crosstool/gcc-3.4.4-glibc-2.3.5-linux-2.6.12/arm-softfloat-linux-gnu/arm-softfloat-linux-gnu/lib/libc.so.6"}[1.157.461.298.906] (gdb)[1.157.461.298.906] 208-stack-info-depth[1.157.461.298.968] &"Previous frame identical to this frame (corrupt stack?)\n"[1.157.461.298.968] 208^error,msg="Previous frame identical to this frame corrupt stack?)"[1.157.461.298.968] (gdb)[1.157.461.298.968] 209-stack-info-depth[1.157.461.299.000] 209^done,depth="4"[1.157.461.299.000] (gdb)[1.157.461.299.000] 210-stack-info-depth[1.157.461.299.015] 210^done,depth="4"[1.157.461.299.015] (gdb)[1.157.461.299.015] 211-thread-select 3[1.157.461.299.031] 211^done,new-thread-id="3",frame={level="0",func="f2",args=[],file="../threads.cpp",fullname="/cygdrive/e/eclipse/ws_threads/Threads-arm/threads.cpp",line="30"},line="30",file="../threads.cpp"[1.157.461.299.031] (gdb)[1.157.461.299.031] 212-thread-select 4[1.157.461.299.046] 212^done,new-thread-id="4",frame={level="0",addr="0x402c8d60",func="poll",args=[],from="/opt/crosstool/gcc-3.4.4-glibc-2.3.5-linux-2.6.12/arm-softfloat-linux-gnu/arm-softfloat-linux-gnu/lib/libc.so.6"}[1.157.461.299.046] (gdb)[1.157.461.299.046] 213-stack-list-frames 0 4[1.157.461.299.140] &"Previous frame identical to this frame (corrupt stack?)\n"[1.157.461.299.140] 213^error,msg="Previous frame identical to this frame (corrupt stack?)"[1.157.461.299.140] (gdb)[1.157.461.299.140] 214-thread-select 3[1.157.461.299.156] 214^done,new-thread-id="3",frame={level="0",func="f2",args=[],file="../threads.cpp",fullname="/cygdrive/e/eclipse/ws_threads/Threads-arm/threads.cpp",line="30"},line="30",file="../threads.cpp"[1.157.461.299.156] (gdb)------------------------------------------------------------output of gdb (sorry, commas and brackets were not captured)new-thread-id="3"frame=level="0"func="f2"args=file="../threads.cpp"fullname="/cygdrive/e/eclipse/ws_threads/Threads-arm/threads.cpp"line="30"line="30"file="../threads.cpp"new-thread-id="4"frame=level="0"addr="0x402c8d60"func="poll"args=from="/opt/crosstool/gcc-3.4.4-glibc-2.3.5-linux-2.6.12/arm-softfloat-linux-gnu/arm-softfloat-linux-gnu/lib/libc.so.6"Previous frame identical to this frame (corrupt stack?)Previous frame identical to this frame (corrupt stack?)depth="4"depth="4"new-thread-id="3"frame=level="0"func="f2"args=file="../threads.cpp"fullname="/cygdrive/e/eclipse/ws_threads/Threads-arm/threads.cpp"line="30"line="30"file="../threads.cpp"new-thread-id="4"frame=level="0"addr="0x402c8d60"func="poll"args=from="/opt/crosstool/gcc-3.4.4-glibc-2.3.5-linux-2.6.12/arm-softfloat-linux-gnu/arm-softfloat-linux-gnu/lib/libc.so.6"frame=level="0"addr="0x402c8d60"func="poll"from="/opt/crosstool/gcc-3.4.4-glibc-2.3.5-linux-2.6.12/arm-softfloat-linux-gnu/arm-softfloat-linux-gnu/lib/libc.so.6"frame=level="1"addr="0x40024114"func="__pthread_manager"from="/opt/crosstool/gcc-3.4.4-glibc-2.3.5-linux-2.6.12/arm-softfloat-linux-gnu/arm-softfloat-linux-gnu/lib/libpthread.so.0"frame=level="2"addr="0x40024304"func="__pthread_manager_event"from="/opt/crosstool/gcc-3.4.4-glibc-2.3.5-linux-2.6.12/arm-softfloat-linux-gnu/arm-softfloat-linux-gnu/lib/libpthread.so.0"frame=level="3"addr="0x40024304"func="__pthread_manager_event"from="/opt/crosstool/gcc-3.4.4-glibc-2.3.5-linux-2.6.12/arm-softfloat-linux-gnu/arm-softfloat-linux-gnu/lib/libpthread.so.0"Previous frame identical to this frame (corrupt stack?)Previous frame identical to this frame (corrupt stack?)new-thread-id="3"frame=level="0"func="f2"args=file="../threads.cpp"fullname="/cygdrive/e/eclipse/ws_threads/Threads-arm/threads.cpp"line="30"line="30"file="../threads.cpp"new-thread-id="5"frame=level="0"addr="0x402a319c"func="nanosleep"args=from="/opt/crosstool/gcc-3.4.4-glibc-2.3.5-linux-2.6.12/arm-softfloat-linux-gnu/arm-softfloat-linux-gnu/lib/libc.so.6"	While command line gdb shows backtrace and messages gdb seems to behave different when called via gdb/mi (shows those messages as an ^error and therefore throws away backtrace). I will contact the gdb developers next in order to discuss this matter.LATER/REMIND are deprecated. Changing to reopened milestone '--'	2.0
id=104360	REOPENED	CDT	cdt-debug	3.0	PC Linux	P3 normal	cdt-debug-inbox@eclipse.org	2005-07-19 11:28 EDT by	Nikolay	2007-08-21 11:06 EDT (	1 user	First of all sorry for my english.I create managed make c/c++ project. There is just one file - main.cpp:#include "ace/Log_Msg.h"#include "ace/SOCK_Acceptor.h"#include "ace/SOCK_Stream.h"#include "ace/INET_Addr.h"class Class{public: Class (unsigned int portNo): m_addr (portNo), m_acceptor (m_addr) {} void handleInput () { //... } void acceptConnection () { ACE_INET_Addr remoteAddr; if (m_acceptor.accept (m_stream, &remoteAddr) != -1) { ACE_DEBUG (( LM_DEBUG, "Connection accepted:\n\tHost: %s .\n\tPort: %d .\n", remoteAddr.get_host_name (), remoteAddr.get_port_number () ));//When current instruction pointer points to previous line and I press F6 (Step over)//current instruction pointer (little arrow) disappear.// gdb says:// Warning://Cannot insert breakpoint 0.//Error accessing memory address 0x1: Input/output error.////Single stepping until exit from function _dl_debug_state, //which has no line number information. handleInput ();//If I toggle breakpoint on previous line, after current instruction pointer has//disappeared and press F8 (Continue) then it come back. } }private: ACE_INET_Addr m_addr; ACE_SOCK_Acceptor m_acceptor; ACE_SOCK_Stream m_stream;};int main (int argc, char * argv []){ const int PORT_NO = 50000; Class instance (PORT_NO); instance.acceptConnection(); return 0;}EOFWhen I try to debug Class::acceptConnection current instruction pointer disappear and F6, F5 does nothing. Please look at comments in source code.To compile this project you need ACE library. I try hard, but I can not reproduce this bug whithout using ACE. ACE is free and open source. You can get it from.	You are trying to step into a module with no debug information. In this case gdb doesn't know how to step, there is no line information. The instruction pointer disappears because the program is stepping (see the icon and label of the debug target in the Debug view). Same applies to F5 and F6 keys - they do nothing because the program is not suspended.(In reply to)I am sure that this library was built with debug info (-g3 -O0), becouse when I meet this bug this was first what I done.And anyway when I press _Step Over_ I expect that debugger go to next instruction in my programm not into library module.CreatedHow it looks like just before I press F6 (Step Over)CreatedHow it looks like just after I press F6 (Step Over)Please take a look at screenshots.Please, turn off the "Automatically load symbols" option and try it again. The option is located on the "Debugger" page of the launch configuration dialog under the "Shared Libraries" tab.(In reply to)It helps. Thank you!Another (and better) workaround is to use the debug version of ACE. This bug would go away when we switch to deferred breakpoints in gdb.(In reply to)The instruction pointer disappears even in the following simple case (with the "Automatically load symbols" option off):1: void f()2: {3: int a = 0;4: ++a;5: }6:7: int main( int argc, char** argv )8: {9: f();10:11: return 0;12: }- Place breakpoint on line 9- Start debugging -> now the arrow is on line 9- Step in (F5) -> now the arrow is on line 3- Step over (F6) -> the arrow disappearsClicking on the "Debug" view makes the arrow reappear (something I would like to avoid, of course :-).I agree with what Nikolay said: "And anyway when I press _Step Over_ I expect that debugger go to next instruction in my programm not into library module."I am using:- Eclipse 3.2.0 M20060629-1905- CDT 3.1.1.100609270800Future means you commit to fix it in the Future. Inboxes can't make committments. Moving to '--'.	10.0
id=156315	REOPENED	CDT	cdt-debug	3.1	PC Windows XP	P3 normal	cdt-debug-inbox@eclipse.org	2006-09-06 02:57 EDT by	Michael Luber	2009-02-20 14:19 EST (	3 users	If you debug a binary with CDT, that has been built with gcc and cygwin on Windows, and if you click on "Add global variables" in the "Variables" view,CDT tries to call the tool "cygpath" that comes with cygwin.CDT then sends its requests to the stdin of the cygpath process, and readsthe results from stdout.However, it is possible that the cygpath binary complains about an incompatibleversion of the cygwin DLL (cygwin1.dll).If so, it prints out the following error message, and terminates itself:"H:\>cygpath 182 [main] ? (6992) D:\cygwin\bin\cygpath.exe: *** fatal error - D:\cygwin\bin\cygpath.exe: *** system shared memory version mismatch detected - 0x75BE0084/0x75BE009C.This problem is probably due to using incompatible versions of the cygwin DLL.Search for cygwin1.dll using the Windows Start->Find/Search facilityand delete all but the most recent version. The most recent version *should*reside in x:\cygwin\bin, where 'x' is the drive on which you haveinstalled the cygwin distribution. Rebooting is also suggested if youare unable to find another cygwin DLL."When this occurs, CDT waits forever for a response that never comes.As cygpath is an external tool, CDT should not rely on it. It should nothang if anything goes wrong when calling cygpath.Therefore, I think this is a bug.	I think I have backhandedly fixed this. I noticed that CygPath was using the CDT's spawner to fork off the cygpath utility. We shouldn't be using spawner when java's Runtime.exec will do fine. So I changed it and the hang I was experiencing when cygpath wasn't in my path went away.I'm going to mark this fixed. Please retest with CDT 4.0.1.I retested with CDT 4.0.1 (4.0.1.200709241202)Eclipse SDKVersion: 3.3.0Build id: I20070625-1500I have exchanged my cygpath binary with a small dummy program, that writes a dozen lines on stderr, and then terminates. I did this to simulate the situation of incompatible cygwin-DLLs.Now, when a build a C project with external make, CDT invokes the discoveryscanner after the build is complete, and the discovery scanner runs forever.I have an entry in the Progress view which I cannot get rid of, andI cannot close Eclipse. I have to kill the eclipse.exe process.I also observe an entry "cygpath.exe" in the process list of Windows.Eclipse must read not only stdout from the cygpath process, but alsostderr, so that cygpath.exe can terminate itself.For that reason, I reopen the bug report.Had the same unexpected response situation running ErrorParserManager test cases (test case fixed by now),, see the very last word in the comment. The problem was that too long line was passed to CygPath as a file name by error parser and cygpath complained 'File name too long'. The result was the test case hanging.	3.0
id=247172	REOPENED	CDT	cdt-debug	5.0	Other Linux	P3 enhancement	cdt-debug-inbox@eclipse.org	2008-09-12 11:08 EDT by	Vladimir Prus	2008-09-12 15:58 EDT (	4 users	Create a hello, world program, and add a global variable "int foobar;" to that problem as well. Build and launch it under debugger. Right click the source, select "add watch expression" and type 'foobar' as the name. The "Expressions" window appears. Right click on the 'foobar' there, and observe "Change Value" menu item, grayed out.An expression can be either lvalue or rvalue, and lvalues should be editable via UI. One can use GDB -var-show-attributes command to discover is a variable object is editable or not.	The enablement of "Change Value" depends on IValueModification interface. The WatchExpression object created by "Add Watch Expression" command doesn't implement IValueModification interface. This code is part of the Platform and we don't have access to it.cc-ing to platform for comment.The platform models a watch expression as an expression that changes value based on the context in which it is evaluated. It is not something that is assigned a value - the value comes from the evaluation.I can't resist making a shameless plug for DSF, which does support editing in the Expressions view... For standard debug model/CDI, it's probably safe to mark it as WONTFIX.If DSF can do it, we can do it too :). Marking as "enhancement".(In reply to)Wisely you speak :-) I definitely won't deny that it's possible.	5.0
id=289216	REOPENED	CDT	cdt-debug	6.0	PC Linux	P3 normal	cdt-debug-inbox@eclipse.org	2009-09-11 10:18 EDT by	Pierre Belzile	2015-05-13 00:12 EDT (	3 users	I used to be able in CDT 5 + Eclipse 3.4 to type in the gdb console a gdb command such as: p someObject.toString()And whereever the object string rendition included a '\n' character, the console would continue the text on the next line. This made displaying of object content very easy to read.I have now installed CDT 6 + Eclipse 3.5 and the output from the same command now treats '\n' as any other normal character. It shows up as "first line\nsecond line".	Duplicate of 286785, please update to new version of CDT 6.0.1*** This bug has been marked as a duplicate of***This was initially marked as a duplicate of. However the followingindicates that not a duplicate after all.	2.0
id=303440	REOPENED	CDT	cdt-debug	6.0	PC All	P3 normal	cdt-debug-inbox@eclipse.org	2010-02-21 10:30 EST by	Marc Khouzam	2010-05-29 05:28 EDT (	2 users	Currently, the CDT Debug preference pages are very confusing. Nothing distinguishes between CDI-GDB preferences and DSF-GDB preferences.Also, the DSF-GDB options are under Debug->DSF->GDB but should probably be under C/C++->Debug->somethingI haven't check EDC, but it's preferences should also be part of such a unified debug preferences.	+1Since we have a growing diversity of debuggers under the hood of CDT, we need to figure out how to present their collective preferences and avoid completely confusing the users. I would suggest that we organize the preferences like this:C/C++ Debug Standard Debugger Framework Debugger Types View Options GDB MI Debugger Services Framework (DSF) GDB Eclipse Debugger for C/C++ (EDC) Breakpoint Actions Source Lookup DisassemblyUnder the top-level Debug, we should give the user some explanation about what CDT debuggers are installed and have a link to the Run/Debug -> Launching -> Default Launchers preference page. At the same time we should standardize on the launcher names which are currently long and confusing.(In reply to)The only issue I see with this approach (and mind you, I don't have a better alternative), is that we force the framework concept on users that would otherwise not need to know about it. A Freescale customer doesn't need or care to know that the debugger we've given them is DSF-based, and particularly EDC based. The product they get simply has "a debugger", and they couldn't care less if it's DSF, ABC, or XYZ based. So, we'd like to shield them from that. Through capabilities/activities, we can filter out preference pages that don't apply, but we can't easily rename or collapse pages. So, when they go looking for debugger preferences, they're going to have to drill into ... > Debugger Services Framework (DSF) > Eclipse Debugger for C/C++ (EDC)and that's going to cause some head scratching. We've had some recent threads on how new users are overwhelmed with the Eclipse IDE, and this is an example of how users get hit with an overly complex path/presentation to what they consider something very basic. We've chosen to make CDT a home for, frankly, a head-spinning assortment of debugger technologies. Fine. But we need to make sure vendors can expose just the technology they've chosen to adopt without burdening the end-user with extraneous concepts. It's not going to be easy, but we need to try.(In reply to)I agree, this has been a problem for DSF from the start and we haven't been able to avoid having "DSF" in some places in the UI. My only suggestion (and this is what we've done in our product), is that in the product-specific preference pages put link directly to the DSF preferences, which are currently under Run/Debug -> DSF. This is hardly satisfying, so I'd love to find a better solution.I think a better solution might be to create capabilities for DSF, CDI, DSF-GDB, and CDI-GDB. I created one for EDC so I could try this out for the other debugger integrations too.Createdreorg prefsThis patch reorganizes and creates activities for the pref pages. There are five new activities: Core CDT Debug: "CDT Debug - C/C++ Development Tools" - C/C++ Debug, Breakpoint Actions, Common Source Lookup. This activity is enabled by default.CDI-GDB: "CDT CDI-GDB - GDB Debugging (Legacy)" : Debugger Types, MI Preferences. This activity is enabled when a CDI launch delegate is created.DSF-GDB: "CDT DSF-GDB - GDB Debugging" - DSF GDB Prefs, Tracepoint Actions. This activity is enabled when a DSF GDB launch delegate is created.DSF: "CDT-DSF Debug Services Framework" - DSF page (now View Performance). This activity is enabled when the DSF UI plug-in is loaded.EDC: "EDC - Eclipse Debugger for C/C++" - Snapshot page, Snapshot Album View. This activity is enabled when an EDC launch delegate is created.Other changes:Moved the DSF GDB page under C/C++ DebugMoved DSF Disassembly under C/C++ DebugRenamed DSF page to View PerformanceOnce activities are enabled they remain enabled unless manually disabled by the user.The end result is that pref pages (except the DSF page) are grouped under C++ Debug and only visible if you are using the applicable framework/feature. For the disabled activities only the UI is hidden, all of the underlying pref setting information is undisturbed.What this means in practice is that a user of CDT will see none of the disabled pages until they launch a debug session, then they will only see the ones that apply. I think this is OK because none of the disabled pages are part of any common pre-debug workflow.I also considered, but have not yet implemented, having the C/C++ debug pref pages appear under Run/Debug as well. Most people seem to look for them under C++ bug some go straight to Run/Debug.Committed to HEAD.I think this is a good start.However, when multiple activities are enabled, the preferences don't indicate if they will affect CDI only, or DSF-GDB only, etc.Although this may seem to not happen often because people will choose a single debugger, it actually does happen because when running an application, the CDI launch is used, so it's properties appear and remain there.Another problem is the actual Debug preference page. It contains CDI-specific preferences as well as (what I believe are) old Disassembly setting.I'm re-opening so we remember to continue to cleanup the preferences	8.0
id=425072	REOPENED	CDT	cdt-debug	Next	PC Linux	P3 normal	cdt-debug-inbox@eclipse.org	2014-01-08 04:34 EST by	Chandrayya Kumarswamimath	2014-01-10 10:02 EST (	5 users	CreatedWrong stepping intoHow to reproduce==================1. Create C project using hello world template2. Open any c file and set break points by double-click on break point ruler as shown in the picture.3. Right click on c file and click on Debug As->Local C/C++ Application.4. Initially debug pointer will be at line number 27.5. Click F6 again and again then debug pointer will go inside the fun() method as shown in picture.Observation:==============If fun() and fun2() method are moved below the main method then debug pointer will not go inside fun method on pression F6.=================OS: Ubuntu 13.10===================Eclipse version: Eclipse IDE for C/C++ DevelopersVersion: Kepler Service Release 1Build id: 20130919-0819==================	This is caused by the invalid breakpoints that are set. GDB sets them at an address that does not correspond to the line they were actually set on. In this case, they are set at the first valid address in the binary which happens to be inside your function.*** This bug has been marked as a duplicate of***After looking intoin more detail, I no longer think these two bugs are duplicates. The problem seen here would be fixed by, but other solutions could also be used.The problem seen here is that when we tell GDB to set a breakpoint at an invalid line, GDB will automatically set it at the first valid address but CDT does not pay attention to that. I see a couple of ways of improving this.1- Fixwhich would prevent setting a bp at an invalid line2- Prevent GDB from setting a bp at another line than the specified one. I didn't see any way to do this with the current GDB, so we'd need to modify GDB.3- Have GDB notify CDT of the actual line where the bp was truly set. CDT could then somehow indicate this to the user. This also needs a modification to GDB.4- Have CDT check every bp when set and check if the address of the bp returned by GDB actually maps to the user-specified line for the bp. If not, CDT could indicate this to the user. This may be possible without any changes to GDB.I'm not sure options 3 or 4 are the right way to go though. What would CDT do when it realized the breakpoint was set at a different line than what the user requested? We could:a) move the eclipse breakpoint to the new line. This may not be what the user wants. A bp in Eclipse can affect multiple debug sessions so moving it may affect multiple sessions. Also, a bp can be set in Eclipse at a different time than when we debug; in that case the bp will stay at the invalid line until the debug session is started, and then be moved.b) remove the breakpoint from the invalid line. That would be good if we could do it as soon as the bp is set, however, since a bp can be set when GDB is not running, it may be a long time before we realize the bp is at an invalid line.I prefer options 1 or 2.(In reply to Marc Khouzam from)Are there cases when some lines can be valid for one target and invalid for other? For instance, code inside the "ifdef" preprocessor statements.(In reply to Mikhail Khodjaiants from)Good point. I believe such a situation would only cause a problem for #1 which is handled in. But it may not even be a problem since CDT should know from the compilation what part of the ifdef is valid or not. In fact, we compile for a single target at a time, so I believe this shouldn't cause a problem.(In reply to Marc Khouzam from)Ir could be a problem for some CDT based products. Anyway, I just wanted to mention it here.	5.0
id=314126	REOPENED	CDT	cdt-doc	6.0.2	PC Linux	P3 normal	cdt-debug-inbox@eclipse.org	2010-05-24 11:16 EDT by	Jerry Quinn	2010-05-25 10:37 EDT (	2 users	Build Identifier: 20100218-1602Centos5.4 x86_64, gdb 6.8-37.el5CDTVersion: 6.0.2.201002161416Build id: 201002161416I'm adding the path to my shared libs under theDebug Configurations->Debugger->Shared Librariestab.However, the app starts up and can't find its libs. If I set LD_LIBRARY_PATHunder Debug Configurations->Debugger->Environment, then it works.Reproducible: Always	Debug paths are only for debugger to find symbols for shared libraries.You still have to set LD_LIBRARY_PATH on unix or whatever on windows to launch it.(In reply to)There is no documentation that this is the case. Should I reopen this bug or create another?Yes you can re-open this one for documentationPlease document the meaning of Debug Configurations->Debugger->Shared Librariesto indicate that this sets shared libs for gdb, not for the program being debugged.	4.0
id=427410	REOPENED	CDT	cdt-debug	8.2.1	PC Mac OS X	P3 normal	cdt-debug-inbox@eclipse.org	2014-02-04 15:23 EST by	Didier Bertrand	2016-02-03 23:44 EST (	4 users	PROBLEM:Writing a MI interface to LLDB, I found a major bug with JRE 7 on Mac OS X.Considering the following application:1 #include <stdio.h>2 int main (void)3 {4 printf ("hello, world\n");5 return 0;6 }With Java SE 7,- if the program is debugged with no breakpoint, it terminates normally- if a breakpoint is set on line 4 and then the program is run and continued after break stop, all is fine- if a breakpoint is set on line 5 and then the program is run and continued after break stop, Eclipse hangsWith Java SE 6, all is OKThe same problem arises with GDB (DSF) and Standard launcher.Reproducible: AlwaysCONFIGURATION:Mac OS X Mavericks 10.9.1Eclipse 4.3.1 64 bits + Java SE 7 (1.7.0_51), (same problem with 1.7.0_25)GNU version 7.6.2 (but any debugger will behave the same way)INVESTIGATION (on DSF version):The problem is related to the pipe created by CDT to capture the debugged application' output.In normal case, this stream is read by org.eclipse.debug.internal.core.OutputStreamMonitor.read() and displayed on the Eclipse's console.On exit, the read loop is interrupted, and Java_org_eclipse_cdt_utils_pty_PTYInputStream_close0 from libpty.jni is called to close the stream.Later, org.eclipse.cdt.dsf.mi.service.command.closeIO() is called to close again the stream (which is already closed) and free memory.When breakpoint is set at line 5, the closed stream (from remote) is not detected and read loop is never interrupted. Then, when CloseIO() tries to close the stream, it is hold by read() in read loop and close0() never return causing Eclipse hang (normal behaviour on Mac OS X).I tried to disable the stream close from CloseIO, and then the debugged process terminate normally, but the OutputStreamMonitor (and related InputStreamMonitor) continues to run. And after many runs, we get many monitors running.So, why the OutputStreamMonitor read() is never interrupted when breakpoint is set just before the exit?I don't know if it is a JRE 7 related problem, but if forbids it's use on Max OS X, which could turn to be a problem, as many applications require JRE 7 and it is nor sure how long we will be able JRE 6 on Mac OS X.	Didier, have you found a solution for this issue? I just came across this bug. I tried making PTYInputStream.read, PTYOnputStream.write and close synchronized and I don't see the issue anymore. But I don't understand why that would be necessary now.Hello Marc-Andre. No, I didn't found an altermnative solution. I tried your fix with Luna and the bug was cleared. Will the fix be inserted in standard releases?(In reply to Didier Bertrand from)Not the Luna release but I want to fix this for Luna SR1 (September). I want to understand the issue first before applying a fix.Hmm, I don't see this problem with gdb running Java 1.8u5.(In reply to Doug Schaefer from)It's interesting because I just tried Apple GDB (installed from MacPorts) and it works fine. But if I use the "normal" FSF GDB from MacPorts, I have the problem. I do also have the problem with Java 1.8u5 as well. I simply start debugging the Hello World project which stops at main then click on Terminate in the toolbar. I'll need to investigate some more, but at least there is a way to make it work.I'm using the gdb from Brew which requires a bit of magic to set up, especially to get the security settings right. I wonder if that has something to do with it.Hello Marc-André and Doug,I tried many debuggers as suggested by Doug, but in my case, none of them (MacPorts and HomeBrew) resolved my problem.It also tried to reimplement the synchronise patch as proposed by Marc-André but it was not working anymore.I investigated a little more and confirmed my problem was related to org.eclipse.debug.internal.core.OutputStreamMonitor.read(). When GDB closes, the read is never interrupted if I'm using JRE 1.7 or JRE 1.8, but is ok if using JRE 1.6.I don't understand why this problem arise, but I made the read call unblocking and it resolved my problem.I modified the JNI library for Mac OS X org.eclipse.cdt.core.macosx to make read0 non blocking. This patch was not tested on Luna but should work.diff ptyio.c ptyio-new.c19a20,4141c63< status = read( fd, data, data_len );---If you have a better idea, advise me. Thanks,DidierIn fact the timer is useless. We just want to be able to catch read events and let the pty free to be closed when the program terminate. The new version is:diff ptyio-org.c ptyio-new.c19a20,3341c55< status = read( fd, data, data_len );---CreatedPatch to avoid hang on PTY closeHello,I investigated a little more about this bug and found it was the same that: [launch] Error in Launch sequence leaves Debug view with a hanging launch.Instead of using a select as I proposed in comments #7 and #8, I applied what was proposed in, i.e., open the slave side of the PTY and send a character to unlock the read end of the pipe just before to close the master side.I made a patch (atteched) at the C library level but it assumes that there is just one PTY open during the debugging process (in fact, it is the case). A more general patch would involve PTY.java, PTYOutputStream.java and PTYInputStream.java.This patch have been tested on CDT 8.5.Didier, can you sign the CLA:and post your patch on Gerrit:We cannot accept patches from Bugzilla anymore for Intellectual Property tracking.ThanksHi Didier. I can't reproduce this issue anymore with Yosemite (OSX 10.10). Are you still able to reproduce it?Hello Marc-André, I did not upgrade yet to Yosemite 10.10 because I'm afraid to loose performances on my mid 2009 Macbook Pro. I'll try to upgrade next week and then give you feedback.For now I happily run Eclipse with my patch described in.(In reply to Didier Bertrand from)Don't feel like you have to, it's just in case you had upgraded. (BTW I run it on a 2007 MBP, some UI operations are a bit slower but the rest is OK).Interesting! An upgrade to Yosemite (10.10.1) cleared the problem.It tried it with a fresh copy of Eclipse 4.4.1.It seems this bug was related to Mavericks.Anyway, this bug helped me to understand Eclipse's internals.I guess you can close this bug.Thanks for your support.(In reply to Didier Bertrand from)OK, let's keep an eye on it and reopen if necessary.I'm seeing similar hangs again. I'll try to narrow down the conditions where it happens.Also, this somewhat sounds similar to.	16.0
id=301949	REOPENED	CDT	cdt-editor	6.0	PC Windows XP	P3 enhancement	Project Inbox	2010-02-05 07:38 EST by	agt{c}soft	2015-08-31 10:02 EDT (	4 users	May be released switch-case structure view in Outline view for functions ?	I'm not sure what you mean.Something like this?Outline tree:+function1-function2 -switch -case -case+function3(In reply to)I am not the original poster of this feature request. But I had this structure in my mind.We have some source files with many switch cases and some of them contain a lot of code, i.e. you will not see the whole switch/case tree in the editor at once. It would be very helpful to use the outline view to go straight to one case.-It's fixed?(In reply to)I don't think so. Can somebody with the appropriate rights please reopen this bug?Reopened.---Reopened...I would also find this enhancement very useful when dealing with "legacy" code.This would be awesome, because I have tons of large switch statements (for FSM, response handling, etc.)	10.0
id=251050	REOPENED	CDT	cdt-editor	5.0.1	PC Windows XP	P3 enhancement	Project Inbox	2008-10-16 04:29 EDT by	Fredric Moestedt	2016-12-28 05:29 EST (	13 users	It would be very useful if it would be possible to use the doxygen tags for the editor hover functionality (text hover name Documentation) just like it is implemented for javadoc.Generally, doxygen comments for functions are added in the declaration for public functions (e.g. in the header file) and in the implementation for static functions (in the source file). If it's possible it would be great if the documentation engine should be aware of the doxygen comments even if only added on the declaration.	I second this request.Doxygen syntax is very similar to javadoc's so I think the javadoc module for eclipse could be a good place to start.It would be very interesting if cdt has a documentation integration as javadoc for Java ...I'm surprised this is not already in CDT, it seems so logical.Is there any way to extend CDT to make this possible?I added the keyword "helpwanted".In contrast to Java, there is not the one and only documentation system for C/C++, which makes tooling support much more difficult.Couldn't this be merged with?(In reply to)Yes. Seems like the same thing.*** This bug has been marked as a duplicate of***I think it would make sense to track this separately from; that concerns content assist, while this concerns hovers.***has been marked as a duplicate of this bug. ***Reopening per.	10.0
id=310237	REOPENED	CDT	cdt-editor	4.0	PC Linux	P3 normal	Project Inbox	2010-04-23 04:06 EDT by	Jens Seidel	2016-11-29 11:25 EST (	9 users	Build Identifier: 3.6.0 M6I tried from a C++ editor to add a missing word in my (not yet existing) dictionary and Eclipse asks:"Missing User DictionaryA user dictionary is needed to add words.Do you want to configure it now?"I replied with yes and chose /home/jens/.eclipse/dictionary.en_GB where/home/jens/.eclipse is my workspace. I selected OK in the dialog, tried adding the word again and got the same "Missing User Dictionary" dialog.Mhm, what now? I created an empty file but it still does not work. Even after a restart of Eclipse it doesn not work. I also added the missing word ("Destructor"), still no success ...Reproducible: Always	*** This bug has been marked as a duplicate of***This is notas it is about a missing spell engine. I have a working spell engine.Now I found a solution: In the preferences I switch the spelling engine from "default spelling engine" to "C/C++ spelling engine" and the user defined dictionary was not set after this. So it seems that my input in the dialogwas not properly propagated ...Neverthless you're right that I have no JDK plugins installed.I suffered from this too - and so do others on the web, where I searched to find out what was wrong and how to fix it.The problem is that answering "Yes" to "Do you want to configure a user dictionary?" leads to the user-dictionary config page, but the page opens to the settings for the "default" engine, not the C++ engine. There is no way to discover that you need to change the selection to the C++ engine FIRST, and THEN fill out the form.If there is no way to force the Preferences window's Spelling dialog to open with the C++ engine pre-selected, then the dialog that leads you there should tell you to "Select the C++ engine on the Preferences page" or something. That is not a preferred UI but it's better than what is there now.This is platform independent issue. I had troubles on Windows too. I have spent 20 minutes until found this kind of solution.The solution explained by Allan Pratt works. The bug is that when the Preferences dialog opens, the selection for "Spelling Engine to use" isn't automatically set to "C/C++ spelling engine".The solution was also noted here:Problem still exists in 4.2.1. Allen Pratt's solution worked, but it's not very user friendly. The idea to bring up the dialog when a user dictionary needs to be created is good, but it is non-obvious that you need to select the C++ spelling engine.Still a problem in 4.4.0 in 2015.If anyone cares, it's still an issue in 4.6.1 in Nov 2016. Allan Pratt's solution still works, but it's not easy to find.	8.0
id=308721	REOPENED	CDT	cdt-editor	7.0	All All	P3 enhancement	Project Inbox	2010-04-10 03:43 EDT by	Marc-André Laperle	2016-09-19 02:31 EDT (	1 user	CreatedPatch adding the toolbar buttons in plugin.xmlIn VS where there is a Text Editor tool bar containing:-Comment-Uncomment-Shift left-Shift right-Others less important IMOThis especially helps beginners. I think it would be great to have something similar in CDT and more advanced users could still disable the tool bar.CDT could have:-Toggle Comment (//)-Add block comment-Remove block comment(Toggle block comment would be better but it not available)-Shift left-Shift right	CreatedIcons to put in icons/elcl16Added the comment icons, updated shift_r_edit.gif because it was not properly aligned with the left.I'm not sure how to set the order of the tool bars. I would definitely put it more to the right.CreatedScreenshot of the toolbarI think that the beginners are overwhelmed with all the eclipse options and not sure if adding more is a good thing. Toggle comment and the others are very useful and common operations but they are most useful when using keyboard shortcuts not toolbar. Users need a way to discover those - once, and I think "Source" menu is good enough. But I suppose I lost my beginner viewpoint a few years ago.From my perspective, adding more buttons on the toolbar will make the toolbar to take two lines instead of one as I widen perspectives panel to keep open 4-5 perspective buttons for easier access.(In reply to)I'm not convinced the toolbar should be added either but I've seen people coming from VS looking for this and just give up on the operations. Another issue with the actions is the key binding. Sometimes, on non-english keyboards, '/' and '\' have to be done with a modifier (shift, or other) so the binding doesn't work which leaves the user to use the menu every time or change the key bindings. I didn't change the bindings for a while thinking they were just broken.I wish there were "UI profiles" matching the kind of user using it...I agree that if you leave all the default toolbars, it's too much. It would be nice to have the actions more obvious but yeah, it will clutter the UI too much. So, I won't pursue this idea further.I've been also thinking that the Manage configurations button could be merged with the Build button so it would be more like Debug and Run configurations. The drop down would look like:DebugRelease---------------Configuration...This Visual Studio migrant argues that it should at least be possible to add a toolbar for Source actions, which appears to be an impossibility from what I can decipher from the altogether challenged user interface of Eclipse.Whether the toolbar is there by default or not upon installation would seem to be an argument (posed by Andrew Gvozdev) that is besides the point, being a separate discussion altogether, as I see it.I don't mind adding the toolbar and not enable it by default. Any objections?Patrick, do you think my original proposal made sense? Or do you think some actions should be removed or added?Wow, a proper answer on an open-source bug system. Thanks, Mr. Laperle, I am newly encouraged. :)Your original proposal looks great. I have no problem with leaving it disabled by default, either: Mr. Gvozdev's opinion that there was little room available is certainly valid enough (but it would be great to have the option, as you and I [and others] would like).Thanks for getting back and for the willingness to improve the situation!	8.0
id=361891	REOPENED	CDT	cdt-editor	8.0	PC Linux	P3 major	Project Inbox	2011-10-25 03:59 EDT by	Yevgeny Shifrin	2011-11-21 10:56 EST (	4 users	Build Identifier: 20110615-0604Hi,When opening a specific file, eclipse freezes every time for several seconds.I attached jstack output taken every second period while eclipse did not respond.Thanks,YevgenyReproducible: Always	Created20111025.0954.53Created20111025.0954.55Created20111025.0954.56Created20111025.0954.57Can you share the file for a reproducible test case?The thread dumps indicate that a TreeViewer.refresh() in the Outline view is taking a long time.In three cases the main thread is at org.eclipse.swt.internal.gtk.OS._gtk_tree_model_get_path()So, this could be a performance issue with SWT/GTK.Moving to Platform/SWT for comment.Hi,Unfortunately I cannot share this file (our company code ...). I can say that this file has ~50K lines of "#define" statements.I am not sure I understand why code related to "Outline" view causes eclipse to freeze. In many cases when there is a big file, it takes time till "Outline" view is shown (meanwhile "Pending" is shown). But it does not freeze eclipse.BTW: As you mentioned, it is related to "Outline" view. If I close "Outline" view eclipse is not freezing. Thanks,Yevgeny(In reply to)By default opening a file with more than 5000 lines would enable "Scalability mode" to avoid such performance penalties. I assume the scalability mode preferences have been changed on your side.Populating the view with 50k items takes its time and this cannot be done in the background.I am moving this bug back to CDT.(In reply to)You are correct, scalability mode was disabled.I still cannot understand why code in specific view causes eclipse to freeze (why cannot it be done in background ...). As far as I know, UI thread should not be blocking for several seconds. This is very problematic for users.There is no problem if outline will be built after several seconds, but it should not freeze eclipse. BTW: There are many files that have ~10K lines. It takes outline time to show the info (meanwhile "Pending" is shown), and it does not freeze eclipse.(In reply to)The model is computed in the background, but populating the tree viewer must occur on the UI thread.We could use the TreeViewer in virtual mode where only items currently visible are realized, but that would require a major rework.It's the number of items to fill into the TreeViewer, not the file size in general.If you think the performance of the TreeViewer is not adequate, please file a bug with Platform/UI.Hi,From what I understood from your reply: The problem is not caused as a result lines count the file, it is because outline view needs to populate ~50K items.I am not an eclipse developer so I cannot comment how it should be implemented.I do not think I need to open a new bug. This bug was opened for functionality problem, which needs to be addressed. It would be great if Platform/UI and CDT guys could decide who should handle this issue.BTW: Another thought, maybe you could add a new (additional) condition for scalability mode based on elements count and not lines number. Let me know, if you want me to open a feature request for this.Thanks a lot,Yevgeny(In reply to)This would require parsing the file, but that itself might incur a performance or memory issue. Scalability mode must be enabled based on a simple heuristic.I did some tests on Windows and adding 50,000 items to a tree without JFace takes over 60 seconds. Either SWT could try to optimize this or CDT can change their code to use a virtual tree. A DeferredTreeContentManager might help but I'm not sure.CDT should be using a virtual tree.	13.0
id=472686	REOPENED	CDT	cdt-editor	Next	PC Linux	P3 normal	Project Inbox	2015-07-15 02:06 EDT by	ray shpeley	2015-07-15 04:12 EDT (	1 user	Under Window:Preferences:General:Editors:Text Editors I set "Displayed tab width:" to 2 and checked the box "Insert spaces for tabs". The c++ editor does not respect the new setting and remains with a default tab of 4 (with no spaces), however the text editor (right click on file and open with Text Editor) does respect the setting.Under Window:Preferences:C/C++:Editor it states that C/C++ preferences are set via Text Editors with a link back to the setting above where it shows my changes. If I remember correctly this is a change from Luna where the tab policy was set for each editor. I haven't checked if the problem occurs with other editors.Needless to say it makes the editor difficult to use when your coding standard is for 2 space tabs.	*** This bug has been marked as a duplicate of***Anton stated in:Since 4.0 the C/C++ Editor has advanced code style preferences which override tab settings from the general Text Editors page, just like the Java Editor. The tab width for the C/C++ Editor can be set on the C/C++ > Code Style preference page.------In Mars I see no setting in C/C++ Code Style for tab width or for setting the tab as spaces. Perhaps you can take the effort to point out to me and others who see this bug how this setting is changed. I want a tab width of 2 space characters, not 1 tab character.As I pointed out the setting for the C/C++ editor specifically states that general settings in the Text Editor are respected by the C/C++ editor. This statement is wrong since it doesn't align with the operation of the editors. If Code Style does change the tab as you suggest then this statement should be corrected and the link back the the text editor settings removed.Incidently, I did reviewprior to posting a new instance and I still think it's not relevant to the problem. This looks like a case where the general preferences of the textual editors have been centralised in Mars but yet not actualised in practice.(In reply to ray shpeley from)The Code Style page was renamed/moved to Code Style > Formatter some time ago.Therefore above statement should read now:The tab width for the C/C++ Editor can be set on the C/C++ > Code Style > Formatter preference page.Sorry if this has caused confusion.Maybe we should add a note in the C/C++ > Editor page with a link to the Formatter page. I also noticed that we miss tab and space keywords for the Formatter page.	3.0
id=422681	REOPENED	CDT	cdt-indexer	Next	PC Linux	P3 enhancement	Project Inbox	2013-11-27 11:06 EST by	Andrew Eidsness	2013-12-05 08:51 EST (	1 user	PDOMBinding stores three lists of PDOMName; one for each of the declarations, definitions, and references to the binding. I would like to have a fourth list, to store references from other linkages.When a reference is retrieved from a binding (with PDOMBinding.getFirstReference()) there is an assumption that the name is from the same linkage as the binding. However, there isn't a test in PDOMBinding.addReference(PDOMName) to confirm that this is true.I would like to add this external references feature to support the new Qt tooling. Here is an example: class Q : public QObject { Q_OBJECT enum E { e1 }; // line a Q_ENUMS( E ) // line b };We will be submitting a QtLinkage that will store all Qt-related information in the PDOM. At "line b" we want to create a PDOMName in the QtLinkage. That name should be added as a reference to the PDOMCPPEnumeration binding created for "line a". This will make "Find References" work for "enum E" without any other changes.This will also allow the special cases in PDOM.getCrossLanguageBindings to be removed.I have a patch for this that I'll submit to Gerrit shortly.	See:Committed. Thanks!I said, committed. ;pThe test case and therefore the implementation is invalid. The test case is not changing the binding that is referenced by the name (so the name doesn't actually have a cross-linkage reference) and the test case is checking for the wrong binding after reading the name.	4.0
id=453163	REOPENED	CDT	cdt-editor	8.3.0	PC Windows 7	P3 critical	Project Inbox	2014-11-25 04:35 EST by	Yevgeny Shifrin	2016-09-17 21:00 EDT (	8 users	Hi,My eclipse hang - out of memory issue. I was not doing anything special, only opening my workspace. When this happens I have issues using jvisualvm to save thread dumps. I was able this time, only after I tried to close eclipse.2 thread dumps are attached.Eclipse version (64 bit):----------------Eclipse IDE for C/C++ DevelopersVersion: Kepler Service Release 2Build id: 20140224-0627(c) Copyright Eclipse contributors and others 2000, 2014. All rights reserved.Visiteclipse.ini:-------------startupplugins/org.eclipse.equinox.launcher_1.3.0.v20130327-1440.jar--launcher.libraryplugins/org.eclipse.equinox.launcher.win32.win32.x86_64_1.1.200.v20140116-2212-productorg.eclipse.epp.package.cpp.product--launcher.defaultActionopenFile--launcher.XXMaxPermSize256M-showsplashorg.eclipse.platform--launcher.XXMaxPermSize256m--launcher.defaultActionopenFile--launcher.appendVmargs-vmargs-Dosgi.requiredJavaVersion=1.6-Xms40m-Xmx2048mC:\Users\yevgenys>java -versionjava version "1.7.0_60"Java(TM) SE Runtime Environment (build 1.7.0_60-b19)Java HotSpot(TM) 64-Bit Server VM (build 24.60-b09, mixed mode)Exception:----------!ENTRY org.eclipse.ui 4 0 2014-11-25 11:16:36.094!MESSAGE Unhandled event loop exception!STACK 0java.lang.OutOfMemoryError: GC overhead limit exceeded at org.eclipse.swt.graphics.TextLayout.itemize(TextLayout.java:2599) at org.eclipse.swt.graphics.TextLayout.computeRuns(TextLayout.java:238) at org.eclipse.swt.graphics.TextLayout.getLineCount(TextLayout.java:1853) at org.eclipse.swt.custom.StyledTextRenderer.getTextLayout(StyledTextRenderer.java:982) at org.eclipse.swt.custom.StyledTextRenderer.getTextLayout(StyledTextRenderer.java:720) at org.eclipse.swt.custom.StyledTextRenderer.calculate(StyledTextRenderer.java:211) at org.eclipse.swt.custom.StyledTextRenderer.calculateClientArea(StyledTextRenderer.java:229) at org.eclipse.swt.custom.StyledText.calculateTopIndex(StyledText.java:1620) at org.eclipse.swt.custom.StyledText.scrollVertical(StyledText.java:7949) at org.eclipse.swt.custom.StyledText.handleVerticalScroll(StyledText.java:6331) at org.eclipse.swt.custom.StyledText$9.handleEvent(StyledText.java:5670) at org.eclipse.swt.widgets.EventTable.sendEvent(EventTable.java:84) at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1057) at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1081) at org.eclipse.swt.widgets.Widget.sendSelectionEvent(Widget.java:1098) at org.eclipse.swt.widgets.ScrollBar.wmScrollChild(ScrollBar.java:1064) at org.eclipse.swt.widgets.Scrollable.wmScroll(Scrollable.java:528) at org.eclipse.swt.widgets.Scrollable.WM_VSCROLL(Scrollable.java:334) at org.eclipse.swt.widgets.Control.windowProc(Control.java:4698) at org.eclipse.swt.widgets.Canvas.windowProc(Canvas.java:340) at org.eclipse.swt.widgets.Display.windowProc(Display.java:4977) at org.eclipse.swt.internal.win32.OS.CallWindowProcW(Native Method) at org.eclipse.swt.internal.win32.OS.CallWindowProc(OS.java:2443) at org.eclipse.swt.internal.BidiUtil.windowProc(BidiUtil.java:639) at org.eclipse.swt.internal.win32.OS.SendMessageW(Native Method) at org.eclipse.swt.internal.win32.OS.SendMessage(OS.java:3302) at org.eclipse.swt.widgets.Scrollable.wmScrollWheel(Scrollable.java:428) at org.eclipse.swt.widgets.Scrollable.WM_MOUSEWHEEL(Scrollable.java:312) at org.eclipse.swt.widgets.Control.windowProc(Control.java:4659) at org.eclipse.swt.widgets.Canvas.windowProc(Canvas.java:340) at org.eclipse.swt.widgets.Display.windowProc(Display.java:4990) at org.eclipse.swt.internal.win32.OS.CallWindowProcW(Native Method)!ENTRY org.eclipse.core.jobs 4 2 2014-11-25 11:18:54.626!MESSAGE An internal error occurred during: "Notifying selection listeners".!STACK 0java.lang.OutOfMemoryError: GC overhead limit exceeded at org.eclipse.core.internal.jobs.DeadlockDetector.reduceGraph(DeadlockDetector.java:562) at org.eclipse.core.internal.jobs.DeadlockDetector.lockWaitStop(DeadlockDetector.java:440) at org.eclipse.core.internal.jobs.LockManager.removeLockWaitThread(LockManager.java:287) at org.eclipse.core.internal.jobs.OrderedLock.updateOperationQueue(OrderedLock.java:316) at org.eclipse.core.internal.jobs.OrderedLock.doAcquire(OrderedLock.java:183) at org.eclipse.core.internal.jobs.OrderedLock.acquire(OrderedLock.java:110) at org.eclipse.cdt.internal.ui.viewsupport.SelectionListenerWithASTManager$PartListenerGroup$3.run(SelectionListenerWithASTManager.java:142) at org.eclipse.core.internal.jobs.Worker.run(Worker.java:53)	Createdthread_dump1Createdthread_dump2Seems to be related to call hierarchy functionality, once I perform it memory usage jumps from 300M to 1400M and eclipse is stuck. For some reason Java visual VM is not able to connect to eclipse. It does not show it under local as it should. Any ideas?Another exception:org.eclipse.swt.SWTException: Failed to execute runnable (java.lang.OutOfMemoryError: GC overhead limit exceeded) at org.eclipse.swt.SWT.error(SWT.java:4397) at org.eclipse.swt.SWT.error(SWT.java:4312) at org.eclipse.swt.widgets.Synchronizer.runAsyncMessages(Synchronizer.java:138) at org.eclipse.swt.widgets.Display.runAsyncMessages(Display.java:4145) at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3762) at org.eclipse.e4.ui.internal.workbench.swt.PartRenderingEngine$9.run(PartRenderingEngine.java:1113) at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:332) at org.eclipse.e4.ui.internal.workbench.swt.PartRenderingEngine.run(PartRenderingEngine.java:997) at org.eclipse.e4.ui.internal.workbench.E4Workbench.createAndRunUI(E4Workbench.java:140) at org.eclipse.ui.internal.Workbench$5.run(Workbench.java:611) at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:332) at org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:567) at org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:150) at org.eclipse.ui.internal.ide.application.IDEApplication.start(IDEApplication.java:124) at org.eclipse.equinox.internal.app.EclipseAppHandle.run(EclipseAppHandle.java:196) at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:110) at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:79) at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:354) at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:181) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) at java.lang.reflect.Method.invoke(Unknown Source) at org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:636) at org.eclipse.equinox.launcher.Main.basicRun(Main.java:591) at org.eclipse.equinox.launcher.Main.run(Main.java:1450) at org.eclipse.equinox.launcher.Main.main(Main.java:1426)Caused by: java.lang.OutOfMemoryError: GC overhead limit exceeded at org.eclipse.cdt.internal.ui.editor.SemanticHighlightingManager$HighlightedPosition.createStyleRange(SemanticHighlightingManager.java:127) at org.eclipse.cdt.internal.ui.editor.SemanticHighlightingPresenter.applyTextPresentation(SemanticHighlightingPresenter.java:551) at org.eclipse.jface.text.TextViewer.changeTextPresentation(TextViewer.java:4911) at org.eclipse.jface.text.presentation.PresentationReconciler.applyTextRegionCollection(PresentationReconciler.java:582) at org.eclipse.jface.text.presentation.PresentationReconciler.processDamage(PresentationReconciler.java:571) at org.eclipse.jface.text.presentation.PresentationReconciler.access$3(PresentationReconciler.java:567) at org.eclipse.jface.text.presentation.PresentationReconciler$InternalListener.textChanged(PresentationReconciler.java:227) at org.eclipse.jface.text.TextViewer.updateTextListeners(TextViewer.java:2830) at org.eclipse.cdt.internal.ui.editor.CSourceViewer.updateTextListeners(CSourceViewer.java:610) at org.eclipse.jface.text.TextViewer.invalidateTextPresentation(TextViewer.java:3501) at org.eclipse.jface.text.source.AnnotationPainter.invalidateTextPresentation(AnnotationPainter.java:972) at org.eclipse.jface.text.source.AnnotationPainter.updatePainting(AnnotationPainter.java:954) at org.eclipse.jface.text.source.AnnotationPainter.access$1(AnnotationPainter.java:948) at org.eclipse.jface.text.source.AnnotationPainter$1.run(AnnotationPainter.java:1087) at org.eclipse.swt.widgets.RunnableLock.run(RunnableLock.java:35) at org.eclipse.swt.widgets.Synchronizer.runAsyncMessages(Synchronizer.java:135) at org.eclipse.swt.widgets.Display.runAsyncMessages(Display.java:4145) at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3762) at org.eclipse.e4.ui.internal.workbench.swt.PartRenderingEngine$9.run(PartRenderingEngine.java:1113) at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:332) at org.eclipse.e4.ui.internal.workbench.swt.PartRenderingEngine.run(PartRenderingEngine.java:997) at org.eclipse.e4.ui.internal.workbench.E4Workbench.createAndRunUI(E4Workbench.java:140) at org.eclipse.ui.internal.Workbench$5.run(Workbench.java:611) at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:332) at org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:567) at org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:150) at org.eclipse.ui.internal.ide.application.IDEApplication.start(IDEApplication.java:124) at org.eclipse.equinox.internal.app.EclipseAppHandle.run(EclipseAppHandle.java:196) at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:110) at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:79) at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:354) at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:181)The same problem happen on CDT 8.4. I opened the same workspace with newer eclipse (8.4). The same issue as with 8.3.With 8.4 (while memory usage is ~1800M and eclipse is very low) I was able to thread dump 3 times, hopefully it will help understanding the issue. After about 5 minutes eclipse returned being responsive again.Created8.4-thread_dump1Created8.4-thread_dump2Created8.4-thread_dump3Hard to debug without knowing what's in your workspace. You wouldn't have the source to boost (or some similarly complex C++) there would you? I know this causes out of memory conditions.(In reply to Doug Schaefer from)Hi Doug,Thank you for your reply. I have C code several K files (C and H). Can thread dumps that I provided assist?Thanks,YevgenyHi guys,This issue really makes eclipse not usable. Avery restart there is some memory leak. It makes eclipse stuck. It happens after call hierarchy is used for the first time. Sometimes only for a minute and sometimes for more. Now the problem is even worse. Eclipse does not recover. It is stuck for ever :-(I provided thread dumps. Please help !!!Thanks,Yevgeny(In reply to Yevgeny Shifrin from)I think your best bet is to try to use Eclipse Memory Analyzer to narrow down what is leaking:If you are having problem getting the memory dump, you can configure the JVM to create a heap dump on "out of memory"If you could reproduce the problem with an open source code base, that could help too.For what's it's worth, after fixing a few leaks, I was able to use CDT 8.1.x and 8.2.x for weeks without having to restart. So it might be a "recent" regression.(In reply to Marc-Andre Laperle from)Hi Marc,Thank you for your reply. Unfortunately it is not open source code base. I already provided thread dumps. I think it should be enough for investigating this issue. Also it is not always memory leak (out of coverage problem), eclipse is stuck completely for long time.Thanks,Yevgeny(In reply to Yevgeny Shifrin from)I meant "out of memory" not "out of coverage". :-)I had a brief look at the thread dumps.It looks like in each case, there are 20-40 CReconciler threads running. They are contending for access to the index (most of them are blocked in Database.getChunk(), waiting to get access to the lock that protects Database.fCache).Meanwhile, in each case there is a worker thread (with no descriptive name) also blocked in Database.getChunk(). At the top of its stack is SelectionListenerWithASTManager. A look through the codebase of what uses that suggests that it's likely the "mark occurrences" feature.Can anyone comment on whether it is normal to have 20-40 CReconciler threads running at the same time? If not, that's likely to be the problem.Meanwhile, a thing to try is to disable "mark occurrences" (in Preferences -> C/C++ -> Editor -> Mark Occurrences), and see if that mitigates the problem.(In reply to Nathan Ridge from)Hi Nathan,Thank you very much for looking into it :-) I will try your suggestions. It generally happens after eclipse restart and it is somehow related to running call hierarchy (opening several levels in the call hierarchy view). Thanks,YevgenyDisabling "mark occurrences" did not help. It is related somehow to call hierarchy that is called for the first time (after eclipse is started). Memory usage jumps to almost 2.5G. In most cases, it is ok after 20-30 seconds. In some rare cases it causes eclipse to stuck completely (this is why I opened this ticket). During this time mouse pointer "flickers"How many editor tabs do you have open when this happens?(In reply to Nathan Ridge from)Hi,This issue happened when I had about 50-100 editors opened, and also when I had only several editors opened.Every eclipse restart when I run the first call hierarchy with one editor opened, there is a memory issue for at least 10-20 seconds.Thanks,YevgenyYevgeny, do you have any other plugins installed beside CDT? I've seen 2 plugins before that forced all editor to load at different points that caused huge memory usage and a large number of reconciler threads. The two plugins in questions were the Vrapper plugin and Eclipse Checkstyle. Both were fixed after the issue was reported. But I wonder if another plugin is going something like that.Original Eclipse report:(In reply to Marc-Andre Laperle from)Hi Marc,Thank you for your input.I have the following plugins installed:* PyDev* AnyEdit* MULTI - Green Hills compiler support* start explorerI will check if this issue is reproduced on eclipse CDT without additional plugins installed and update.Thanks,YevgenyI suspect AnyEdit tool, I am still checking it.(In reply to Yevgeny Shifrin from)Hi,I think it is a problem caused by AnyEdit tool. I uninstalled it and the problem is not reproduced. I tried sending an email to developer of this tool, unfortunately there is a problem with his mail.Thanks,YevgenyAfter month of working without anyedit tool, I am sure that it caused the problem. Unfortunately I am not able to contact by email its developer Andrey Loskutov. The 2 email adresses that I found, are not active.Thanks,Yevgeny(In reply to Yevgeny Shifrin from)This Andrey Loskutov?(In reply to Marc-Andre Laperle from)I guess so ;)I send him an email but got delivery failure notifocation.(In reply to Yevgeny Shifrin from)I think this is the place where you could report the issue:(In reply to Yevgeny Shifrin from)Yes and no. Sure, AnyEdit has code to restore editors, and in this bug this is the "trigger" for GC overhead limit errors but this code exists for purpose and I do not plan to change it. The memory is used/requested by CDT, not by AnyEdit. Don't shoot the messenger if CDT has memory issues :-)Therefore I would say this is a CDT scalability issue and should be fixed in CDT. CDT is not alone in IDE and should not assume that unlimited resources were available :-) Obviously, this bug will appear again as soon as someone (manually or automated) decides to open lot of CDT editors.The right solution would be (for example) to avoid using unlimited number of threads (e.g. allow only N CReconciler threads via fixed thread pool or something similar, where N <= CPU cores). Also one should investigate why CDT uses so much memory and how it can offload some of it (e.g sharing some common data structures, use better serializer etc)? I'm unaware about similar reports from JDT and we can be sure that there are much more JDT users so that the probability that this issue with too many editors would appear in JDT is much higher.So just saying "3rd party plugins" are guilty or that one should not open 100 CDT editors is not the right solution for this bug => reopening.There is a main address (see my bugzilla account) which is active since ever and where I even found a mail from you from year 2011. Probably your current mail account is blacklisted somewhere.I tried sending you email on April 2015 and got "Delivery Status Notification (Failure)" :-(	30.0
id=348018	REOPENED	CDT	cdt-parser	8.0	PC Windows XP	P3 normal	Project Inbox	2011-06-01 16:52 EDT by	John Liu	2011-06-17 13:00 EDT (	3 users	In the following example I can't navigate from the call to matmul to the definition. The definition of matmul is not highlighted as a function in the editor.If I remove the 'restrict' keywords from the parameters then it works. #define N 2500typedef double matrix[N][N];matrix A, B, C;extern "C" inline double fma(double a1, double m1, double m2) { return a1 + m1 * m2 ;}extern "C" void matmul(matrix& restrict a, matrix& restrict b, matrix& restrict c) { for (int i=0; i < N; i++) for (int j=0; j < N; j++) for (int k=0; k < N; k++) c[i][j] += a[i][k]*b[k][j];}extern "C" void initialize(matrix mat, int seed, int mod) { for (int i=0; i < N; i++) for (int j=0; j < N; j++) mat[i][j] = (double)((seed + N*i + j) % mod);}int main(int argc, char* argv[]) { initialize(A, 5, 19);// cout << A[0][0] << endl; initialize(B, 7, 23);// cout << B[0][0] << endl; matmul(A, B, C);// cout << C[0][0] << endl;}	There is a syntax error, 'restrict' is not a keyword in c++. The parser accepts the gnu-extension '__restrict'. In case your c++-compiler supports 'restrict' you can either provide a macro definition '-Drestrict=__restrict', or configure it as a keyword via an IScannerExtensionConfiguration.I think this is still a bug against the XLC++ parser. The XLC++ compiler supports a command line option that turns on the 'restrict' keyword for C++. CDT supports this when you have the XLC++ parser installed, there is a preference page "XL C/C++ language options" that lets you turn on the restrict keyword for XLC++. However this doesn't seem to be working.I've reopened the bug and refiled it against the XLC++ parser.It might also be a good idea to test all the language options to see if they are working.	2.0
id=343479	REOPENED	CDT	cdt-parser	8.0	All All	P3 normal	Project Inbox	2011-04-21 02:47 EDT by	Sergey Prigogin	2013-12-15 15:39 EST (	4 users	The following codevoid test() { switch (0) default: if (true) ;}gets parsed into:ICPPASTTranslationUnit ICPPASTFunctionDefinition: test ICPPASTSimpleDeclSpecifier: void ICPPASTFunctionDeclarator IASTName: test IASTCompoundStatement ICPPASTSwitchStatement ICPPASTLiteralExpression: 0 IASTDefaultStatement ICPPASTIfStatement ICPPASTLiteralExpression: true IASTNullStatementICPPASTIfStatement, which should be a child of IASTDefaultStatement, is instead considered a child of the function body.The code in this example may look exotic, but it is similar to the code used inside googletest () assertions.	Similar to. I will follow the same strategy as used for the fix of, i.e. an artificial compound-statement is inserted into the AST.The more correct fix would make the statement following the case/default label part of the IASTCaseStatement/IASTDefaultStatement. However, I don't think weshould make this kind of change after the API has been frozen. Do you agree with this solution?For reference, here is the relevant part of the grammar: labeled-statement: attribute-specifier-seqopt identifier : statement attribute-specifier-seqopt case constant-expression : statement attribute-specifier-seqopt default : statementFixed in 8.0 > 20110421.*** cdt cvs genie on behalf of mschorn ***: Switch statement without compound statement.[*] AbstractGNUSourceCodeParser.java 1.162(In reply to)This approach is problematic since it is likely to confuse code formatter. Code formatter will expect curly braces that are not present in the code. In fact, the AST anomaly was discovered while debugging code formatter.I would like to add that the issue seems serious enough to warrant an exemption from the API freeze.ICPPASTIfStatement didn't get reparented as a result of the parser change. The new structure is:ICPPASTTranslationUnit ICPPASTFunctionDefinition: test ICPPASTSimpleDeclSpecifier: void ICPPASTFunctionDeclarator IASTName: test IASTCompoundStatement ICPPASTSwitchStatement ICPPASTLiteralExpression: 0 IASTCompoundStatement IASTDefaultStatement ICPPASTIfStatement ICPPASTLiteralExpression: true IASTNullStatementI'm going to revert the change.*** cdt cvs genie on behalf of sprigogin ***. Reverted previous change.[*] AbstractGNUSourceCodeParser.java 1.163*** cdt cvs genie on behalf of mschorn ***: Switch statement without compound statement.[*] AbstractGNUSourceCodeParser.java 1.164(In reply to)Thx, I have completed the change. With that we have at least the same solutionfor 'switch(cond) case ...' and 'switch(cond) default ...'.(In reply to)I would not worry a lot if we'd change the AST for the special situation, only.However, a correct modelling requires to nest subsequent case label statementsinto each other and this change has the potential to break clients (e.g. flowanalysis? formatter?).I am conservative about it and will make the change only after 8.0, however youand the other committers can make a different decision. switch(x) { case 1: case 2: x= 2; break; }Current AST: switch-stmt compound-stmt case-stmt case-stmt assignment break-stmtFuture AST: switch-stmt compound-stmt case-stmt case-stmt assignment break-stmt(In reply to)Thanks for the fix. It was sufficient for the code formatter. We should keep the bug open and rearrange the AST after 8.0.(In reply to Markus Schorn from)Is there a reason the AST cannot be switch-stmt compound-stmt case-stmt case-stmt assignment break-stmtHere a case-stmt would act as a compound statement, with 0 or more statement children. I think this structure reflects the code most closely, and is intuitive for things like the formatter to deal with.	11.0
id=351659	REOPENED	CDT	cdt-indexer	8.0	All All	P3 normal	Project Inbox	2011-07-10 12:39 EDT by	Volker Diesel	2017-01-13 02:39 EST (	16 users	Build Identifier: 201106081058CDT's C/C++ indexer should use multiple threads to speedup indexing. Modern CPUs tend to have more cores running at constant or even lower frequency, therefore indexing will never become faster (maybe even slower) if it is single threaded.A first idea is to start not only one PDOMIndexerJob, but a configurable number of jobs and to have a fixed mapping of one project to one of these jobs and to have one task queue per indexer job (instead of one global task queue) and let the jobs pick their next task from the appropriate task queue.This would at least speedup indexing of multiple C++ projects.Second idea is to prepare the parsing layer before doing the actual parse call. If a bulk of files needs to be reindexed, the parsing layer should first be informed about these files and their scanner configuration. With that information, the parsing layer could start parsing in background with multiple threads and keep the ASTs until the indexer requests them.Comments and further ideas are welcome :-)Reproducible: AlwaysSteps to Reproduce:1. Index large number of large C++ projects :-)	(In reply to)Sounds like a reasonable approach to me. You need to watch out for dependent projects though, where the order in which they are indexed is important. Projects that relate to each other via project references should probably be indexed in the same thread.When parsing a translation unit we reuse information about headers that have been parsed before. Therefore a simple parallelization is not possible here.There are other options, therefore we should base what we do on some numbers. Where do we spend CPU-time? How much time do we need for read/write operations on the database.Other options:(1) Run preprocessor in parallel to the syntax parser.(2) Run name resolution (including template instantiation) in parallel to the syntax parser of the next translation unit.(3) Run syntax parser on multiple translation-units in parallel.(4) Run name resolution of multiple translation-units in parallel. There are some restrictions on when we can do that, however that should be managable.Note, that we'll still have the potential bottle-neck of writing to the database in a single thread.I don't expect a lot of problems in implementing (1) and (2). It can at least put some load on 3 cores per project.Also (3) would not be hard to implement, however I expect that we spend more CPU time on name-resolution than on the syntax parsing. Doing (3) may not have an effect without doing (4). An implementation for (4) will be more challenging.(In reply to)Hi Markus.Thanks for your reply.Let's start with idea one... parallel indexing of multiple projects.I didn't get the point about project references and why dependent projects must be indexed in appropriate order. My (naive) understanding was that the index only contains information about source and object files, no matter in what project these files are located and wether there are dependencies to other projects. Can you please explain in more detail, why dependent projects must be indexed in a specific order. And if this holds true... Does this mean that wrong project dependencies will result in wrong/corrupted indexes? And btw... how about cyclic project dependencies?Thanks + kind regards,Volker(In reply to)Yes, lets do that.In case you have a project 'B' that depends on project 'A' and sources in 'B' that includes headers from 'A', then the indexer will read the information about the header from the index of project 'A' rather than parsing the header again. For that to work project 'A' needs to be indexed before project 'B'.Wrong or cyclic dependencies will at the worst cause information to be duplicated in the indexes of multiple projects.(In reply to)Hi Markus.Thanks for the prompt reply.Okay, that makes things a bit more complicated, but I think it's still managable.First...If I got you right and if I didn't miss something, dependent projects don't need to be indexed in one and the same thread necessarily.In your example, thread of indexer of project B must wait for thread of indexer of project A to finish. I think this is an important difference with regards to parallelization.Consider a more realistic situation:project Aproject B, C, D, E --> depend on Aproject F --> depends on B, Cproject G --> depends on B, D, EBattle plan:1) run indexer on A2) run indexers on B, C, D, E in parallel3) as soon as B, C is finished run indexer on F in parallel4) as soon as B, D, E is finished run indexer on G in parallelIf this is right, I would suggest associating one indexer job to one project and model these jobs in a graph-like structure, with each job beeing blocked by running parent jobs.Any objections or other ideas?Second...Integration of parallel indexing into the huge eclipse world.1) Adding, deleting, closing(?) projects must be handled2) Changing project dependencies must be handled3) Stoping one ore more jobs must stop dependend jobs as wellWhat else?Thanks + kind regards,Volker(In reply to)I agree.You are right.With the plan you'll win the battle.I can think of 4) New jobs (e.g. because user saved a file) need to be merged into the pending jobs.(In reply to)Hi Markus,thanks for your reply.Good point! That made me think for a moment :-)Let's assume project A with file A.h and project B (depending on A) with B.h (which #include's A.h) and let's assume I do a full indexing and meanwhile edit A.h and save my changes every few seconds.1) Current implementationI assume that A.h and B.h are added to the job queue again and again in appropriate order (first A.h and then B.h). After a moment, my index is up to date. Right?2) Future parallel implementationNow, we have two different cases2.1) Indexer A is still runningA.h will be added to indexer job A again and again, B.h will be added to indexer job B again and again. Indexer A will keep running and running and indexer B will never get started, because it will be waiting for A. Would that be acceptable?Well, from my point of view it would, for two reasons...First: If I don't like that behaviour, I could set number of parallel queues to "1" in indexer configuration and would be back at the old behaviour.Second: As long as I edit project A, I don't care much about the index of project B.How do you think about that?2.2) Indexer A has finished and indexer B is runningI modify A.h and it will be added to indexer job A and B.h will be added to indexer job B. Indexer A must be restarted and therefore indexer B must be stopped. And now we are back at 2.1)Right?So my conclusion is...Before a new task is put into one of the indexer jobs, each and every indexer job has to be paused first, and after all new jobs are in, the entire job tree must be started again, beginning with the most basic project (the root of the job tree).Right?BTW... cyclic dependencies need to be broken anyway, otherwise it won't work. But that's no difference to current implementation.Comments welcome :-)Kind regards,VolkerHi, CDT people.Coming back to:!!!!!!!!!!!!!!!!!!!!!!!NO, BETTER NOT!!!!!!!!!!!!!!!!!!!!!!!I tried it in our real-life project...171 large C++ projects in workspace and we used to have no project references (no project had references to other projects). Full C/C++ indexing took about three hours (by far too long... for comparison... scratch make including archiving and linking takes about 40 minutes).I thought it was a good idea to write a plugin that generates appropriate project references according to our build descriptions, hoping that this would speed up CDT indexing... And I did....Well, writing that plugin might have been a good idea, but running CDT indexer with approriate project references in place wasn't.I started a full indexer job (with appropriate project references) today at 10:50am and canceled it right now at 9:30pm, after it had managed to index one percent of our sources.It seems to me that parsing files and building the AST is at least 1000 times faster than looking up references in the index (at least in our real-life project).Could anyone please comment on that?Thanks + kind regardsVolker(In reply to)When you have project references, then the index has to span multiple databases (one for each project). This makes access to the index slower. I assume that this is the cause of the extreme slowdown.Not watching out for project references when parallelizing the indexing does not solve this problem, though. Rather than that we need to consider to index each project on its own, regardless of project references. By your measurements, this would speed up the indexing and it would make it easier to parallelize the indexer. The drawback is, that information about headers included from multiple projects gets duplicated.(In reply to)Hi Markus.Thanks for your reply.First of all the root cause should be found instead of working around the performance issues. Why is looking up references in other indexes so much slower than parsing the files again and how can it be made faster. I did a simple test and added debug output before and after the 'getASTTranslationUnit' call. It turned out that this call takes between one and three seconds in most cases, and then it takes ages (sometimes 20-30 seconds) until 'getASTTranslationUnit' is called again. I am currently doing some analysis and will be coming back to that point later (maybe I will open an additional bug for that issue).Regards,Volker(In reply to)In both cases things are looked up in the index. Without project references the index consists of a single database (the one of the project), whereas with project preferences the index consists of a bunch of databases. Therefore my top candidates causing the slow-down are:* The layer that combines the databases is inefficient, or* The number of entities to be considered during overload resolution increases, this may slow down the parser. This may especially hurt when there are a lot of overloaded operators. You can try to turn off indexing of implicit references and see whether this makes a great difference.CreatedProfiler data without project referencesCreatedProfiler data with project referencesCreatedComparison between runs without and with project referencesI reduced number of projects (and thereby number of project references) from 170 to 20 and then...1) ran full indexing without project references -> 22min13sec2) ran full indexer WITH project references -> 44min24secIt seems that some code is not scaling linear with number of projects / number of references. With 170 projects and much more references, indexing is not only two times slower, but hundred or thousand times slower.3) I ran both tests again with profiling enabled. It seems that the entire time difference results from AST visiting (and actions therein).See attached profiler data and diff file.Hi.I implemented a first version of indexer parallelization on project level (see attached patch, based on origin/master 0b330a4c9e) and tested it with our 170 C++ projects on a 16 core machine. Full indexing time is now down from ~3hrs to ~40mins. This is factor 4 1/2 which means that parallelization does not really scale well with number of cores. I tried some things but did not yet find out why it scales so bad.I encountered another severe issue when running parallel indexer with project references configured. It turned out that project references kill parallelization completely, because all parallel jobs are synchronizing on WritablePDOM's write lock.I stopped at that point (actually I did not spend much effort in honouring project references for indexing, since parallelization is currently not usable anyway when there are many project references in place).To me it seems the entire indexer infrastructure is currently not really ready for mutithreading and that a larger refactoring will be nescessary.Could some of you please review my changes and comment on how to continue with that issue?Thanks + kind regards,VolkerCreatedFirst version of parallel indexerHi.Coming back to the issue mentioned in...I found three major issues, why parallel indexing on project level does not scale with number of CPU cores / parallel jobs and resolved two of them.First of all... I am talking about parallel indexing WITHOUT any references between projects. Parallel indexing WITH project references is still a nightmare :-(Reason 1: Lock contention in class ChunkCacheI resolved this by introducing multiple cache slots and assigning chunks to these slots round-robin. When chunks are added to or removed from ChunkCache, only the slot associated with that chunk needs to be locked, not the entire cache.This brought a 25% speedup during parallel indexing (full-indexing time for our 170 C++ projects decreased from ~40mins to ~30mins).Reason 2: Lock contention in class DatabaseI resolved this by not locking Database chunk operations on global ChunkCache, but by introducing a lock per Database.This brought another 33% speedup during parallel indexing (full-indexing time for our 170 C++ projects decreased from ~30mins to ~20mins)I don't think, that these changes introduce any new race conditions, but it would be great, if someone could review my changes and comment on them.Reason 3: Java garbage collectionYes, I know what kind of discussion I am starting here... Anyway...The only thing that prevents parallel indexer from scaling linear with number of CPU cores / indexer jobs is java garbage collection. And the only solution I see is pooling and reusing objects as much as possible instead of creating and destroying them over and over again. In fact, if garbage collection would not happen, then parallel indexer would scale almost linear with number of jobs / CPU cores aleady. So, at the end of the day.. I started with 3hrs full indexing time for our 170 C++ projects and ended at ~20mins with the attached patch.Would be great to have this at least in next CDT release (and maybe also in one of the next updates for CDT 8).How to proceed?Open topics?Objections?Kind regardsVolkerCreatedParallel indexer with lock contention reduced to almost zero(In reply to)Do you really have 170 projects without dependencies between them?(In reply to)Of course, our 170 projects have a lot of dependencies, but as already mentioned in:!!!!!!!!!!!!!!!!!!!!!!!NO, BETTER NOT!!!!!!!!!!!!!!!!!!!!!!!If I set up my workspace with 170 C++ projects and appropriate project dependencies, C++ indexing takes aprox. 1000 times longer than without dependencies. As already mentioned before, it normaly takes about 3hrs for full indexing (without project dependencies) and WITH project dependencies, I canceled full indexing after 10hrs and after indexer had managed to index approx. 1% of our sources.So... We definitely have project dependencies, but C++ indexer is completely unusable when configuring these dependencies.(In reply to)I have a gut feeling that in spite of the great performance improvements you were able to achieve with projects without dependencies, inter-project parallelization is a dead-end approach. Parallelization between files, although harder to implement, is much more promising than the inter-project one and would benefit everybody, not just those who use a lot of projects.My 2c.(In reply to)Hi Sergey.Sorry, but I don't share your opinion for several reasons.First, I question that it is possible to utilize a 4 core machine 100% with parallelization on parser level only (and I consider anything else than 100% utilization a waste of resources). And normal desktop PCs will probably have much more than 4 cores in two or three years. So I think, paralleliziation ONLY on parser level is the dead end (even without taking CDT code complexity into account).Second, I wonder for whom CDT is built? Probably not for "hello world" style projects. Hello world projects probably don't have performance issues with CDT indexing, right? And large projects have a lot of subcomponents (and hence a lot of potential CDT projects). How does a larger C++ project look like? You probably have some executables and a bunch of shared libraries, and at least each shared library must be in its own CDT project, because in real life, each shared library will have it's own set of #define's, that is different from any other shared library (at least a #define for DLL symbol import/export will be different in each shared library project). So I think, non-hello-world C++ projects will naturally consist of a lot of CDT projects.This leads me to point three (another CDT dead end)...If projects differ in only one single #define (and real life projects do, as mentioned above), it doesn't make much sense to honour project references during indexing, because reuse of indexing information across projects will be almost zero. Not to mention that it is a thousand times slower today (that could probably be fixed). But it simply doesn't make much sense in real C++ projects and it currently prevents inter-project parallelization, when project references are configured.And last but not least, why not have both? Why not have inter-project parallelization AND a reasonable parallelization on parser level (reasonable with regards to code complexity)? Is there anything wrong with inter-project parallelization?At least it has been easy to achive with some hundred lines of code, and if your review my changes, you will find out, that most of my code has not even been invented from scratch but simply reorganized / moved from one class to another.But maybe this is more a topic for cdt-dev mailing list. I you don't mind, I would like to post this discussion there.Kind regards,Volker(In reply to)This confuses me.Let's assume for a moment there are no dependency cycles. This means in the worst case that for N projects, at worst you will haveProject N-1 depends on N-2, which depends on N-3 ... depends on Project 0That means that at worst, you cannot parallelize any indexing at all, and you index each project sequentially, which ought to be the same as the current behaviour without any of your patches applied. There'd be some additional overhead to look at those dependencies, but it should not be a great deal and it would scale linearly with the number of projects.There might be some confusion between what you think of as a project dependency, and what some of the rest of us think of as a dependency. I think of project A depending on B if in A's project properties, B is listed as a project that A depends on. This is a user configured relationship that is stored, and not computed automatically in any way. Resolving whether an arbitrary project X depends on Y in this case is a simple matter of looking ito X's properties and seeing if Y is listed in the dependencies. Hence, it's not a huge amount of overhead to do in and of itself.If you are talking about trying to automatically resolve whether the code in project A actually calls/includes code in project B, that I can see taking a huge amount of time that would make the entire exercise impractical.(In reply to)Hi Chris.Let me make this a bit more clear...There are three different things with regards to project references (and yes, I mean project references between eclipse projects, NOT references between source files).First, take CDT8 as it was shipped with Indigo, import 170 C++ projects, configure many references between these projects and try to run a full indexer... But be careful... You will need much patience and a lot of coffee. It takes ages!Remove the dependencies, run full indexer again and it is faster by a factor of 1000.This is a bug in official CDT8 and has nothing to do with parallelization.Second (and disregarding the above bug), if you try to run indexer in parallel on projects with many references, you will fail, because all parallel jobs synchronize on write lock of PDOM index, which spans over many -if not all- project PDOMs.Third, I do not see much reason why indexer should honour project references at all. As already explained in my previous comment, in real life almost all projects have different sets of #define's and therefore reuse of indexer information across projects is minimal anyway.Kind regards,Volker(In reply to)Hmm... what do your dependencies look like? Are there any cycles in the dependency graph? Otherwise I can't imagine why that ought to take 1000 times faster, since as I said, without cycles, it should behave close to the same as without dependencies. This is purely conjecture, but if there were cycles in the graph, then perhaps the indexer is reindexing your projects over and over again as a result of the changes it generates with each successive indexing pass?I don't dispute that there is a bottle neck right now in some parts of the index code, which you've outlined. Even still though, without resolving that bottleneck, it should still be faster than doing it sequentially, as you'll at least parallelize the parsing,Well as Markus stated, we use the index of the other project to help speed up indexing by getting information out of it rather than reparsing headers that project provides. In theory that speeds things up a lot.(In reply to)Hi Chris. Thanks for your reply.I did not explicitly check our dependencies for cycles, but I am 100% sure there are cycles in our project depencencies. I asked Markus Schorn about cyclic depencencies inand he replied:Is that right? Or will cyclic dependencies lead to cyclic indexing, as you suspect?As already mentioned earlier in, my impression is, that some indexer code is not scaling linear with number of projects / project references.With 170 projects, full indexing takes three hours WITHOUT project references and 10 hours for the first percent of full indexing WITH project references (after ten hours and one percent progress, I cancelled the test).I reduced workspace size from 170 to 20 projects (and consequently less project references). Now the difference was 20 mins WITHOUT project references compared to 40 mins WITH project references (official CDT8 without any parallel stuff).See also profiler data attached to this bugzilla.That's what I had hoped for, but it isn't that way:-(You can try it with my attached patch. When complex project references are in place, parallel indexing is basically single-threaded. Whenever you stop in debugger, you see 1 of N jobs parsing and N - 1 jobs waiting on WritablePDOM's write lock.Maybe, I still didn't get the point...1) Consider project P1 with a set of include pathes I1 and a set of #defines D1.2) Consider project P2 with a set of include pathes I2 and a set of #defines D23) Consider P2 has a reference to P1.How can you reuse indexing information of P1 while indexing P2, if either I1 != I2 or D1 != D2?As far as I understand, indexer of P2 will not be able to reuse any information of P1's indexer.Am I right or did I miss something?Thanks + kind regards.Volker(In reply to)Better parallelization is achieved when work units are smaller and therefore there are more of them. 170 project-level work units is enough for efficient parallelization when there are no dependencies between them. With dependencies between projects 170 may no longer be a big enough number for efficient parallelization. Parallelization at file level would benefit from thousands of work units. Even with constraints due to dependencies between files, there will be more parallelizable work units than in the case of projects.The above assertion is based on the assumption that writing to the index database constitutes a small fraction of indexing time. If this assumption is incorrect writing to the database will create be a bottleneck precluding efficient parallelization.CDT projects used for large bodies of code are usually monolithic, not consisting of many small projects. This tendency reflects the fact that given a set of complex makefiles it's easier to create a single project out of them than many small projects.At Google monolithic projects are used to work with one of the largest codebases in the industry.Having both is fine, but intra-project parallelization would likely achieve larger performance gains and would benefit more users.Absolutely.I created a third patch that makes parallel indexing more convenient (e.g. one job progress for the entire jobs queue), fixes bugs in cancel handling and job scheduling and adds some beautification to indexer preferences UI.Would be great if some of you would review and comment the stuff.I will post a message on cdt-dev for fueling further discussion.CreatedBug fixes, more convinient progess handling, UI beautification(In reply to)Hi Sergey. Thanks for your reply.Okay, now I got you... You hav been talking about parallelization on file level while I have been talking about parallelization on intra-parser level).I already asked about parallelization on file level (see), but there was no reply.Discussion instead went on to parallelization on parser level (see).Well, that's one point of view. In our project, we have a different point of view. We are using our company's lagacy make infrastructure... no make/gmake files, etc... one may question if that is smart, but at the end of the day, that's the way it is. And it has the advantage of beeing able to model fine grained projects with fine grained project dependencies. And I am talking about "one of the largest code bases in industry" as well :-)I don't think CDT should be developed only for monolithic projects, but should also support fine grained project configurations with many fine grained dependencies.And I wonder how you can manage situations, where library A needs to be build with "#define X 1" and library B with "#define X 0"?How do you model that situation in one monolithic project, that contains both library A and library B? I don't see how you can get consistent indexer information in your monolithic environment.Maybe we are doing something the wrong way. Could we achive a consistent monolithic configuration in our environment as well?Thanks + kind regards.VolkerWe are about to change the behavior of the indexer with respect to dependent projects (see), which opens up the path for parallelizing the indexer accross projects.We have changed the behavior of the indexer, such that indexing of projects is entirely independent. This makes parallelization of the indexer accross projects easier.Volker, if you are willing to port your patch, such that it applies on the master branch I'll work on getting it committed.Createdgit patch for this bug based on CDT masterI created and attached a patch for indexer parallelization across projects. Please let me know if you encounter any build or runtime issues.***has been marked as a duplicate of this bug. ***(In reply to)Yes, parallelization on file level is desperately needed in Google. I agree there is no easy solution for file level parallelization, but solving hard problem is more fun.Hi all,If this enhancement already available in a given CDT 8.x version ? If not, are there any plans to deliver it ?Sorry by advance if the answer is known by all (but me :-(), I'm trying to catch this thread and the final status is not clear to me.Regards, Jerome(In reply to)AFAIN nobody is working on indexer parallelization at the moment.Why this work stopped? It is a really useful feature!I experienced CDT with chromium, webkit which contains many many files, the single thread index procedure takes more than 4 hours on my 4 core 8 threads CPU, and during that UI have unsmooth/less response...CDT is really good, but that maybe the only reason I give up it.thanks!PanHi,Has the investigation of this proble, stopped?Steve: Do you know anything about this work?Thanks MartinFYI, Eclipse CDT Neon is still using single-threaded indexing. It takes a very long time to index my 5 projects one at a time, with 3 VM cores sitting idle.	40.0
id=463563	REOPENED	CDT	cdt-parser	Next	PC Linux	P3 normal	Project Inbox	2015-03-31 05:36 EDT by	Dongseong Hwang	2015-03-31 12:23 EDT (	2 users	Createdcore dumpWhen indexing large project, Eclipse crash on Ubuntu 14.10 with both oracle jdk 1.8, openjdk 1.7 and openjdk 1.8Crash log in stdout;java.lang.InterruptedException at java.lang.Object.wait(Native Method) at org.eclipse.core.internal.jobs.Semaphore.acquire(Semaphore.java:39) at org.eclipse.core.internal.jobs.JobManager.join(JobManager.java:861) at org.eclipse.core.internal.jobs.InternalJob.join(InternalJob.java:384) at org.eclipse.core.runtime.jobs.Job.join(Job.java:420) at org.eclipse.linuxtools.internal.cdt.libhover.LibHover.getFunctionInfo(LibHover.java:388) at org.eclipse.cdt.internal.ui.text.CHelpSettings.getFunctionInfo(CHelpSettings.java:121) at org.eclipse.cdt.internal.ui.CHelpProviderManager.getFunctionInfo(CHelpProviderManager.java:163) at org.eclipse.cdt.internal.ui.text.c.hover.CDocHover.getHoverInfo(CDocHover.java:81) at org.eclipse.cdt.internal.ui.text.c.hover.AbstractCEditorTextHover.getHoverInfo2(AbstractCEditorTextHover.java:84) at org.eclipse.cdt.internal.ui.text.c.hover.BestMatchHover.getHoverInfo2(BestMatchHover.java:144) at org.eclipse.cdt.internal.ui.text.c.hover.CEditorTextHoverProxy.getHoverInfo2(CEditorTextHoverProxy.java:84) at org.eclipse.jface.text.TextViewerHoverManager$4.run(TextViewerHoverManager.java:166)## A fatal error has been detected by the Java Runtime Environment:## SIGSEGV (0xb) at pc=0x00007f7660f8835c, pid=19408, tid=140145627846400## JRE version: Java(TM) SE Runtime Environment (8.0_40-b25) (build 1.8.0_40-b25)# Java VM: Java HotSpot(TM) 64-Bit Server VM (25.40-b25 mixed mode linux-amd64 compressed oops)# Problematic frame:# J 29151 C2 org.eclipse.cdt.internal.core.dom.parser.cpp.CPPASTDeclarator.accept(Lorg/eclipse/cdt/core/dom/ast/ASTVisitor;)Z (254 bytes) @ 0x00007f7660f8835c [0x00007f7660f87660+0xcfc]Refer to dump file for more detail	Looks like a bug in Java. Can you try the workaround mentioned in?thx for workaround*** This bug has been marked as a duplicate of***Createdanother crashAfter -XX:-UseCompressedOops to eclipse.ini workaround, another reason still causes crash[libjvm.so+0x976fdd] oopDesc* PSPromotionManager::copy_to_survivor_space<false>(oopDesc*)+0x4d[libjvm.so+0x976978] PSPromotionManager::drain_stacks_depth(bool)+0x808[libjvm.so+0x3f8c4e] CardTableExtension::scavenge_contents_parallel(ObjectStartArray*, MutableSpace*, HeapWord*, PSPromotionManager*, unsigned int, unsigned int)+0xafe[libjvm.so+0x97a25b] OldToYoungRootsTask::do_it(GCTaskManager*, unsigned int)+0x4b[libjvm.so+0x5cabaf] GCTaskThread::run()+0x12f[libjvm.so+0x910ee8] java_start(Thread*)+0x108refer to attached file for more detailreopenDo you have sample code that causes the crash that could be attached? In the end, it's probably better to open a bug against openjdk though.	5.0
id=490239	REOPENED	CDT	cdt-parser	8.8.1	PC Windows 7	P3 normal	Project Inbox	2016-03-23 01:45 EDT by	Thomas McLeod	2017-01-27 01:07 EST (	3 users	The pattern of the false positive is as follows, but this code itself does not appear to reproduce the error. Unfortunately, after many attempts, I could not devise a minimum example. The actually example in my code involves many classes and headers - too much to paste in a bug report. But it does correctly compile and it does give me a false positive.This is bug was just introduced in Mars.2 (not present in Mars.1). template <typename ...Ts> struct P { };struct S{ template <typename ...Ts> void f(P<Ts...>* pReceiver) { }};int main(){ S s; P<int, int, int> p; s.f(&p); // <== underline f, error below return 0;}Invalid arguments 'Candidates are:void f(? *)'	(In reply to Thomas McLeod from)Unfortunately, there isn't much we can do without a testcase that reprodces the problem. One tip for preparing a reduced testcase is not to try and collapse everything into one cpp file, but into one cpp file and one header. Because headers are processed slightly differently than cpp files, sometimes a bug requires the presence of a header to reproduce.If you're really not having any luck preparing a reduced testcase, but you're able to share the code that does demonstrate the problem, you can also zip up and attach an entire project.Thank you. I was actually wondering about this, because pasting declarations from the header into the cpp made the error disappear.I'm not having any success in producing a minimal test case. It appears that there is some subtle interaction with the project, which is immense (about 1000 source files). It's disappointing when upgrading to a service release introduces new bugs.We generally close bug reports as INVALID if the behaviour being described isn't actually a bug. In this case, it is a bug, we just don't have a testcase for it, but perhaps at some point we will, so let's keep the bug report open.(In reply to Thomas McLeod from)I agree. Unfortunately, making any change comes with the risk of introducing a regression. The alternative is not making changes at all (in which case, there's no point in having a service release to begin with).I do try to fix regressions (in the parts of the CDT code that I'm familiar with) quickly. I just need a testcase that reproduces the problem to fix it.Thomas, are you still experiencing this problem with Neon.2? A lot of bugs have been fixed between Mars.2 and Neon.2.I haven't installed Neon.2 yet. This particular bug was not fixed in Neon.1. I'll report back.	6.0
id=187576	REOPENED	Target Management	RSE	2.0	PC Windows XP	P3 normal	David Dykstal	2007-05-17 11:46 EDT by	Rupen Mardirossian	2010-05-26 23:03 EDT (	2 users	The first tutorial of the RSE developers guide, labelled "Creating a Remote Resource Property Page" is out of date. Looking at the first step in the tutorial and clicking on the link " create or prepare a plugin project" will direct the user to a page with instructions that do not comply with eclipse3.3M7.-----------Enter bugs above this line-----------TM 2.0M7 Testinginstallation : eclipse-SDK-3.3M7 RSE install : RSE-SDK-I20070517-0600java.runtime : Sun 1.5.0_06-b05os.name: : Windows XP 5.1, Service Pack 2------------------------------------------------	Doc-only fix, can be done late in the game.Updated the screen shots, the steps, and the program text for creating the sample plugin found in the tutorials so that it correctly uses the Eclipse 3.3 new plugin wizard.Some quick notes from running through it.1. Dependencies is missing org.eclipse.rse.core.2. The tutorials assume RSESamplesPlugin.java is in a package called "samples" not "rsesamples". The code in org.eclipse.rse.examples.tutorial also uses the "samples" package.I will reopen this one because Kevin has tested it and seems to found that a dependency is needed in order to complete the tutorials which is not stated in the "create or prepare a plugin project" link.Please provide more detail. Thanks.Kevin had said that Dependencies is missing org.eclipse.rse.core. Apparently this plugin is required in the dependencies in order to complete the tutorials.The Dependencies that are needed are listed in step # 7 of the "Step By Step: Creating an RSE Plug-in Project" link.Rupen is correct. If you look at the org.eclipse.rse.examples.tutorial.plugin.xml you will see it has a dependency on org.eclipse.rse.core. If you remove that you will get a lot of errors. The "Creating a Plug-in Project" doc page should list org.eclipse.rse.core as one of the dependencies you should add. This is step #7.If you follow this doc page you will get a project that's package under src is "rsesamples". The tutorials refer to using samples. Actually the 2 out of date tutorials do. Which can be modified when they are updated.Bulk update target milestone 2.0.1 -> 3.0Assigning documentation bugs to RC4	10.0
id=198395	REOPENED	Target Management	RSE	2.0	All All	P3 major	David Dykstal	2007-07-31 09:48 EDT by	Kevin Doyle	2009-08-06 02:47 EDT (	4 users	If you let your password expire, you can still connect to a dstore connection, but ftp/ssh do not work.Steps to Reproduce:1. Create a new user and set it's password to expire in 0 days.2. Try to login to a dstore linux connection. You are allowed.If you have ftp/ssh also setup on that machine try connecting to those and you won't be able to.-----------Enter bugs above this line-----------TM 2.0.1 Testinginstallation : eclipse-SDK-3.3RSE install : Dev Driver - java.runtime : Sun 1.5.0_11-b03os.name: : Windows XP, Service Pack 2------------------------------------------------	I'm not sure whether this can really be considered a bug.I suppose you are talking about dstore linux daemon, because I'd assume that dstore rexec would not allow the login.The point is that dstore daemon uses "su" command to switch to the other user whereas ftp/ssh/rexec use the normal login process. The "su" command does not seem to honor the login expiration.Please investigate if on your machine the "su" command does behave differently with or without password to expire. Perhaps the dstore daemon could act accordingly and disallow login if the password expired.Checking again, I think the issue is in the auth.pl script -- it does Perl getpwnam() in order to retrieve the password struct. At that point, it should also check whether the password is expired or not, and return a proper error message to the dstore daemon.Assigning DaveD for now, was it you who was in charge of the scripts for the daemon?Not initially, but I will take a look at it.auth.pl does perform the user authentication. It can, in fact, be replaced at the customer location by another script so I'm wondering if site tailoring is the correct solution.Authentication schemes vary on Linux/Unix (and are entirely different on Mac OS X) and so it is difficult to determine if a password has expired or when it might expire. For examplepasswd -S user-namewill show the last change date of the password and the maximum number of days that the password can remain in effect. However, the date format for the last change date varies from system to system possibly depending on the current locale. Parsing such a date and calculating the expiry date from it is beyond the scope of auth.pl.So, I'm going to mark this as "helpwanted" and defer it to a future release. A method of determining expiration should be written entirely in Perl and run on multiple Linux/Unix system. It will still likely be an example implementation only however.Reopening - was marked resolved-wontfix by accident.***has been marked as a duplicate of this bug. ***	6.0
id=234736	REOPENED	Target Management	RSE	3.0	PC Linux-GTK	P3 normal	David Dykstal	2008-05-29 17:48 EDT by	CDE Administration	2008-06-12 14:29 EDT (	4 users	<response_by> Mostafa Ali at 2008.05.13.16.01.27 </response_by>The Launcher Properties tooltip has 2 errors:1. the English words (Server Launcher) should be in the beginning of the string.2. the string in line 2 should be right to left displayed followed by the period at the end.Procedure1) From the Remote Systems view pulldown menu, turn on the Show Filter Pools option.2) Right-click on TestConnection to bring up the context menu and select Properties3) Select the ?Connector Service? category. And then select Launcher Properties under DStore Connector Service -> Remote Server Launcher 4) Verify the following text and tooltips are correct.<response_by> John Ryding at 2008.05.29.16.42.50 </response_by>This article was reassigned from Category:''TVT/Testing,Inbox''.	Created10.001640.jpg<cde:tctdetail>Testcase: 10.001640Project: WSW34Component: Xfer - Target Management/RSEPriority: 2Subject: BiDi problem in the Launcher Properties tooltipArticle ID: 233Originator:</cde:tctdetail>Is this a translation error?The string is wholly contained in /org.eclipse.rse.core/src/org/eclipse/rse/internal/core/messages.propertiesRESID_MODELOBJECTS_SERVERLAUNCHER_DESCRIPTION<response_by> Matthew Mazaika at 2008.06.12.10.00.12 </response_by>This is not a translation error. More info can be found in.This bug has been deferred. It will be considered for the 3.4.1 service pack.*** This bug has been marked as a duplicate of***The status of the article and the state of the corresponding problem may be out of sync.]	6.0
id=235627	REOPENED	Target Management	RSE	3.0	PC Linux-GTK	P3 normal	David Dykstal	2008-06-04 11:48 EDT by	CDE Administration	2011-05-31 17:49 EDT (	4 users	<response_by> Mostafa Ali at 2008.05.13.10.16.07 </response_by>The closing bracket is not in the right direction, also the word Telnet should come between the two Arabic words.Procedure1) Go to the pulldown menu on the Remote Systems title bar.2) Select the ?New Connection...? item, this will bring up the New Connection Wizard.3) Select the Linux system type.4) Verify the text on the page.<response_by> Mostafa Ali at 2008.05.14.07.55.47 </response_by>Please provide me with the file and the string line number because I don't have this file in my TM files. Thanks<response_by> Matthew Mazaika at 2008.05.14.07.59.19 </response_by>The text displays properly on windows, but not on linux. See screenshots.The text can be found in this file:eclipse/plugins/org.eclipse.rse.subsystems.shells.telnet/plugin.propertiesTelnetSystemLabel= Telnet Only (Experimental)<response_by> Matthew Mazaika at 2008.06.04.10.34.29 </response_by>This article was reassigned from Category:''TVT/Testing,Inbox''.	Createdtelnet-linux.pngCreatedtelnet-windows.PNG[Added by CDE: Rejected by the CDE Bridge]<cde:tctdetail>Testcase: 10.001380Project: WSW34Component: Xfer - Target Management/RSEPriority: 2Subject: The closing bracket direction is reversedArticle ID: 191Originator:</cde:tctdetail><response_by> Mostafa Ali at 2008.06.10.12.54.14 </response_by>The problem is still not fixed on linux though it is OK on windows, it is a BiDi issue.ThanksMostafaCreated10.001380.jpgtargeting 3.1 to fix (Eclipse 3.5)<response_by> Matthew Mazaika at 2008.06.12.11.42.50 </response_by>This bug has been deferred.Please seefor additional mixed string bidi issues.*** This bug has been marked as a duplicate of***The status of the article and the state of the corresponding problem may be out of sync.]Bulk moving 3.3 deferred items to 3.3.1	11.0
id=173324	REOPENED	CDT	cdt-memory	6.0	PC Windows XP	P3 critical	DD General Inbox	2007-02-07 14:26 EST by	Alain Lee	2017-02-10 15:31 EST (	3 users	I have a 16-bit Little Endian target connected. Traditional Memory Rendering shows “00000000” in the cell. I put the cursor in front of the first character in the cell and typed “1234”. I expected that “12340000” would be displayed in the cell. Instead, the cell was displaying “10300402”. Back in last October, it was working as I expected. I believe the change of the behavior was caused by the Big Endian/Littie Endian fixes.	fixed, please verify.This still does not work correctly.My target is a 16-bit addressable target (i.e. each address is represented by 2 bytes). Before I edited the memory, Traditional Memory showed the following:0x000000 00000000 00000000 00000000 00000000 00000000 00000000 0x00000C 00000000 00000000 00000000 00000000 00000000 00000000 After I entered "11112222" to the first cell, Traditional Memory Rendering showed the following:0x000000 11112222 22220000 00000000 00000000 00000000 00000000 0x00000C 00000000 00000000 00000000 00000000 00000000 00000000 It seems that the memory was set correctly but the data was presented in wrong cells.HEX Rendering showed the following after I edited the memory: Address 0 1 2 3 4 5 6 7 8 9 A B C D E F 000000 1111 2222 0000 0000 0000 0000 0000 0000 0000 0000 0000 0000 0000 0000 0000 0000 000010 0000 0000 0000 0000 0000 0000 0000 0000 005F 0000 0000 0000 0000 0300 0000 0000reopenTraditional Memory Rendering now lives in CDT -> moving bugs	4.0
id=153652	REOPENED	Target Management	RSE	unspecified	PC Windows XP	P3 normal	David McKnight	2006-08-11 16:57 EDT by	Martin Oberhuber	2011-05-31 17:48 EDT (	7 users	Cannot Copy & Paste from RSE FileSubsystem into the Eclipse Resource Navigator--> Message "Cannot paste into selected elements".Copy & Paste from Resource Naviagor into RSE FileSubsystem does work.But Drag & Drop doesn't seem to work properly.Cannot Drag & Drop from RSE FileSubsystem into Windows Explorer.--> Simply doesnt workCannot Drag & Drop from Windows Explorer into RSE FileSubsystem--> org.eclipse.swt.SWTException: Data does not have correct format for type	I looked at this briefly and realize there may be a bit of design work required here. There used to be a coupling between some of this support (the SystemDropActionDelegate) and the file subsystem support. But, because the drag and drop/copy paste framework is generic, it needs to be independent of the file system support. Any ideas on how we ought to separate the file DND support from the generic?I've fixed the drag and drop for RSE to Navigator. The problem I see with copy & paste is that the Navigator enables paste based on FileTransfer data types, which are basically local file paths (same as used in windows explorer). In order to get local file paths for RSE resources, we'd have to copy the files to local in the copy action (i.e. before the paste). I'm not sure whether we want to do that. Any thoughts?Initiating a download when the user chooses "Copy" would be nonstandard I think. The actual download should only happen when "Paste" is invoked.Do you see any chance how this could be done? For instance, by using a PluginTransfer instead of a FileTransfer? Or deferring the actual download by some other means?Current status as of HEAD on 20-Sep-2006:Drag&Drop RSE-Local -> Windows Explorer : FAIL -> Eclipse Project Explorer : FAIL -> Eclipse Navigator : OK Windows Explorer -> RSE-Local : File -> FAIL Folder -> OK Eclipse Navigator -> RSE-Local : File -> FAIL Folder -> OK Eclipse Project Explorer -> RSE-Local : FAILCopy&Paste RSE-Local -> Windows Explorer : FAIL -> Eclipse Project Explorer : FAIL -> Eclipse Navigator : FAIL Windows Explorer -> RSE-Local : File -> FAIL Folder -> OK Eclipse Navigator -> RSE-Local : OK Eclipse Project Explorer -> RSE-Local : OKIMHO this is not yet good enough for a 1.0 release, so I'm keeping priority P2.1. Wherever a Folder works OK, a file should also work OK; looks like the update policies are currently not ok - Windows Explorer -> RSE-Local - Eclipse Navigator -> RSE-Local2. Wherever Copy&Paste works OK, drag&drop should also work ok and vice versa - Eclipse Project Explorer -> RSE-Local - RSE-Local -> Eclipse Navigator3. Eclipse Project Explorer should work the same as Eclipse Navigator - RSE-Local -> Eclipse Project ExplorerDrag and drop from Windows Explorer to Local for both files and folders seem to work for me. Martin, which driver are you trying?See: "HEAD on 20-Sep-2006", I did the test right after our committer call and had updated the workspace before, so that was about 16.00 UTC or 12.00 Toronto time.I'd not be surprised if this bug is a regression due to the fix forwhich was checked in by Dave D two days ago.When I paste or drop a single file into the Local subsystem, the expanded/collapsed indicator besides the folder flickers a little, it looks really strange.***has been marked as a duplicate of this bug. ***I fixed one bug yesterday that was related to drag and drop of files and folders from windows explorer to RSE.No additional work will be done on this now so I'm lowering the priority.Since the Project Explorer is a default view now, this should be addressed soon.Dave do you have a chance to look into copy&paste to Project Explorer any time soon? The Project Explorer is the Eclipse Default View since M5.I notice with HEAD that I can neither copy&paste from Remote into the Project Explorer, nor the CDT C/C++ View (which is based on the Project Explorer), nor the good old Resource Navigator.According to, it looks like the problem in Resource Navigator is that it uses FileTransfer types for paste, which means we'd have to download on Copy already (which is not what we want). I'm wondering whether we could announce it as PluginTransfer instead, such that we can programmatically do the download after the paste operation.Pasting remote elements into user-defined local views is an important use-case, and we should fix at least the Project Explorer issue. Resource Navigator is perhaps not that important any more since it's not a default view any more.SystemDropActionDelegate is supposed to help accomplish the dragging and dropping from rse to navigator. I wonder if there's something broken with that now.By removing the FileTranferType support from the system views we avoid a transfer type that we stopped supporting as of going open source (because rse.ui is file-independent). This support was causing the common navigator to skip plugin transfer checking. I've also changed the SystemDropActionDelegate to handle the case where an IProjectNature is the target. This allows us to drag and drop to projects in the Project Explorer.I've fixed up the drop action delegate to reset the target for unknown types to be the IResource we adapted to. This allows for drag and drop to source folders and packages in the Project Explorer. I still don't have this working for the Package Explorer. Package Explorer supports the following drop types: Transfer[] transfers= new Transfer[] { LocalSelectionTransfer.getInstance(), FileTransfer.getInstance()};It doesn't, however, support PluginTransfer, which is what we do for Resource Navigator and now Project Explorer so we might not be able to do much about it.I've renabled the drop support for FileTransfer (but not the drag support) so that drag and drop from Windows Explorer to RSE can work.RSE to Windows Explorer still won't work because we don't support the drag this way (to do so requires remote-file awareness in the generic drag adapter. We may be able to enable this by having some kind of File.class adapter for RSE objects. We'd need to know whether files are local or not. For local ones, we would be able to make use of FileTransfer, while for remote ones, we'd be faced with the dilmemma of whether to automatically download on a drag or not.Any thoughts on that?Tested with HEAD as of 14-Mar-2007:* Drag & drop works fine now RSE -> Resource Nav and Project Explorer.* Copy & paste out of RSE does NOT work. Neither in resource navigator nor in project explorer, neither on the project target nor on a folder target. The "Paste" action just is not enabled. I think that this is very important to fix.* For copying or dragging out of LocalFileSubSystem, I believe we should make use of the FileTransfer method. This makes us more compatible, and allows people to dump remote files in local intermediately, so they can drag from RSE-Remote -> RSE-Local -> Final destination. The cost of doing some extra if() for local seems OK for this extra benefit.* For Package Explorer, I'm not worried at all. It's unlikely that people will need it, and if they do they can either create a remote EFS project or switch to the Project Explorer.I also tested the following EFS based scenario, which I found interesting: On an SSH Only connection, select a remote folder and choose right-click > Create Remote Project. This creates an EFS-backed project in the Eclipse Resource System. From this remote project, I can NOT drag&drop or copy&paste to Windows explorer - I get a dialog "Error: Cannot copy file: Cannot read from source file or disk". So this is in line with RSE not supporting drag&drop remote -> Windows Explorer. Therefore, I still think we should not automatically download on Copy or Drag. But what I can do in this scenario, is copy & paste to package explorer or resource navigator. So here, the EFS-backed scenario is better and this is another indication that we should fix RSE native copy&paste as mentioned above.The Navigator PasteAction.updateSelection() method is described as follows: /** * The <code>PasteAction</code> implementation of this * <code>SelectionListenerAction</code> method enables this action if * a resource compatible with what is on the clipboard is selected. * * -Clipboard must have IResource or java.io.File * -Projects can always be pasted if they are open * -Workspace folder may not be copied into itself * -Files and folders may be pasted to a single selected folder in open * project or multiple selected files in the same folder */ protected boolean updateSelection(IStructuredSelection selection)That means, unless the src is an IResource or a java.io.File, paste will be disabled. The only way to get an IResource from RSE is to download it and java.io.File only makes sense for the localfilesubsystem (and to do that we'd need find a way to couple copy/paste with file subsystems). Perhaps download on "copy" would not be as much of an issue as it is on drag since it's a complete operation on it's own. What do you think?Hm. The problem with download-on-copy is, that we'd need to wait for the operation to complete before we can allow paste. So we cannot do it in background. Or if we'd do it in background, we'd need to somehow update state of the Clipboard once it is complete. Desired behavior is to copy some meta-info only and do the actual transfer in a background job on paste.Perhaps we can address this properly soon, when the EFS support is more stable. Then, we should be able to wrap any remote file in an IResource that's backed by EFS. I did not check whether it's possible to create an IResource that's not below a current project but I think that this should be possible (Editors are able to load files outside any projects, and Debugger is able to show source for such external files).On the other hand, since we'll not get around making a local copy in order to be able and paste it to the Windows Explorer, perhaps the following is an option:- On Copy or Drag, create a local empty file in the RSE file cache- Populate the file in a background download- When the download is complete before the paste / drop action happens, we are good. If not, ... (well I'd be wondering what would happen).Seems not perfect, but probably OK for small files. And better than having nothing at all, which is the current state. Should we give that a try?Thoughts?Createddownload during copy action patchHere's a patch to download during the copy. What do you think of this?I've committed the patch that causes a download during the "copy" action. The same has not been done for drag but the drop action delegate gets used in that case anyway.Since the project explorer copy/paste and drag and drop should work now, the defect described in the title should be fixed. I'd still like to look at this for windows explorer, since the copy solution should allow us to give win explorer a file path to the temp files. I'll do that in m7.Marking fixed since Project Explorer works with M6.For Windows Explorer, discussion is continued on.We had to take out this fix again because of critical.A proper fix will need the Project Explorer to support the PluginTransfer method.Seefor an idea how the situation could be improved in RSE in the meantime, though we cannot guarantee fixing this in 2.0.1.***has been marked as a duplicate of this bug. ***I found a very nice write-up of how drag&drop is supposed to work in the Common Navigator / Project Explorer, in.This basically says that Project Explorer does support PluginTransfer, but "drops between views which only understand PluginTransfer are limited to theLocalSelectionTransfer type", if I understand it right. Dave could you also read this and let us know if that iformation might help getting drag&drop to the Project Explorer to work?If not, then perhaps what we need is a general new kind of Transfer type for deferred transfer of files that are available as Streams only.requests this on behalf of dragging remote files to Windows Explorer, and I believe it is a general request needed also by Eclipse Platform to support drag & drop in any views that support EFS as their resources. We should closely watch that bug.Drag&Drop seems to work reliably now, supposedly thanks to the fix for.It seems that Copy&Paste just cannot work.Tentatively targeting 3.1It seems that there are still issues with copy and paste as well as drag and drop, at least under Linux in PHP-Explorer (Versions: eclipse galileo 3.5.1.M20090917, PDT 2.1.3.v20090914, RSE 3.1.1.v200907301400)scenario: LOCAL folder in local php-project REMOTE linked folder (per ssh) in same local php-projectwhat is working for me is: copy and paste as well as drag and drop for files AND folders from LOCAL to REMOTE copy and paste as well as drag and drop for files from REMOTE to LOCAL what is NOT working is: copy and paste as well as drag and drop for folders! from REMOTE to LOCALThe problem is, that the remote folder is locally created but with file systemrigths rw- r-- r-- so that the user cannot write to the newly created folder (umask is 0022).An error message pops up saying "Could not move rse:://hostname/..../REMOTE". Clicking Undo does'nt remove the localy created folderI have screen shots of the error messages but don't know how to attach them. By the way: Debugging with xdebug on the remote php-files doesn't work as well (the path mapping between URL and linked REMOTE folder in the local project seems not to work). But this seems to be a bug, that should be addressed to the PDT project.Never the less: thank you all for your great workBulk moving 3.2.x bugs to 3.3Bulk moving 3.3 deferred items to 3.3.1	31.0
id=294914	REOPENED	Target Management	RSE	3.0.3	PC Windows XP	P3 normal	David McKnight	2009-11-11 15:58 EST by	Samuel Wu	2011-05-31 17:48 EDT (	1 user	This is a problem found in RSE 3.0.3 build on 20091020.1. Start a connection with a remote host2. Start a remote search3. When the remote search is running, disconnect the connection4. The following NPE is thrown.java.lang.NullPointerExceptionat org.eclipse.rse.connectorservice.dstore.DStoreConnectorService.internalConnect(DStoreConnectorService.java:918)at org.eclipse.rse.core.subsystems.AbstractConnectorService.connect(AbstractConnectorService.java:412)at org.eclipse.rse.core.subsystems.SubSystem.internalConnect(SubSystem.java:2779)at org.eclipse.rse.core.subsystems.SubSystem.implicitConnect(SubSystem.java:1850)at org.eclipse.rse.core.subsystems.SubSystem$ConnectJob.performOperation(SubSystem.java:1753)at org.eclipse.rse.core.subsystems.SubSystem$SubSystemOperationJob.run(SubSystem.java:1429)at org.eclipse.rse.core.subsystems.SubSystem$ConnectJob.run(SubSystem.java:1736)at org.eclipse.core.internal.jobs.Worker.run(Worker.java:55)	I tried to reproduce this but it worked okay for me. Is this something you can consistently reproduce?Yes, I can still reproduce the problem.The following exception was thrown with RSE org.eclipse.rse.core_3.0.4.v200903242127-7Z47QEB7sQU1VMaactrtjava.lang.NullPointerException at org.eclipse.rse.connectorservice.dstore.DStoreConnectorService.internalConnect(DStoreConnectorService.java:918) at org.eclipse.rse.core.subsystems.AbstractConnectorService.connect(AbstractConnectorService.java:412) at org.eclipse.rse.core.subsystems.SubSystem.internalConnect(SubSystem.java:2779) at org.eclipse.rse.core.subsystems.SubSystem.implicitConnect(SubSystem.java:1850) at org.eclipse.rse.core.subsystems.SubSystem$ConnectJob.performOperation(SubSystem.java:1753) at org.eclipse.rse.core.subsystems.SubSystem$SubSystemOperationJob.run(SubSystem.java:1429) at org.eclipse.rse.core.subsystems.SubSystem$ConnectJob.run(SubSystem.java:1736) at org.eclipse.core.internal.jobs.Worker.run(Worker.java:55)Createdpatch to cancel monitor on disconnectSamuel, could you try with this patch?The patch fixed the NPE. But there is still a little problem. The status in the Rremote Search view says Running instead of Cancelled. Can the status be changed to Cancelled?Createdupdated patchCan you try with this patch?Does this require a backport?Thank you for the fix, Dave. I openedfor back porting.I've committed the change to cvs.The problem happened again with the following exception.java.lang.NullPointerExceptionat org.eclipse.rse.connectorservice.dstore.DStoreConnectorService.internalConnect(DStoreConnectorService.java:918)at org.eclipse.rse.core.subsystems.AbstractConnectorService.connect(AbstractConnectorService.java:412)at org.eclipse.rse.core.subsystems.SubSystem.internalConnect(SubSystem.java:2779)at org.eclipse.rse.core.subsystems.SubSystem.implicitConnect(SubSystem.java:1850)at org.eclipse.rse.core.subsystems.SubSystem$ConnectJob.performOperation(SubSystem.java:1753)at org.eclipse.rse.core.subsystems.SubSystem$SubSystemOperationJob.run(SubSystem.java:1429)at org.eclipse.rse.core.subsystems.SubSystem$ConnectJob.run(SubSystem.java:1736)at org.eclipse.core.internal.jobs.Worker.run(Worker.java:55)(In reply to)Do you hit this consistently? I've tried several times to reproduce this but I was unable to hit it.It doesn't happen every time. It happens quite frequently. One out of five probably.Bulk moving 3.2.x bugs to 3.3Bulk moving 3.3 deferred items to 3.3.1	14.0
id=150954	REOPENED	Target Management	RSE	unspecified	PC Windows XP	P3 normal	David McKnight	2006-07-18 10:29 EDT by	Martin Oberhuber	2010-05-27 09:26 EDT (	3 users	Set Preferences > Remote Systems > Use Deferred Queries = true.When the Remote Monitor is used to poll a very slow system,and refresh rate is set to 5 seconds,refresh jobs are scheduled very frequently.While a remote monitor's refresh job is running, the RSE Tree only shows "Pending..." so the view elements are not usable. As soon as the result of the query gets visible, "Pending..." is shown again.The Remote Monitor should leave the old view contents intact until its new results are available from the remote system. Only then, the old data should be replaced with the new one.	Dave can you check if this is fixed by 1.0M5?The monitor view is driven by SystemDeferredTableTreeContentManager which extends DeferredTreeContentManager. DeferredTreeContentManager is responsible for creating the "Pending..." item and then collecting results to show in the view. I'm not sure if we should be interfering with that standard Eclipse behaviour.Any thoughts about this?Looking ata the view here again and I really don't see any problems. I'm going to mark it as fixed - feel free to reopen if you still see a problem.The problem is in the interaction of the two views. The monitor is causing an automatic refresh of the Systems View at the point of the monitor. If I monitor the actual host (instead of a folder) the "pending..." appears and the whole tree collapses back to its first level. This makes it very difficult to navigate the tree while a monitor is running since the tree is constantly being refreshed.Both the monitor and the system view are driven from the same model so it may not be possible to dissociate the monitor from the view without some work. I believe folks would see the automatic refresh of the tree when the monitor refreshes as unnatural. Would it be possible or make sense to refresh a copy of a section of the model in the viewer - or perhaps use a filter as a root object that is not visible in the tree?Reopening - I recommend that this be deferred for some continuing discussion on how monitors should work.Agree -> setting target milestone 2.0My personal feeling is that the refresh queries from the remote monitor should not show a "pending..." message while they are ongoing. Once the data has arrived from the query, the model (and tree) should be updated without destroying existing selection.One thing that could simplify this problem a bit would be to turn the Remote Monitor back into a table rather than a table-tree. For the most part the value of this view lies in it's use as table, however others may see the tree aspect of this as an important (albeit problematic) bonus. Any thoughts on that?I've changed the monitor back from a table-tree to a table since the value of this view is mostly in it's table capabilities. Although this doesn't probably doesn't address the SystemView issue described, it does reduce some of the complexity issues of the monitor.moving to m6 to look at laterdeferring to m7 since it does not seem API is affected***has been marked as a duplicate of this bug. ***There is little we can do in the RSE framework to fix this, as long as the client subsystems use deferred jobs and the DeferredTreeContentManager. Deferring to after 2.0.The DeferredTreeContentManager is responsible for collapsing tree nodes inorder to refresh them. While this is done, the tree node is unusable. The problem might be alleviated slightly when the REFRESH events do a better job maintaining the current selection and expand state, as discussed on.Clients can work around this as follows:1. Have an ISystemViewElementAdapter with supportsDeferredQueries==false2. Have ISystemViewElementAdapter#getChildren() always return local (cached) model objects3. Listen to ISystemResourceChangeEvents.REFRESH* events 3a. When a refresh event is received, perform an asynchronous retrieval of data from the remote side, with a callback 3b. When the callback is received, update the local (cached) model and send a REFRESH event that is a subclass of the normal refresh event 3c. Have step (3a) distinguish the special local refresh event from the RSE one, and do not perform the asynchrous retrieval in this case.In other words, the client doesn't use the RSE deferred query / job mechanismbut rather performs asynchrouns remote queries itself.Actually, hacking this up might work as follows:* In SystemView.getContextObject(TreeItem), extend the IContextObject to also contain the TreeItem referring to the requested parent.* In SystemDeferredTreeContentManager.getChildren() get the TreeItem out of the IContextObject in order to get the currently displayed children. Instead of just returning the pendingAdapter, return an array of pendingAdapter AND the existing children, and remember the list of existing children.* At the callback when the deferred getter job returns, Perform a refresh of the remembered old list of children against the new list of children; removing, adding, updating properties where needed. The absoluteName may be needed to do this properly. Also, for those TreeItem children that were expanded at the time of refresh, another deferred job needs to be started now. Finally, when all previously expanded members are returned, apply the selection that was remembered at the very beginning.Basically, this idea applies a similar algorithm as was in place in the SystemView at the time when no deferred queries were supported. Note that with the Local files subsystem, the case of non-deferred-queries can still be tried out: it retains selection and expand state in many more cases.Anyways, I'm not pushing this fix forward any more, since at Wind River we're using the async query method described inso it's not so much of an issue for us. A fix for this might be considered for 2.0.1.	13.0
id=308221	REOPENED	Target Management	RSE	unspecified	PC Windows 7	P3 normal	David McKnight	2010-04-06 11:23 EDT by	Mai El-Sayad	2011-05-31 17:48 EDT (	9 users	Build Identifier: 20100331When opening properties view for a folder properties are displayed correctly, but the date is displayed incorrectly. The date/time should be displayed from right to left (i.e. am hr:min:sec year month day), and instead it is displayed (day am hr:min:sec year month)The same happens when a folder is shown in Table.Reproducible: AlwaysSteps to Reproduce:Prerquisites:From Control Panel -> Regional Settings set the locale and language to ArabicScenario:1.Select a folder from the "My Home" Filter in the Remote Systems Explorer2.Open the Properties view.The same happens when:1.Select a folder from the "My Home" Filter in the Remote Systems Explorer2.Right click and select "Show in Table"	Createdthe wrong display of the dateThis defect is related toA possible fix would be using icu SimpleDateFormat and inserting RLE or RLM at the pattern beginning(that is under Arabic locale condition).However if this date will be used for other purpose than display,the control character (RLE or RLM)should be removed.CreatedSample for using SimpleDateformat from ICUThe suggested approach relies on:import com.ibm.icu.util.*;import com.ibm.icu.text.SimpleDateFormat;These are IBM library dependencies. Are we allowed to have that in Eclipse open source?com.ibm.icu is shipped with the Eclipse SDK, and using it is recommended (if not required) for any Eclipse project participating in Helios.Just be sure to use "import-package" rather than "require-bundle" in the MANIFEST.MF such that the icu.base replacement bundle can be used instead of the full ICU bundle, if a product builder wants that.If the locale is passed in to create the DateFormat, will the following work?ULocale locale = ULocale.getDefault(); DateFormat icufmt = DateFormat.getDateTimeInstance(DateFormat.LONG,DateFormat.MEDIUM, locale);String formattedDate = icufmt.format(date);Or do we need to use SimpleDateFormat?It looks like a change for this has been committed (accidentally?) to SystemViewRemoteFileAdapter as well as rse.files.ui/META-INF/MANIFEST.MF, together with a change for.Please either add a line to the copyright comment of that file, or revert the change.(In reply to)Yes, that change did go in with. I was waiting on a response from the originators to my question but I guess for now I'll just update the copyright.Thanks Dave.Since the patch went in, I think it's better to mark this resolved as per 3.2M7. Submitter should re-open the defect if the issue is still there. I'm afraid that if we just move this out to 3.2 it may get lost.This defect still exisits in the build if 07 May (I20100507-1000)I have opened a new defect as proposed ()I have reopened the defect in a new bug (312386)*** This bug has been marked as a duplicate of***(In reply to)Mai El-Sayad, could you please respond to Command #7?Reopening this defect and will close defect #312386 to keep history comments***has been marked as a duplicate of this bug. ***Bulk moving 3.2.x bugs to 3.3Bulk moving 3.3 deferred items to 3.3.1	17.0
id=246826	REOPENED	Target Management	RSE	3.0	PC Windows XP	P3 minor	David McKnight	2008-09-10 03:35 EDT by	Masao Nishimoto	2011-09-27 03:28 EDT (	2 users	The KeepAlive thread make a KeepAlive request pending, and waits for the response. When the server is busy sending a data to a client, the KeepAlive request takes long time to be actually sent. If the busy time is long enough, the KeepAlive thread gets timed-out even before the request is sent. The thread should wait for the response after the request has been sent to the client.	Are you saying that the keepalive timeout is now counted against the timestamp when the keepalive thread is created, but it should be counted against the timestamp when the keepalive packet is sent?This seems a minor issue to me since it should always be possible to work around it by increasing the keepalive time, no? At least I'd expect a user running into the issue of keepalives timing out would naturally just increase the keepalive time, or am I missing something?Yes, it should be counted against the timestamp when the keepalive packet is sent.It is used on the server to detect an unresponsive user, and resources owned by the user are released on the detection . Since this is the server side setting, if the time-out value is increased, it applies to all users, and causes resources unusable for longer time.Createdexperimental patchThis experimental patch has the the keep alive requests and responses sent immediately (rather than waiting for the handler). I'm not sure whether or not this would have side-effects but could you try this out?The fix works when it takes more than KEEPALIVE_RESPONSE_TIMEOUT and less than IO_SOCKET_READ_TIMEOUT to send a data. When it takes more than IO_SOCKET_READ_TIMEOUT, the exception with "The connection to the server has been lost." is thrown, because (_kart != null && _kart.isAlive()), and in == -1, after in = reader.read() in XMLparser.readLine().Createdupdated experimental patchMasao, does this update to the patch help?I still get the following exception.java.lang.Exception: The connection to the server has been lost. at org.eclipse.dstore.internal.core.util.XMLparser.readLine(XMLparser.java:391)I've committed the patch with the improvements. I haven't had a chance yet to look at the other issue.I can't tell from the text of this problem if the timeout issue is resolved or not. We have a few customer reported problems which are pointing back to this defect.Bulk move to 3.2.1 target milestone.(In reply to)What does that mean? That you are fixing in a different release than it was reported against?(In reply to)I'm just moving HEAD stream target milestones since we can't use the 3.2 or less target milestone anymore. The associated backports (i.e. for 3.0.3+) are a different story.I've openedto address the case where KEEPALIVE_RESPONSE_TIMEOUT is greater than IO_SOCKET_READ_TIMEOUT. Since the code for the regular case has already been committed, I'll mark this as fixed.It occurs if time to send a data is greater than both KEEP_ALIVE_RESPONSE_TIMEOUT and IO_SOCKET_READ_TIMEOUT. It does not matter which of these two is larger. While sending a data, keep-alive request is pending in the send queue. On the other hand, the timer starts when the request is put in the queue. So the timer expires even if the request is not sent to the client.Bulk moving 3.2.x bugs to 3.3Bulk moving 3.3 deferred items to 3.3.1	15.0
id=309813	REOPENED	Target Management	RSE	3.0.3	PC Windows XP	P3 normal	David McKnight	2010-04-20 10:08 EDT by	Violaine Batthish	2011-05-31 17:48 EDT (	3 users	3.0.3 RSE driver usedIf a file is in the RSE file cache, and access to that file is removed and the RSE tree is not refreshed, a user is still able to open the file and view the contents.To reproduce:1. Create an SSH connection to a Linux on System z host, (the one I tried was running RHEL Server release 5.2 (Tikanga), should work with other Linux hosts/versions)2. Open a file that you have read access to, by expanding the appropriate folders and double clicking on the file.3. Close the file.4. Use chmod to remove rw access on the file.5. Double click to open the file again - file is opened - but access should be denied.I also found the same problem with a dstore connection to the same Linux on System z host.If the file is not in the cache - and error message appears as expected.If the RSE tree is refreshed after authority is removed, then open is not available - which is also ok, but the cached file is still available for viewing outside the workbench.	Createdpatch to detect change in readonly propertyI've committed the change to cvs and opened by 309982 for the backport.Dave, I tried the patch but it doesn't work.When I double-click or click on open - it seems to use the class SystemEditFilesAction instead of SystemEditFileAction (note missing s)(In reply to)Okay, I guess I'll need to address the SystemEditFilesAction case as well.Actually Open menu action uses SystemEditFilesAction.isFileCached()Double click uses SystemViewRemoteFileAdapter.isFileCached()Createdammendment for handling ebcdic nl and lf charsComment onammendment for handling ebcdic nl and lf charswrong bugCreatedadding SystemEditFilesAction caseViolaine, could you verify that the additional patch solves the problem for you?I've committed the fix to cvs.Hey Dave,The patch still does not work (tested both SSH and dstore connection) with Open menu. Also, as mentioned in, double-click requires a fix in SystemViewRemoteFileAdapter(In reply to)I'm assuming you've applied both patches. Could you please list each of the scenarios this does not work for you?I've tried in the following cases:1) double-click (SystemViewRemoteFileAdatper)2) context menu -> Open3) context menu -> Open WithEach of these seems to work okay for me although I did notice that with 3) a refresh will be required before the open.I haven't yet addressed the non-writable cases. I'll have to come back and look at this when I have some time.Is this actually fixed with recent changes?(In reply to)Only the read-only cases are fixed. The non-readable cases have not yet been dealt with.Bulk moving 3.2.x bugs to 3.3As already mentioned, the scenarios of adding or removing of write permissions from the shell as described in this defect have been addressed. The scenarios of adding or removing read permissions are considerably more difficult issues to fix for various reasons.RSE doesn't detect or get notified of file changes that occur via shell commands. Aside from the fact a file that just lost it's read permissions can be opened via the cache in RSE, the context menu for a file would continue to display 'open' actions when such actions should not be available (actually these show regardless of the permissions but that can be easily dealt with) . If a file has already been opened and then has it's read permissions are taken away, the file stays open. It's not very optimal or practical to do notification in response to a random shell command, periodic polling for remote file permissions nor to do a new query every time a user brings up a context menu. Because of these kinds of issues, I don't expect to be able to satisfactorily address the lost read permission cases anytime soon.I can make things a bit better by not showing open actions when a given file lacks read permissions. The user can use the Permissions property page to change permissions in a way that RSE will automatically be aware of, but otherwise, for things like files already in editors and context menus, it's probably best that the user just refreshes the file in the view after adding/removing read permissions via the shell (i.e. chmod).Bulk moving 3.3 deferred items to 3.3.1	18.0
id=463981	REOPENED	CDT	cdt-core	8.6.0	PC Mac OS X	P3 normal	Doug Schaefer	2015-04-06 12:22 EDT by	Doug Schaefer	2016-03-04 19:23 EST (	1 user	I'm getting an invalid thread access from the WorkbenchThemeManager init that is triggered from the CDT UI Preference initializer being invoked from the CUIPlugin start activator method where our "A workaround for black console", which is a pretty crappy workaround, initializes the colors for the build console.I'll wrap the call to the theme manager in a display sync exec.	New Gerrit change created:I've run into a few cases now where we're trying to access UI preferences from Activators.But really the issue was the crash I had with the IDE. CDT UI elements were open but we've lost the preferences so they're re-initializing at an inopportune moment.But still, we shouldn't be access UI preferences from Activators. That's just bad code to work around problems.Leaving for now since I managed to get my workspace fixed up. Wasn't the first time I ran into it, won't be the last.As expected. it's back.For now, I'm just going to delete the code from the UI plug-in activator that loads the preferences.Actually, I'll just jove two calls that trigger this into a UIJob.(In reply to Doug Schaefer from)s/jove/move/New Gerrit change created:Gerrit changewas merged to [master].Commit:The fix seems to work. We'll leave it at that for now.This change causes UI freezes due to excessive class loading on the UI thread:!MESSAGE UI freeze of 1.0s at 15:03:29.053!SUBENTRY 1 org.eclipse.ui.monitoring 1 0 2016-03-04 15:03:30.085!MESSAGE Sample at 15:03:29.391 (+0.338s)Thread 'main' tid=1 (RUNNABLE)!STACK 0java.lang.Exception: Stack Trace at java.util.zip.ZipFile.read(Native Method) at java.util.zip.ZipFile.access$1400(ZipFile.java:61) at java.util.zip.ZipFile$ZipFileInputStream.read(ZipFile.java:722) at java.util.zip.ZipFile$ZipFileInflaterInputStream.fill(ZipFile.java:425) at java.util.zip.InflaterInputStream.read(InflaterInputStream.java:158) at org.eclipse.osgi.storage.bundlefile.ZipBundleEntry$ZipBundleEntryInputStream.read(ZipBundleEntry.java:156) at org.eclipse.osgi.storage.StorageUtil.getBytes(StorageUtil.java:195) at org.eclipse.osgi.storage.bundlefile.BundleEntry.getBytes(BundleEntry.java:94) at org.eclipse.osgi.internal.loader.classpath.ClasspathManager.findClassImpl(ClasspathManager.java:568) at org.eclipse.osgi.internal.loader.classpath.ClasspathManager.findLocalClassImpl(ClasspathManager.java:540) at org.eclipse.osgi.internal.loader.classpath.ClasspathManager.findLocalClass(ClasspathManager.java:527) at org.eclipse.osgi.internal.loader.ModuleClassLoader.findLocalClass(ModuleClassLoader.java:324) at org.eclipse.osgi.internal.loader.BundleLoader.findLocalClass(BundleLoader.java:327) at org.eclipse.osgi.internal.loader.BundleLoader.findClassInternal(BundleLoader.java:402) at org.eclipse.osgi.internal.loader.BundleLoader.findClass(BundleLoader.java:352) at org.eclipse.osgi.internal.loader.BundleLoader.findClass(BundleLoader.java:344) at org.eclipse.osgi.internal.loader.ModuleClassLoader.loadClass(ModuleClassLoader.java:160) at java.lang.ClassLoader.loadClass(ClassLoader.java:357) at org.eclipse.cdt.ui.CUIPreferenceInitializer.initializeDefaultPreferences(CUIPreferenceInitializer.java:49) at org.eclipse.core.internal.preferences.PreferenceServiceRegistryHelper$1.run(PreferenceServiceRegistryHelper.java:300) at org.eclipse.core.runtime.SafeRunner.run(SafeRunner.java:42) at org.eclipse.core.internal.preferences.PreferenceServiceRegistryHelper.runInitializer(PreferenceServiceRegistryHelper.java:303) at org.eclipse.core.internal.preferences.PreferenceServiceRegistryHelper.applyRuntimeDefaults(PreferenceServiceRegistryHelper.java:131) at org.eclipse.core.internal.preferences.PreferencesService.applyRuntimeDefaults(PreferencesService.java:368) at org.eclipse.core.internal.preferences.DefaultPreferences.applyRuntimeDefaults(DefaultPreferences.java:221) at org.eclipse.core.internal.preferences.DefaultPreferences.load(DefaultPreferences.java:274) at org.eclipse.core.internal.preferences.EclipsePreferences.create(EclipsePreferences.java:409) at org.eclipse.core.internal.preferences.EclipsePreferences.internalNode(EclipsePreferences.java:670) at org.eclipse.core.internal.preferences.EclipsePreferences.node(EclipsePreferences.java:812) at org.eclipse.core.internal.preferences.AbstractScope.getNode(AbstractScope.java:38) at org.eclipse.core.runtime.preferences.DefaultScope.getNode(DefaultScope.java:76) at org.eclipse.ui.preferences.ScopedPreferenceStore.getDefaultPreferences(ScopedPreferenceStore.java:238) at org.eclipse.ui.preferences.ScopedPreferenceStore.getPreferenceNodes(ScopedPreferenceStore.java:269) at org.eclipse.ui.preferences.ScopedPreferenceStore.contains(ScopedPreferenceStore.java:331) at org.eclipse.cdt.internal.ui.preferences.BuildConsolePreferencePage.initDefaults(BuildConsolePreferencePage.java:162) at org.eclipse.cdt.ui.CUIPlugin$3.runInUIThread(CUIPlugin.java:612) at org.eclipse.ui.progress.UIJob$1.run(UIJob.java:97) at org.eclipse.swt.widgets.RunnableLock.run(RunnableLock.java:35) at org.eclipse.swt.widgets.Synchronizer.runAsyncMessages(Synchronizer.java:135)	10.0
id=350522	REOPENED	MTJ	MTJ projects	unspecified	PC Mac OS X - Carbon (unsup.)	P3 major	Project Inbox	2011-06-28 04:20 EDT by	Rainer	2016-07-29 13:00 EDT (	1 user	Build Identifier: 20110615-0604Installed the Eclipse 3.7 for Java developers (cocoa 64 bit), then the MTJ tools via "Install new..." -> all available sites -> type MTJ.I have this version installed now. Mobile Tools for Java 1.1.2.201106060709 org.eclipse.mtj.feature.group Eclipse.orgI then manually added the hook into config.ini as described in the original MTJ install instructions.I have a working project from a 3.6 pulsar release. When trying to preprocess, I see the following error in the log.java.lang.NoSuchFieldError: ruleMemo at antenna.preprocessor.v3.parser.APPParser.<init>(APPParser.java:89) at antenna.preprocessor.v3.parser.Defines.addDefines(Defines.java:197) at antenna.preprocessor.v3.Preprocessor.addDefines(Preprocessor.java:325) at org.eclipse.mtj.internal.core.build.preprocessor.PreprocessorBuilder.preprocess(PreprocessorBuilder.java:692) at org.eclipse.mtj.internal.core.build.preprocessor.PreprocessorBuilder.doPreprocessing(PreprocessorBuilder.java:498) at org.eclipse.mtj.internal.core.build.preprocessor.PreprocessorBuilder.doBuild(PreprocessorBuilder.java:347) at org.eclipse.mtj.internal.core.build.MTJIncrementalProjectBuilder.build(MTJIncrementalProjectBuilder.java:70) at org.eclipse.core.internal.events.BuildManager$2.run(BuildManager.java:728) at org.eclipse.core.runtime.SafeRunner.run(SafeRunner.java:42) at org.eclipse.core.internal.events.BuildManager.basicBuild(BuildManager.java:199) at org.eclipse.core.internal.events.BuildManager.basicBuild(BuildManager.java:239) at org.eclipse.core.internal.events.BuildManager$1.run(BuildManager.java:292) at org.eclipse.core.runtime.SafeRunner.run(SafeRunner.java:42) at org.eclipse.core.internal.events.BuildManager.basicBuild(BuildManager.java:295) at org.eclipse.core.internal.events.BuildManager.basicBuildLoop(BuildManager.java:351) at org.eclipse.core.internal.events.BuildManager.build(BuildManager.java:374) at org.eclipse.core.internal.events.AutoBuildJob.doBuild(AutoBuildJob.java:143) at org.eclipse.core.internal.events.AutoBuildJob.run(AutoBuildJob.java:241) at org.eclipse.core.internal.jobs.Worker.run(Worker.java:54)I guess that the version of ANTLR that is picked up is not compatible with MTJ.Reproducible: AlwaysSteps to Reproduce:1. try and build an MTJ project with preprocessing enabled	I see that antenna.preprocessor bundle only provides a minimum version number for ANTLR runtime. Eclipse indigo ships both ANTLR runtime 3.2 and 3.0.1 and I think 3.2 is picked up. I will update the bundle and give a maximum supported version so that 3.2 is not used anymore.A fix is released to git repository and you can pick up the update that includes the fix fromupdate site.Hmm, now I get the following errorPreprocessor invoked, but hook is not installed. Consult the installation instructions for MTJ.I do have the following in configurations/config.ini#This configuration file was written by: org.eclipse.equinox.internal.frameworkadmin.equinox.EquinoxFwConfigFileParser#Tue Oct 25 10:39:40 CEST 2011org.eclipse.update.reconcile=falseeclipse.p2.profile=epp.package.java/Documents/workspaceosgi.framework=file\:plugins/org.eclipse.osgi_3.7.1.R37x_v20110808-1106.jarequinox.use.ds=trueeclipse.buildId=M20110909-1335osgi.bundles=reference\:file\:org.eclipse.equinox.simpleconfigurator_1.0.200.v20110502-1955.jar@1\:startorg.eclipse.equinox.simpleconfigurator.configUrl=file\:org.eclipse.equinox.simpleconfigurator/bundles.infoeclipse.product=org.eclipse.platform.ideosgi.splashPath=platform\:/base/plugins/org.eclipse.platformosgi.framework.extensions=org.eclipse.mtj.core.hooksosgi.bundles.defaultStartLevel=4eclipse.application=org.eclipse.ui.ide.workbench/../p2/I.e. the hook for osgi.framework.extensions=org.eclipse.mtj.core.hooks. But somehow that doesn't seem to be enough.Reopening to take a lookOh well guess nobody noticed this before, but this line of eclipse:Seems to add a dot to the classpath of the "org.eclipse.mtj.core.hooks" library. entries[j] = one entry from the eclipse.properties: Content of eclipse.properties:I'm not really shure if this is intended but i guess it is not.But even if this would be correct it would probably get a problem with asm-all-3.0.jar, because the following line will fail:So the classloader was looking for a file called "org.eclipse.mtj.core.hooks-*.jar.".So basically it doesn't even read the hookconfigurators.properties file after that.The only Solution for me was to add "Eclipse-BundleShape: dir" to the manifest of the plugin ,package it with maven again, and install it from the plugin-zip-file.That way it would take the classpath "org.eclipse.mtj.core.hooks-*/." instead, because the plugin gets stored inside a directory in the plugin-folder and not as jar file.I also modified the "Debug.java" because it throw Exceptions about not finding a Platform class.(But I'm not shure if this step is really needed, i changed this before i found the problem with the classloader)So i just used "DEBUG_GENERAL = false" for example.	5.0
id=480580	REOPENED	CDT	cdt-arduino	8.8.0	PC Windows 10	P3 enhancement	Doug Schaefer	2015-10-24 20:11 EDT by	Faisal Iqbal	2016-01-01 00:49 EST (	3 users	Currently when adding a build target, i.e. for Arduino Nano or ESP8266 one have to have this module connected to PC on a Serial Port.It would be great to have the possibility to set a build target without needing to connect actual hardware to PC to quickly start working on a project, and compile it against desired board / platform.	Yeah, that's something I need for testing too :). Problem is, I don't know what the serial port is going to be so the target will be incomplete. I need to make sure we don't break when things are set that way.When adding new Target, let the Serial Port field empty, and save it with NULL value, but save rest of the Target settings as configured.There can be a check if Target have NULL Serial Port field, then don't do the Run command, show note in Console to set port in Target settings.Expanding this to allow serial ports that are any string, including empty.***has been marked as a duplicate of this bug. ***Change upcoming. Once gerrit gets back on line that is.New Gerrit change created:Gerrit changewas merged to [cdt_8_8].Commit:Change submitted. Will do a build later this week.Using: Arduino C++ Tools - Preview 8.8.0.201512282018 org.eclipse.cdt.arduino.feature.group Eclipse CDTDuplicate #483415 not fixed.It is possible to enter an arbitrary file path, but it is NOT always persisted.Sample string: "/dev/micro".Assumption: only the file paths matching the internal pattern for "serial port" are presisted.Should I open a new bug ?I'll just reopen this one. There must be a check on startup that I missed.	10.0
id=509628	REOPENED	andmore	General	unspecified	Macintosh Mac OS X	P3 major	David Carver	2016-12-22 04:24 EST by	vikram vi	2016-12-22 09:46 EST (	2 users	Eclipse : Neon Release 4.6.0Mac OS : 10.11.6Pre-requisitcs:1. ANDROID_HOME is set up in .bash_profile as belowexport ANDROID_HOME=/Users/vikram-anna/Library/Android/sdkexport PATH=$ANDROID_HOME/platform-tools:$PATHexport PATH=$ANDROID_HOME/tools:$PATH2. terminal command env, is showing correct valueSteps:1. Create simple java project2. Run command String[] temp = { "adb", "start-server" }; Process p = Runtime.getRuntime().exec(temp);Actual Result;1. Always throws errorjava.io.IOException: Cannot run program "adb": error=2, No such file or directory at java.lang.ProcessBuilder.start(ProcessBuilder.java:1048) at java.lang.Runtime.exec(Runtime.java:620) at java.lang.Runtime.exec(Runtime.java:485)2. Set ANDROID_HOME under project Run > Run Configurations Environment. But still no luckNote:This works if full path of adb is mentioned//String[] temp = { "/Users/vikram-anna/Library/Android/sdk/platform-tools/adb", "start-server" };References:Kindly fix this critical bug.	I see no indication that this is a bug in Eclipse.As mentioned in the referenced threads, you have two options to ensure that Java's Runtime.exec() finds adb:- provide the path in the Environment tab of your launch configuration, or- ensure that Eclipse is launched from a shell with an environment as needed.I'm not a Mac expert, but it looks like you launched Eclipse in a way that does not source your .bash_profile (and neither does launching your application read that file of course, since no bash is involved).@Stephan,In my bug description, I've mentioned that even after explicitly mentioning ANDROID_HOME under project Run > Run Configurations Environment, it doesn't workI have put Eclipse under Application on Mac.Ideally it should pick up all the environment variables.Please clarify with these circumstances, why do you feel it's not a Eclipse bug.This does work well with Netbeans and only has issue with Eclipse, if you google you can find many other complaints about this.Kindly re-open and revisit the issueAs per Accepted answer to this, I have setup variable explicitly. Refer to Pt.2 under Actual Result.Setting only ANDROID_HOME doesn't mean anything to the Java process that is launched from Eclipse. You'd have to define PATH to make adb accessible for the application. This issue only involves the interaction between Java and your operating system, Eclipse isn't involved in that.Recommendation for debugging: insert in your application a debug routine that prints out the environment of the current process. Only if that environment contains a definition of PATH that includes the path to adb, only then can Java possibly find the executable.What you are requesting sounds like: Eclipse should know that ANDROID_HOME is an environment variable that should be interpreted as to append its value to the PATH environment every time a Java application is launched. But consequently, Eclipse should probably do the same for a million of other XYZ_HOME environment variables that should point to some application's home directory. And then Eclipse wouldn't even have a chance to even know for all these applications which of the subdirectories of their XYZ_HOME contains executables.=> This is a game that *JDT* can never possibly win.OTOH, if you install any Android-specific plug-ins (like- frankly I don't know its state), then *that* plugin might want to implement rules like described above. Moving to the Andmore project for consideration.Thanks Stephan for detailed clarifications.I'll try out the solutions you proposed and update in this thread.But it's interesting to find out how Netbeans & IntelliJ handles this kind of scenario. As my colleagues say it just works.Regards,Vikram	5.0
id=358301	REOPENED	Target Management	RSE	unspecified	PC Windows XP	P3 normal	David McKnight	2011-09-20 16:19 EDT by	Samuel Wu	2012-05-23 19:52 EDT (	1 user	Build Identifier: RSE 3.2 maintenance (RSE-runtime-M20110601-1650.zip)When the source file was not found for a debug session, the user ran the action Change Text File to find a file on a remote host, the UI was locked upReproducible: SometimesSteps to Reproduce:1. Set the source look up to Default and start a debug session2. In the Source_Not_Found debug editor, run the action Change Text File 3. Select a remote host and expand its Root directory4. The UI was locked upWill attach the stacktrace	CreatedStack trace during when UI was lockedA few traces were taken and they all contain the following.Thread[ModalContext,RUNNABLE,118] java.util.HashMap.findNonNullKeyEntry(HashMap.java:525) java.util.HashMap.putImpl(HashMap.java:622) java.util.HashMap.put(HashMap.java:605) org.eclipse.rse.internal.services.dstore.files.DStoreFileService.convertToHostFile(DStoreFileService.java:1375) org.eclipse.rse.internal.services.dstore.files.DStoreFileService.convertToHostFiles(DStoreFileService.java:1401) org.eclipse.rse.internal.services.dstore.files.DStoreFileService.fetch(DStoreFileService.java:2170)It looks that the call never returned and the UI was waiting for it.The following trace was from another case which never returned as well. Since it was on a non-GUI thread, the UI was not blocked.Thread[Worker-8,RUNNABLE,40] java.util.HashMap.findNonNullKeyEntry(Unknown Source) java.util.HashMap.getEntry(Unknown Source) java.util.HashMap.containsKey(Unknown Source) org.eclipse.rse.subsystems.files.core.subsystems.RemoteFileSubSystem.cacheRemoteFile(RemoteFileSubSystem.java:1275) org.eclipse.rse.subsystems.files.core.subsystems.RemoteFileSubSystem.cacheRemoteFile(RemoteFileSubSystem.java:1313) org.eclipse.rse.internal.subsystems.files.local.model.LocalFileAdapter.convertToRemoteFiles(LocalFileAdapter.java:59) org.eclipse.rse.subsystems.files.core.servicesubsystem.FileServiceSubSystem.list(FileServiceSubSystem.java:578) org.eclipse.rse.subsystems.files.core.subsystems.RemoteFileSubSystem.list(RemoteFileSubSystem.java:976)Similar problem.Thread[Worker-0,RUNNABLE,18] java.util.HashMap.findNonNullKeyEntry(HashMap.java:526) java.util.HashMap.putImpl(HashMap.java:622) java.util.HashMap.put(HashMap.java:605) org.eclipse.rse.internal.services.dstore.files.DStoreFileService.convertToHostFile(DStoreFileService.java:1375) org.eclipse.rse.internal.services.dstore.files.DStoreFileService.convertToHostFiles(DStoreFileService.java:1401) org.eclipse.rse.internal.services.dstore.files.DStoreFileService.fetch(DStoreFileService.java:2170) org.eclipse.rse.internal.services.dstore.files.DStoreFileService.list(DStoreFileService.java:2030) org.eclipse.rse.subsystems.files.core.servicesubsystem.FileServiceSubSystem.internalList(FileServiceSubSystem.java:379) org.eclipse.rse.subsystems.files.core.servicesubsystem.FileServiceSubSystem.list(FileServiceSubSystem.java:571) org.eclipse.rse.subsystems.files.core.subsystems.RemoteFileSubSystem.list(RemoteFileSubSystem.java:976)The user ran into this problem was on RSE-runtime-M20110316-2215.zip and that worked fine for him.Createdpatch to synchronize on mapsCan you see if this patch helps?Thank you for the patch, Dave. I can't actually reproduce the problem myself. I tried to do a source look up in a directory which contains a lot of files. And I got the following problem and the source look up didn't return.Thread[Worker-11,TIMED_WAITING,47] java.lang.Object.wait(Native Method) java.lang.Object.wait(Object.java:196) org.eclipse.rse.services.dstore.util.DStoreStatusMonitor.waitForUpdate(DStoreStatusMonitor.java:372) org.eclipse.rse.services.dstore.util.DStoreStatusMonitor.waitForUpdate(DStoreStatusMonitor.java:288) org.eclipse.rse.services.dstore.util.DStoreStatusMonitor.waitForUpdate(DStoreStatusMonitor.java:236) org.eclipse.rse.services.dstore.AbstractDStoreService.dsQueryCommand(AbstractDStoreService.java:129) org.eclipse.rse.internal.services.dstore.files.DStoreFileService.getFile(DStoreFileService.java:1270) org.eclipse.rse.subsystems.files.core.servicesubsystem.FileServiceSubSystem.updateRemoteFile(FileServiceSubSystem.java:594) org.eclipse.rse.subsystems.files.core.servicesubsystem.FileServiceSubSystem.list(FileServiceSubSystem.java:575) org.eclipse.rse.subsystems.files.core.subsystems.RemoteFileSubSystem.list(RemoteFileSubSystem.java:977)The connection was still active and I tried to expand a filter in RSE. But it did return either.Thread[Worker-13,TIMED_WAITING,90] java.lang.Object.wait(Native Method) java.lang.Object.wait(Object.java:196) org.eclipse.rse.services.dstore.util.DStoreStatusMonitor.waitForUpdate(DStoreStatusMonitor.java:372) org.eclipse.rse.services.dstore.util.DStoreStatusMonitor.waitForUpdate(DStoreStatusMonitor.java:288) org.eclipse.rse.services.dstore.util.DStoreStatusMonitor.waitForUpdate(DStoreStatusMonitor.java:236) org.eclipse.rse.services.dstore.AbstractDStoreService.dsQueryCommand(AbstractDStoreService.java:129) org.eclipse.rse.internal.services.dstore.files.DStoreFileService.fetch(DStoreFileService.java:2187)I then tried to expand root and it didn't return. java.lang.Object.wait(Native Method) java.lang.Object.wait(Object.java:196) org.eclipse.rse.services.dstore.util.DStoreStatusMonitor.waitForUpdate(DStoreStatusMonitor.java:372) org.eclipse.rse.services.dstore.util.DStoreStatusMonitor.waitForUpdate(DStoreStatusMonitor.java:288) org.eclipse.rse.services.dstore.util.DStoreStatusMonitor.waitForUpdate(DStoreStatusMonitor.java:236) org.eclipse.rse.services.dstore.AbstractDStoreService.dsQueryCommand(AbstractDStoreService.java:129) org.eclipse.rse.services.dstore.AbstractDStoreService.dsQueryCommand(AbstractDStoreService.java:97) org.eclipse.rse.internal.services.dstore.files.DStoreFileService.getRoots(DStoreFileService.java:1986) org.eclipse.rse.subsystems.files.core.servicesubsystem.FileServiceSubSystem.getRoots(FileServiceSubSystem.java:389)Something seems to be wrong with the server. I'll attach the stack traceCreatedStacktraceSamuel, do you see that stacks you're hitting as the same problem as the one your customer hit? Is there a way to reproduce this from pure RSE (i.e. without your source lookup mechanism)?Hi Dave,When I tried the Remote Folder source look up with the same directory, it simply returned quickly with the source not found message. But the source file was in a subdirectory of the remote folder. That's why the customer switch to the source look up of our own.I also did a file search on the same file in the same directory in RSE. It ended up with a connection drop. I didn't see the out of memor message on the server side when I let the server to launch in the foreground.(In reply to)Samuel, it looks like you're described a few different problems. I'm not sure whether this bug is the place each of these issues. For whatever is reproducible via RSE, could you provide me with a environment that I could use to hit the problem?A bit of further investigation shows that a possible cause of the problem is that the RSE server had run out of memory but the RSE connection didn't drop. When the user tried to get anything from the GUI thread, it locked up the GUI.We may want to terminate the dstore server once it runs out of memory.Createdpatch to check for outofmemory errorsThe attached patch will detect out of memory errors and attempt exit. It's still possible that in some of those cases, an out of memory error will be hit during the exit. I've committed the patch to the HEAD stream. Do you need this backported?was opened for backporting. Thanks.Createdadditional patch to deal with other out of memory casesThere are a couple more cases that can be handled.Createda couple more casesI committed the updated patch.Catching away the OutOfMemoryError seems an odd way handling this.Here are a couple thoughts:1.) Has it ever been analyzed why the OOME occurs ? The Eclipse Memory Analyzer makes it fairly easy to analyze a heap dump. On an Oracle VM, just launch with "-vmargs -XX:+HeapDumpOnOutOfMemoryError". For other VM's see2.) OutOfMemoryError is a subclass of "Error" for which the Java API Docs say: "An Error is a subclass of Throwable that indicates serious problems that a reasonable application should not try to catch." My understanding is that an OOME should terminate the app automatically. Unless the dstore sever catches Error or Throwable somewhere else ? I suggest checking whether dstore server catches away errors, since it shouldn't do that. Similar errors (eg ThreadDeatch) would otherwise likely lead to the same problem we see here.3.) Note that some VM's allow running a command on OutOfMemoryError. This could eg be used to re-start the server ... see - -XX:OnError="<cmd args>;<cmd args>" -XX:OnOutOfMemoryError="<cmd args>;<cmd args>" here:This seems to make more sense than just do a hardcoded exit...I'm not going to enforce any of these suggestions (Wind River doesn't use dstore) but I'll reopen the bug for comments. Feel free to mark closed again if you think these comments are bogus.REOPENED doesn't look like a proper state for this, can you look at some of my thoughts and comment ?	20.0
id=305493	REOPENED	CDT	cdt-doc	0 DD 1.1	All Windows XP	P3 normal	L. Frank Turovich	2010-03-11 09:17 EST by	RenÃ© ijkerk	2010-04-24 13:11 EDT (	1 user	Build Identifier: M20100211-1343Currently there is no documentation available for the Memory Browser View. Pressing F1 in the view results in "The context help for this user interface element could not be found." Please add it. In general, when you add a new feature, document it ;-)Reproducible: AlwaysSteps to Reproduce:1. Open the Memory Browser (Window > Show View > Other > Debug > Memory Browser)2. Press F1Help is missing.	F1 is working on the Memory view in Build id: I20100312-1448.(In reply to)Dear Frank,I'm not talking about the Memory view. I'm talking about the new Memory Browser view and it's corresponding dialogs, org.eclipse.cdt.debug.ui.memory.memorybrowser.Okay, I've got it now, but from looking atthere doesn't yet appear to be a consensus on the Memory Browser view. Its an optional view and one I'm not sure a lot of people know about or use at this time.Anyone else want to chime in for getting the Memory Browser view documented?	3.0
id=420982	REOPENED	PTP	RDT.sync	7.0.3	PC Linux	P3 normal	Greg Watson	2013-11-04 07:35 EST by	Gianluca Bertaina	2016-03-01 12:20 EST (	2 users	In a clean installation of PTP 8 and Eclipse Kepler on a Linux (Ubuntu 13.04 64bit), if I create a Fortran project in a clean workspace, then I convert it to a Synchronized project, when I right-click on the project in the Project Explorer view I can change the active synchronized configuration via Synchronize/Set Active. However, if I do the same thing in the Fortran Projects view, the menu Set Active suddenly gets grey and I cannot access the synchronized configurations. Even if I left-click on the project in Project Explorer and then right-click on the project in Fortran Projects, the Set Active menu gets grey.Of course I can from the "Manage..." option or the project settings.	Patch set:The same problem occurs in the C++ Project View (the Fortran Projects View is a subclass of this).Unfortunately it doesn't look like it's possible to add the synchronized icon to the project in these views.Committed.Still happens on a clean Eclipse Mars installationThe drop-down menu next to the synchronize button (double arrow) in the tool bar also becomes inactive. Most likely this is caused by the same underlying bug.	4.0
id=409470	REOPENED	PTP	RDT.sync	7.0	Macintosh Mac OS X	P3 normal	Greg Watson	2013-05-30 05:19 EDT by	Greg Watson	2015-06-23 16:39 EDT (	2 users	On some platforms, it is possible to open the project context menu without the Project Explorer view having focus (e.g. Mac OS X). In this case, the synchronize menu is missing from the context menu.Repeat by:1. Left click on a synchronized project in the Project Explorer view.2. Right click on the project and verify that the context menu contains the Synchronize menu.3. Move focus to a view other than the Project Explorer (e.g. by left clicking in the editor view).4. Without restoring focus to the Project Explorer, right click on the synchronized project.5. The context menu should be displayed without the synchronize menu.	Fixed in master.Maybe this is a related effect:Sometimes the synchronize menu item is missing completely, also when the focus is within the project explorer.This is in Kepler under Linux and happens with different projects at different times. It seems to me that it occurs more frequently since the last update.It seems this is not fully fixed. If the synchronize menu is selected when Project Explorer does not have focus, it is not fully functional. If I select "Set Active" it is greyed out and does not open. The "Auto-Sync Settings" submenu does not show a checkmark next to the current setting. If I select "Sync Active" or something else, I get the log message "Unable to get project". This is on Mac OS X.Daniel: The synchronize menu item only appears for a right click on a synchronized project. It does not appear for files, folders, etc. This is a regression in Kepler. It used to appear for both of these if they were contained inside a synchronized project.(In reply to)This is not a regression. Including the menu on files and folders gives the impression that it is possible to synchronize just these resources, but it is in fact a project-level operation. Restricting the menu to just the project reinforces this fact.(In reply to)Can you provide an exact sequence to reproduce this? Even if I have another window covering the Eclipse window (e.g. Safari), then right click in the project explorer, I'm seeing a synchronize context menu and can select Sync Active Now, etc.(In reply to)Yes, the menu is present and works partially. It is only (at least) the two items mentioned inthat aren't working. The steps to reproduce are similar to what you listed before:1. Left click on a synchronized project in the Project Explorer view.2. Move focus to a view other than the Project Explorer (e.g. by left clicking in the editor view).3. Without restoring focus to the Project Explorer, right click on the synchronized project.4. The context menu contains the synchronized menu but with the problems described in: a) "Set Active" submenu does not open. b) "Auto-Sync Settings" submenu does not work properly (no checkmark and the log message "Unable to get project" if you click on any of the options).It looks like this no longer happens in Luna (at least on the Mac). Please verify.This problem still occurs for me on mac for the Luna RC2 development build. All items, except for the submenus, are greyed out after following the steps in. OS X version is 10.8.5.I don't see this in either RC2 or my workspace (I am seeing the Synchronize menu disappear -). I'm using OSX 10.9.3 with Java 1.8, so maybe this has something to do with it.The "Auto-Sync (Global)" setting is not checked until I mouse over it, but this may be a lazy loading issue. It doesn't seem too serious in any case.I don't see this in Mars RC4 at all. Are you still seeing the problem?	10.0
id=277354	REOPENED	PDT	PHP Explorer & Projects management	2.1	All All	P3 normal	Roy Ganor	2009-05-21 12:53 EDT by	Anton Danilchenko	2010-05-27 07:04 EDT (	1 user	I select folder for my working set and select this working set (activate).Create subfolder in working set.Actual result: this folder not show in my working set!Expected result: created in working set directories shiuld automatically add in current working set.P.S. Now inconvenient select elements for new working set. Please, show OLD style in hierarchy instead of flat list.	Please, fix itHi Anton I do not know how to reproduce your bug,can you supply the steps to reproduce it,thanksworks for meI think I understand what Anton means and was able to reproduce it. Try this:1. Create the following projects structure:Project_name+ folderA+ + folderB1+ folderC2. Create a new working set for folderA and select this working set to be active. In the PHP Explorer you should see the following:Project_name+ folderA+ + folderB13. While you are in the activated working set create another folderB2 under folderAResult: You do not see this folderB2. Instead ofProject_name+ folderA+ + folderB1+ + folderB2you still see onlyProject_name+ folderA+ + folderB1Note1: If you deselect the working set and get back to normal view you see that folderB2 is created and visible.Note2: If you open the working set for editing you will see that the selection is no longer on the whole folderA as in the beginning but only on its subfolder folderB1, which is not correct.Reopening[Sylvia Tancheva -]	4.0
id=400073	REOPENED	CDT	cdt-indexer	8.1.1	PC Windows 7	P3 normal	Sergey Prigogin	2013-02-06 05:43 EST by	Kai Benndorf	2016-09-26 03:32 EDT (	27 users	I am using a workspace containing several projects (libraries and executable). Until recently I used Eclipse CDT in the Indigo release and all works fine. Recently I tried to update to the current Juno release and got an error everytime the indexer runs:An internal error occurred during: "Update Monitor".Java heap spaceStarting eclipse with the -vmargs -Xmx1024m option does not improve the situation. So I switched back to indigo for now.Removing the include paths to Qt in the C/C++ General/Path and Symbols section removes this problem, but is not an option because I like to have Qt in the index.I tried to reproduce this problem in a small workspace containing a single file and using Qt, but there the problem does not occur. As the big workspace contain all our company code, I am sorry, but I cannot provide the workspace for you to reproduce the problem.	java.lang.OutOfMemoryError: Java heap spaceDialog open exception:java.lang.NullPointerException at org.eclipse.ui.internal.ide.IDEWorkbenchErrorHandler.openQuestionDialog(IDEWorkbenchErrorHandler.java:195) at org.eclipse.ui.internal.ide.IDEWorkbenchErrorHandler.handleException(IDEWorkbenchErrorHandler.java:154) at org.eclipse.ui.internal.ide.IDEWorkbenchErrorHandler.access$0(IDEWorkbenchErrorHandler.java:146) at org.eclipse.ui.internal.ide.IDEWorkbenchErrorHandler$1.runInUIThread(IDEWorkbenchErrorHandler.java:121) at org.eclipse.ui.progress.UIJob$1.run(UIJob.java:95) at org.eclipse.swt.widgets.RunnableLock.run(RunnableLock.java:35) at org.eclipse.swt.widgets.Synchronizer.runAsyncMessages(Synchronizer.java:135) at org.eclipse.swt.widgets.Display.runAsyncMessages(Display.java:4144) at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3761) at org.eclipse.swt.widgets.Display.release(Display.java:3814) at org.eclipse.swt.graphics.Device.dispose(Device.java:295) at org.eclipse.ui.internal.ide.application.IDEApplication.start(IDEApplication.java:140) at org.eclipse.equinox.internal.app.EclipseAppHandle.run(EclipseAppHandle.java:196) at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:110) at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:79) at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:353) at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:180) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) at java.lang.reflect.Method.invoke(Unknown Source) at org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:629) at org.eclipse.equinox.launcher.Main.basicRun(Main.java:584) at org.eclipse.equinox.launcher.Main.run(Main.java:1438)Can you use Memory Analyserto look what objects take most memory or just acquire heap dump?The top components listed by Eclipse Memory Analyzer are:org.eclipse.ctd.core (43%)org.eclipse.core.jobs (37%)org.eclipse.ctd.ui (10%)Is this what you want to know?The .hprof file is around 300 MB. If you like I can attach it here, if not too big, or copy to any ftp server.I'd be interested to take a look. I suppose if bugzilla lets you attach it it is not against the policy. If not I can take from ftp server or you can send it to me privately.CreatedThe heap dump as a zip archiveI can confirm this issue. I'm having exactly the same error in Juno.Increasing the heap size does not resolve anything. Also removing Qt includes solves the problem, but also this is not an option as I don't have Qt indexed then. In eclipse 3.8 everything is working fine, so I'll keep using it until this can be resolved. I am using Debian x64 with OpenJDK 1.6(In reply to)This heapdump does not indicate problems with heap. There is only 250Mb of heap used total, nothing out of ordinary.I created this heapdump by starting eclipse as follows.c:/Program\ Files\ \(x86\)/eclipse-juno/eclipse -vmargs -XX:+HeapDumpOnOutOfMemoryError & I just repeated this step and got a heap dump of similar size. I could upload this again, but I fear that it would be similar.Add -Xmx1024m option, otherwise we may not even get to the real problem. The bigger the heapdump the better for troubleshooting.CreatedHeapdump with -Xmx1024m option(In reply to)It appears that instances of CPPASTName hold over 500Mb of heap space here... With related objects it is over 800Mb of heap. Everything else appears normal.Class Name | Objects | Shallow Heap | Retained Heap---------------------------------------------------------------------------------------------------org.eclipse.cdt.internal.core.dom.parser.cpp.CPPASTName| 1,854,409 | 89,011,632 | >= 552,818,640---------------------------------------------------------------------------------------------------Well, somebody with better expertise in indexer/parser than me should take it from here.(In reply to)When one of the first indexed source files directly or indirectly includes many header files, all that volume of code has to be parsed together. To verify how large the code is you can pass the source file causing stack overflow through the C++ preprocessor. 1.8 million is a lot of names. With 4 names per line this is equivalent to 450000 lines of code. Compare your preprocessed file to that and try to estimate the number of names in it.This may be, It is a quite big workspace containing several libraries and executables with a lot of files. How should I detect the one that causes the overflow?By the way does Juno need so much more memory than indigo? indigo runs without an -Xmx1024m argument, so it seems to be still quite modest with memory.(In reply to)Total size of the project doesn't matter as much as the number of header files included directly or indirectly into one of the first files being indexed.Watch Progress View for the file being indexed when Eclipse runs out of memory.I have located the file where the indexer runs out of memory. After running the MSVC preprocessor and removing empty lines from the output I get a file of 161588 lines.If I apply your rule of thumb, 4 names per line, I would get around 600.000 names.Additionally I observed that the file contains a lot of template code.(In reply to)Hmm, 600K names is more than 3 times less than 1854K names reported by the profiler. Can you attempt to get a more accurate name count by replacing all nonalphanumeric characters with spaces and counting the number of words after that?I tried to get a more accurate count, by1) Removing non alphanumeric characterssed 's/[^a-zA-Z0-9]/ /g' prepro-clean.txt > prepro-clean2.txt2) Replace white space by newlinesed 's/\s\+/\n/g' prepro-clean2.txt > prepro-clean3.txt 3) Count lineswc -l prepro-clean3.txt => 13019144) Remove duplicatessort -f prepro-clean3.txt | uniq > prepro-clean4.txt5) Count lines without duplicateswc -l prepro-clean4.txt => 11328(In reply to)You also need to replace C/C++ keywords with spaces.Each name occurrence requires a separate object. No need to remove duplicates.How should I do this ?Why? This sounds like a defect in the indexer, if it has to create separate objects for the same identifiers.And the question of why such a regression in Juno vs. Indigo still stands big time.P.S. I have the same problem -- the code that Indigo indexer was able to index without a problem now causes Juno indexer to run out of memory.(In reply to)Each name contains unique location information that is later stored in the index. This location information is used by C/C++ search, call hierarchy, etc.(In reply to)Got it. Still, there is an obvious regression in Juno, regarding the memory utilization by the Indexer. I've given Juno 2gb heap, and it still could not finish what Indigo could with just 1gb heap.(Going back to these records, I would assume that 99% of identifiers in a translation unit are duplicates. Does the entire record have to be replicated, or is there lots of common information that can be shared by those records?)I had the same problem with the indexer consuming up to more than 30GB of memory without progressing (always at the same percentage) before I had to kill it.A workaround for me was decreasing the indexers absolute cache limits from 64MB to 32MB, though I don't know if this will work in general. You may find the settings at Window -> Preferences -> C/C++ -> Indexer(In reply to)How does indexer statistics (written to error log on rebuild) compares between Juno and Indigo?If you look at CPPASTName and the classes it extends, you will find that only a small fraction of data could be shared.CreatedOptions file to enable indexer tracingI'm also running OutOfMemory with CDT 8.1.2 and it looks like the BOOST library is involved somehow in my case.It looks like Kai got pretty far by being able to create a heapdump and isolating the problem to one specific file. Kai also mentioned that there was a lot of template code. I'm wondering whether BOOST was involved in Kai's case and if yes, what version of BOOST. Maybe if Kai could extract the list of include files pulled in in his case, then Sergey could reproduce the case with a minimal *.cpp file just pulling in those headers that are Open Source.In either case, generating a parser log file would help (both to identify the list of headers included, to get the statistics, and to see whether any syntax errors are involved).Please download attached indexer-debug-options.txt and save it in the root of your Eclipse install, then run Eclipse like this to pipe output into a file:cd eclipsehomejava -XX:MaxPermSize=512m -Xmx2048m -jar plugins\org.eclipse.equinox.launcher_*.jar -debug indexer-debug-options.txt > indexer-debug.lognow open your project in the UI and make sure that your problematic file gets indexed (for instance, right-click > Index > Generate Parser Log on the file).I fear I am of not much help. Starting eclipse this time, with the given call, it get the heap dump while parsing another file (albeit of the same module).I append the parser log generated on this file.We are using boost, too, so this would be an optionCreatedindexer-debug-logCreatedParser LogIt would be really helpful if somebody could create a reproducible example using just the open source headers that requires more than 1GB to index.It seems to be fixed for me on build id: 20130225-0426 (tested on debian sid x64 and debian wheezy x86)Kai, would you be able to provide a similar heap dump from your workspace when indexing succeeds without running out of memory? Either using Indigo or a newer build (if you've found the problem has gone away as Javier suggests) would be equally helpful.I'm trying out a new kind of heap dump analysis tool and this problem is a good case study for it.Thanks very much,RobinWhere can I download a fixed build?Below my experience with the problem, maybe can be helpful:I experienced the same problem for Juno (Eclipse IDE for C/C++ Developers / Version: Juno Service Release 2 / Build id: 20130225-0426) when trying to index a project that has boost dependency (quantlib.org). I did not try to modify the eclipse.ini, I jumped directly to nightly builds (Eclipse SDK /Version: 4.4.0/ Build id: N20130624-2000 and CDT from). With the default eclipse.ini I got the same problem. But changing parameters to --launcher.XXMaxPermSize1024m--launcher.defaultActionopenFile--launcher.appendVmargs-vmargs-Xms256m-Xmx1024mThe indexer worked fine.In a glance, an 'nightly' environment with more memory did not reproduce the problem.(In reply to)Indexing the same library (QuantLib), I got a ClassCastException, see. It also ran out of memory with the default -Xmx512m, see screenshot.CreatedMemory Analyzer screenshot(In reply to)What are the titles of the columns in the Memory Analyzer screenshot?CreatedMemory Analyzer screenshot, grouped by classSorry, I was a by too aggressive with the cropping.CreatedMemory Analyzer screenshot, no groupingThe HashMap that is shown in Memory Analyzer is most likely PDOM.fResultCache. Keys in that cache are AST bindings, so they hold the whole AST in memory. Maybe we are not calling PDOM.clearResultCache() as often as we should.I don't think the PDOM.fResultCache map is the main cause of the memory issue Kai originally reported: it's only holding on to 50 MB of space in the attached heap dump. Might be an independent issue.I'm having a go at diagnosing this using a tool that can execute the CDT source code against the heap dump. I think I'm finding useful information but I don't know enough about the CDT implementation to arrive at any firm conclusions. I'm starting with the theory that there are a lot of duplicate CPPASTNames, where I'm defining "duplicate" as same name and node locations (i.e. using a unique key of "name.toString() + " - " + Arrays.toString(name.getNodeLocations())"). Does that definition make sense? Is there another source-level analysis I should try instead?I believe I've made some real progress on this bug.Using the research tool I've developed that I mentioned earlier, I've been analyzing the set of CPPASTName instances by the source location they come from. There seems to be a lot of duplicates. That is, names with the same content and the same location, as calculated by methods like getNodeLocations().I've attached some data files in case it helps find the actual bug. The first is the results of grouping the first 100,000 names by location. You can see just how many duplicates are coming from boost libraries, and especially macros in those libraries.The second is a list of the locations (more precisely this time - differentiating distinct expansions of the same macro) of all names for a particular symbol in the Boost library ("return_type_N_prot") - you can see that there are 15 instances for each occurrence of the macro in question (source here:). I also attached the code I used. Perhaps we're ending up with a separate name instance every time the header is included?Please let me know if I've missed something, or if there's something else I can try running to further diagnose things. I could definitely use some guidance from someone who knows the code better than I do!CreatedDuplicate names in the first 100,000 CPPASTName objectsCreatedPrecise locations of all "return_type_N_prot" namesCreatedDuplicate CPPASTName analysis Java code(In reply to)I't a common practice in boost library to include the same header multiple times but with different macro definitions so that each inclusion produces different code.Ah, I'm not familiar with that technique. What would that looks like in source code? Would you have to manually undef the include guard in order to actually include the header text multiple times?(In reply to)I'm not sure if multiple inclusion applies to lambda_functor_base.hpp. Usually it is done with files without include guards.You can enable /debug/scanner and /debug/scanner/missingIncludeGuards tracing options to get some insight into it.Okay, I think I may have found the actual source of the leak.I discovered that each of the 15 duplicate "return_type_N_prot" names are actually contained by 15 separate parse trees for the same compilation unit. That is, 15 different instances of CPPASTTranslationUnit returning the same .cpp path from getFilePath().Digging into what's keep the different trees alive, it turns out that one thread has references to all of them via thread locals. The "Worker-3" thread (0x1be3d568) retains 824MB of heap in its "threadLocals" field.It looks like the CPPClassSpecialization.fInProgress thread local is at least partially to blame for the leak. It's populated to avoid infinite recursion but never cleared. There may be other leaks caused by thread locals as well, as I haven't done the math to figure out if that one is responsible for all or most of the member, but it at least looks like a big chunk of it.(In reply to)Thanks a lot for your investigative work. Submitted an attempted fix.*** cdt git genie on behalf of Sergey Prigogin ***- Indexer runs out of memory. An attempt to fix a memory leak.[*](In reply to)No problem! Honestly it was all for selfish reasons anyway. :) I needed a compelling case study for my research and this happened to fit the bill.(In reply to)Pretty impressive. Will your research materialize into a new freeware or open source memory analysis tool?I'm definitely planning on making the tool available, once I get past my paper deadline this week. :) It's currently just a set of plugins for the Eclipse Memory Analyzer tool, but I could make some features easier to use if I hacked the tool directly.Robin, do you see any improvement with the latest changes?You're asking the wrong person. :) I never actually reproduced the bug, or tired, really. I just worked with the heap dump that Kai uploaded.(In reply to)Any chance to get this into the 8.2.1 release?(In reply to)The change is in 8.2.1 already.(In reply to)Cool. The git genie script () did not say anything about which branch. So I expected your commit would be in master only.(In reply to Robin Salkeld from)Hi all,For anyone interested, I've made my tool available for installation into Eclipse. It adds a few additional custom queries to the Memory Analyzer tool.I've done my best to document the basics but it's still very much a research prototype. :)Cheers,RobinI just updated to latest CDT 2.0.1.20130919 on Linux 64bit and the indexer still eats ups 16+GB RAM, standing at 4% steadily. We also have boost. :( Does that CDT version contain this fix mentioned to be in 8.2.1 SR?(In reply to Mekk Elek from)What is 2.0.1.20130919? The latest release CDT version id 8.2.1.(In reply to Sergey Prigogin from)It's the version for the C/C++ EPP (Eclipse IDE for C/C++ Developers).(In reply to Marc-Andre Laperle from)I just double checked and the EPP does contain the correct 8.2.1 version. C/C++ Development Tools 8.2.1.201309180223I recently started using boost with Eclipse Kepler and I have run into memory issues as well. The CDT version in use is 8.2.1.201309180223.eclipse.ini looks like this:startupplugins/org.eclipse.equinox.launcher_1.3.0.v20130327-1440.jar--launcher.libraryplugins/org.eclipse.equinox.launcher.gtk.linux.x86_1.1.200.v20130807-1835-productorg.eclipse.epp.package.cpp.product--launcher.defaultActionopenFile-showsplashorg.eclipse.platform--launcher.XXMaxPermSize1024m--launcher.defaultActionopenFile--launcher.appendVmargs-vmargs-Dosgi.requiredJavaVersion=1.6-Xms256m-Xmx1024mI have taken a heap dump using the Eclipse memory analyser and have run the Leak Suspects report. It finds two problem suspects. Out of a total heap of 603.4 MB suspect 1 uses 410 MB and suspect 2 uses 124 MB.Suspect 1: 29,584 instances of "java.lang.ref.Finalizer", loaded by "<system class loader>" occupy 429,936,896 (67.95%) bytes.Suspect 2: 8 instances of "org.eclipse.cdt.internal.core.parser.scanner.LocationMap", loaded by "org.eclipse.cdt.core" occupy 72,802,744 (11.51%) bytes.I have attached the dominator tree for one of the many Finalizer objects holding an org.eclipse.cdt.codan.core.cxx.model.CxxModelsCache object, which account for most of the memory use of the Finalizer. Maybe it is of help to someone.Best regards,MarkusCreatedDominator tree for finalizer objectFixed by commit.Everybody who experienced this problem, please verify that there is no remaining leak.*** cdt git genie on behalf of Sergey Prigogin ***- Indexer runs out of memory. Fixed a soft memory leak caused by accumulation of data in PDOM.fResultCache when several consecutive files fail to parse.[*]*** cdt git genie on behalf of Sergey Prigogin ***- Indexer runs out of memory. An attempt to reduce memory consumption.[*](In reply to Sergey Prigogin from)If you can point me to instructions on how to do this, I would gladly test your fix.(In reply to Markus Schöpflin from)You can use this update site in "Install New Software" to update your CDT to the lastest nightly build:*** cdt git genie on behalf of Sergey Prigogin ***- More robust clearing of results cache.[*]*** cdt git genie on behalf of Sergey Prigogin ***- More robust clearing of results cache.[*]*** cdt git genie on behalf of Sergey Prigogin ***- Indexer runs out of memory. Fixed a soft memory leak caused by accumulation of data in PDOM.fResultCache when several consecutive files fail to parse.[*]I tested the fix using the CDT version 8.3.0.201312061958 and the results are impressive. Whilst the heap size does jump to the configured maximum value (990M in my case) from time to time, it always returns to the same level of about 250MB.I also observed a general speed improvement for suggestions and code completions; and the indexer now finds references which it did not find before. (Interestingly, the indexer seems unable to merge C and C++ references, as I'm getting two distinct sets of references when looking up certain symbols either from C or C++ code, but this is another matter.)Thank you very much for the fix!Similar problem after just unzipped Kepler on a 64x Ubuntu 13.10 machine.Opened marketplace then got:./eclipse 2014-02-21 16:19:45,920 [Worker-0] INFO o.e.m.c.i.i.nexus.NexusIndexManager - Updating index for repository: nexus|2014-02-21 16:19:45,962 [Worker-0] INFO c.n.h.c.p.n.NettyAsyncHttpProvider - Number of application's worked threads is 162014-02-21 16:19:46,033 [Worker-0] ERROR o.e.m.c.i.i.nexus.NexusIndexManager - Unable to update index for nexus|java.io.IOException: Conexão recusada toat org.eclipse.m2e.core.internal.index.nexus.AsyncFetcher$PipedErrorInputStream.checkError(AsyncFetcher.java:250) ~[org.eclipse.m2e.core_1.4.0.20130601-0317.jar:na] at org.eclipse.m2e.core.internal.index.nexus.AsyncFetcher$PipedErrorInputStream.read(AsyncFetcher.java:258) ~[org.eclipse.m2e.core_1.4.0.20130601-0317.jar:na] at java.io.PipedInputStream.read(PipedInputStream.java:378) ~[na:1.7.0_09] at java.io.InputStream.read(InputStream.java:101) ~[na:1.7.0_09] at java.util.Properties$LineReader.readLine(Properties.java:434) ~[na:1.7.0_09] at java.util.Properties.load0(Properties.java:353) ~[na:1.7.0_09] at java.util.Properties.load(Properties.java:341) ~[na:1.7.0_09] at org.apache.maven.index.updater.DefaultIndexUpdater.downloadIndexProperties(DefaultIndexUpdater.java:457) ~[indexer-core-3.1.0.jar:3.1.0] at org.apache.maven.index.updater.DefaultIndexUpdater.access$100(DefaultIndexUpdater.java:75) ~[indexer-core-3.1.0.jar:3.1.0] at org.apache.maven.index.updater.DefaultIndexUpdater$IndexAdaptor.setProperties(DefaultIndexUpdater.java:607) ~[indexer-core-3.1.0.jar:3.1.0] at org.apache.maven.index.updater.DefaultIndexUpdater.fetchAndUpdateIndex(DefaultIndexUpdater.java:788) ~[indexer-core-3.1.0.jar:3.1.0] at org.apache.maven.index.updater.DefaultIndexUpdater.fetchAndUpdateIndex(DefaultIndexUpdater.java:135) ~[indexer-core-3.1.0.jar:3.1.0] at org.eclipse.m2e.core.internal.index.nexus.NexusIndexManager.updateRemoteIndex(NexusIndexManager.java:1126) [org.eclipse.m2e.core_1.4.0.20130601-0317.jar:na] at org.eclipse.m2e.core.internal.index.nexus.NexusIndexManager.updateIndex(NexusIndexManager.java:1083) [org.eclipse.m2e.core_1.4.0.20130601-0317.jar:na] at org.eclipse.m2e.core.internal.index.nexus.NexusIndexManager$1.run(NexusIndexManager.java:660) [org.eclipse.m2e.core_1.4.0.20130601-0317.jar:na] at org.eclipse.m2e.core.internal.index.nexus.IndexUpdaterJob.run(IndexUpdaterJob.java:72) [org.eclipse.m2e.core_1.4.0.20130601-0317.jar:na] at org.eclipse.core.internal.jobs.Worker.run(Worker.java:53) [org.eclipse.core.jobs_3.5.300.v20130429-1813.jar:na]java.net.ConnectException: Conexão recusada toat com.ning.http.client.providers.netty.NettyConnectListener.operationComplete(NettyConnectListener.java:95) ~[na:na] at org.jboss.netty.channel.DefaultChannelFuture.notifyListener(DefaultChannelFuture.java:381) ~[na:na] at org.jboss.netty.channel.DefaultChannelFuture.notifyListeners(DefaultChannelFuture.java:372) ~[na:na] at org.jboss.netty.channel.DefaultChannelFuture.setFailure(DefaultChannelFuture.java:334) ~[na:na] at org.jboss.netty.channel.socket.nio.NioClientSocketPipelineSink$Boss.connect(NioClientSocketPipelineSink.java:389) ~[na:na] at org.jboss.netty.channel.socket.nio.NioClientSocketPipelineSink$Boss.processSelectedKeys(NioClientSocketPipelineSink.java:354) ~[na:na] at org.jboss.netty.channel.socket.nio.NioClientSocketPipelineSink$Boss.run(NioClientSocketPipelineSink.java:276) ~[na:na] at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108) ~[na:na] at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:44) ~[na:na] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110) ~[na:1.7.0_09] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603) ~[na:1.7.0_09] at java.lang.Thread.run(Thread.java:722) ~[na:1.7.0_09]Caused by: java.net.ConnectException: Conexão recusada at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[na:1.7.0_09] at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:692) ~[na:1.7.0_09] at org.jboss.netty.channel.socket.nio.NioClientSocketPipelineSink$Boss.connect(NioClientSocketPipelineSink.java:384) ~[na:na] at org.jboss.netty.channel.socket.nio.NioClientSocketPipelineSink$Boss.processSelectedKeys(NioClientSocketPipelineSink.java:354) ~[na:na] at org.jboss.netty.channel.socket.nio.NioClientSocketPipelineSink$Boss.run(NioClientSocketPipelineSink.java:276) ~[na:na] ... 3 common frames omitted2014-02-21 16:19:47,548 [Worker-6] WARN o.e.m.c.i.embedder.EclipseLogger - The artifact jdom:jdom:jar:1.1 has been relocated to org.jdom:jdom:jar:1.1Exception in thread "ModalContext" Exception: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread "ModalContext"Error while logging event loop exception:(In reply to Tesso Costa from)Is it with CDT 8.3?(In reply to Sergey Prigogin from)Im using the contents of eclipse-jee-kepler-SR1-linux-gtk-x86_64.tar.gzJava(TM) SE Runtime Environment (build 1.7.0_09-b05)Java HotSpot(TM) 64-Bit Server VM (build 23.5-b02, mixed mode)Well, just found out that i cant even enter on install details on about screen! oh good lord!2014-02-21 16:39:18,835 [Worker-3] INFO o.e.m.c.i.i.nexus.NexusIndexManager - Updating index for repository: nexus|2014-02-21 16:39:18,869 [Worker-3] INFO c.n.h.c.p.n.NettyAsyncHttpProvider - Number of application's worked threads is 162014-02-21 16:39:18,924 [Worker-3] ERROR o.e.m.c.i.i.nexus.NexusIndexManager - Unable to update index for nexus|java.io.IOException: Conexão recusada toat org.eclipse.m2e.core.internal.index.nexus.AsyncFetcher$PipedErrorInputStream.checkError(AsyncFetcher.java:250) ~[org.eclipse.m2e.core_1.4.0.20130601-0317.jar:na] at org.eclipse.m2e.core.internal.index.nexus.AsyncFetcher$PipedErrorInputStream.read(AsyncFetcher.java:258) ~[org.eclipse.m2e.core_1.4.0.20130601-0317.jar:na] at java.io.PipedInputStream.read(PipedInputStream.java:378) ~[na:1.7.0_09] at java.io.InputStream.read(InputStream.java:101) ~[na:1.7.0_09] at java.util.Properties$LineReader.readLine(Properties.java:434) ~[na:1.7.0_09] at java.util.Properties.load0(Properties.java:353) ~[na:1.7.0_09] at java.util.Properties.load(Properties.java:341) ~[na:1.7.0_09] at org.apache.maven.index.updater.DefaultIndexUpdater.downloadIndexProperties(DefaultIndexUpdater.java:457) ~[indexer-core-3.1.0.jar:3.1.0] at org.apache.maven.index.updater.DefaultIndexUpdater.access$100(DefaultIndexUpdater.java:75) ~[indexer-core-3.1.0.jar:3.1.0] at org.apache.maven.index.updater.DefaultIndexUpdater$IndexAdaptor.setProperties(DefaultIndexUpdater.java:607) ~[indexer-core-3.1.0.jar:3.1.0] at org.apache.maven.index.updater.DefaultIndexUpdater.fetchAndUpdateIndex(DefaultIndexUpdater.java:788) ~[indexer-core-3.1.0.jar:3.1.0] at org.apache.maven.index.updater.DefaultIndexUpdater.fetchAndUpdateIndex(DefaultIndexUpdater.java:135) ~[indexer-core-3.1.0.jar:3.1.0] at org.eclipse.m2e.core.internal.index.nexus.NexusIndexManager.updateRemoteIndex(NexusIndexManager.java:1126) [org.eclipse.m2e.core_1.4.0.20130601-0317.jar:na] at org.eclipse.m2e.core.internal.index.nexus.NexusIndexManager.updateIndex(NexusIndexManager.java:1083) [org.eclipse.m2e.core_1.4.0.20130601-0317.jar:na] at org.eclipse.m2e.core.internal.index.nexus.NexusIndexManager$1.run(NexusIndexManager.java:660) [org.eclipse.m2e.core_1.4.0.20130601-0317.jar:na] at org.eclipse.m2e.core.internal.index.nexus.IndexUpdaterJob.run(IndexUpdaterJob.java:72) [org.eclipse.m2e.core_1.4.0.20130601-0317.jar:na] at org.eclipse.core.internal.jobs.Worker.run(Worker.java:53) [org.eclipse.core.jobs_3.5.300.v20130429-1813.jar:na]java.net.ConnectException: Conexão recusada toat com.ning.http.client.providers.netty.NettyConnectListener.operationComplete(NettyConnectListener.java:95) ~[na:na] at org.jboss.netty.channel.DefaultChannelFuture.notifyListener(DefaultChannelFuture.java:381) ~[na:na] at org.jboss.netty.channel.DefaultChannelFuture.notifyListeners(DefaultChannelFuture.java:372) ~[na:na] at org.jboss.netty.channel.DefaultChannelFuture.setFailure(DefaultChannelFuture.java:334) ~[na:na] at org.jboss.netty.channel.socket.nio.NioClientSocketPipelineSink$Boss.connect(NioClientSocketPipelineSink.java:389) ~[na:na] at org.jboss.netty.channel.socket.nio.NioClientSocketPipelineSink$Boss.processSelectedKeys(NioClientSocketPipelineSink.java:354) ~[na:na] at org.jboss.netty.channel.socket.nio.NioClientSocketPipelineSink$Boss.run(NioClientSocketPipelineSink.java:276) ~[na:na] at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108) ~[na:na] at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:44) ~[na:na] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110) ~[na:1.7.0_09] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603) ~[na:1.7.0_09] at java.lang.Thread.run(Thread.java:722) ~[na:1.7.0_09]Caused by: java.net.ConnectException: Conexão recusada at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[na:1.7.0_09] at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:692) ~[na:1.7.0_09] at org.jboss.netty.channel.socket.nio.NioClientSocketPipelineSink$Boss.connect(NioClientSocketPipelineSink.java:384) ~[na:na] at org.jboss.netty.channel.socket.nio.NioClientSocketPipelineSink$Boss.processSelectedKeys(NioClientSocketPipelineSink.java:354) ~[na:na] at org.jboss.netty.channel.socket.nio.NioClientSocketPipelineSink$Boss.run(NioClientSocketPipelineSink.java:276) ~[na:na] ... 3 common frames omitted2014-02-21 16:39:20,256 [Worker-1] WARN o.e.m.c.i.embedder.EclipseLogger - The artifact jdom:jdom:jar:1.1 has been relocated to org.jdom:jdom:jar:1.1Error while logging event loop exception:Error while logging event loop exception:ok so my nexus repository is offline, but should not make eclipse crash right?Ok, started nexus!! But still, permgen ./eclipse 2014-02-21 16:43:56,645 [Worker-0] INFO o.e.m.c.i.i.nexus.NexusIndexManager - Updating index for repository: nexus|2014-02-21 16:43:56,688 [Worker-0] INFO c.n.h.c.p.n.NettyAsyncHttpProvider - Number of application's worked threads is 162014-02-21 16:43:57,308 [Worker-4] WARN o.e.m.c.i.embedder.EclipseLogger - The artifact jdom:jdom:jar:1.1 has been relocated to org.jdom:jdom:jar:1.12014-02-21 16:43:57,627 [Worker-0] ERROR o.e.m.c.i.i.nexus.NexusIndexManager - Unable to update index for nexus|java.io.IOException: Server returned status code 404: Not Found at org.eclipse.m2e.core.internal.index.nexus.AsyncFetcher$PipedErrorInputStream.checkError(AsyncFetcher.java:250) ~[org.eclipse.m2e.core_1.4.0.20130601-0317.jar:na] at org.eclipse.m2e.core.internal.index.nexus.AsyncFetcher$PipedErrorInputStream.read(AsyncFetcher.java:258) ~[org.eclipse.m2e.core_1.4.0.20130601-0317.jar:na] at java.io.PipedInputStream.read(PipedInputStream.java:378) ~[na:1.7.0_09] at java.io.InputStream.read(InputStream.java:101) ~[na:1.7.0_09] at java.util.Properties$LineReader.readLine(Properties.java:434) ~[na:1.7.0_09] at java.util.Properties.load0(Properties.java:353) ~[na:1.7.0_09] at java.util.Properties.load(Properties.java:341) ~[na:1.7.0_09] at org.apache.maven.index.updater.DefaultIndexUpdater.downloadIndexProperties(DefaultIndexUpdater.java:457) ~[indexer-core-3.1.0.jar:3.1.0] at org.apache.maven.index.updater.DefaultIndexUpdater.access$100(DefaultIndexUpdater.java:75) ~[indexer-core-3.1.0.jar:3.1.0] at org.apache.maven.index.updater.DefaultIndexUpdater$IndexAdaptor.setProperties(DefaultIndexUpdater.java:607) ~[indexer-core-3.1.0.jar:3.1.0] at org.apache.maven.index.updater.DefaultIndexUpdater.fetchAndUpdateIndex(DefaultIndexUpdater.java:788) ~[indexer-core-3.1.0.jar:3.1.0] at org.apache.maven.index.updater.DefaultIndexUpdater.fetchAndUpdateIndex(DefaultIndexUpdater.java:135) ~[indexer-core-3.1.0.jar:3.1.0] at org.eclipse.m2e.core.internal.index.nexus.NexusIndexManager.updateRemoteIndex(NexusIndexManager.java:1126) [org.eclipse.m2e.core_1.4.0.20130601-0317.jar:na] at org.eclipse.m2e.core.internal.index.nexus.NexusIndexManager.updateIndex(NexusIndexManager.java:1083) [org.eclipse.m2e.core_1.4.0.20130601-0317.jar:na] at org.eclipse.m2e.core.internal.index.nexus.NexusIndexManager$1.run(NexusIndexManager.java:660) [org.eclipse.m2e.core_1.4.0.20130601-0317.jar:na] at org.eclipse.m2e.core.internal.index.nexus.IndexUpdaterJob.run(IndexUpdaterJob.java:72) [org.eclipse.m2e.core_1.4.0.20130601-0317.jar:na] at org.eclipse.core.internal.jobs.Worker.run(Worker.java:53) [org.eclipse.core.jobs_3.5.300.v20130429-1813.jar:na]java.io.IOException: Server returned status code 404: Not Found at org.eclipse.m2e.core.internal.index.nexus.AsyncFetcher$MonitorListener.onStatus(AsyncFetcher.java:280) ~[na:na] at com.ning.http.client.SimpleAsyncHttpClient$BodyConsumerAsyncHandler.fireStatus(SimpleAsyncHttpClient.java:828) ~[na:na] at com.ning.http.client.SimpleAsyncHttpClient$BodyConsumerAsyncHandler.onStatusReceived(SimpleAsyncHttpClient.java:779) ~[na:na] at com.ning.http.client.providers.netty.NettyAsyncHttpProvider.updateStatusAndInterrupt(NettyAsyncHttpProvider.java:1587) ~[na:na] at com.ning.http.client.providers.netty.NettyAsyncHttpProvider.messageReceived(NettyAsyncHttpProvider.java:1242) ~[na:na] at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:80) ~[na:na] at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564) ~[na:na] at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:783) ~[na:na] at org.jboss.netty.handler.stream.ChunkedWriteHandler.handleUpstream(ChunkedWriteHandler.java:149) ~[na:na] at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564) ~[na:na] at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:783) ~[na:na] at org.jboss.netty.handler.codec.http.HttpContentDecoder.messageReceived(HttpContentDecoder.java:104) ~[na:na] at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:80) ~[na:na] at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564) ~[na:na] at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:783) ~[na:na] at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:302) ~[na:na] at org.jboss.netty.handler.codec.replay.ReplayingDecoder.unfoldAndFireMessageReceived(ReplayingDecoder.java:522) ~[na:na] at org.jboss.netty.handler.codec.replay.ReplayingDecoder.callDecode(ReplayingDecoder.java:506) ~[na:na] at org.jboss.netty.handler.codec.replay.ReplayingDecoder.messageReceived(ReplayingDecoder.java:443) ~[na:na] at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:80) ~[na:na] at org.jboss.netty.handler.codec.http.HttpClientCodec.handleUpstream(HttpClientCodec.java:77) ~[na:na] at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564) ~[na:na] at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:559) ~[na:na] at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:274) ~[na:na] at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:261) ~[na:na] at org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:349) ~[na:na] at org.jboss.netty.channel.socket.nio.NioWorker.processSelectedKeys(NioWorker.java:280) ~[na:na] at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:200) ~[na:na] at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108) ~[na:na] at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:44) ~[na:na] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110) ~[na:1.7.0_09] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603) ~[na:1.7.0_09] at java.lang.Thread.run(Thread.java:722) ~[na:1.7.0_09]Error while logging event loop exception:java.lang.OutOfMemoryError: PermGen space at java.lang.ClassLoader.defineClass1(Native Method) at java.lang.ClassLoader.defineClass(ClassLoader.java:791) at org.eclipse.osgi.internal.baseadaptor.DefaultClassLoader.defineClass(DefaultClassLoader.java:188) at org.eclipse.osgi.baseadaptor.loader.ClasspathManager.defineClassHoldingLock(ClasspathManager.java:638) at org.eclipse.osgi.baseadaptor.loader.ClasspathManager.defineClass(ClasspathManager.java:613) at org.eclipse.osgi.baseadaptor.loader.ClasspathManager.findClassImpl(ClasspathManager.java:574) at org.eclipse.osgi.baseadaptor.loader.ClasspathManager.findLocalClassImpl(ClasspathManager.java:492) at org.eclipse.osgi.baseadaptor.loader.ClasspathManager.findLocalClass(ClasspathManager.java:465) at org.eclipse.osgi.internal.baseadaptor.DefaultClassLoader.findLocalClass(DefaultClassLoader.java:216) at org.eclipse.osgi.internal.loader.BundleLoader.findLocalClass(BundleLoader.java:395) at org.eclipse.osgi.internal.loader.BundleLoader.findClassInternal(BundleLoader.java:464) at org.eclipse.osgi.internal.loader.BundleLoader.findClass(BundleLoader.java:421) at org.eclipse.osgi.internal.loader.BundleLoader.findClass(BundleLoader.java:412) at org.eclipse.osgi.internal.baseadaptor.DefaultClassLoader.loadClass(DefaultClassLoader.java:107) at java.lang.ClassLoader.loadClass(ClassLoader.java:356) at org.eclipse.equinox.p2.ui.InstalledSoftwarePage.getProvisioningUI(InstalledSoftwarePage.java:259) at org.eclipse.equinox.p2.ui.InstalledSoftwarePage.createControl(InstalledSoftwarePage.java:71) at org.eclipse.ui.internal.about.InstallationDialog.tabSelected(InstallationDialog.java:274) at org.eclipse.ui.internal.about.InstallationDialog.createContents(InstallationDialog.java:245) at org.eclipse.jface.window.Window.create(Window.java:432) at org.eclipse.jface.dialogs.Dialog.create(Dialog.java:1104) at org.eclipse.jface.window.Window.open(Window.java:791) at org.eclipse.ui.internal.dialogs.AboutDialog$1.run(AboutDialog.java:127) at org.eclipse.swt.custom.BusyIndicator.showWhile(BusyIndicator.java:70) at org.eclipse.ui.internal.dialogs.AboutDialog.buttonPressed(AboutDialog.java:122) at org.eclipse.jface.dialogs.Dialog$2.widgetSelected(Dialog.java:628) at org.eclipse.swt.widgets.TypedListener.handleEvent(TypedListener.java:248) at org.eclipse.swt.widgets.EventTable.sendEvent(EventTable.java:84) at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1392) at org.eclipse.swt.widgets.Display.runDeferredEvents(Display.java:3742) at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3363) at org.eclipse.jface.window.Window.runEventLoop(Window.java:826)Logging exception:java.lang.OutOfMemoryError: PermGen space at java.lang.ClassLoader.defineClass1(Native Method) at java.lang.ClassLoader.defineClass(ClassLoader.java:791) at org.eclipse.osgi.internal.baseadaptor.DefaultClassLoader.defineClass(DefaultClassLoader.java:188) at org.eclipse.osgi.baseadaptor.loader.ClasspathManager.defineClassHoldingLock(ClasspathManager.java:638) at org.eclipse.osgi.baseadaptor.loader.ClasspathManager.defineClass(ClasspathManager.java:613) at org.eclipse.osgi.baseadaptor.loader.ClasspathManager.findClassImpl(ClasspathManager.java:574) at org.eclipse.osgi.baseadaptor.loader.ClasspathManager.findLocalClassImpl(ClasspathManager.java:492) at org.eclipse.osgi.baseadaptor.loader.ClasspathManager.findLocalClass(ClasspathManager.java:465) at org.eclipse.osgi.internal.baseadaptor.DefaultClassLoader.findLocalClass(DefaultClassLoader.java:216) at org.eclipse.osgi.internal.loader.BundleLoader.findLocalClass(BundleLoader.java:395) at org.eclipse.osgi.internal.loader.BundleLoader.findClassInternal(BundleLoader.java:464) at org.eclipse.osgi.internal.loader.BundleLoader.findClass(BundleLoader.java:421) at org.eclipse.osgi.internal.loader.BundleLoader.findClass(BundleLoader.java:412) at org.eclipse.osgi.internal.baseadaptor.DefaultClassLoader.loadClass(DefaultClassLoader.java:107) at java.lang.ClassLoader.loadClass(ClassLoader.java:356) at org.eclipse.ui.statushandlers.StatusManager.logError(StatusManager.java:277) at org.eclipse.ui.statushandlers.StatusManager.handle(StatusManager.java:201) at org.eclipse.ui.statushandlers.StatusManager.handle(StatusManager.java:231) at org.eclipse.ui.statushandlers.StatusManager.handle(StatusManager.java:242) at org.eclipse.ui.application.WorkbenchAdvisor.eventLoopException(WorkbenchAdvisor.java:326) at org.eclipse.ui.internal.ExceptionHandler.handleException(ExceptionHandler.java:65) at org.eclipse.jface.window.Window.runEventLoop(Window.java:830) at org.eclipse.jface.window.Window.open(Window.java:802) at org.eclipse.ui.internal.about.AboutHandler.execute(AboutHandler.java:32) at org.eclipse.ui.internal.handlers.HandlerProxy.execute(HandlerProxy.java:290) at org.eclipse.ui.internal.handlers.E4HandlerProxy.execute(E4HandlerProxy.java:90) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:601) at org.eclipse.e4.core.internal.di.MethodRequestor.execute(MethodRequestor.java:56) at org.eclipse.e4.core.internal.di.InjectorImpl.invokeUsingClass(InjectorImpl.java:243)java.lang.OutOfMemoryError: PermGen spaceError while logging event loop exception:java.lang.OutOfMemoryError: PermGen spaceLogging exception:java.lang.OutOfMemoryError: PermGen spacejava.lang.OutOfMemoryError: PermGen spaceError while logging event loop exception:java.lang.OutOfMemoryError: PermGen spaceLogging exception:java.lang.OutOfMemoryError: PermGen space(In reply to Tesso Costa from)Kepler SR1 contains CDT 8.2.1, not 8.3.Did this regress in CDT 8.5? I cannot get 32-bit Eclipse Luna SR1 to index Boost on Linux without running out of heap space, even when I give it a full 2GB to work with.I'm now trying 64-bit Eclipse Luna SR1 with CDT 8.5 and the following memory settings in eclipse.ini:-server-XX:MaxPermSize=320m-XX:+UseParallelOldGC-Xmx4g-Xmn1gIt's currently taking a very long time at 26%, and has come close enough to the ~4GB limit a couple of times that it freezes up completely for a minute or two.I've disabled all plugins except for Codan and Devhelp.(In reply to Benjamin Shadwick from)It's definitely a regression, not sure when it was introduced. But yes, CDT runs out of memory indexing Boost, we've tried up to 8GB and still couldn't do it.I've seen forum posts confirming this too.How can we get this bug report reopened?(In reply to Benjamin Shadwick from)Please create a new bug with detailed reproduction steps.(In reply to Sergey Prigogin from)Create a project with the Boost source code. Boom. Not that complicated.Update: Gave it 6GB of heap and it still eventually blew up.The interesting thing is that it does *not* blow up when I instead just add it as an exported preprocessor/macro include directory, even though I saw it subsequently index the boost directories for a few seconds. I guess it must ignore the "index unused headers" setting for headers that come in that way?So while Doug claims "Any BOOST will blow up", it would still be good to get the _exact version_ for reproducing. Has this been posted anywhere ? In the past I have seen some versions of BOOST blowing up while other versions were fine.Could somebody perhaps attach the version of BOOST they are using ? And also let us know the host OS / host compiler version in use, since the host's gcc system headers may also influence the outcome.(In reply to Martin Oberhuber from)And yes, one key difference between pulling in BOOST just thought the -I path versus having it in the project is that "in the project" forces CDT to index all files. Versus "pulled in by include" only those headers that are actually used are pulled in, AND they are pulled in with the correct context (a cpp file using them).That combined with the fact that I suppose few people on the earth understand BOOST well enough to actually edit / modify it, I would assume all of us just want to _USE_ it in order to get data structures properly indexed. Therefore I consider removing BOOST from the workspace (and just having it pulled in by -I path) more than just a workaround. It's a reasonable workflow IMO unless you deliberatly want to hurt yourself...(In reply to Benjamin Shadwick from)That's as expected. The problem is caused by one of the test files for boost, not the public headers.I've been able to easily reproduce this by creating a CDT project and importing the boost source, all of it, into it.(In reply to Martin Oberhuber from)Why not just try the latest one. I can't imagine how any recent version works. We've seen this for quite a while.I did it with mingw on Windows, but I don't think that matters. We've seen it with the QNX toolchain as well.For me it was Boost 1.54 on Red Hat 6.2 x64. I won't be able to get the GCC version until Monday if it matters.While it's probably acceptable for most people's use to not directly index all of Boost, it seems to be a good test case for the indexer.Any progress on this?I cant use eclipse Mars at all for our project at work, since the indexer will always crash. This obviously got way worse since Luna.I cant help out with sources, but it definitely is not limited to Boost. Our Project is ~370KLOCs, uses C++11 and the project includes multiple executables (which for example means multiple main functions in different directories).If the indexer just gracefully fails on a couple of these, or cant parse some complicated templates it wont be a problem (or would be easy to accept). Gobbing up all RAM and then failing is pretty seriousThere appears to be a very sharp discontinuity in indexer behavior b/w Luna and Mars. I attempted to upgrade to Mars.1 today by copying the entire Luna workspace dir, deleting .metadata and .*project files, and recreating the same workspace and project settings.The upshot: Mars fails to complete a single index run with a -Xmx setting that's even twice as large as that used for Luna. Luna struggled but worked with -Xmx3g on ~1500 files. Mars, on the other hand, runs out of heap space before its Progress counter goes beyond "0/6xx sources, ...".There appears to be a very sharp discontinuity in indexer behavior b/w Luna and Mars. I attempted to upgrade to Mars.1 today by copying the entire Luna workspace dir, deleting .metadata and .*project files, and recreating the same workspace and project settings.The upshot: Mars fails to complete a single index run with a -Xmx setting that's even twice as large as that used for Luna. Luna struggled but worked with -Xmx3g on ~1500 files. Mars, on the other hand, runs out of heap space before its Progress counter goes beyond "0/6xx sources, ...".Hi everyone! I'd just like to ask if there's a plan to do something with this indexer problem? Does it lack human "resources", or additional information would be needed, or anything else is missing?I'm asking this because IMO it is a blocking issue for anyone who would like to use CDT for real-world C++ development: with the indexer working correctly, Eclipse+CDT is one of the best C++ IDEs currently available, but without proper indexing it's just a bad editor with a ridiculous amount of resource usage.To be honest, I'm a bit surprised that there is no automated (or at least manual) functional regression testing before each release, that would consist of importing a real-world, complicated, huge project (like boost, clang or something like that), and see if CDT can cope with it. By coping with it, I mean that some fixed set of indicators could be measured and compared to the previous versions (like the number of files processed, the number of symbols/references/whatever discovered in each file, the number of unresolved symbols, the duration and resource usage of the indexing, etc.).BTW,seems to be similar to this one.For what it's worth, I've managed to avoid this issue for a while now by only adding my own project's source to my project tree, and bringing in dependencies only via header include paths.Even with this approach, Content Assist is too slow (which is a separate but probably related issue).Yes, this bug renders eclipse unusable for our project, the Neon Release makes no difference.Just to restate the problem: after opening the project, eclipse will gobble up all heap space (I tried with up to 14Gb) and then report a crash in the indexer. Rinse and repeat.I understand that parsing C/C++ is complex, particularly if some headers/sources are mutually exclusive in different builds. But please, just add a recursion counter and bail out if it goes over 1000 (ideally give some reports with traces to help you find bugs or work around the problematic sources). I can live with some missing symbols, I cant live with constant crashes and disabling the indexer altogether ain`t a good option eitherI am still using Luna SR2 to avoid this problem.To echo, it should be relatively simple to bisect the list of commits between Luna SR2 and the first version for which this bug was reopened.This is a blocking issue for Eclipse adoption by C++ community."CDT does not work for C++ code" is a blocking issue. Hardly anything else can have a higher priority.There's been a lot of discussion in this bug, so let me ask again to be sure:Is everyone who is experiencing this problem trying to index the *sources* (not just headers) of Boost, by creating a project for Boost itself (as opposed to just having Boost headers on the include path for other projects)?Or is just including Boost headers sufficient to cause this problem? Or are people seeing this in projects that don't use Boost at all?FWIW, I use CDT regularly for C++ development on projects that include many Boost headers, and I haven't seen this problem.(In reply to Tamás Kiss from)Human resources is definitely a problem. There are only a handful of people maintaining the CDT indexer code, and many of us do so in our spare time only.Given that:(In reply to Igor Lubashev from)If someone who is actually suffering from this problem, could do such a bisection, that would be a huge help.I am not using Boost at all, and am suffering from this issue.Some points:*) The indexer always had crashes, just from Luna to Mars they got almost certain*) On Luna sometimes removing the .pdoms helps.*) I was unable to reduce the Project, it doesn`t seem to be entirely deterministic.*) The crashes leave little information on what happened. If I could re-construct the cause (sequence of parsed files, backtrace) I might be able to isolate the issue.*) I really doubt you will find *all* relevant bugs in a timely mannerIn my opinion, you should add a detection and limitation on recursion and/or heap-usage ASAP and allow us to provide you with reports on issues that seem to exists in various form on ALL eclipse version.Just expect that indexing might fail.@(In reply to Nathan Ridge from)I have a not too large project, which includes lots of Boost headers (including Boost.Test), OpenLDAP client library headers, and the Turtle Mock headers. The source code of those libraries are not imported.I haven't tried yet to import the project without the UT part, and drop the Boost.Test and Turtle Mock headers. Chances are that it might work, but I have to develop the UT code too, so it would not really be an solution.Two of my customers have been in similar situations -- at some point, they wanted to import a large source code, and CDT took ages to index or ran OOME. How to identify the offending source code ?I propose that as a very first step, the CDT Indexer Tracing options should be improved to include timing information (what took how long to parse). That way, it's easier to find hot spots where the indexer is slow. This may also help identify problematic source code, which could then help creating reproducible test cases to improve the indexer.I've created, could this simple enhancement be considered ?As a suggestion to people having issues indexing large projects; I did much better when I indexed my large project as a bunch of Eclipse projects. It was a good fit for other reasons too, but indexing became more straightforward. Practically, if the indexer hangs or gets corrupted on an Eclipse project, you can reindex that project (deleting the .pdom file too if necessary), and this doesn't take too long so you can do it without wasting too much time. You have to specify inter-project dependencies this way but at least this is a fixed cost.I hate to be that guy, but maybe at this point in time, a serious consideration should be taking the time that would have gone towards fixing the old indexer and thinking about writing a new one that is clang based.The irony in my mind is that its problems notwithstanding, a few years ago, the CDT indexer was probably really the best multi platform option for a) code nav, b) auto complete, c) as-you-type error flagging w/ CODAN.Now, numerous projects are heavily exploiting clang. The result is indexing that is both more accurate and more reliable. If your projects compiles in clang, then it can be parsed by the clang frontend and indexed in a database, pure and simple.CODAN was a big plus of Eclipse a few years ago, now it's a weak point of the platform compared to projects like QtCreator or YouCompleteMe that offer as-you-type error flagging based on actual clang frontend parsing. This simply finds tons of errors that CODAN misses, and virtually never has false positives. This was one of the main motivators in my leaving Eclipse recently. I'd love to see Eclipse get a nice clang based indexer. The best part too is that by leaning heavily on clang, a ton of dev time that would go towards duplicating a C++ frontend, can instead go to more fruitful things, like trying to improve its performance or making sure the indexer is more transparent in its performance/correctness.As a suggestion to people having issues indexing large projects; I did much better when I indexed my large project as a bunch of sub- Eclipse projects. It was a good fit for other reasons too, but indexing became more straightforward. Practically, if the indexer hangs or gets corrupted on an Eclipse project, you can reindex that project (deleting the .pdom file too if necessary), and this doesn't take too long so you can do it without wasting too much time. You have to specify inter-project dependencies this way but at least this is a fixed cost.I hate to be that guy, but maybe at this point in time, a serious consideration should be taking the time that would have gone towards fixing the old indexer and thinking about writing a new one that is clang based.The irony in my mind is that its problems notwithstanding, a few years ago, the CDT indexer was probably really the best multi platform option for a) code nav, b) auto complete, c) as-you-type error flagging w/ CODAN.Now, numerous projects are heavily exploiting clang. The result is indexing that is both more accurate and more reliable. If your projects compiles in clang, then it can be parsed by the clang frontend and indexed in a database, pure and simple.CODAN was a big plus of Eclipse a few years ago, now it's a weak point of the platform compared to projects like QtCreator or YouCompleteMe that offer as-you-type error flagging based on actual clang frontend parsing. This simply finds tons of errors that CODAN misses, and virtually never has false positives. This was one of the main motivators in my leaving Eclipse recently. I'd love to see Eclipse get a nice clang based indexer. The best part too is that by leaning heavily on clang, a ton of dev time that would go towards duplicating a C++ frontend, can instead go to more fruitful things, like trying to improve its performance or making sure the indexer is more transparent in its performance/correctness.(In reply to Nir Friedman from)It's OK to be that guy :). We've discussed this off and on over the last couple of years.However, the guy I want to hear from is the one who'll bring a team in to do the work. It would be a pretty massive undertaking to replace our current indexer and hook up all the features that depend on it it.Until then, we can only do what our small band of contributors can. It's cheaper at this point to fix these occasional bugs.BTW, we do have other bugs complaining specifically about Boost. Fix that and we probably have this one fixed too.(In reply to Martin Oberhuber from)Sounds good to me. Would you like to write the patch?	107.0
id=258251	REOPENED	PDT	General UI	2.0.0	PC Windows XP	P3 minor	Roy Ganor	2008-12-10 04:56 EST by	Kalin	2010-05-26 09:47 EDT (	2 users	CreatedUnexpectedButtonOnToolbarThe button disappears immediately after project creation.See the attachment.Found in pdt-runtime-2.0.0RC1	Now that toolbar button is always there:)mark as fixedRe-tested in EclipsePdt-2.2.0.v20100521Still reproducible...Kalin Yanev	3.0
id=175998	REOPENED	GEF	GEF-Legacy Draw2d	3.2	PC Windows XP	P3 normal	gef-inbox	2007-03-01 05:48 EST by	Andras Varga	2007-03-22 10:36 EDT (	0 users	Build ID: I20060512-1600Steps To Reproduce:See source.More information:There seems to be no way to obtain text size from Graphics. One must invoke textExtent() of the underlying GC object, which is error-prone (as graphics.setFont() does not immediately propagate font setting to GC, so gc.textExtent() will return bogus results unless you made a dummy graphics.drawText() first).	Use FigureUtilities. This bug should be resolved as invalid.Use FigureUtilities for this support.Guys, Are you sure this is the Right Thing to do? Force people use a workaround, instead of fixing the issue?draw2d.Graphics wraps each and every method of GC, *except* textExtent()? What's the reason? Other than it was left out accidentally?BTW, I just noticed there is setForegroundPattern()/setBackgroundPattern() but no getForegroundPattern()/getBackgroundPattern()...?? GC does have them.It was not accidental. Text Extent is required during layout, which occurs outside of a paint, without a GC. Also, the GC's font might not be the one you passed in, due to ScaledGraphics.The problem with using FigureUtilities is that it doesn't know the textAntialias setting of the Graphics I'm using, and the difference in the result can be quite significant in either direction (see URL and screenshot attachment in). I actually got bitten by LabelFigure because of this: it shaved off some pixel columns of labels, e.g. making trailing "d" appear as "c", and "n" as "r". Perhaps this would be worth a separate bugtracker entry.Also, I was using the Graphics class without Figures (just for raw canvas painting) for its convenience features over GC, so I'd rather invoke a textExtent() method on Graphics than using extra class.Is there a practical difficulty involved in adding textExtent() [and other missing methods like getForegroundPattern()/getBackgroundPattern()] into Graphics?Yes, the font passed to ScaledGraphics is not necessarily used with any GC.Getters are easily added.Also, the problem you mentioned with different text sizes based on usage of advanced graphics is a real problem. But, adding getTextExtent will not solve that problem. During layout, the figure will still incorrectly answer what it's preferred size is, so even if it measured the string later, the figure's bounds won't be big enough to paint it. I guess if you're not using Figures at all you don't have that problem.That'd be great, thanks.I'm not sure, do you mean that the Font in the localFont member of ScaledGraphics may have been created for a different Device than the underlying GC, so localfont cannot be used for measuring? It looks more correct to me to call textExtent with the zoomed Font not localFont, and divide the result by the zoom factor. So when the returned size gets multiplied back by the zoom factor in some later drawXXX() call, the error would be less than one zoomed pixel, which is about as good as one can hope when using zoomed graphics.	7.0
id=179194	REOPENED	GEF	GEF-Legacy GEF (MVC)	3.3	PC Windows XP	P3 major	gef-inbox	2007-03-25 10:39 EDT by	amir	2008-07-14 14:07 EDT (	4 users	Build ID: I20061214-1445Steps To Reproduce:1. Launch eclipse in mirrored mode (using dir -rtl attribute)2. Create a simple project in workspace3. Go to File -> New -> Example… -> Logic Diagram and create a model file4. Create a label in the logic editor that opens up (by dragging a label – under components – from the palette).5 Create a LED in the logic editor.6. From properties view, set the following values for these objects:For label: Location = (80,300); Size = (90,-1)For LED: Location = (100,200); Size = (61,47)7. From menu select: a)View -> Grid b)View -> Snap to Geometry8. Select the left edge of the label and try to reduce the lable width using the mouse.Result: The LED is disappeared from the editorMore information:In order ot make the LED to appear again, one should select it in the outline view	CreatedThe initial state in the logic editorCreatedThe LED object is disappeared after reduce the lable widthSee attachments that illustrate the problemI cannot reproduce with Eclipse I20070323-1616 (M6) and GEF I20070323 on Windows XP.I tried it with the builds you specified and reproduced it.Please try again with following notes:1. Set on the option: View -> Snap to Geometry, otherwise you won't see it.2. This problem is very gentle for reproducing. Therefore try several times to reduce and expand the label width (only with the left edge of the label).3. When you reduce the label width, make the label width less than the LED widthI have reproduced the issue. The issue does not occur in non-rtl mode.I would route this one to SWT and see if they know about it. It would take a lot of effort to reduce this to a simple test case showing an SWT problem.Anthony, any progress on this? Can this be fixed in 3.3?Defer BIDI issues to the next release.	8.0
id=179593	REOPENED	GEF	GEF-Legacy GEF (MVC)	3.2.1	PC Windows XP	P3 enhancement	gef-inbox	2007-03-27 15:12 EDT by	Tonny Madsen	2015-01-22 02:36 EST (	1 user	I would like to implement a number of options in the palette. Currently this seems to be impossible as all palette EditParts must inherit from PaletteEditPart (due to saveState and restoreState). And PaletteEditPart is internal and thus inaccessible.My only option seems to be to copy org.eclipse.gef.internal.ui.palette.editparts.* to my own plug-in....But that cannot be right ;-)	The Palette editparts are internal because these classes are implementation detail that are not part of the API. It is the same with JFace's PartSashContainer, ViewPane, etc. The implementation could change between releases. For example, maybe GEF should switch to using SWT's ExpandBar at some point. Currently, we could do this without breaking our "contract" with clients.You can reference internal packages from your plug-in. Copying should not be the only option.Can you start by presenting the types of options you are trying to do? Maybe a better solution is for GEF to support those options, rather than committing to the current mechanism for how GEF solves the problem of displaying a bunch of push buttons.I would like to present a number of checkbox options as well as a number of comboboxes. (And yes, I know that GEF/Draw2D does not have support for the later, so they would need to be simulated anyway..)But why do these checkboxes and combos have to be inside the palette? What's their relationship to the rest of the palette?Have you looked at PaletteStack?The checkboxes should be used to alter the behavior of some of the tools. E.g. the select and marquee tool can either select all objects or just the object with a specific state (which means they can be altered/manipulated).For now, I have changed the palette into a ordinary toolbar, and that works just fine...The way photoshop does this, the active tool replaces a portion of the toolbar so that it can be configured. This scales better than reserving a static configuration area for every tool, whether or not it is active.Two different tools could share their preferences values, as with selection and marquee tool. This sounds like a reasonable enhancement for GEF, but not a reason to open up the internal implementation and prevent GEF from making significant changes to the palette in the future.Sounds good. I just hope that the extension will not limit the possible controls that can be added. Reasonable controls could be check boxes, radio groups, combos and plain editing fields (well, just about everything :-))	6.0
id=18413	REOPENED	CDT	cdt-core	2.0	PC Windows 2000	P3 normal	Yasser Elmankabady	2002-05-31 04:01 EDT by	Dmitry B. Khlonin	2014-03-23 14:25 EDT (	1 user	first - I create new project and added main.cpp file:#include <iostream>int main(){ cout << "Eclipse says hello." << endl; return 0;}Then I tried to Autoconf->Configure->Program - all passes ok, but then itreaches end - I got error:checking for ANSI C header files... (cached) yesconfigure: creating ./config.statusconfig.status: creating Makefileconfig.status: creating \config.status: error: cannot find input file: \.inAlso I have seen some interlocking in cygwin and cmd.exe processes - and thinkthis problem maybe in Eclipse CDT usage of them.	The generated Makefile.am(s) contains lines like the following:SOURCES = dir1 \dir2 \..etc..that uses the "\" continuation character which autoconf/automake on cygwin - for some reason - does not accept. So, check all your Makefile.am(s) - you will find one in each dir- and if you have lines containing the continuation character, changed as follows:SOURCES = dir1 dir2 . ..... etc. This, I believe, has been resolved in the latest autoconf automake versions - 2.53 and 1.6 - although they contain lots of problems and I don't recommend using them at this moment.Hope this solve the problem but If you find that it did not, you may reopen the bug.LATER/REMIND are deprecated. Changing to reopened milestone '--'	2.0
id=478461	REOPENED	GEF	Misc	unspecified	All All	P3 normal	gef-inbox	2015-09-25 20:26 EDT by	Marc-André Laperle	2016-02-03 13:02 EST (	2 users	I installed Mars.1 along with almost all features in the simrel update site, which includes GEF4 MVC SDK 0.1.0.201506081138When I start Eclipse, I get this error (among other simiar ones):org.osgi.framework.BundleException: Could not resolve module: org.eclipse.gef4.mvc [1416] Bundle was not resolved because of a uses contraint violation. org.osgi.service.resolver.ResolutionException: Uses constraint violation. Unable to resolve resource org.eclipse.gef4.mvc [osgi.identity; osgi.identity="org.eclipse.gef4.mvc"; type="osgi.bundle"; version:Version="0.1.0.201506081138"] because it is exposed to package 'javax.annotation' from resources org.eclipse.osgi [osgi.identity; osgi.identity="org.eclipse.osgi"; type="osgi.bundle"; version:Version="3.10.101.v20150820-1432"; singleton:="true"] and javax.annotation [osgi.identity; osgi.identity="javax.annotation"; type="osgi.bundle"; version:Version="1.2.0.v201401042248"] via two dependency chains.Chain 1: org.eclipse.gef4.mvc [osgi.identity; osgi.identity="org.eclipse.gef4.mvc"; type="osgi.bundle"; version:Version="0.1.0.201506081138"] require: (&(osgi.wiring.bundle=org.eclipse.osgi)(&(bundle-version>=3.9.0)(!(bundle-version>=4.0.0)))) | provide: osgi.wiring.bundle: [org.eclipse.osgi, system.bundle] org.eclipse.osgi [osgi.identity; osgi.identity="org.eclipse.osgi"; type="osgi.bundle"; version:Version="3.10.101.v20150820-1432"; singleton:="true"]Chain 2: org.eclipse.gef4.mvc [osgi.identity; osgi.identity="org.eclipse.gef4.mvc"; type="osgi.bundle"; version:Version="0.1.0.201506081138"] import: (&(osgi.wiring.package=com.google.common.collect)(&(version>=12.0.0)(!(version>=16.0.0)))) | export: osgi.wiring.package=com.google.common.collect; uses:=javax.annotation com.google.guava [osgi.identity; osgi.identity="com.google.guava"; type="osgi.bundle"; version:Version="15.0.0.v201403281430"] import: (osgi.wiring.package=javax.annotation) | export: osgi.wiring.package: javax.annotation javax.annotation [osgi.identity; osgi.identity="javax.annotation"; type="osgi.bundle"; version:Version="1.2.0.v201401042248"] at org.eclipse.osgi.container.Module.start(Module.java:434) at org.eclipse.osgi.container.ModuleContainer$ContainerStartLevel.incStartLevel(ModuleContainer.java:1582) at org.eclipse.osgi.container.ModuleContainer$ContainerStartLevel.incStartLevel(ModuleContainer.java:1561) at org.eclipse.osgi.container.ModuleContainer$ContainerStartLevel.doContainerStartLevel(ModuleContainer.java:1533) at org.eclipse.osgi.container.ModuleContainer$ContainerStartLevel.dispatchEvent(ModuleContainer.java:1476) at org.eclipse.osgi.container.ModuleContainer$ContainerStartLevel.dispatchEvent(ModuleContainer.java:1) at org.eclipse.osgi.framework.eventmgr.EventManager.dispatchEvent(EventManager.java:230) at org.eclipse.osgi.framework.eventmgr.EventManager$EventThread.run(EventManager.java:340)	Can you please install the Luna Compatibility features fromand confirm that this resolve the problem?(In reply to Alexander Nyßen from)It works, thanks! I just noticed though, the Mars.1 simrel [1] contains version 0.1.0.201506081138 for GEF but the repo you gave has 0.2.0.201509140217. Is this intentional? Does Mars.1 contain the right version?[1](In reply to Marc-Andre Laperle from)Yes, that's by intention. As announced on gef-dev, GEF4 0.2.0, which is part of the 3.10.1 (Mars.1) release, is not contributed to simrel update-site but only to the GEF4 releases site, because its not compatible to GEF4 0.1.0 (and we thus wanted to prevent updating 'by chance').While this is not the exact same exception stack, its the same underlying problem as the one depicted in. As such, resolving this as a duplicate.*** This bug has been marked as a duplicate of***As #476044 involved another additional problem, decided to rather resolveas a duplicate of this bug.***has been marked as a duplicate of this bug. ***Generalized title to indicate that this problem affects all GEF4 bundles that specify bundle dependencies on org.eclipse.osgi and have package imports on com.google.guava packages, i.e. o.e.g4.fx, o.e.g4.mvc, o.e.g4.mvc.fx, and o.e.g4.zest.fx, as reported in cross-projects.As documented in, this seems to be reproducible in the Mars SDK (and the Luna SDK, as documented in), but not in the IDE for committers or the IDE for Java developers. It seems that the IDEs already bundle com.google.guava (15.0.0), while the SDK does not contain Guava yet.Irrespective of the fact if we can fix the underlying issue, we should rename our *.compatibility.luna.* fragments and features to something more appropriate, e.g. *compatibility.equinox.*.(In reply to Alexander Nyßen from)I applied above mentioned renamings for 4.0.0 M6.	10.0
id=292047	REOPENED	ATF	Core	unspecified	PC Windows XP	P3 enhancement	Jacek Pospychala	2009-10-12 09:40 EDT by	Jacek Pospychala	2009-10-15 04:15 EDT (	0 users	Currently we're only notified about Network call request start and response receive event.It'd be useful to be notified about various phases of request, such as resolving state (where' we don't yet know the target server IP number), connecting state (where we've not yet connected to destination server), etc.	FIXED in HEAD.Following states have been added (to ACTIVE and DONE):RESOLVINGCONNECTINGWAITINGRECEIVINGSENDING.Not all events are published now. That's because events generated by Mozilla on http-on-examine-response and by nsIWebProgressListener are different for the same URLs. This results in incomplete or missing events.FIXED in HEAD	4.0
id=486664	REOPENED	GEF	GEF FX	0.2.0	All All	P3 minor	gef-inbox	2016-01-27 11:32 EST by	Camille Letavernier	2016-10-04 11:39 EDT (	1 user	Due to the (im)precision of doubles, zooming in and out around 1.0 results in blurred lines/elements. For example, we often end up with a zoom of 0.999[...]997 instead of 1.0 which, when rendered, gives very visible blurred lines/text/imagesFor example, here's the transformation applied to the viewport after a few zoom in/out operations (+ irrelevant scrolling):AffineTransform[[0.999999999999997, 0.0, 707.4296889707344], [0.0, 0.999999999999997, -2710.1944145297266]]The transformations should be rounded after the concatenation occurs. This might also make sense for scrolling (I don't know if moving a vertical line from 0.0001px to the right also results in a blurred line. It's probably the case, but I've not experienced it so far)	I think we should provide methods for setting the absolute zoom level, as well as a method for normalizing the zoom level. The latter would round the absolute zoom level to the next multiple of, for example, 0.0078125 (so that it divides one: 1/0.0078125 = 128).I experimented a bit with the zoom level and adjusted the code as follows: - Added methods to FXChangeViewportPolicy: * setZoomLevel(zoomLevel): Sets the zoom level within the transformation matrix without altering any other values. * roundAndZoomRelative(zoomFactor,pivotX,pivotY): Computes the final zoom level, rounds it to 6 decimal places, ensures that integral zoom levels are not skipped (e.g. when zooming at a level of 0.99 by 1.05 the integral zoom level of 1 will be applied), applies the resulting zoom level using #zoomRelative(), and counter-acts any floating point errors by overwriting the zoom level in the transformation matrix (using #setZoomLevel()) if it is incorrect after #zoomRelative(). - Renamed FXChangeViewportOperation#getNewTransform() to #getNewContentTransform() in alignment with #getInitialContentTransform(). - Use the new roundAndZoomRelative() method within the zooming interaction policies.The code is published on the master branch, therefore, I resolve this ticket as fixed for 5.0.0 M2. If you encounter a problem with this approach, or have a better mechanism in mind, feel free to re-open this ticket.Reopen to enhance and finalize the API: - Remove the confusing "Absolute"/"Relative" suffixes from the methods. They are meant to signify if the respective transformation is applied to the initial transformation or to the current transformation (which is important in the context of an interaction that continuously changes the zoom level, for example). Instead, a boolean parameter with a more expressive name should be used, such as "concatenate". => zoom(double factor, boolean concatenate) => scroll(double tx, double ty, boolean concatenate) - Remove the roundAndZoomRelative() method. Instead, add parameters "round" and "discretize" that can be used to control if the resulting final zoom factor should be rounded, and if zooming should be done discretely (so that some zoom levels cannot be skipped), respectively. => zoom(double factor, boolean concatenate, boolean round, boolean discretize) - The same set of parameters should be provided for scroll(), too. => scroll(double tx, double ty, boolean concatenate, boolean round, boolean discretize) - Add methods for setting the absolute scroll offsets / zoom level. => setAbsoluteZoom(double factor) => setAbsoluteScroll(double tx, double ty)	3.0
id=291751	REOPENED	CDT	cdt-build-managed	6.0	PC Windows XP	P3 normal	James Blackburn	2009-10-08 10:04 EDT by	James Blackburn	2011-05-10 09:43 EDT (	9 users	Createdpatch 1When I build a CDT project which references others in the Workspace, thereferenced projects are built twice.This is because: - BuildAction#pruneResources collects all the ReferencedProjects (asreferenced at the platform level). The default/current configuration of eachof these is built - When the project is built CommonBuilder builds the correct configurationsin each of the referenced projects.The result is that the projects are built twice as a matter of course.A simple fix would be for the supplied BuildActions to return false fromshouldPerformResourcePruning(...)Proposed patch attached.	***has been marked as a duplicate of this bug. ******has been marked as a duplicate of this bug. ******has been marked as a duplicate of this bug. ***Createdpatch 2patch 2- Add same behaviour to CNF- Single CDTBuildAction type used (minimize illegaly extends warnings)- Override the BuildProjectAction defined by ResourceMgmtActionProvider- If any of the projects are not new-style cprojects, fall back to standard BuildAction behaviour.Toni, I'm not sure if there's a better way of handling the CNF action contribution collision I've got...ResourceMgmtActionProvider contirbutes a BuildAction as well as the standard open, close, refresh etc. The CNavigatorBuildActionProvider dependsOn ResourceMgmtActions in the cdt.ui plugin.xml.Is there any better way of overriding the RMA provided BuildAction with our own (other than physically replacing it in the fillContextMenu as this patch does)?Requesting review doesn't seem to email user...(In reply to)The general approach is OK from my POV.I guess the proper way would be to completely override the ResourceMgmtActionProvider, but that would mean to clone all the actions it provides and it is likely this would introduce a few API warnings.I noticed that if there is no build action in the menu, you add one in addition to the clean action. I.e. if I enabled "Build Automatically", the order of build and clean actions is reversed.Createdpatch 3Thanks for taking a look.(In reply to)Woops, good catch. Perhaps the build action in this case is superfluous -- however I guess it seems (to me) to be more consistent that the build action's visibility isn't predicated on the global BuildAutomatically switch. This makes it have the same visibility behaviour as in the C/C++ Projects view.Ordering fixed.Patch committed to HEAD***has been marked as a duplicate of this bug. ***Patch partially reverted, restoring previous behaviour for 7.0.1 / HEAD as we no longer run non-CDT builders on referenced projects (see).Will re-examine this for 8.re-open	12.0
id=476810	REOPENED	Xtend	Core	2.8.4	PC Mac OS X	P3 normal	Jan Koehnlein	2015-09-07 12:42 EDT by	Jan Koehnlein	2016-06-10 05:56 EDT (	1 user	Given the following combination of Xtend and Java filesFoo.java: public interface Foo { public Bar.Baz foo(); }Bar.xtend: class Bar { static class Baz { } }I cannot refer to Foo#foo from an Xtend class, e.g. class FooBar{ def test(Foo f) { f.foo // error The method or field foo is undefined for the type Foo } }or class FooBar implements Foo { // Java problem: // The type FooBar must implement the inherited abstract method Foo.foo() override Bar.Baz foo() {} // Error: // The method foo() of type FooBar must override a superclass method. }From Java the method is referable as expected. Converting Bar to Java makes it referable form Xtend as well.	The EObjectDescriptionBasedStubGenerator needs to create stubs for static nested types, too.This happens in Eclipse. Isn't the EObjectDescriptionBasedStubGenerator only used in standalone compilers?It is used by the WorkingCopyOwner, too to make Xtend types available when loading TypeResources. The nested type is missing thus the method binding is filtered from the ICompilationUnit.GitHub Pull Request 542 created by [JanKoehnlein]mergedReopened to make sure review comment isn't lost.GitHub Pull Request 546 created by [JanKoehnlein]	7.0
id=390229	REOPENED	PTP	RDT.sync	6.0.2	PC Mac OS X	P3 normal	John Eblen	2012-09-24 11:55 EDT by	Greg Watson	2014-05-30 10:31 EDT (	2 users	When creating a new synchronized project, no check is made to verify that the remote path is accessible and/or a directory. For example, specifying an existing file as the path causes the synchronization error:Synchronization error for project: xxxremote git init failed with message: /bin/sh: line 0: cd: /uf/ac/grw/xxx: Not a directoryThis should be checked prior to the sync so that the local project is not created and a more appropriate message can be displayed.	Fixed in ptp_6_0 and master. Path now must be validated in the new project wizard.Reopening since the fix was reverted for Juno SR2.Seefor some discussion on checking the remote path.I suggest we do it like the Mylyn/Bugzilla or Mylyn/Gerrit "New Repo" wizards. There is a "Validate on Finish" checkbox and/or a "Validate Settings" button. While the validation is happening a status bar is shown which allows one to cancel it (as part of the dialog not as a separate dialog).BTW: The validation should also check for the existence of a .ptp-sync folder and warn the user that using that folder (without deleting the .ptp-sync) means downloading all previous added files.Please update the target milestone for this bug.	5.0
id=293245	REOPENED	CDT	cdt-build	6.0	PC All	P3 normal	James Blackburn	2009-10-24 19:32 EDT by	David Brady	2015-04-08 12:04 EDT (	2 users	User-Agent: Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.9.1.3) Gecko/20090824 Firefox/3.5.3Build Identifier: M20090917-0800If the option "Build configurations only when there are Eclipse resource changes within the project and its references" is checked, the project won't actually be built if a referenced project is changed.This bug dramatically increases compile times in projects with a large amount of libraries, as the option does not work.Reproducible: AlwaysSteps to Reproduce:1. Create workspace with an executable and library project2. Reference the library project from the executable.3. Enable the "Build configurations only when there are Eclipse resource changes within the project and its references" option in Preferences->C/C++4. Build workspace5. Change a cpp file in the library project6. Build workspace7. Observe that only the library is built, and the executable remains out of date.	This seems to be fixed in HEAD. Nevermind, and thanks.Reproduced.Steps to Reproduce:1. Extract attached test project, import into new workspace2. Enable the "Build configurations only when there are Eclipse resourcechanges within the project and its references" option in Preferences->C/C++3. Build workspace4. Change the cpp file in the testlib project5. Build workspace (with ctrl-B or Build All)6. Observe that only the library is built, and the executable remains out ofdate.Createdtest projectsPerhaps the build order should be reversed when the option is selected in the IDE? Seems like the most unobtrusive method.This is related to. The resource delta isn't being correctly checked when the dependent project is built.We have the same problem when the option "Build configurations only when there are Eclipse resource changes within the project and its references" is checked.If project A depends on project B and project B changes source code, project A doesn't rebuild.I think the reason for this is in the org.eclipse.cdt.managedbuilder.core.CommonBuilder Line 500if (buildConfigResourceChanges()) IResourceDelta delta = getDelta(project);if (delta != null && delta.getAffectedChildren().length > 0) { //do the build here...}The second if statement is only true if there is a delta for the current project ignoring all referenced project deltas. Maybe this could be changed to something like this, taking the referenced project deltas chain into account:if (buildConfigResourceChanges()) IResourceDelta delta = getDelta(project);if (projectResourceChanged(project)) { //do the build here...}protected boolean projectResourceChanged(IProject project) throws CoreException { IResourceDelta delta = getDelta(project); if (delta == null) return false; if (delta.getAffectedChildren() != null && delta.getAffectedChildren().length > 0) { return true; } IProject[] referencedProjects = project.getReferencedProjects(); for (IProject iProject : referencedProjects) { if (!iProject.isAccessible()) continue; if (projectResourceChanged(iProject)) { return true; } } return false;}Maybe a cache is required for cyclic dependencies to prevent infinite recursion. Shall I create a patch and commit this to gerrit for code review?	5.0
id=397053	REOPENED	PTP	Photran.Editor & Outline View	unspecified	PC Windows 7	P3 enhancement	Jeffrey Overbey	2012-12-21 03:10 EST by	Danqing Xu	2013-02-13 13:00 EST (	3 users	Createdall modified files and documentation1. Memory limitation2. Multithreading for parserIt's a final project for CS 427 - UIUCSee documentation in the attachment.	I just realized this was supposed to replace(correct?)If so, I have a two favors to ask...1. What are the full names of the people in your group? I will need to add their names to each of the Java source files.2. Please ask *each* member of your group to add a comment to this bug confirming that:(a) you wrote 100% of the code without incorporating content from elsewhere or relying on the intellectual property of others,(b) you have the right to contribute the code to Eclipse, and(c) you have included the EPL license header in all source ﬁles.Thanks again!***has been marked as a duplicate of this bug. ***(a) you wrote 100% of the code without incorporating content from elsewhere or relying on the intellectual property of others,(b) you have the right to contribute the code to Eclipse, and(c) you have included the EPL license header in all source ﬁles.-Danqing XuYou marked this bug as RESOLVED/NOT_ECLIPSE -- was that a mistake? I'm marking it REOPENED, since I'm assuming you still want to contribute this patch... correct me if I'm wrong...(a) We wrote 100% of the code without incorporating content from elsewhere or relying on the intellectual property of others,(b) We have the right to contribute the code to Eclipse, and(c) We have included the EPL license header in all source ﬁles.-Wei ChenI certify that(a) we wrote 100% of the code without incorporating content from elsewhere or relying on the intellectual property of others,(b) we have the right to contribute the code to Eclipse, and(c) we have included the EPL license header in all source ﬁles.- Steven CanningHi guys -- I still need confirmations from Kevin Gasparini and Jeffrey Stanislaw before I can submit this to the IP team for review.Today is the deadline for IP review requests for the Kepler release, so this may be postponed until the 2014 release.	7.0
id=356999	REOPENED	WindowBuilder	Swing	unspecified	PC Windows 7	P3 normal	Konstantin Scheglov	2011-09-07 15:38 EDT by	None	2014-02-05 13:30 EST (	3 users	Internal ErrorWindowBuilder encountered unexpected internal error. This could be caused by a WindowBuilder bug or by a misconfiguration issue, conflict, partial update, etc.Show stack trace. Hide stack trace. Stack trace:java.lang.NullPointerException at org.eclipse.wb.internal.swing.MigLayout.model.MigLayoutInfo.getIntervalsForOrigins(MigLayoutInfo.java:1506) at org.eclipse.wb.internal.swing.MigLayout.model.MigLayoutInfo.refresh_afterCreate2(MigLayoutInfo.java:1235) at org.eclipse.wb.core.model.ObjectInfo.refresh_afterCreate2(ObjectInfo.java:635) at org.eclipse.wb.core.model.ObjectInfo.refresh_afterCreate2(ObjectInfo.java:635) at org.eclipse.wb.core.model.ObjectInfo.refreshCreate0(ObjectInfo.java:553) at org.eclipse.wb.core.model.ObjectInfo.access$0(ObjectInfo.java:546) at org.eclipse.wb.core.model.ObjectInfo$5$1.run(ObjectInfo.java:486) at org.eclipse.wb.internal.core.utils.execution.ExecutionUtils.runDesignTime(ExecutionUtils.java:139) at org.eclipse.wb.core.model.ObjectInfo$5.run(ObjectInfo.java:484) at org.eclipse.wb.internal.swing.utils.SwingUtils$2.run(SwingUtils.java:76) at java.awt.event.InvocationEvent.dispatch(Unknown Source) at java.awt.EventQueue.dispatchEventImpl(Unknown Source) at java.awt.EventQueue.access$000(Unknown Source) at java.awt.EventQueue$1.run(Unknown Source) at java.awt.EventQueue$1.run(Unknown Source) at java.security.AccessController.doPrivileged(Native Method) at java.security.AccessControlContext$1.doIntersectionPrivilege(Unknown Source) at java.awt.EventQueue.dispatchEvent(Unknown Source) at java.awt.EventDispatchThread.pumpOneEventForFilters(Unknown Source) at java.awt.EventDispatchThread.pumpEventsForFilter(Unknown Source) at java.awt.EventDispatchThread.pumpEventsForHierarchy(Unknown Source) at java.awt.EventDispatchThread.pumpEvents(Unknown Source) at java.awt.EventDispatchThread.pumpEvents(Unknown Source) at java.awt.EventDispatchThread.run(Unknown Source)	Createdbug infoUnable to reproduce. Please provide a complete test case that will reproduce the problem and reopen the case. Also provide details on exactly what you were doing when the exception occurred.Could you please reopen this bug? I'm attaching a simple test program that triggers the problem. It has two classes:1. NormalFrame.java: this creates a JPanel, sets its layout to MigLayout, adds a few components to it, and then adds the panel to a JFrame. This frame can be opened in Design mode without problems.2. BuggyFrame.java: this creates a JXCollapsiblePane (from SwingX), sets its layout to MigLayout, adds a few components to it, and then adds the pane to a JFrame. This frame fails to load in Design mode.To trigger the error, open BuggyFrame.java in the Eclipse Editor. In the lower left part of the editor window, click on the Design tab, and the error should show up.CreatedSimple test program that triggers the problem.Reproduced using test case. Thanks!	5.0
id=491823	REOPENED	Tracecompass	TMF	2.0.0	PC Linux	P3 normal	Marc-André Laperle	2016-04-15 11:57 EDT by	Marc-André Laperle	2016-10-24 01:26 EDT (	0 users	Seen atjava.lang.AssertionError: null at org.junit.Assert.fail(Assert.java:86) at org.junit.Assert.assertTrue(Assert.java:41) at org.junit.Assert.assertFalse(Assert.java:64) at org.junit.Assert.assertFalse(Assert.java:74) at org.eclipse.tracecompass.tmf.ui.tests.project.model.ProjectModelOutputTest.testListOutputs(ProjectModelOutputTest.java:117)	New Gerrit change created:Gerrit changewas merged to [master].Commit:Still happening. Even after 5 mins of waiting, the analysis outputs do not appear. I printed the running jobs when the failure happens and there is nothing interesting.17:09:58 Running org.eclipse.tracecompass.tmf.ui.tests.project.model.ProjectModelOutputTest17:14:59 Periodic workspace save.(6) state: SLEEPING17:14:59 17:14:59 Workbench Auto-Save Job(15) state: SLEEPING17:14:59 17:14:59 Compacting resource model(12) state: SLEEPING17:14:59 17:14:59 Periodic workspace save.(6) state: SLEEPING17:14:59 17:14:59 Workbench Auto-Save Job(15) state: SLEEPING17:14:59 17:14:59 Compacting resource model(12) state: SLEEPING17:14:59 17:19:59 Periodic workspace save.(6) state: SLEEPING17:19:59 17:19:59 Workbench Auto-Save Job(15) state: SLEEPING17:19:59 17:19:59 Compacting resource model(12) state: SLEEPING17:19:59 17:19:59 Periodic workspace save.(6) state: SLEEPING17:19:59 17:19:59 Workbench Auto-Save Job(15) state: SLEEPING17:19:59 17:19:59 Compacting resource model(12) state: SLEEPING17:19:59 17:19:59 Tests run: 2, Failures: 0, Errors: 2, Skipped: 0, Time elapsed: 600.837 sec <<< FAILURE! - in org.eclipse.tracecompass.tmf.ui.tests.project.model.ProjectModelOutputTest17:19:59 testListOutputs(org.eclipse.tracecompass.tmf.ui.tests.project.model.ProjectModelOutputTest) Time elapsed: 300.734 sec <<< ERROR!17:19:59 org.eclipse.tracecompass.tmf.ui.tests.shared.WaitTimeoutException: Timeout while waiting for TmfAnalysisElement(/Test_Project/Traces/A-Test-10K/.views/org.eclipse.linuxtools.tmf.ui.tests.test) to have number of children. Expected: 1 Actual: 017:19:59 at org.eclipse.tracecompass.tmf.ui.tests.shared.WaitUtils.waitUntil(WaitUtils.java:134)17:19:59 at org.eclipse.tracecompass.tmf.ui.tests.shared.WaitUtils.waitUntil(WaitUtils.java:90)17:19:59 at org.eclipse.tracecompass.tmf.ui.tests.project.model.ProjectModelOutputTest.testListOutputs(ProjectModelOutputTest.java:118)17:19:59 17:19:59 testOpenView(org.eclipse.tracecompass.tmf.ui.tests.project.model.ProjectModelOutputTest) Time elapsed: 300.092 sec <<< ERROR!17:19:59 org.eclipse.tracecompass.tmf.ui.tests.shared.WaitTimeoutException: Timeout while waiting for TmfAnalysisElement(/Test_Project/Traces/A-Test-10K/.views/org.eclipse.linuxtools.tmf.ui.tests.test) to have number of children. Expected: 1 Actual: 017:19:59 at org.eclipse.tracecompass.tmf.ui.tests.shared.WaitUtils.waitUntil(WaitUtils.java:134)17:19:59 at org.eclipse.tracecompass.tmf.ui.tests.shared.WaitUtils.waitUntil(WaitUtils.java:90)17:19:59 at org.eclipse.tracecompass.tmf.ui.tests.project.model.ProjectModelOutputTest.testOpenView(ProjectModelOutputTest.java:147)The workspace log has something VERY interesting:!ENTRY org.eclipse.tracecompass.tmf.core 4 0 2016-10-23 21:06:35.007!MESSAGE Error creating module output listener!STACK 1org.eclipse.core.runtime.CoreException: Plug-in org.eclipse.tracecompass.tmf.ui.tests was unable to load class org.eclipse.tracecompass.tmf.ui.tests.stubs.analysis.TestAnalysisUi. at org.eclipse.core.internal.registry.osgi.RegistryStrategyOSGI.throwException(RegistryStrategyOSGI.java:194) at org.eclipse.core.internal.registry.osgi.RegistryStrategyOSGI.createExecutableExtension(RegistryStrategyOSGI.java:176) at org.eclipse.core.internal.registry.ExtensionRegistry.createExecutableExtension(ExtensionRegistry.java:905) at org.eclipse.core.internal.registry.ConfigurationElement.createExecutableExtension(ConfigurationElement.java:243) at org.eclipse.core.internal.registry.ConfigurationElementHandle.createExecutableExtension(ConfigurationElementHandle.java:55) at org.eclipse.tracecompass.tmf.core.analysis.TmfAnalysisModuleOutputs.getListenerFromOutputElement(TmfAnalysisModuleOutputs.java:102) at org.eclipse.tracecompass.tmf.core.analysis.TmfAnalysisModuleOutputs.getOutputListeners(TmfAnalysisModuleOutputs.java:79) at org.eclipse.tracecompass.tmf.core.analysis.TmfAnalysisManager.initializeNewModuleListeners(TmfAnalysisManager.java:92) at org.eclipse.tracecompass.tmf.core.analysis.TmfAnalysisManager.initialize(TmfAnalysisManager.java:75) at org.eclipse.tracecompass.internal.tmf.core.Activator.start(Activator.java:88) at org.eclipse.osgi.internal.framework.BundleContextImpl$3.run(BundleContextImpl.java:774) at org.eclipse.osgi.internal.framework.BundleContextImpl$3.run(BundleContextImpl.java:1) at java.security.AccessController.doPrivileged(Native Method) at org.eclipse.osgi.internal.framework.BundleContextImpl.startActivator(BundleContextImpl.java:767) at org.eclipse.osgi.internal.framework.BundleContextImpl.start(BundleContextImpl.java:724) at org.eclipse.osgi.internal.framework.EquinoxBundle.startWorker0(EquinoxBundle.java:932) at org.eclipse.osgi.internal.framework.EquinoxBundle$EquinoxModule.startWorker(EquinoxBundle.java:309) at org.eclipse.osgi.container.Module.doStart(Module.java:581) at org.eclipse.osgi.container.Module.start(Module.java:449) at org.eclipse.osgi.framework.util.SecureAction.start(SecureAction.java:470) at org.eclipse.osgi.internal.hooks.EclipseLazyStarter.postFindLocalClass(EclipseLazyStarter.java:107) at org.eclipse.osgi.internal.loader.classpath.ClasspathManager.findLocalClass(ClasspathManager.java:529) at org.eclipse.osgi.internal.loader.ModuleClassLoader.findLocalClass(ModuleClassLoader.java:325) at org.eclipse.osgi.internal.loader.BundleLoader.findLocalClass(BundleLoader.java:345) at org.eclipse.osgi.internal.loader.sources.SingleSourcePackage.loadClass(SingleSourcePackage.java:36) at org.eclipse.osgi.internal.loader.BundleLoader.findClassInternal(BundleLoader.java:419) at org.eclipse.osgi.internal.loader.BundleLoader.findClass(BundleLoader.java:372) at org.eclipse.osgi.internal.loader.BundleLoader.findClass(BundleLoader.java:364) at org.eclipse.osgi.internal.loader.ModuleClassLoader.loadClass(ModuleClassLoader.java:161) at java.lang.ClassLoader.loadClass(ClassLoader.java:357) at java.lang.ClassLoader.defineClass1(Native Method) at java.lang.ClassLoader.defineClass(ClassLoader.java:763) at org.eclipse.osgi.internal.loader.ModuleClassLoader.defineClass(ModuleClassLoader.java:273) at org.eclipse.osgi.internal.loader.classpath.ClasspathManager.defineClass(ClasspathManager.java:632) at org.eclipse.osgi.internal.loader.classpath.ClasspathManager.findClassImpl(ClasspathManager.java:586) at org.eclipse.osgi.internal.loader.classpath.ClasspathManager.findLocalClassImpl(ClasspathManager.java:538) at org.eclipse.osgi.internal.loader.classpath.ClasspathManager.findLocalClass(ClasspathManager.java:525) at org.eclipse.osgi.internal.loader.ModuleClassLoader.findLocalClass(ModuleClassLoader.java:325) at org.eclipse.osgi.internal.loader.BundleLoader.findLocalClass(BundleLoader.java:345) at org.eclipse.osgi.internal.loader.BundleLoader.findClassInternal(BundleLoader.java:423) at org.eclipse.osgi.internal.loader.BundleLoader.findClass(BundleLoader.java:372) at org.eclipse.osgi.internal.loader.BundleLoader.findClass(BundleLoader.java:364) at org.eclipse.osgi.internal.loader.ModuleClassLoader.loadClass(ModuleClassLoader.java:161) at java.lang.ClassLoader.loadClass(ClassLoader.java:357) at org.eclipse.osgi.internal.framework.EquinoxBundle.loadClass(EquinoxBundle.java:564) at org.eclipse.tycho.surefire.osgibooter.OsgiSurefireBooter$BundleClassLoader.findClass(OsgiSurefireBooter.java:197) at java.lang.ClassLoader.loadClass(ClassLoader.java:424) at java.lang.ClassLoader.loadClass(ClassLoader.java:357) at org.eclipse.tycho.surefire.osgibooter.CombinedClassLoader.findClass(CombinedClassLoader.java:32) at java.lang.ClassLoader.loadClass(ClassLoader.java:424) at java.lang.ClassLoader.loadClass(ClassLoader.java:357) at org.apache.maven.surefire.util.DefaultScanResult.loadClass(DefaultScanResult.java:131) at org.apache.maven.surefire.util.DefaultScanResult.applyFilter(DefaultScanResult.java:95) at org.apache.maven.surefire.junit4.JUnit4Provider.scanClassPath(JUnit4Provider.java:206) at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:103) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray2(ReflectionUtils.java:208) at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:156) at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:82) at org.eclipse.tycho.surefire.osgibooter.OsgiSurefireBooter.run(OsgiSurefireBooter.java:95) at org.eclipse.tycho.surefire.osgibooter.AbstractUITestApplication$1.run(AbstractUITestApplication.java:35) at org.eclipse.swt.widgets.RunnableLock.run(RunnableLock.java:35) at org.eclipse.swt.widgets.Synchronizer.runAsyncMessages(Synchronizer.java:182) at org.eclipse.swt.widgets.Display.runAsyncMessages(Display.java:4528) at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:4146) at org.eclipse.e4.ui.internal.workbench.swt.PartRenderingEngine$4.run(PartRenderingEngine.java:1121) at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:336) at org.eclipse.e4.ui.internal.workbench.swt.PartRenderingEngine.run(PartRenderingEngine.java:1022) at org.eclipse.e4.ui.internal.workbench.E4Workbench.createAndRunUI(E4Workbench.java:150) at org.eclipse.ui.internal.Workbench$5.run(Workbench.java:687) at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:336) at org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:604) at org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:148) at org.eclipse.ui.internal.ide.application.IDEApplication.start(IDEApplication.java:138) at org.eclipse.tycho.surefire.osgibooter.UITestApplication.runApplication(UITestApplication.java:31) at org.eclipse.tycho.surefire.osgibooter.AbstractUITestApplication.run(AbstractUITestApplication.java:120) at org.eclipse.tycho.surefire.osgibooter.UITestApplication.start(UITestApplication.java:37) at org.eclipse.equinox.internal.app.EclipseAppHandle.run(EclipseAppHandle.java:196) at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:134) at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:104) at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:388) at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:243) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:673) at org.eclipse.equinox.launcher.Main.basicRun(Main.java:610) at org.eclipse.equinox.launcher.Main.run(Main.java:1519) at org.eclipse.equinox.launcher.Main.main(Main.java:1492)Caused by: java.lang.ClassNotFoundException: org.eclipse.tracecompass.tmf.ui.tests.stubs.analysis.TestAnalysisUi cannot be found by org.eclipse.tracecompass.tmf.ui.tests_1.0.1.qualifier at org.eclipse.osgi.internal.loader.BundleLoader.findClassInternal(BundleLoader.java:461) at org.eclipse.osgi.internal.loader.BundleLoader.findClass(BundleLoader.java:372) at org.eclipse.osgi.internal.loader.BundleLoader.findClass(BundleLoader.java:364) at org.eclipse.osgi.internal.loader.ModuleClassLoader.loadClass(ModuleClassLoader.java:161) at java.lang.ClassLoader.loadClass(ClassLoader.java:357) at org.eclipse.osgi.internal.framework.EquinoxBundle.loadClass(EquinoxBundle.java:564) at org.eclipse.core.internal.registry.osgi.RegistryStrategyOSGI.createExecutableExtension(RegistryStrategyOSGI.java:174) ... 91 more!SUBENTRY 1 org.eclipse.equinox.registry 4 1 2016-10-23 21:06:35.009!MESSAGE Plug-in org.eclipse.tracecompass.tmf.ui.tests was unable to load class org.eclipse.tracecompass.tmf.ui.tests.stubs.analysis.TestAnalysisUi.!STACK 0java.lang.ClassNotFoundException: org.eclipse.tracecompass.tmf.ui.tests.stubs.analysis.TestAnalysisUi cannot be found by org.eclipse.tracecompass.tmf.ui.tests_1.0.1.qualifier at org.eclipse.osgi.internal.loader.BundleLoader.findClassInternal(BundleLoader.java:461) at org.eclipse.osgi.internal.loader.BundleLoader.findClass(BundleLoader.java:372) at org.eclipse.osgi.internal.loader.BundleLoader.findClass(BundleLoader.java:364) at org.eclipse.osgi.internal.loader.ModuleClassLoader.loadClass(ModuleClassLoader.java:161) at java.lang.ClassLoader.loadClass(ClassLoader.java:357) at org.eclipse.osgi.internal.framework.EquinoxBundle.loadClass(EquinoxBundle.java:564) at org.eclipse.core.internal.registry.osgi.RegistryStrategyOSGI.createExecutableExtension(RegistryStrategyOSGI.java:174) at org.eclipse.core.internal.registry.ExtensionRegistry.createExecutableExtension(ExtensionRegistry.java:905) at org.eclipse.core.internal.registry.ConfigurationElement.createExecutableExtension(ConfigurationElement.java:243) at org.eclipse.core.internal.registry.ConfigurationElementHandle.createExecutableExtension(ConfigurationElementHandle.java:55) at org.eclipse.tracecompass.tmf.core.analysis.TmfAnalysisModuleOutputs.getListenerFromOutputElement(TmfAnalysisModuleOutputs.java:102) at org.eclipse.tracecompass.tmf.core.analysis.TmfAnalysisModuleOutputs.getOutputListeners(TmfAnalysisModuleOutputs.java:79) at org.eclipse.tracecompass.tmf.core.analysis.TmfAnalysisManager.initializeNewModuleListeners(TmfAnalysisManager.java:92) at org.eclipse.tracecompass.tmf.core.analysis.TmfAnalysisManager.initialize(TmfAnalysisManager.java:75) at org.eclipse.tracecompass.internal.tmf.core.Activator.start(Activator.java:88) at org.eclipse.osgi.internal.framework.BundleContextImpl$3.run(BundleContextImpl.java:774)Forgot to mark as reopened.(In reply to Marc-Andre Laperle from)And mysterious...	6.0
id=277987	REOPENED	CDT	cdt-debug-cdi-gdb	5.0.2	PC Linux	P3 normal	John Cortell	2009-05-27 02:15 EDT by	Dmitry Kozlov	2009-10-07 09:54 EDT (	8 users	Build ID: M20090211-1700Steps To Reproduce:1. Run debug a program2. Add memory monitor 0x1283. See adresses startinf from 0x1204. Verify in gdb console that lowest requested address was 0x120.More information:This error comes from org.eclipse.debug.internal.ui.views.memory.renderings.TableRenderingContentDescriptor which by default aligns adresses to 16 and there is no way to turn it off. I'd suggest to set TableRenderingContentDescriptor.fAlignAddress to false by default.	org.eclipse.debug.internal.ui.views.memory.renderings.AsyncTableRenderingViewer:// TODO: need pluggable model to be truly flexible protected AbstractVirtualContentTableModel createVirtualContentTableModel() { return new TableRenderingModel(this); }without this TODO done this bug can't be properly fixed from plugins.Can you please provide more information about the expected behavior from your point of view? If the memory monitor is started from 0x128, do you expect the rendering to start at 0x128, rather than 0x120? What are you seeing in the memory rendering in this case? and what do you expect to see?Thanks...CreatedscreenshotObserved behaviour:- The IDE triggers two memory read packets, one at 0x128, which is correct, andanother at 0x120 which is *not* correct and is before the requested readadddress. The IDE or gdb should never try to read before the request memoryaddress as this could fail.~~~(gdb) 117-gdb-show endianSending packet: $m128,64#9e...117^done,value=""118-data-read-memory 296 x 1 1 100(gdb) &"Sending packet: $m128,64#9e..."&"Ack\n"&"Packet received:0030a0e308300be508301be5013083e208300be5fbffffea0010a0e10000a0e310402de90020a0e10030a0e10d0000eb1040bde81eff2fe10010a0e30040a0e1420000eb18309fe5000093e53c2090e5000052e30fe0a01112ff2f110400a0e1de0000eb\n"118^done,addr="0x00000128",nr-bytes="100",total-bytes="100",next-row="0x0000018c",prev-row="0x000000c4",next-page="0x0000018c",prev-page="0x000000c4",memory=[{addr="0x00000128",data=["0x00","0x30","0xa0","0xe3","0x08","0x30","0x0b","0xe5","0x08","0x30","0x1b","0xe5","0x01","0x30","0x83","0xe2","0x08","0x30","0x0b","0xe5","0xfb","0xff","0xff","0xea","0x00","0x10","0xa0","0xe1","0x00","0x00","0xa0","0xe3","0x10","0x40","0x2d","0xe9","0x00","0x20","0xa0","0xe1","0x00","0x30","0xa0","0xe1","0x0d","0x00","0x00","0xeb","0x10","0x40","0xbd","0xe8","0x1e","0xff","0x2f","0xe1","0x00","0x10","0xa0","0xe3","0x00","0x40","0xa0","0xe1","0x42","0x00","0x00","0xeb","0x18","0x30","0x9f","0xe5","0x00","0x00","0x93","0xe5","0x3c","0x20","0x90","0xe5","0x00","0x00","0x52","0xe3","0x0f","0xe0","0xa0","0x11","0x12","0xff","0x2f","0x11","0x04","0x00","0xa0","0xe1","0xde","0x00","0x00","0xeb"]}]AckPacket received:0030a0e308300be508301be5013083e208300be5fbffffea0010a0e10000a0e310402de90020a0e10030a0e10d0000eb1040bde81eff2fe10010a0e30040a0e1420000eb18309fe5000093e53c2090e5000052e30fe0a01112ff2f110400a0e1de0000eb(gdb) 119-data-read-memory 288 x 1 1 320&"Sending packet: $m120,140#c1..."Sending packet: $m120,140#c1...&"Ack\n"Ack&"Packet received:00b08de20cd04de20030a0e308300be508301be5013083e208300be5fbffffea0010a0e10000a0e310402de90020a0e10030a0e10d0000eb1040bde81eff2fe10010a0e30040a0e1420000eb18309fe5000093e53c2090e5000052e30fe0a01112ff2f110400a0e1de0000ebac050000d8c09fe5f0412de900409ce548c194e500005ce353cf84020180a0e104109ce548c184051f0051e30050a0e10260a0e10370a0e1180000ca000055e30600001a012081e2023081e203818ce704208ce50000a0e3f041bde81eff2fe104009ce50130a0e31340a0e1020055e3423080e288219ce503718ce78c319c05221081e2042082e10430830101618ce788218ce58c318c050010a0e1e8ffffea40309fe5000053e30100001a0000e0e3e8ffffea190ea0e3ffffffea00c050e2f9ffff0a482194e50030a0e30c008ce848c184e5\n"Packet received:00b08de20cd04de20030a0e308300be508301be5013083e208300be5fbffffea0010a0e10000a0e310402de90020a0e10030a0e10d0000eb1040bde81eff2fe10010a0e30040a0e1420000eb18309fe5000093e53c2090e5000052e30fe0a01112ff2f110400a0e1de0000ebac050000d8c09fe5f0412de900409ce548c194e500005ce353cf84020180a0e104109ce548c184051f0051e30050a0e10260a0e10370a0e1180000ca000055e30600001a012081e2023081e203818ce704208ce50000a0e3f041bde81eff2fe104009ce50130a0e31340a0e1020055e3423080e288219ce503718ce78c319c05221081e2042082e10430830101618ce788218ce58c318c050010a0e1e8ffffea40309fe5000053e30100001a0000e0e3e8ffffea190ea0e3ffffffea00c050e2f9ffff0a482194e50030a0e30c008ce848c184e5119^done,addr="0x00000120",nr-bytes="320",total-bytes="320",next-row="0x00000260",prev-row="0xffffffe0",next-page="0x00000260",prev-page="0xffffffe0",memory=[{addr="0x00000120",data=["0x00","0xb0","0x8d","0xe2","0x0c","0xd0","0x4d","0xe2","0x00","0x30","0xa0","0xe3","0x08","0x30","0x0b","0xe5","0x08","0x30","0x1b","0xe5","0x01","0x30","0x83","0xe2","0x08","0x30","0x0b","0xe5","0xfb","0xff","0xff","0xea","0x00","0x10","0xa0","0xe1","0x00","0x00","0xa0","0xe3","0x10","0x40","0x2d","0xe9","0x00","0x20","0xa0","0xe1","0x00","0x30","0xa0","0xe1","0x0d","0x00","0x00","0xeb","0x10","0x40","0xbd","0xe8","0x1e","0xff","0x2f","0xe1","0x00","0x10","0xa0","0xe3","0x00","0x40","0xa0","0xe1","0x42","0x00","0x00","0xeb","0x18","0x30","0x9f","0xe5","0x00","0x00","0x93","0xe5","0x3c","0x20","0x90","0xe5","0x00","0x00","0x52","0xe3","0x0f","0xe0","0xa0","0x11","0x12","0xff","0x2f","0x11","0x04","0x00","0xa0","0xe1","0xde","0x00","0x00","0xeb","0xac","0x05","0x00","0x00","0xd8","0xc0","0x9f","0xe5","0xf0","0x41","0x2d","0xe9","0x00","0x40","0x9c","0xe5","0x48","0xc1","0x94","0xe5","0x00","0x00","0x5c","0xe3","0x53","0xcf","0x84","0x02","0x01","0x80","0xa0","0xe1","0x04","0x10","0x9c","0xe5","0x48","0xc1","0x84","0x05","0x1f","0x00","0x51","0xe3","0x00","0x50","0xa0","0xe1","0x02","0x60","0xa0","0xe1","0x03","0x70","0xa0","0xe1","0x18","0x00","0x00","0xca","0x00","0x00","0x55","0xe3","0x06","0x00","0x00","0x1a","0x01","0x20","0x81","0xe2","0x02","0x30","0x81","0xe2","0x03","0x81","0x8c","0xe7","0x04","0x20","0x8c","0xe5","0x00","0x00","0xa0","0xe3","0xf0","0x41","0xbd","0xe8","0x1e","0xff","0x2f","0xe1","0x04","0x00","0x9c","0xe5","0x01","0x30","0xa0","0xe3","0x13","0x40","0xa0","0xe1","0x02","0x00","0x55","0xe3","0x42","0x30","0x80","0xe2","0x88","0x21","0x9c","0xe5","0x03","0x71","0x8c","0xe7","0x8c","0x31","0x9c","0x05","0x22","0x10","0x81","0xe2","0x04","0x20","0x82","0xe1","0x04","0x30","0x83","0x01","0x01","0x61","0x8c","0xe7","0x88","0x21","0x8c","0xe5","0x8c","0x31","0x8c","0x05","0x00","0x10","0xa0","0xe1","0xe8","0xff","0xff","0xea","0x40","0x30","0x9f","0xe5","0x00","0x00","0x53","0xe3","0x01","0x00","0x00","0x1a","0x00","0x00","0xe0","0xe3","0xe8","0xff","0xff","0xea","0x19","0x0e","0xa0","0xe3","0xff","0xff","0xff","0xea","0x00","0xc0","0x50","0xe2","0xf9","0xff","0xff","0x0a","0x48","0x21","0x94","0xe5","0x00","0x30","0xa0","0xe3","0x0c","0x00","0x8c","0xe8","0x48","0xc1","0x84","0xe5"]}](gdb) Expected behaviour:don't read memory before requested address. see screenshot.May be it is better to allow more control when adding new memory monitor:whether to align, number of bytes to read in addition to existing startaddress.Sending over to CDT for comments.The memory rendering can ask the model for memory before the start of the memory block. It is the model's responsibility request memory from its debug engine. If memory cannot be retrieved, the model is supposed to pad the returned values with "unreadable" MemoryBytes.From GBG's point of view, if it cannot retrieve memory at an address location, GDB should probably handle it gracefully and somehow report that an error has occurred? I am not sure that an IDE can guaranteed that it will always ask for memory from a valid location.I believe this this something CDT debug needs to handle?(In reply to)The "incorrect" address is passed to CDT from "getMemoryToFitTable". I agreethat GDB should handle this situation better. Not sure if there is anythingthat CDT can do in this case without providing a UI to control the memoryaccess as it is suggested by Dmitry. At the same time it could be confusing forthose users who don't know or don't want to know about GDB specifics.Sorry but I've missed what the actual problem is. Is it the console printouts? I thought GDB did handle this properly.(In reply to)The request to get memory starting from the "incorrect" address fails and it overwrites the "correct" one. As a result you get an error message in the view for a valid address. It will affect the DSF implementation too.The actual problem is that Memory View has some autoscrolling that tries toread memory before requested address and error handling is not good in this case.If you set the lower bound of the memory block correctly, does the view still ask you for memory before the start of the memory block? Does the user need to scroll before the start of the memory block?(In reply to)Yes, that's what I see. The first request is correct, but the view asks for memory before the start.No, it happens without user's interaction.The additional memory read is due to preload of lines before visible region and can be controlled from "Table Renderings" preferences. Unfortunately user cannot disable preload as the minimum number of lines to preload is 1. An workaround is to use manual loading mode. However this has a disadvantage that you cannot scroll and have to use "Go To Address" to see other memory regions.IMO, CDT does handle this correctly by returning an error when rendering requests for "invalid" address. However when this is happening, table rendering is switching the view page to message page to show detailed info of the failure. Another input is that when table rendering shows error message page, all actions are disabled, thus user cannot go to other "correct" address. The only thing left to do is to remove the memory monitor and try again at a different bigger address so that automatic preloader would not use "incorrect" addresses.I see to ways to improve:1. Allow setting preload to 0 lines. 2. When a memory block has a presentation failure to allow "Reset to Base Address" and "Go to Address ..." commands. Eventually to allow scrolling outside of the current block.Teo, re-reading your comments, I think you're saying the problematic behavior is in Debug Platform, not CDT, correct?(In reply to)The problem seems to be a Debug Platform Issue.Preloading is controlled by platform preferences and the actual logic is in org.eclipse.debug.internal.ui.elements.adaptersMemoryBlockContentAdapter. While CDT could in theory use a different IAsynchronousContentAdapter still the preference editor "TableRenderingPreferencePage" is in Debug Platform.Same is for scrolling outside/getting away of the current invalid block. This is handled from AbstractAsyncTableRendering.Closing this bug as it's not a CDT problem (see latest comments). A new issue should be opened against Debug Platform.(In reply to)When CDT is unable to read an address before the start of a memory block, does CDT throws a DebugException, or does it pad the memory that it cannot read with INVALID / UNREADABLE MemoryBytes?The "correct" behavior is that if the model has trouble reading memory because memory is not available, it should simply return an array of MemoryByte with the READABLE bit set to false. This will cause the view to show "??" in place of those memory. Throwing a DebugException means that you have an unexpected error, like the expression for creating the memory block is invalid. In this case, we will show the error message in the rendering to tell the user that something really bad has happened.(In reply to)Yes. Technically, the CDI plugin throws an exception, which CDT catches and converts to a DebugException, which it then throws.Ah. That makes a lot of sense. I'll look at fixing the gdb/mi backend tomorrow.So, here's the dilemma for gdb/mi. All we can do is try to read memory at an address. It's either going to fail or succeed. So, let's say the Debug Platform asks us for 0x100 units of memory at 0xFF70. On the target, memory can't be read before 0x10000. So, in theory, we should return to the platform an array of MemoryByte whose first 0x30 bytes are tagged non-readable (so we get '?') and the other 0x70 bytes readable. But how can we do that when the gdb command is simply going to fail when we ask for memory at 0xFF70? Immediately, some hacks come to mind, but they're all impractical. E.g., we could use a binary-divide approach to keep calling gdb to find where the first readable byte is, but what if the range is not half-invalid, half-valid. What if there are pockets of valid memory surrounded by invalid memory? This is not uncommon in the embedded world. Another idea is that we can just give all invalid MemoryBytes to the platform for the memory it's asked for. But that's misleading the user. The debugger is going to tell him that memory from 0x10000 to 0x10070 is unreadable. Without a smarter debugger engine (one that returns marked memory) I just don't see a good fix.(In reply to)BTW, excuse my poor hex math. I should have said 0x100 units at 0xFFD0	19.0
id=340446	REOPENED	MAT	Core	unspecified	All All	P3 normal	Project Inbox	2011-03-18 11:49 EDT by	Brian Peacock	2011-03-28 10:01 EDT (	1 user	Build Identifier: If a txt file exists in the same directory as the phd file, and the txt file is not a valid javacore, then it will fail with:Error opening heap dump 'bp.phd'. Check the error log for further details.Error opening heap dump 'bp.phd'. Check the error log for further details.Unable to read dump /data/dumps/bp/bp.phd metafile /data/dumps/bp/bp.txt in DTFJ format DTFJ-PHD (java.io.IOException)Unable to read dump /data/dumps/bp/bp.phd metafile /data/dumps/bp/bp.txt in DTFJ format DTFJ-PHDError parsing Javacore (java.io.IOException)Error parsing JavacoreNot a javacore file. First line: this is some stuff (com.ibm.dtfj.javacore.parser.framework.parser.ParserException)Not a javacore file. First line: this is some stuffThis is because the txt file is considered to be a javacore even though it isn't, and it will be passed as the metaFile to the DTFJ ImageFactory.getImage().This will then fail with the exception described above. The fix is to catch any IOException, then retry without the metaFile. This will cure any problem that has occurred with a bad metaFile. If the IOException was actually something to do with the PHD itself, the second invocation of ImageFactory.getImage() will fail with the same Exception which will be caught and handled in the correct way.Reproducible: Always	CreatedHere is a patch to do what is described in the bugzillaI'm not convinced we need this. It doubles the time to report an error if the main dump file is corrupt. I haven't heard of a problem with people creating a text file of the same base name as the dump. The MAT notes view creates a file called dumpname.notes.txt which doesn't cause problems.DTFJ 1.5 won't read 1.4.2 javacore dumps, but that is unlikely to cause a problem as by default the heap dump and java dumps are named heapdump*.phd and javacore*.txt, so MAT will not pass both dumps to DTFJ. The PHD reader silently ignores the associated javacore it cannot read.I think this is all down to how people work.I have a number of directories that each contain a number of dumps. A single directory will contain everything concerned with a particular issue that I am working on.Let's assume I have 3 heapdumps in the directory. I want to keep a few notes on each dump reminding my what I was doing when each dump was created. The 3 heapdumps are called:heapdump.20110211.135004.3802.0002.phdheapdump.20110218.122113.5445.0002.phdheapdump.20110311.152435.7882.0002.phdCleverly, MAT names all it's indices so they have the same basic naming convention and so to list all the files associated with the first heapdump once MAT has run I would type:ls heapdump.20110211.135004.3802.0002.*(Yes, I'm using Linux, but just replace ls with dir if you're a Windows person)Thus, if I was writing some information about the first dump I've got in the habit of giving the file an extension of .txt (probably back from the old DOS days, although lots of editors used to default to .txt for text files) and thus to make sure I can get all the information along with this extra information using the same ls command I would create a file called:heapdump.20110211.135004.3802.0002.txt... and thus the problem occurs.... and I have had this problem a couple of times already hence I wrote this fix.Personally, I think the extra time required to fail is negligible and thus the downside is very small.	3.0
id=77279	REOPENED	CDT	cdt-debug	2.0.2	PC Windows XP	P3 enhancement	Mikhail Khodjaiants	2004-10-29 08:49 EDT by	Oyvind Harboe	2007-06-22 12:56 EDT (	0 users	When debugging embedded targets watching the same memory region all the time is quite common as things are much more locked down than in a PC application.Øyvind	Moving the target milestone to 3.0 when we will switch to the Memory view provided by the Eclipse platform.Consider for 3.0.The partial solution is applied. The memory blocks' base addresses (not expressions) are persistent across sessions. Unfortunately, the renderings are not - no API support for it.Marking as LATER.LATER/REMIND are deprecated. Changing to reopened milestone '--'	4.0
id=189593	REOPENED	CDT	cdt-build	4.0	PC Windows XP	P3 normal	Mikhail Sennikovsky	2007-05-29 03:15 EDT by	Sascha Radike	2012-08-21 04:40 EDT (	1 user	HEADReproduce:- Create a C project with some content- Build- Close Eclipse- Start eclipse- BuildCDT (I only checked the internal builder) will perform a complete build (compile and link) again. This may be fine for small projects, but for big projects (build time of several minutes/hours) I don't think this would be acceptable.	Reproducible for the Internal Builder only, updating the bug summary..Assigning to myself for now..I've checked in a small fix for this. I don't see the Internal Builder running a rebuild on startup any more.Marking as fixed.. Please verify and re-open if this is still an issue for you.(In reply to)Reopening. Sorry for the delay. The internal builder is (still/again?) performing a full build after opening the workspace.Where did you apply the fix ?SaschaI noticed a simple MinGW project won't get rebuild. But my project with custom tool-chain gets (fully) rebuild.Will have to investigate...It looks like I figured out the reason for the full rebuild bug:As you know I'm providing source entries by an external settings provider. CDT forces a rebuild every time the external settings get updated - even when they do NOT change at all!Here's the stack when the rebuildstate gets set to true:Thread [main] (Suspended (breakpoint at line 1713 in Configuration)) Configuration.setRebuildState(boolean) line: 1713 Configuration.setSourceEntries(ICSourceEntry[], boolean) line: 2340 Configuration.setSourceEntries(ICSourceEntry[]) line: 2327 BuildConfigurationData.setSourceEntries(ICSourceEntry[]) line: 123 CConfigurationDescription.setSourceEntries(ICSourceEntry[]) line: 492 CExternalSettingsDeltaProcessor.applySourceEntriesChange(ICConfigurationDescription, CExternalSettinsDeltaCalculator$ExtSettingsDelta[]) line: 78 CExternalSettingsDeltaProcessor.applyDelta(ICConfigurationDescription, CExternalSettinsDeltaCalculator$ExtSettingsDelta[], int) line: 52 CExternalSettingsDeltaProcessor.applyDelta(ICConfigurationDescription, CExternalSettinsDeltaCalculator$ExtSettingsDelta[]) line: 39 CExternalSettingsManager.applyDeltas(CExternalSettingsManager$ICfgContainer, CExternalSettinsDeltaCalculator$ExtSettingsDelta[]) line: 619 CExternalSettingsManager.processContainerChange(int, CExternalSettingsManager$ICfgContainer, CExternalSettingsManager$ICRefInfoContainer, CExternalSettingsManager$CContainerRef, CExternalSettingsManager$DeltaInfo) line: 613 CExternalSettingsManager.processContainerChange(int, CExternalSettingsManager$ICfgContainer, CExternalSettingsManager$CContainerRef, CExternalSettingsManager$DeltaInfo) line: 598 CExternalSettingsManager.containerContentsChanged(CExternalSettingsManager$ICfgContainer, CExternalSettingsManager$CContainerRef, CExternalSettingsManager$DeltaInfo) line: 591 CExternalSettingsManager.update(ICProjectDescription) line: 747 CExternalSettingsManager.handleEvent(CProjectDescriptionEvent) line: 679 CProjectDescriptionManager.notifyListeners(CProjectDescriptionEvent) line: 2782 CProjectDescriptionManager.getProjectDescription(IProject, int) line: 476 CProjectDescriptionManager.getProjectDescription(IProject, boolean, boolean) line: 434 CProjectDescriptionManager.getProjectDescription(IProject, boolean) line: 426 CProject.computeSourceRoots() line: 602 CProject.computeChildren(OpenableInfo, IResource) line: 653 CProject.buildStructure(OpenableInfo, IProgressMonitor, Map, IResource) line: 587 CProject(Openable).generateInfos(Object, Map, IProgressMonitor) line: 260 CProject(CElement).openWhenClosed(CElementInfo, IProgressMonitor) line: 394 CProject(CElement).getElementInfo(IProgressMonitor) line: 274 CProject(CElement).getElementInfo() line: 264 CProject(Parent).getChildren() line: 54 CModelManager.create(IFile, ICProject) line: 301 CoreModel.create(IFile) line: 86 CDocumentProvider.createTranslationUnit(IFile) line: 704 CDocumentProvider.createFileInfo(Object) line: 732 CDocumentProvider(TextFileDocumentProvider).connect(Object) line: 472 CDocumentProvider.connect(Object) line: 688 CEditor(AbstractTextEditor).doSetInput(IEditorInput) line: 3932 CEditor(StatusTextEditor).doSetInput(IEditorInput) line: 190 CEditor(AbstractDecoratedTextEditor).doSetInput(IEditorInput) line: 1224 CEditor(TextEditor).doSetInput(IEditorInput) line: 168 CEditor.doSetInput(IEditorInput) line: 1163 AbstractTextEditor$19.run(IProgressMonitor) line: 2995 ModalContext.runInCurrentThread(IRunnableWithProgress, IProgressMonitor) line: 369 ModalContext.run(IRunnableWithProgress, boolean, IProgressMonitor, Display) line: 313 ApplicationWindow$1.run() line: 758 ...(In reply to)That's interesting.. The Configuration.setSourceEntries() does contain a check for the entries equality.. public void setSourceEntries(ICSourceEntry[] entries, boolean setRebuildState) { -> if(Arrays.equals(getSourceEntries(), entries)) -> return;it seems that the entries being set differ from those currently contained by the configuration. Could you please check what is the difference between them?Thanks,MikhailUpdating the bug summary to mostly reflect the issue..(In reply to)My external settings provider provides the following CSourceEntries:- path = "/Project", exclude = "Devices", flags = VALUE_WORKSPACE_PATH)- path = "/Project/Devices/Abc/Startup", exclude = null, flags = VALUE_WORKSPACE_PATH)- path = "/Project/Devices/Abc/Run", exclude = null, flags = VALUE_WORKSPACE_PATH)-> So I want to EXCLUDE "/Project/Devices" and only INCLUDE "/Project/Devices/Abc/Startup" and "/Project/Devices/Abc/Run"- I also added a "src" source folder manuallyRegarding Arrays.equals:*** First test: ***sourceEntries ICSourceEntry[4] (id=626) [0] CSourceEntry (id=4745) [1] CSourceEntry (id=4746) [2] CSourceEntry (id=4751) [3] CSourceEntry (id=4752) [sourcePath] ; exclude: src, Devices ; flags: VALUE_WORKSPACE_PATH[sourcePath] Devices/Abc/Startup ; flags: VALUE_WORKSPACE_PATH[sourcePath] Devices/Abc/Run ; flags: VALUE_WORKSPACE_PATH[sourcePath] src ; flags: VALUE_WORKSPACE_PATH|RESOLVEDentries ICSourceEntry[3] (id=612) [0] CSourceEntry (id=4773) [1] CSourceEntry (id=4774) [2] CSourceEntry (id=4779) [sourcePath] Devices/Abc/Startup ; flags: VALUE_WORKSPACE_PATH[sourcePath] Devices/Abc/Run ; flags: VALUE_WORKSPACE_PATH[sourcePath] src ; flags: VALUE_WORKSPACE_PATH|RESOLVED*** Second test (new project): ***sourceEntries ICSourceEntry[3] (id=6717) [0] CSourceEntry (id=6722) [1] CSourceEntry (id=6723) [2] CSourceEntry (id=6728) [sourcePath] Devices/Abc/Startup ; flags: VALUE_WORKSPACE_PATH[sourcePath] Devices/Abc/Run ; flags: VALUE_WORKSPACE_PATH[sourcePath] src ; flags: VALUE_WORKSPACE_PATH|RESOLVEDentries ICSourceEntry[4] (id=84) [0] CSourceEntry (id=6651) [1] CSourceEntry (id=6652) [2] CSourceEntry (id=6653) [3] CSourceEntry (id=6654) [sourcePath] ; exclude: src, Devices ; flags: VALUE_WORKSPACE_PATH[sourcePath] Devices/Abc/Startup ; flags: VALUE_WORKSPACE_PATH[sourcePath] Devices/Abc/Run ; flags: VALUE_WORKSPACE_PATH[sourcePath] src ; flags: VALUE_WORKSPACE_PATH|RESOLVEDSomething about the "src" source folder is wrong. I just created a new project _without_ a "src" source folder and I don't even reach the setSourceEntries any more (= good).Hi Sascha, I am unable to reproduce this issue with my test ext settings provider. Could you provide some test-case to reproduce the problem you're seeing?Thanks,MikhailPostponing to the 4.0.2..Since I'm still unable to reproduce this, I'm going to postpone this to the Future..	12.0
id=55725	REOPENED	CDT	cdt-debug	1.2	PC Windows 2000	P3 normal	Mikhail Khodjaiants	2004-03-23 13:43 EST by	James Langley	2007-06-22 12:56 EDT (	0 users	If you change the format of a variable in the variables view, and then click resume, the format of the variable resets to Natural. If you single step on the other hand, it doesn't change the format. In the example code below, if you put a breakpoint on the i++ line, then change the format to hexadecimal, then single stepping through the loop means that the variable's format is remembered. If you hit resume at any point, when you stop at the breakpoint next time, the format of the variable will have reset to Natural.#include <stdio.h>int main(){ int i = 0; while (i < 100) i++; return 0;}	This is an expected behavior. When you resume the execution all local variables are gone. Otherwise, we have to keep the list of all local variables with changed formats.The idea to set the format of local variables individually is becomming more and more questionable.Hmm, I see the problem. Perhaps there should be some kind of global setting for the variables view, but I can't quite see how it's going to deal with different variable types. At the moment, it looks strange to resume inside the same function and find that the variables view has lost it settings, when single stepping doesn't have the same behaviour.Marking as "LATER".LATER/REMIND are deprecated. Changing to reopened milestone '--'	4.0
id=396081	REOPENED	CDT	cdt-debug-dsf-gdb	8.1.1	PC Windows 7	P3 normal	Mikhail Khodjaiants	2012-12-07 18:31 EST by	Mikhail Khodjaiants	2013-06-04 13:03 EDT (	3 users	Standard source directory structure of an MBS project is <workspace-loc>/<project-name>/src/<file-name>. When debugging such a project and entering "break ./src/<file-name>:n" in the GDB console I get two breakpoints in the Breakpoint view. The reason is the synchronization mechanism introduced indoesn't convert the debugger path when comparing the created platform breakpoint's file name with the target breakpoint's file name.	Pushed a fix to Gerrit:Marc, please review it. The code is quite complicated but I couldn't come up with anything better.I'm trying to understand the problem of this bug.I'm testing on Linux and here is what I see before the patch:1- launch a session2- in the gdb console type b ./src/DSFTestApp.cpp:1973- GDB does not find the file and creates a PENDING breakpoint4- the breakpoint synchronizer installs another bp using the absolute path.after the patch, step 4 does not happen.That means that the breakpoint is shown in the breakpoint view but is not installed on the target and therefore will not stop the target.I wonder if it wouldn't be more user-friendly to leave things as is? Eclipse forces the installation of a second breakpoint, which will actually hit, which is probably what the user intended.Or is there some other behavior I didn't notice?Note that removing the ./ prefix makes things work. I wonder why GDB behaves like that?566,050 [MI] 28-interpreter-exec console "b src/DSFTestApp.cpp:197"566,052 [MI] ~"Breakpoint 2 at 0x8048c0a: file ../src/DSFTestApp.cpp, line 197.\n"566,053 [MI] =breakpoint-created,bkpt={number="2",type="breakpoint",disp="keep",enabled="y",addr="0x08048c0a",func="main(int, char**)",file="../src/DSFTestApp.cpp",fullname="/home/lmckhou/runtime-TestDSF/DSFTestApp/src/DSFTestApp.cpp",line="197",times="0",original-location="src/DSFTestApp.cpp:197"}566,053 [MI] 28^done(In reply to)>My intention is to associate the breakpoints installed on the target with platform breakpoints. In this case we have a target breakpoint that has no platform breakpoint associated with it. I think it would be confusing for those who use the console to set breakpoints.In general, the logic in my previous implementation is wrong. It ignores the source lookup when trying to find a platform breakpoint for a target breakpoint.I don't know. Setting a breakpoint at ../src/DSFTestApp.cpp would work even if the work directory is the project directory.(In reply to)Ok, except that we have a similar situation when creating a second breakpoint at the same line. If I create a platform bp at line 20 and then create one using the gdb console at the same line 20, that second target bp does not seem to get associated with the platform bp, or at least is hit an error. Should I open a new bug?You're right. The code looks good. Cosmetics comments in Gerrit.(In reply to)>Yes, please. We need to figure out how to handle this case.Thanks!(In reply to)I've openedand posted your proposed fix to Gerrit.Marc, I changed the code as you suggested (btw, nice trick!) and pushed the new version of the patch to Gerrit. Can you please review that part of the code? I modified your code to handle the case when an error appears in the source lookup and would appreciate your opinion.Thanks!Checked in. Thanks Marc.This patch doesn't work when the source lookup contains a path mapping. Moreover it breaks the normal behavior. I suggest reverting it.Marc, what do you think?(In reply to)We're using the SourceLookup service in the bp synchronizer, which should handle path mappings. Why aren't things working?(In reply to)The usage of the source lookup in the patch is wrong. It's just a coincidence that it works for this case. The main problem is inconsistency between the GDB source lookup and the CDT source lookup.When a breakpoint is set at ./src/DSFTestApp.cpp GDB doesn't find the source file but the CDT does. MIBreakpointsSynchronizer creates a platform breakpoint using the full path (/workspace/project/src/DSFTestApp.cpp). When the platform breakpoint path is passed to MIBreakpointsSynchronizer.getTargetBreakpoint() is already converted to the debugger path by MIBreakpointsManager (in this case it is the same /workspace/project/src/DSFTestApp.cpp path which is important). findTargetLineBreakpoint() converts the path of all existing target breakpoints to the platform paths and compares them with the debugger path. As a result ./src/DSFTestApp.cpp gets converted to /workspace/project/src/DSFTestApp.cpp and "found". So, a duplicate target breakpoint is not created.But if there is a path mapping in the source lookup, the mismatch between the platform and debugger path prevents MIBreakpointsSynchronizer to find the corresponding target breakpoint. It is broken for all breakpoints including non-pending.It's all very complicated, no wonder I missed it when I was implementing the patch.(In reply to)Thanks for the explanation! Yes, that didn't jump out at us at all :)Is it correct to say that the patch put in for this bug does improve the situation a little? In that case, maybe it would be better to keep things as is, and properly fix this bug for the SR1 release?(In reply to)It does improve this particular situation which only applies to breakpoints set using correct relative paths that are not recognized by GDB. But it breaks much more common case for all line breakpoints set from the console that can be affected by a path mapping defined in the source lookup.I would rather keep this bug open and revert the patch.(In reply to)Ok, makes senseReverting the commit required some manual intervention so I'm pushing it to gerrit:Since RC3 hasn't been built yet, I'll commit it now. I have checked that the JUnit tests still work. I'd like Mikhail to confirm that it fixes the path mapping issue since I haven't been able to reproduce it myself.(In reply to)I pushed a second patchset to gerrit. It is simpler than the first one and keeps the new API. I was thinking that this new API will be required when trying to fix this bug again, so it would be better to keep it.I've committed this second patch set to master.Mikhail, can you please review and also confirm it fixes the problem?(In reply to)I tried the latest master on Windows with MinGW and Cygwin. The latter's source lookup contains the path mapping that maps Cygwin paths to Windows paths. In both cases I was able to set console breakpoints using the file name which is good enough for this release.Regarding this particular bug, I think we need to try making the CDT source lookup consistent with GDB.	17.0
id=496248	REOPENED	GEF	GEF MVC	1.0.0	All All	P3 normal	Alexander Nyßen	2016-06-16 05:19 EDT by	Alexander Nyßen	2016-10-20 03:57 EDT (	0 users	We should investigate whether the current separation of core concepts and JavaFX specific specializations is really beneficial, or if the overhead in client code is too large. We could think of merging MVC/MVC.FX and MVC.UI/MVC.FX.UI into MVC and MVC.UI modules.	This is closely related to(investigate dropping the V parameter).When doing so, we should also think about separating out the (then fx-specific) core concepts from the concrete diagram-related specifics (like concrete interaction policies).In analogy to Zest.FX, merged MVC into MVC.FX and MVC.UI into MVC.FX.UI. Renamed classes to no longer provide the FX-prefix (except for MVC.FX.UI, where FX and SWT are mixed).Without the JavaFX-independent abstractions, we now have the change to extend IViewer so it can offer all abstractions needed by the code (so the implementation can be hidden). We can also revisit the 'flag'-interfaces for transform, resize, and bend.Resolving this as fixed in 5.0.0 M3.Reopening, because the wiki documentation still has to be adopted to reflect this change.And one more thing: we should ensure that 'near' the visuals, JavaFX geometric abstractions (e.g. Affine) are used rather than Geometry abstractions (AffineTransform). This should also hold for the respective visual operations and the ITransformableVisualPart, IResizableVisualPart, and IBendableVisualPart interfaces.	5.0
id=331730	REOPENED	Objectteams	OTDT	0.7.1	PC Linux	P3 normal	Project Teams	2010-12-02 17:22 EST by	Jan Marc Hoffmann	2011-01-28 18:11 EST (	1 user	If you add a breakpoint on the first statement of a base method with a callin attached to it, you will get tons of stops on the methodheader without any of them reaching your breakpoint.	The additional stops you are seeing could be intentional.Please check the preference section at Preferences > Object Teasm > Debug > Visualization of callin dispatchIf you uncheck all three checkboxes stepping should no longer stopat unexpected places, right?I'm closing as invalid as I suspect what you were seeing is in factthe intended behavior.Feel free to reopen with more details ifdidn't help.Uh I nearly forgot about this one. I just disabled all the options you mentioned. Same odd behaviour. The debugger stops at the method header several times.Sorry, running out of time for M5.	4.0
id=370021	REOPENED	Tools	Releng	unspecified	All All	P3 normal	Alexander Nyßen	2012-01-27 16:58 EST by	Alexander Nyßen	2014-01-06 09:41 EST (	4 users	CreatedAbout dialog, having GEF installed.The about dialog seems to group features according to their icon and provider names. As there is no standardized provider name and no tools icon (at least I am not aware of one), tools projects, which do not want to provide an own icon, are not consistently grouped. As I have documented in, for GEF it was decided to re-use the modeling icon. The provider of all GEF features/plug-ins was accordingly chosen to be Eclipse Modeling Project, while GEF indeed is located under tools. Having corrected that, GEF is now shown in its own category, neither with the modeling projects (as it does not specify the same provider), nor under the platform plug-ins (as it uses another icon). I would propose that the tools top-level project should provide an own icon and agree on a default provider name to be used in such situations.	Seems like nobody cares about... :(Maybe we just should reuse our itemis logo and provide it as "Eclipse Tools Project" vendor image!? :)There was a bug report, reported by David Williams, about an "About dialog" with more then ten different icons, after installing all the features from the indigo repository. Unfortunately I can't find it anymore. However I think it's very important that the Tools project provides a common providerName and icon.I found an interesting discussion:But without any suggestion what icon should be used for tools subproject branding.Nobody interested in this?(In reply to)Maybe just a wrong inbox... .-/I think its been decided that Tools Projects, such as GEF, CDT, Orbit, etc., are all distinct enough that it did not make sense to have one "Tools" brand/icon/name, etc., and that each subproject was free to do their own, if they desired an icon. And the Provider name should be thinks like "Eclipse Orbit", "Eclipse CDT", "Eclipse GEF", etc. Is this helpful, or am I missing the point?And it did not make sense for a separate category for GEF to show two features, two plugins and one new icon in products about dialog.So we went with using Eclipse Modeling Project in 3.5. So GEF shows up with EMF and GMF and products about dialog is a little cleaner.(In reply to)As Anthony pointed out, we do not want to ship an own icon for GEF, as this makes no sense (its a base technology, no end-user tool). However, GEF does not belong to Modeling but to Tools, so using modeling icon seems to be not helpful (if people search GEF, they should search it under Tools). So my actual concern was that Tools should provide a default icon (as modeling does) for those tools sub-projects that do not want to provide their own icon.We (Xtend) would also like to reuse an existing common Tools Vedor/Icon, currently we participate to Juno with Vendor="Eclipse Xtend" and the modeling icon.... or we need a horizontal scroll bar in "About eclipse SDK" for all the custom providers.Yes, I forgot to mention it. I would also like to re-use a common vendor (maybe "Eclipse Tools") for those who don't want to provide their own icon, as the about dialog evaluates it and only groups those entries that share a common vendor and icon.Excellent. I think if "you build it they will come". :) Tools of course is an umbrella-only project ... i.e. has no committers per se or repository location. My first suggestion would be for one of you to provide one (with feedback from the others and PMC) and once done, my first choice would be for that one project, such as GEF or XTENDS to provide what's necessary in their repo and point others to it. If you really need a common location on "downloads" for one or two icon files, I'm sure we could do that. So, sorry we, Tools, have no designers to throw on the work, but there's nothing wrong with what you are suggesting. Again, feel free to say if I'm mis-understanding.(In reply to)I will check whether itemis (Dennis and I both belong to the group) can "donate" such an icon. We usually have a designer at hand... Maybe he can create something in the style of the modeling icon as a proposal. Do you know where the image sources for it can be found?CreatedDraft for Tools project logoWell, it has taken some time (because of the holidays period), but our designer has created a first draft of a tools project logo. What do you think?...(In reply to)Looks cool! +1 :)I too think it looks great. Just right for "tools". If I had one suggestion, it would be for the word "eclipse" to be moved slightly to the right, so it was completely inside the "nut". Perhaps aligned with the center of the "T" in "Tools", instead of the left edge of that "T". For a couple of reasons, but partially because it kind of gets "lost" in a white background. Plus, I'd assume, that "outside" part of the icon would normally be "transparent", so having 'eclipse' completely inside the "nut" makes is more independent of what ever other colors or backgrounds a user might set for their display. That said, its great. It could be used as it, so just take my comments if you find them helpful. I am not dictating it has to be changed. Greatest thanks!Adding Ian for awareness, since he's aware of many images at Eclipse. Ian, this doesn't rise to the level of a "Tools Branding Effort" ... we just trying to simply and improve some UI details for projects in Tools.Re-reading this, I think we are (nearly) done here. The icons/images look nice. Can you make them available in a "consumable" form for those that would like to use it? Either in Eclipse app ... and perhaps we could put one onI'm not exactly sure what the "requirements" are ... but, hopefully you know more about that than I do already (you know, tools.icn, tools.xcom ... svg? bmp? ... all the various resolutions. "Source" format would be helpful as well as final consumable icons. Or ... would you rather close this as "won't fix"?(In reply to David Williams from)Well, if you find out the "requirements" I will promise to contact our designer and see if he can still remember what he has done a year ago...(In reply to Alexander Nyssen from)I wasn't volunteering my work. So, if you aren't willing to find out requirements for Eclipse icon "packages", let's just close as "won't fix". Thanks for the ideas and apologies for the slow responses in this bug.I'm speechless... Is that how we handle contributions?(In reply to Alexander Nyssen from)I'm not sure how to interpret your question, but if its a serious question, we love contributions ... but not mere suggestions for others to "do the work". So if you research it and find out what resolutions/formats icons need to be in, for Windows, Linux, and Macs, please re-open. I suspect you can google it ... or ask on cross-project list? I just thought you were saying you were unwilling to do that and expected me to ... so me closing as "won't fix" might have been based on a miscommunication?(In reply to David Williams from)I like sarcasm, but please let's discuss this without. If you recall the history of this bug it should get quite clear that we pretty much wanted to support this. Actually we mandated a designer to do the first sketch (with the mere result that our proposal was simply ignored for more than a year).I don't think there is any miscommunication. I have the fear its more a different attitude on how to handle contributions. If a contributor tells me "I am willing to provide what is needed, please just tell me what exactly do you need." I usually don't answer "You will have to find that out on your own. Maybe ask on the cross-project list...".Well I've some how given the wrong impression here (and/or gotten the wrong impression) ... perhaps in part because I was assuming you knew 100 times more about "Eclipse graphics" than I do! Plus, it was you that opened the bug ... so I was assuming you "knew what you wanted", so to speak. But I may have done too much skim reading to fully understand the issues? I guess if it was me, I'd state the requirements as "icons of appropriate sizes and resolutions that can be used by RCP apps on all platforms supported by Eclipse ... and (optionally) one appropriate for web pages".Or ... perhaps, if your intent is this be used only for the "about box" the requirement(s) would be slightly different? I do not know. Sorry I don't know more specifics, but I did a few google searches and found this pagewhich might help you state what you'd like to contribute? Apologies if I seemed sarcastic or rude. Sincerely,Ok, let's forget the quarrel...My primary concern for opening this bug was the need for an icon that could be used in the about.ini (i.e. Feature icons for about dialog) to be used for our GEF features (and I assume its the same use case for Dennis w.r.t to Xtend), so a 32-bit PNG would be sufficient, as far as this is concerned.Nevertheless, while other use cases do not directly come to my mind it would (according to the link you provided) probably make sense to produce the following icons:Png - 32 bit: (all sizes) 16, 22, 24, 32, 48, 64, 128, 256, 512, 1024Gif - 8 bit / 256 colors 16, 22, 24, 32, 48 4 bit / 16 colors 16,22,24,32,48I will see what I can do...CreatedTools Logo in GIF4, GIF8, and PNG formatAttached please find the logo files as produced by our designer. We have included GIF4 and GIF8 (which do not look as nice due to restrictions of the GIF format), as well as PNG versions, each with and without a text label.(In reply to Alexander Nyssen from)Thanks very much! They look cool to me. I'll look at them closer, send appropriates notes, and decide "where to put them" soon, but in the mean time, in the zip is a folder named __MACOSX which appears to have "quarantined" attributes or something. Is that something that will "make sense" if I unzip on my mac? Or something included in the zip file by accident?(In reply to David Williams from)Hmm, I don't see any such folder, also if I download and unzip it on my other mac. Don't know where that comes from...On my mac, if I use "unzip" from command line interface, I see the directory created, but if I use the "native" Archive Utility App on the mac, then I do not see it ... presumably because it knows how to incorporate those "extended file attributes" back into the file system. In short, all is well. I put these icons in our "website git" repository, seeAnd while know the "website" is nothing to brag about ... I put one of the logos (128x128) on the main page:I'll send a note to tools project leads that the icons are here, and ready to use. I honestly don't know if other formats such as "icns" or "xcom" are required or if but assume what we have can be "converted" to those other formats if needed. If there's no other comments/feedback, and if you agree, I think this can be closed as fixed, right?As already mentioned in my first comment, what is still missing is an agreement about a default provider name (e.g. Eclipse Tools) that is to be used by the tools sub-projects, as the about dialog groups features by icon as well as provider names (and we want to have them all grouped together by default).Also, I think it would be a good idea to provide this information (icons as well as provider name) at a prominent place somewhere in the wiki. Do you have an idea about an appropriate place?(In reply to Alexander Nyssen from)I think you could create a page under wiki.eclipse.org/Tools/CommonToolsIconsor, similar. I'll assume you'll create this page?Under the "Tools" Top Level Project, we've said each project can have their own name, such as "Eclipse <projectName>" which seems most appropriate for those tools such as "CDT" which people would install as "users of the tool", but others such as GEF could use "Eclipse Tools". I think the question comes up if projects from other top level projects want to use a common name, to be counted in this common category (and use the common icon). I think fine if they wanted to use "Eclipse Tools", but if something less project-specific was desired, by them, I'd suggest "Eclipse Common Tools". Could you please drive that discussion ... perhaps with a bug in Cross Project component and a note to Cross-Project list?I think "in Git", where they are is fine and most would prefer to get versioned controlled ones from Git. If you wanted to include samples or even a zip from wiki, I think that's fine to have that redundancy, but I think the "official set" should be in Git. Hope that helps,	29.0
id=495163	REOPENED	Oomph	Release Engineering	1.4.0	All All	P3 normal	Project Inbox	2016-06-01 09:32 EDT by	Andreas Sewe	2016-09-01 17:14 EDT (	4 users	Hi,I just noticed in the repository reports [1]that you still contribute an older version of org.apache.httpcomponents.httpclient: 4.3.6.v201411290715.This indicates that you haven't switched to the Orbit R-build for Neon yet. Can you please do so for Neon RC4? Two versions of org.apache.httpcomponents.httpclient that only differ by qualifier are unnecessary in the simrel repo.[1] <>[2] <>	(In reply to Andreas Sewe from)FWIW, if I interpret [1] correctly, you are the last one to contribute the bundle with the v201411290715 qualifier, so I you make the switch the simrel repo should contain only a single org.apache.httpcomponents.httpclient 4.3.6. :-)[1] <>We use this repo for Orbit:It contains the version 4.3.6.v201511171540 of org.apache.httpcomponents.httpclient.I confirm that our RC3 build contains the version 4.3.6.v201411290715. But I have no idea what other repo provides this version or why Tycho/p2/whatever decide to consume it. Maybe because we build against Mars: <repository location=""/> <repository location=""/> <repository location=""/> <repository location=""/> <repository location=""/>I don't think there's anything I can do and because multiple versions of a bundle is not a critical problem I'm closing this bug as worksforme.(In reply to Eike Stepper from)I think I can explain this:If you look at the entire target platform definition (which has a single location), you see that it only references non-Orbit features: <location includeAllPlatforms="false" includeConfigurePhase="true" includeMode="planner" includeSource="true" type="InstallableUnit"> <unit id="org.eclipse.egit.feature.group" version="0.0.0"/> <unit id="org.eclipse.emf.ecoretools.sdk.feature.group" version="0.0.0"/> <unit id="org.eclipse.emf.sdk.feature.group" version="0.0.0"/> <unit id="org.eclipse.equinox.executable.feature.group" version="0.0.0"/> <unit id="org.eclipse.m2e.feature.feature.group" version="0.0.0"/> <unit id="org.eclipse.mylyn.builds.sdk.feature.group" version="0.0.0"/> <unit id="org.eclipse.mylyn.sdk_feature.feature.group" version="0.0.0"/> <unit id="org.eclipse.nebula.widgets.tablecombo" version="0.0.0"/> <unit id="org.eclipse.sdk.feature.group" version="0.0.0"/> <unit id="org.eclipse.swtbot.eclipse.feature.group" version="0.0.0"/> <unit id="org.eclipse.swtbot.generator" version="0.0.0"/> <unit id="org.eclipse.userstorage.sdk.feature.group" version="0.0.0"/> <unit id="org.eclipse.userstorage.tests" version="0.0.0"/> <repository location=""/> <repository location=""/> <repository location=""/> <repository location=""/> <repository location=""/> </location>All of these features contribute whatever version of org.apache.httpcomponents.httpclient was current when *they* were build to your target platform. As you don't reference *any* IU from Orbit directly, no IUs from orbit/latest-R are part of your target platform. (See [1] for an example listing the IUs from Orbit explicitly, along with the CQ for them.)FWIW, you can open the .target file in Eclipse and have a look at its contents; you will only see 4.3.6.v201411290715 of org.apache.httpcomponents.httpclient, so this is not specific to Tycho.Even if multiple versions are fine, I'm reopening because 1) I think there is something you can do and 2) your target platform doesn't work like you think it does.Hope that helps.[1] <>For our build/repo I just don't care about the exact version of this bundle. We do not depend on any specific version.I still don't see how multiple versions of such a bundle cause any harm.And our .target file is automatically generated, so I can't edit it manually.In summary, I don't think I can do anything here.(In reply to Eike Stepper from)Well, at least the Neon RC3 Java package contains both versions:This increases the download size by about 800 kilobytes, which adds up. The Java package alone has seen about 1 million downloads since Mars.2.Moreover, it's sadly not true that having multiple versions of the same bundle does not harm. This only is true in an ideal world where all the bundle metadata is correct. Sadly, we don't life in such a world (seefor a problem with 4.3.6.v201411290715).What about Oomph building different p2 repos for different Eclipse train versions? That way you could consume the Orbit repo that matches the Eclipse train version for each build.(In reply to Eike Stepper from)Seefor an example, likely caused by faulty metadata (uses constraints) in client of org.apache.httpcomponents.httpclient (USS), which caused *its* client to fail (MPC).Can't you build against different target platforms for different release trains? We at Code Recommenders do just that [1].The output of mvn clean install Dsimrel=neongets promoted to our update site for Neon simrel contributions and the output of mvn clean install Dsimrel=oxygengets promoted to our update site for Oxygen simrel contributions.If you use Hudson multi-configuration jobs, you don't even need multiple jobs for this; just multiple *promote* jobs that copy the bits from the correct subdirectory to their simrel-specific destination.[1] <>Just fyi regarding the MPC bug: While a single httpclient version would have prevented it, the fault was on my side for using an internal USS class that exposed its httpclient dependency (which is completely fine for an internal class to do inside its own bundle) - and a bit equinox's for making strange wiring decisions.I also agree in theory with Eike that it shouldn't really matter - and we should improve things so it doesn't actually. But in practice I agree with Andreas: having just one version does not just save a couple of bytes, it also helps lower the risk and increase stability for the released packages.	8.0
id=389510	REOPENED	Orbit	bundles	unspecified	All All	P3 minor	Orbit Bundles	2012-09-13 09:50 EDT by	Raymond Auge	2016-08-11 15:22 EDT (	3 users	CreatedA fragment bundle built using the following bnd file allowed the successfull generation of jsp filesorg.apache.jasper.glassfish is missing imports of: javax.xml.parsers javax.xml.transform org.w3c.dom org.w3c.dom.ls org.xml.sax org.xml.sax.helpers(and perhaps others)Bundle-Version: 2.2.2.v201112011158Implementation: equinox (juno)Other dependencies: satisfied (bundle starts and executes without "other" errors)	Createdpossible fixAnalyzing the class files I came up with the attached patch that adds the necessary imports. I made the ant dependencies optional since we don't use ant tasks provided by jasper in our usage scenarios.I am not sure about the javax.annotation.processing or java.lang.model* packages. I assume these are being used by the copy of ecj we have in the orbit bundle. I am not sure what cases these packages are necessary or if they can be optionally imported. That being said, I don't think it is a problem to make these packages mandatory since these packages are included in JavaSE-1.6 and that is the minimum execution environment for the org.apache.jasper.glassfish bundle anyway.Looks good to me. Hugues, want to try for Kepler M2? (i.e. in 1 day :/ Also, there is a version 2.1.0 still in active builds that might need similar analysis/changes? Tom, what did you use to "analyze the class files"? I used to use "depends" or something named similar but wonder if there's something better. Or, maybe you just look at with hex editor :) Hugues, it'd be good to update your email in the ip_log xml files as it appears to have changed. Thanks all.(In reply to David Williams from)Wish I could recall for sure. I think I used a bnd tool. Or perhaps I imported the jar as a bundle into PDE and had it calculate the imports.(In reply to Thomas Watson from)Sorry Tom .. and Raymond. I am just not seeing it. I tried 3 things to try to confirm these were needed, but none of them panned out. Which is not to say I haven't made an error, somewhere, but ... I do at least want to ask "... are you sure?" First I looked at the org.apache.jasper.glassfish bundle used by Jetty 8.x (latest) distribution ... thinking maybe they did the same or similar thing. But, no. pretty much just like ours. (now that we've added the optional JDT core imports). Next, I used "jdeps" (which comes with Java 8) to see what each package requires ... but could not "see" the requirements that are in the patch. (Granted, that is "just java" (not OSGi) but ... I've used it before and it does help find "top level" missing packages ... which, I think is all we need? Next, I used Eclipse itself, imported in various ways, and computed dependencies in various ways, but it never came up with any differences? I will say, the version that is in CVS right now (and has been for a while) has a requirement on Java 5, in the .classpath -- even though the bundle says "Java 6". I will correct that mistake soon (fixing .classpath) but I wonder if that somehow tainted your earlier results? Especially with bnd? (I did not try that) ... but, I did try, with PDE and 'jdeps' using Java 6 and Java 5, and in neither case did it say I needed more. So, either I don't know how to tell ... or ... the Java 5/6 issue messed things up ... or ... something. Are you sure? ... we need this change? (And, if so, can you account for why I don't see it, but you do?)Oh, this wouldn't be one of the "Vendor" issues would it? I was using Oracle VM in all cases. Were you using IBM's?(In reply to David Williams from)The VM used didn't seem to matter. (i.e. got same non-results). I've only one more guess ... I am wondering if "bnd' treats the files as a "pseudo feature" and "gathers" everything needed, even by "required" bundles, if the "required" bundles do no contain what they should? Also, the .classpath was incorrect for the bundle in CVS, still saying "1.5" instead of the correct "1.6" -- I've just fixed, as part of-- but, if bnd uses the .classpath, that would certainly give incorrect results.Gunnar, you are a "big bnd" user, right? If easy for you, was wondering if 1) you'd be willing to double check with bnd to see that it adds to MANIFEST.MF, and 2) if different from what all these other methods find, if you'd be able to explain it?(In reply to David Williams from)Well, let's put it this way: I realized using bnd is much more reliable for computing packages to import as well as "uses" clauses than PDE that I do trust it more.For 1) I check the org.apache.jasper.glassfish 2.2.2 bundle published by the Jetty team. It came up with the following.--------------------------Import-Package: javax.eljavax.servletjavax.servlet.descriptorjavax.servlet.httpjavax.servlet.jspjavax.servlet.jsp.eljavax.servlet.jsp.tagextjavax.toolsjavax.xml.parsersjavax.xml.transformjavax.xml.transform.domjavax.xml.transform.streamjavax.xml.validationorg.eclipse.jdt.core.compilerorg.eclipse.jdt.internal.compilerorg.eclipse.jdt.internal.compiler.classfmtorg.eclipse.jdt.internal.compiler.envorg.eclipse.jdt.internal.compiler.problemorg.w3c.domorg.w3c.dom.lsorg.xml.saxorg.xml.sax.extorg.xml.sax.helpersExport-Package: org.apache.jasper uses: javax.servlet javax.servlet.jsp.tagext org.apache.jasper.compiler org.apache.jasper.runtime org.apache.jasper.servletorg.apache.jasper.compiler uses: javax.el javax.servlet javax.servlet.jsp.tagext javax.tools org.apache.jasper org.apache.jasper.compiler.tagplugin org.apache.jasper.servlet org.xml.saxorg.apache.jasper.compiler.tagpluginorg.apache.jasper.resourcesorg.apache.jasper.runtime uses: javax.el javax.servlet javax.servlet.http javax.servlet.jsp javax.servlet.jsp.el javax.servlet.jsp.tagext org.apache.jasper org.glassfish.jsp.apiorg.apache.jasper.securityorg.apache.jasper.servlet uses: javax.servlet javax.servlet.descriptor javax.servlet.http javax.servlet.jsp.tagext org.apache.jasper org.apache.jasper.compilerorg.apache.jasper.tagplugins.jstl uses: org.apache.jasper.compiler.tagpluginorg.apache.jasper.xmlparser uses: org.apache.jasper org.apache.jasper.compiler org.w3c.dom org.xml.saxorg.glassfish.jsp.api uses: javax.servlet.jsp.tagext--------------------------As for 2), the differences between PDE and bnd are (I'm 100% certain on this) deficiencies in PDE when calculating imports.(In reply to Thomas Watson from)The patch created by Thomas contains additional imports (Ant, javax.annotation.*, javax.lang.model.*). The Jetty version doesn't seem to contain the ECJ compiler. I did use the download published by Jetty in Maven:.Thanks Gunnar, I'm not 100% convinced :) but also comparing to jetty's version would give different results, since they don't have embedded JDT. So ... what I'll do is take Tom's "possible fix" patch, and if/when anyone finds other issues, please open a new bug. Even though this is a "minor" bug, the change will be in Luna SR2, since it will be part of the "blocker".I am "backing out" this fix, since it seems to cause trouble for consumers, by adding new dependencies. That should be avoided, especially in maintenance streams.Doing a mass "reset to default assignee" of 21 bugs to help make clear it will (very likely) not be me working on things I had previously planned to work on. I hope this will help prevent the bugs from "getting lost" in other people's queries. Feel free to "take" a bug if appropriate.	11.0
id=485903	REOPENED	Oomph	Dynamic Working Sets	1.5.0	All All	P3 enhancement	Project Inbox	2016-01-15 04:35 EST by	Andreas Sewe	2016-07-18 08:51 EDT (	2 users	Hi,Oomph dynamic working sets are great. There's just one enhancement I'd like to see:Eclipse allows you to reorder the working sets (Configure Working Sets...), e.g., showing "Plugins" before "Features". Alas, the order in which I define my Working Sets in the project configuration does not carry over to the provisioned IDE; AFAICT, the working sets created by Oomph are always sorted alphabetically.Would it be possible to change this behavior?	I can't reproduce this behavior. In the Package Explorer, the working sets appear in the order in which they are defined in the setup. In the Project Explorer they are always alphabetical and there is no mechanism to change that order manually.CreatedConfigure Working Sets dialog(In reply to Ed Merks from)To reproduce:- Use the Code Recommenders > Code Oomph setup.- Note that it has the working sets listed in the setup file [1] in the order of Plugins, Tests, Features, Target Definitions, Update Sites, Release Engineering, Aggregators- Switch to Top Level Elements > Working Sets in the Package Explorer- Open the Configure Working Sets dialog in the Package Explorer. It shows the working sets in the order Other Projects, Aggregators, Features, Plugins, Release Engineering, Target Definitions, Tests, Update Sites- Also, the Package Explorer sorts the working sets alphabetically.[1] <>Steps to reproduce in.The recommender's setup doesn't include this task:<?xml version="1.0" encoding="UTF-8"?><setup:ResourceCreationTask xmi:version="2.0" xmlns:xmi="" xmlns:setup="" excludedTriggers="STARTUP MANUAL" content="..." targetURL="${workspace.location|uri}/.metadata/.plugins/org.eclipse.jdt.ui/dialog_settings.xml" encoding="UTF-8"/>You can copy it from the Oomph.setup. When that task is present, the working sets are shown by default, *and* the order in which Oomph creates them is respected. Note that the logic for creating the working sets is the same in both cases, so why in one case they're sorted (when working sets aren't shown by default) and in the other case they're not, is kind of mysterious...You can confirm this strangeness as follows. Ensure that working sets are displayed in the package explorer and then use Window -> Preferences -> Oomph -> Dynamic Working Sets -> Edit... to open the editor. Select all the working sets, delete them, save. All the working sets should be gone except for "Other Projects". Now Perform Setup Tasks and select just the Working Sets task. The working sets come back in the order they're specified in the setup. I'm not sure this problem is fixable. It's not as if the platform provides any decent API to control these things properly...Moving all unresolved bugzillas to 1.4.0...Moving all unresolved bugs to version 1.5.0.	6.0
id=492816	REOPENED	Orbit	bundles	unspecified	All All	P3 major	Orbit Bundles	2016-05-02 08:10 EDT by	Charlie Mordant	2016-05-03 03:06 EDT (	1 user	Hi,The Eclipse ecosystem really lacks of some nice testing jars, particularly within Eclipse projects themselves.It could be nice to add some jars to orbit, as well as some project wizards, etc... to encourage people embracing TDD, BDD.There are some cool jars to add on Orbit:** * assertj-core* * assertj-guava* * assertj-joda-time* * assert-java8** * hamcrest existing orbit jar update*** * cucumber-java8* * cucumber-osgi* * cucumber-guice* * cucumber-java* * cucumber-junit* * cucumber-jvmBest Regards,	Orbit is just for Eclipse projects themselves. Only Eclipse projects will add libraries to Orbit.You are encouraged to submit recipes (pull requests) to.I'm a Polarsys committer, potentially an Amalgam one, Sirius one...Thank you for the link I'll pull for sure, I reopen this ticket to put a link to it from the PR. Regards,	2.0
id=511435	REOPENED	Oomph	Preferences Management	1.6.0	PC Windows 7	P3 enhancement	Project Inbox	2017-02-01 02:47 EST by	Georgi Sotirov	2017-02-07 15:58 EST (	4 users	CreatedScreen shot of File Types in Preferences (with cdt-proc extension)I'm using a freshly installed Eclipse CDT Neon.2 with the extension for Oracle Pro*C (see), but I have a problem, because file types for Pro*C sources are doubled (see attached screen shot cdt_proc-file_types.jpg). I could remove the ones highlighted in red, but after restart of Eclipse they're back and I have no clue where they're reappearing from. I also do not remember adding them myself. Unfortunately, Eclipse only shows "User defined", without any detail about where exactly is this setting defined. As a result I get *.pc and *.pcs files opened in the wrong editor unless I fix file types each time after starting Eclipse, but this is annoying. I would appreciate any help in resolving this issue, so let me know what other information I have to provide.	It sounds like it would be more appropriate to file an issue in the Pro*C extension's issue tracker:If the extension's developers indicate that they believe it's a bug in CDT itself, please feel free to post back here.(In reply to Nathan Ridge from)What exactly makes you think that the problem is coming from the extension? Clearly the extension only adds .pc file type, which is "Locked" and I have additionally added .pcs, because we use such extension for Pro*C sources as well. To me it's not clear whether the other "User defined" types are coming from and this is what I'm trying to clarify with this bug. Can the "User defined" status be expanded somehow?(In reply to Georgi Sotirov from)I don't know whether the problem is coming from the extension or CDT.I'm suggesting that the extension developers investigate first, and rule out an issue with the extension.Not that I'm aware of.CreatedNew screen shot of File Types in Preferences (without cdt-proc extension)(In reply to Nathan Ridge from)Well, I've made a simple experiment to rule out the extension. I made a new installation of Eclipse CDT Neon.2 in separate directory _without_ installing the extension. And I find the same types already defined without even importing any project (see).And that's the problem. It should be clear where the setting comes from and why it's restored after restart of Eclipse even though it has been removed.(In reply to Georgi Sotirov from)Is that also in a fresh workspace?(In reply to Nathan Ridge from)Yes, a fresh new workspace. I just forgot to mention it in my previous comment.CreatedScreenshot of File Types in Preferences (fresh Neon.2 installation)Strange - I do not see those files types in a fresh Neon.2 installation.Attached is what my File Types dialog looks like, with a fresh Neon.2 install (downloaded from [1]) and a fresh workspace.Perhaps the file associations are somehow coming from your operating system?[1](In reply to Nathan Ridge from)Yes, that's what I suspect, but from where? Registry, .ini file, elsewhere? I checked file type associations and I have there .pc and .pcs extensions associated with UltraEdit, but why should these have any effect on Eclipse? In this regards it would be very nice to have information about where the setting comes from.To get a list of the filename patterns corresponding to, for example, "C Source File", CDT makes the Platform API call Platform.getContentTypeManager().getContentType("org.eclipse.cdt.core.cSource")(where "org.eclipse.cdt.core.cSource" is the content type id for "C Source File"), and then calls IContentType.getFileSpecs() on the result.I'm not an authority on Platform APIs, but from a quick reading of the implementations of these APIs, it appears that only Eclipse plugins can define new file associations for content types.Is it possible that the Pro*C plugin is somehow getting loaded even by your fresh Eclipse installation? You can verify by looking at Help -> Installation Details (check the Plug-ins tab as well to be sure).(In reply to Nathan Ridge from)I checked "Installations details" and I do not find the plug in "Plug-ins" tab. On my other installation (with the plug in installed) it well appears.Hmm, interesting. Let's ask the Platform folks whether they're aware of Platform.getContentTypeManager().getContentType() getting content types or file associations from anywhere besides installed plugins.Georgi, I think you are using Oomph preferences recorder. This one saves all user changes in *every* workspace into one user file, and applies the settings on *every* new workspace. So I guess your extensions are added on startup by Oomph.(In reply to Andrey Loskutov from)Would the extension not show up in Help -> Installation Details -> Plug-ins in such a case?(In reply to Nathan Ridge from)I meant of course not plugins but file type extensions. But you did not answered my question: do you use Oomph or not?(In reply to Andrey Loskutov from)My bad, I misunderstood.That is a question for Georgi, not me :)Georgi, I believe the place to check is Preferences -> Oomph -> Setup Tasks -> Preference Recorder. If recording is enabled there, please try disabling it, and see if that resolves your problem.(In reply to Nathan Ridge from)That about Oomph is an interesting point. Perhaps I clicked on a dialog suggesting recoding in the past, but I do not have recording enabled currently. I tried to disable initialization of all preference pages from Preferences -> Oomph -> Setup Tasks -> Preference Recorder, but after restarting Eclipse the settings for file types persist. I then tried to clean up the bundle pools, but still no joy. Is there any way to manually wipe everything that Oomph eventually recorded or find exactly where this setting is removed, so I could delete it? Again, "File types" preferences page doesn't give enough information where the "User defined" settings come from and button Remove has effect only for the current session.Please create new workspace, please *disable* preference recorder before. Please check if the extra content types are in the new workspace or not. I guess they will be not there.(In reply to Andrey Loskutov from)OK. As I wrote my preference recorder was already disabled, so I've made new installation with fresh new workspace, but the file type settings (expectedly) reappeared :-( I thus decided to perform my own investigation and this was what I found into setup.log found in %HOMEPATH%\.eclipse\EclipseCDT\configuration\org.eclipse.oomph.setup\ folder:[2017-02-06 09:07:46] Performing Preference /instance/org.eclipse.core.runtime/content-types/buntatsun.cdt.proc.pcSource/file-extensions = pcs[2017-02-06 09:07:46] Performing Preference /instance/org.eclipse.core.runtime/content-types/org.eclipse.cdt.core.cSource/file-extensions = pcs[2017-02-06 09:07:46] Performing Preference /instance/org.eclipse.core.runtime/content-types/org.eclipse.cdt.core.cSource/file-names = .pcSo clearly the file types settings were coming from Oomph, but I was still not sure from where exactly. Therefore, I moved all org.eclipse.oomph.* folders found under %HOMEPATH%\.eclipse and finally the wrong settings disappeared. Apparently at some moment in the past I have somehow recorded those settings, but I really do not remember clearly. However, I find it really annoying to not have information into the IDE about where the settings are coming from and even worse to not be able to delete a setting restored by Oomph. Perhaps it's a good idea to disable Oomph extension unless you're willing to lose time debunking your IDE settings.Andrey, do you have an idea of what went wrong that required manual removal of files in %HOMEPATH%\.eclipse to fix? Surely having to do that is not the intention.(In reply to Nathan Ridge from)Not sure I got this right. Removal of those files helped finally. The question is: how an Eclipse user can *easily* have a *clean* set of the preferences in the workspace, in presence of automatic Oomph setup tasks? I mean most of the users installed Eclipse with "installer" are most likely unaware about user settings stored by Oomph outside the workspace, and also that those settigs are automatically applied on every startup.Just wondering if Oomph should contribute something like this to the Preferences->Workspace->Startup->Global user settingsDisable global user settings Delete global user settingsEdit global user settingsReopening and moving to Oomph.There is already Navigate -> Open Setup -> User and you can edit or delete any of those. Or delete the entire node where the preferences are stored.(In reply to Ed Merks from)Sure, but which user will *ever* use "Navigate" menu to fix the problem with workspace preferences? Additionally to that, users have no idea how "Open Setup" can be related to "my preferences are broken" problem.I think global preferences management is a very cool and mighty feature, but because of this it should come along with a clear user guidance how to disable itself or fix unexpected preferences saved "globally".Therefore the best way would be by Oomph to contribute preference page to "Preferences->General->Preferences Management"where users can do:Disable global user settings Delete global user settingsEdit global user settingsetc.	23.0
id=496589	REOPENED	Oomph	Setup	1.5.0	PC All	P3 normal	Project Inbox	2016-06-22 16:25 EDT by	Tim Webb	2016-07-06 11:18 EDT (	3 users	CreatedScreenshotThe Eclipse Installer offered from Eclipse.org needs to clearly indicate which version of Eclipse is being installed! Right now for Neon, you have to infer you are now getting Neon packages from the existence of JavaScript.Either the title should indicate the version Eclipse IDE for Java Developers (4.6) or maybe there is some sort of version combo showing which one you are on. Either way, would be superb to know!	The second page very clearly shows you the version, *but* only for the non-restricted installer. The restricted installer is something the foundation wanted (insisted upon) to make it as simple as possible; it can only install the one version and that version is clear when you downloaded it (so it was argued), so there is nothing to indicate the version (because the foundation didn't want that).Createdclear indication?I assume per screenshot, the clear indication that this is Eclipse 4.6.0 is based on the default path having "neon" in it for the second page?To be fair, saying "this is how the foundation wanted it" seems a bit of a cop out. If I had installed Mars using the installer, and then went to install Neon, and nothing on the download page, nor the installer indicated version / difference, I would be confused.Or said another way, the goal as I understand it is to make a great initial experience getting Eclipse to maximize it's adoption rate. If it is unclear that you are getting what you expect to get, some % of users would hesitate / abandon / be frustrated -- things the community doesn't want.If the installer cannot change, I would ask whether have the default Download path only terminate at the Installer is actually a good thing. Yes, there is a subtle "Other Packages" option on the web flow -- but if I look at overall download numbers for Mars SR2 -- there were, at least from the outside, more downloads of packages than the top billed Installer.I'm all for evolution and migrating to an installer, but is suggesting a tiny bit of clarity as part of the flow worthy of an immediate "WORKSFORME"?CreatedUnrestricted second pageIf I had my way, the second page would always look like this.As I said, I'd prefer there always be a choice of which version to install. It would not be on the first page. There you choose what to install. On then second page you choose the version, the JVM, and where.But the foundation argued it needed to be even simpler with less choice. And it's been this way for a year with no one complaining it was too simple or unclear. You downloaded something to install Neon, and it installs Neon, is the argument, and that's exactly what you get. If more indication is needed, I would argue the installer should never be restricted, but I lost that argument, and the restricted version is the compromise.CreatedprogressYes, that would be clearer. Or even some hybrid of just bringing over the product version to the "simple" version.I realize it is unfair to comment after the release. I had missed the fact that the community was changing to route *all* new people through the installer. Top of the download page is different than hiding the most popular packages.Other observations that are problematic:1. You have no idea how much software you are downloading2. You have no idea how much longer it will take to download3. The progress bar is well past 50% before the actual download starts4. It is less obvious for people on a team to just share a file aroundNow, I think it's awesome that we tell you there are problems! In the morning, I was getting an install at 10MB/s. Just now it was fluctuating between 1 and 2/MBs. And that's with a 200Mb/s fibre connection. If you had a bad internet..."You downloaded something to install Neon, and it installs Neon, is the argument, and that's exactly what you get."To be fair, from the primary download pagethere is no indication that this is Neon either.And if I go to download Mars from:it also takes you to this download neon flow. For that matter, how DO I get to the Eclipse 4.5 download links to test the installer from there to see if I get Neon for the old Mars installer? :)"But the foundation argued it needed to be even simpler with less choice. And it's been this way for a year with no one complaining it was too simple or unclear."And during that time, there were more downloads of individual packages than the installer. The installer IS slick. And I do really like the other variations of the pages you shared -- the version dropdown in particular is really nice.My concern is really that we're doing ourselves a disservice by not making the experience surprise free / very clear.If this page were really clear that you were getting an installer for Neon, I think there would be similarly less of a surprise. Other than neon in the URL, there really is nothing to let you know. On the page, or in the filename of the download.(In reply to Tim Webb from)I agree having the product version in the title on second page of the simple version would be an improvement. @Ed, it is have the multi-select list of different versions that I think is overly complicated. I believe what Tim is request is worth while to add.Now that we have the Installer on a page with no packages, I think having the download size in the Installer would make sense. I am re-opening since I'd like to see these considered.(In reply to Ian Skerrett from)What exactly are you proposing it look like? Perhaps prioritize as a FEEP item...The download size is related to what part of this thread?Moving all unresolved bugs to version 1.5.0.	9.0
id=464100	REOPENED	Orbit	releng	unspecified	PC Linux	P3 normal	Project Inbox	2015-04-08 01:37 EDT by	David Williams	2016-08-11 15:22 EDT (	3 users	I'll attach listing, but many Orbit jars (81!) come out as "invalid" if using Java 7 to pack and unpack. But, from quick scan, these are all very "old" bundles, that were probably originally "conditioned" with Java 5, and signed. and our build will uses those old versions, since qualifier didn't change. I think in general, pre-conditioning (re-pack) and pack200 have to be done with the same VM. So, my initial plan, rather than to just mark these as "do not pack" is just to 'touch' them, let them be reconditioned with Java 7, and then packed with Java 7. One issue, at the moment, is that I'm not sure if "infrastructure" changes have been made yet, to use Java 7. (). So will need to wait for that, to have a good test of the procedure. One question in my mind, is if we are going to touch 81 of them, should we touch them all? And, of course, if we are going to do that, should probably fixat the same time.	Createderrors when moving to Java 7 to run build (and pack.Another thing to keep in mind, is that when we recently "moved to Java 6" there were a few bundles that broke, that were fixed by adding "pack=false" to eclipse.inf. We should revisit those and try packing again.This may be off-topic, but one thought occurred to me, was that if we "take a jar" from a previous release, because it hasn't changed, why we don't also take it's corresponding pack.gz file? Not sure if that's limitation of PDE build, or, the way we just happen do do the builds in Orbit? I don't plan to make major changes to Orbit builds, at this point, but seems that is an important principle any build system should support.(In reply to David Williams from)It does seem we should be able to maintain the existing pack.gz files ... from a wiki page: = = = = =To create a new repository using the properties of an existing repository the format attribute is added to the repository element. This can be used to prevent storing pack200'd artifacts in the .blobstore, preserving them as siblings (if they were siblings in the stated site from which to pull the format). = = = = =I just need to figure out what property to specify!?(In reply to David Williams from)<property name='publishPackFilesAsSiblings' value='true'/>I guess.(In reply to David Williams from)Blow by blow status: I've found we already had that property set. So, not that alone. Two other possibilities: Previous to now, we were not "packing" the jars, BEFORE the comparator mirror, but after. So, I've changed the build to do it before the comparator mirror runs. Initial attempt showed "no change". Second possibility: We were using the "mirroring" *application*. I think it just evolved that way. We could also use the ant task without major changes. AND, it is the ant task to has/discusses the "format" attribute. So, that's what I'm trying now, setting the "format" repo, to be the same as the repo we are using for "comparator". If that doesn't work, I'll be out of ideas.Changing title to focus on "packed" part of the workflow. My suspicion is that it is packing with a different vm than the jars were conditioned with that is the source of the problem ... not the vm that a user might use to later do the unpack.Created21 jars not-valid when central service changed tooA fair reduction (from 81 to 21) "bad jars" were found then using Java 8 to do the conditioning, and the "pack". We are trying Java 7 now, to do the conditioning, and the pack, to see if much less. If so, we'll stay with Java 7, if about the same, just as well stay on Java 8.***has been marked as a duplicate of this bug. ***I have fixed the build so it will use "Java 8" to do the "pack200" (Thus, matching the Java 8 used to to the pre-conditioning, and signing). ANDI've fixed the "comparator" part of the build, so if a *jar* is taken from a previous repo, then its *pack.gz* counterpart is also taken from that previous repository -- even if, from there, back then, Java 5 or 6 was used to produce it.And, all those (previously created) pack.gz files 'verify' correctly, even using Java 8. My intuition is if any of the "21 bad bundles" are ever modified, and they have to be re-built/packaged, then we'll probably also have to add eclipse.inf with jarprocessor.exclude.pack=true. I believe we still use -E4 ... (default is 5) ... in theory we could experiment with other effort levels, to see if it makes a difference?I am re-opening this. Orbit has move back to Java 6, due to, but if/when we do move up to Java 8 in the future, this will again show up, in some circumstances.Note, since "we" in Orbit, have a lot of control of what's packed, and how, should remember to investigate use of --pass-file as one of the custom parameters to jarprocessor (via eclipse.inf). Likely to be most important for bundles like "ICU4J", which are huge, but fail due to one class file, when re-packed/packed/unpacked with Java 8. SeeDoing a mass "reset to default assignee" of 21 bugs to help make clear it will (very likely) not be me working on things I had previously planned to work on. I hope this will help prevent the bugs from "getting lost" in other people's queries. Feel free to "take" a bug if appropriate.	12.0
id=322336	REOPENED	PDT	Code Assist	2.2	PC All	P3 enhancement	PHP Core	2010-08-11 06:40 EDT by	Silver Zachara	2015-02-10 05:49 EST (	3 users	Hi,any CA for *Type Casting* as is e.g. *(int)* , *(float)* , *(bool)* , etc., as is described here:	CreatedpatchCreatedunit testsCreatedpatchafter reviewing the patch,I saw it only consider such condition if I am right:(|)$blablamy question is do we need to support:(|)ABC::getBoolean()the patch has been appliedPatch looks to be applied.The fix in my opinion somewhat partial. Consider the following example (from the link):<?php$foo = 10; // $foo is an integer$bar = (boolean) $foo; // $bar is a booleanThe fix will work in case you type all except the type cast and then call CA inside the ():$bar = (|) $foo; // here CA will show the typesBut the fix will not work in case of normal typing, e.g. you type$bar = (|) // CA will not show the types in this case before you type the variable after the ()I think that it should show in any case between the ().Reopening the issue	7.0
id=439161	REOPENED	PTP	Photran.Problems View & Error Markers	unspecified	PC Windows 7	P3 normal	Photran Inbox	2014-07-08 14:12 EDT by	Bruno Medeiros	2014-07-24 08:29 EDT (	1 user	CreatedEditor annotations that are no longer displayed missing.This problem manifests itself in the UI, but I believe it is related to the runtime, OSGi, p2, or something similar.A short description of the problem is: After installing the Parallel Tools Platform, the file resource errors/problems are no longer displayed as annotations in "Vertical ruler" and the "Overview ruler" of any editor opened on the respective file.Note that if the "org.eclipse.osgi" directory is deleted from the Eclipse configuration folder, and Eclipse is started, the problem will be gone. This seems to indicated that "org.eclipse.osgi" has become outdated or corrupted in some way after installation. (this is why I also don't think this bug is related to PTP)	More detailed steps to reproduce:=== First part: creating a resource error marker on the workspace.This first part could be vastly simplified, but its the only way I have for now to reproduce. The objective is simply to create a file resource error marker on the workspace.* Download the Eclipse platform.* Install the GoClipse IDE as described here:* You'll also need to install a Go compiler () and set the GOROOT preference page setting of GoClipse to that Go compiler location.* Set GOPATH to any directory.* Create a new Go project.* Create a new_file.go in the "src" folder. Set the file to some invalid contents, such as:------- new_file.go:package main func main() { asdfasd asdfsdf}------* Build the workspace.Now an error should be created, and it will be displayed in the "Vertical ruler" and the "Overview ruler" of the Go editor (as well as in the built in text editor)=== Second part: Install Parallel Tools Platform from Luna. Restart.Now the resource error no longer is displayed "Vertical ruler" and the "Overview ruler" of the Go editor (or any other editor).See "AnnotationsBug.after.png" attachment for example.CreatedBug example after installing PTPCreatedBug example before installing PTPCan you please attach your error log? <workspace>/.metadata/.logPWCreatedlog file after PTP installation.It doesn't have much info though.If it might help, here's a complete Eclipse installation after the steps above, it should be enough to replicate the bug (it does on my machine):(open it on the workspace included in the zip - Go compiler installation should not be necessary)I couldn't attach it to the bugzilla cause it exceeds the file limits.Are the markers also gone for Java files in the Java editor?No, the editor annotations for Java Problems are still displayed in the Java editor. Even if I force the Java file to be opened with the Go editor, the Java Problems annotations will be displayed. But if I open the Go file (with the Go problems), with the Java editor, the editor annotations for the Go problems will not be displayed.(In reply to Bruno Medeiros from)This looks like a bug in GoClipse.It's not a GoClipse bug.I've found an alternative way to manifest this bug, which doesn't involve GoClipse, but instead uses PDE only:* Download Eclipse Standard* Start Eclipse, create a new PDE plugin project.* Open the MANIFEST.MF file, write some syntax garbage there. (an error marker will be created, and displayed in the editor annotation ruler)* Install Parallel Tools Platform from Luna. Restart.* The error annotation is no longer displayed in the manifest editor (or the text editor):Just as the GoClipse case, uninstalling PTP, or deleting the "org.eclipse.osgi" directory from the Eclipse configuration directory (and restarting) will make the bug state disappear (the error editor annotations appear again).(In reply to Bruno Medeiros from)Thanks for those steps. Moving to PTP since obviously they somehow damage it.	11.0
id=390058	REOPENED	Orbit	bundles	unspecified	PC Mac OS X	P3 normal	Orbit Bundles	2012-09-20 17:12 EDT by	Chris Aniszczyk	2016-04-06 10:53 EDT (	4 users	After a very long time, bouncycastle is finally approved by the Eclipse IP team!We should add this to Orbit as JGit and other projects need it.	I added bouncycastle to Orbit:org.eclipse.orbit/org.bouncycastlebranch: v1_47Relevant CQ:Also created CQ for the OpenPGP bits:I noticed you targeted this for "Juno SR2". Is that really want you meant? That is, will you be asking for a "maintenance release" of Orbit to be used for Juno SR2?(In reply to)Ya, this will be most likely included in the next JGit release which should end up in Juno SR2.I noticed that the orbit build is faling with following message:Seems that the symbolic name of bouncycastle isn't the same as the project name. One of both has to be corrected.I fixed the issue, the new BSN is org.bouncycastle.bcprov(In reply to)Now build fails with Unable to find plug-in: org.bouncycastle.bcprov_1.47.0.qualifierversioning/map issue?(In reply to)yep, sigh, fixed now.This is now in Orbit I-builds.I'll ping again near Juno SR2 time.Hi Chris,has bouncycastle been removed from orbit?Can't find it in latest releaseregardsAndreas(In reply to Andreas Mihm from)Yeah, I can't find it in the latest repos either.(In reply to David Carver from)I don't see it any *any* repo. And spot checked our main build feature back to 2012, and ever saw it added (much less removed). I loaded 1_47 into my workspace, and says that it is missing build.properties. (which, I only mention as a sign that it was never "ready to build"). I do see some files in DL sites, named./R20140525021250/ip_logs/bcprov.xmlthat imply it is "in the build"? Plus, I see plugin@bcprov,1.47.0=CVS,tag=v201211121600, in map files ... but, also see a project in Orbit namedorg.bouncycastle.bcprov(that's the one I loaded, and saw no "build.properties". Confusing.this never reached a released orbit, we stalled onWe didn't yet find a way to sign artifacts in a way not breaking JCE signatures which are required for crypto providers (see)(In reply to Matthias Sohn from)I can't really decipher the signing problem in 391302, but if it is a matter of leaving it unsigned, then that's easy enough ... but and then is consumer expected to sign, with what ever "split package" they provide? Otherwise, seems kind of bad that for anyone installing JGit, in Eclipse IDE, that they'd git a message "you are installing unsigned content, is that OK?". Would be good to drive to closure, one way or the other ... for example mark as "won't fix" if there's a better solution already being used by JGit and no longer needed?(In reply to David Williams from)I meant, I tried to use the jar produced by the orbit build and got an exception when trying to register it as a JCE provider saying that the signature needed for JCE crypto providers is broken [1]I think that's not ok, we still need a solution for this to use it from JGitAs a workaround we could avoid registering bouncycastle as a JCE provider anduse its own API.We don't have a solution for JGit yet. I agree we should drive this to an end,will try to find time to take this up again.[1]	16.0
id=361372	REOPENED	PDT	Code Assist	unspecified	PC Windows XP	P3 critical	PHP Core	2011-10-19 06:55 EDT by	Kalin	2012-07-06 06:42 EDT (	0 users	Typing code in editor seems broken after you have used php template with variable ${line_selection} or ${word_selection}Scenario:Go to Preferences>PHP>Editor>Templates > Press New button. In Add template dialog press Insert Variable button . Add ${line_selection} in Pattern list.Type testlineselection in Name field.Save the new added template.Open a php file in editor.Type some valid code, e.g.<?php class CCC { function fff() { echo "test"; }}Select the whole class and it body (lines 2 to 6), then invoke Content Assist and type part of template name, e.g. "test"You will see the suggested template in CA list.Select it in CA list.Problem 1:First 4 chars of the template will be placed in editor, since you typed 4 chars ("test") of template name ("testlineselection")Problem 2 If you try to continue typing you will see the cursor goes unexpectedly at the beginning of line 2, then it goes to line 1 just before opening php tag <?phpThe cursor cannot be moved from this position by typing anymore.Just in a few seconds the error becomes as much as 1 MB size.	Similar problem when you use ${word_selection} template.Createdscreenshot-step1Createdscreenshot-step2Createdscreenshot-step3Createdscreenshot-step4Saving the file does not solve the problem.The only workaround:Close the file and open it again.fixedI re-tested the problem.Now if you select the template in Content Assist list you will get nothing added in editor and the cursor just goes to the first position on the line.Of course you have to select the whole class and its body in advance (as described in the issue.) See the new attachment.This happens for ${line_selection}The same problem for ${word_selection}Reopening...CreatedNew_step1CreatedNew_step2(reslult)	10.0
id=370074	REOPENED	PDT	Code Assist	unspecified	All All	P3 normal	PHP Core	2012-01-29 12:05 EST by	itay friedman	2016-06-01 08:24 EDT (	3 users	Createdexample testWhen creating a namespace myNS which contains inner types,they are not shown in the content assist when typing use myN|example test attached produces:junit.framework.AssertionFailedError: EXPECTED COMPLETIONS LIST:-----------------------------type(One)type(One\Agree)type(One\D)ACTUAL COMPLETIONS LIST:-----------------------------type(One)	Createdupdated example testAttached is an updated test which has modifications in the desired results section.These modifications are important since they're based on better practice.fixedCurrent situation:--EXPECT--type(One)type(Agree)type(D)--ACTUAL----EXPECT--type(One)type(Agree)ReopenIlina StefanovaI think current results are correct.PDT complete classes that contact prefix "On" (empty results) and namespaces that starts with "On" prefix. After complete user is able to rerun CA and select Trait or Class.Only think that should be improved is auto-run CA after complete namespace.So, when PDT complete with "\" on the end, PDT should recompute CA.	4.0
id=389150	REOPENED	PDT	Code Assist	unspecified	PC All	P3 normal	PHP Core	2012-09-10 06:40 EDT by	Rik Bartolini	2015-06-10 09:05 EDT (	1 user	After the keywords include, include_once, require, require_once,code completion works only for object variables (instance of a class), while is not working for normal variables, named constants (defined()), and static methods of class (this last one had already been reported in, marked as fixed in the 2006, but it's back again).Tested with IndigoVersion: 3.7.2Build id: M20120208-0800And the PDT from the Indigo releases repo	works for meTry$object=new SimpleXMLIterator();$test='hello.php';$tes (here we have code completion)$obj (as above)include $tes (here we haven't any code completion)include $obj (same as above)include $object-> (here we get code completion)I can reproduce the given example.	3.0
id=396841	REOPENED	PDT	Code Assist	unspecified	PC Windows 7	P3 normal	PHP Core	2012-12-18 09:42 EST by	Zhongwei Zhao	2013-01-25 07:32 EST (	0 users	Steps:1. Have a php code in a file. 2. Ctrl+A to select all and then Toggle. Repeat the 2. to uncomment all.Expected:The code looks like before commentingActual:The opening php tag stays with // in front.	fixedrevert the code to make it work in Eclipse 3.8.1,see	2.0
id=423089	REOPENED	PDT	Code Formatter	3.2.2	PC Linux	P3 normal	PHP Core	2013-12-03 14:18 EST by	Alsar X	2014-06-07 15:29 EDT (	3 users	Code formatting doesn't work, when there are non-PHPDoc tags.Example: /** * @var integer * * @ORM\Column(type="integer") * @ORM\Id() * @ORM\GeneratedValue() */ protected $id;Gets formatted into: /** * * @var integer @ORM\Column(type="integer") * @ORM\Id() * @ORM\GeneratedValue() */ protected $id;	It's same problem*** This bug has been marked as a duplicate of***Hello,just wanted to tell that this bug is NOT a duplicate of.is about correctly formatting block comments (depending on the formatter settings), while this bug is about formatting PHPDoc comments having PHPDoc and non-PHPDoc tags.I think it's more an evolution/feature request than a real bug.For now, to workaround this problem, it could be possible to write all non-PHPDoc tags before the PHPDoc tags (and force "Never join lines" in the formatter settings).For example /** * @var integer * * @ORM\Column(type="integer") * @ORM\Id() * @ORM\GeneratedValue() */ protected $id;could be written /** * @ORM\Column(type="integer") * @ORM\Id() * @ORM\GeneratedValue() * * @var integer */ protected $id;My mistake, sorry***has been marked as a duplicate of this bug. ***	4.0
id=408994	REOPENED	PDT	Code Formatter	3.1.2	PC Windows 7	P3 normal	PHP Core	2013-05-24 10:19 EDT by	Natalia Bartol	2015-07-01 15:21 EDT (	8 users	CreatedWrong auto-insertion of closing braces - unit testTwo cases are broken after changes introduced by.Test cases attached (to be added to org.eclipse.php.formatter.core.tests/workspace/formatter-autoedit/php5).#1 Wrong auto-insertion of closing braces--FILE--<?phpfoo(function (){|)?>EXPECTED:--------------<?phpfoo(function (){***** })?>ACTUAL:--------------<?phpfoo(function (){*****})#2 Incorrect formatting of array statement--FILE--<?php$schema = array( 'options' => array( ServiceInstruction::VALIDATOR => function ($data) { return is_callable($data); })|);?>EXPECTED:--------------<?php$schema = array( 'options' => array( ServiceInstruction::VALIDATOR => function ($data) { return is_callable($data); })*****);?>ACTUAL:--------------<?php$schema = array( 'options' => array( ServiceInstruction::VALIDATOR => function ($data) { return is_callable($data); })***** );	CreatedIncorrect array formatting - unit testCreatedpatch for reverting the changes leading to this regressionthe patch reverts the changes, solving this issue, while 406357 also remains resolvedPatch committed. Changes introduced by 406357 have bee reverted. The original bug reported in 406357 is fixed.Unit tests:* 4 new unit tests added to org.eclispe.php.ui.tests.formatter-autoedit* 2 new tests added to org.eclipse.php.formatter.core.testsThanks Itay!Natalia,it seems you reverted too much. Robert's patch included extension point indentationStrategy, which was now just removed with Itay's patch.Was this extension point problematic? If not, could you restore it?I thought this extension point was only for fixing the original bug.Sure, we can add it back but please open a separate bug and submit a patch that adds this new extension point + example Java code with dummy contribution + proper documentation in exsd file (seeas a reference).ThanksWell work out missing ext.point docs in coming days but for now I need correct PDT build for testing signing so I reverted Itay's patch to restore lost extension point.I'll be back to this issue tomorrow and will try to reapply his patch without removing extpoint and associated logic.Why build without this extension point is incorrect? All tests pass.(In reply to)Are you sure that your expectation regarding arrays is correct?I would say that end of a statement when placed on a new line should have the same indentation level as the beginning of that statement.If im not mistaken this is already what you expect for functionsfoo(function (){***** })So I would say EXPECTED:--------------<?php$schema = array( 'options' => array( ServiceInstruction::VALIDATOR => function ($data) { return is_callable($data); }));?>To illustrate why I think this is the correct way to format I present a new test in which the closing parenthesis for the options array is placed on a new line:--FILE--<?php$schema = array( 'options' => array( ServiceInstruction::VALIDATOR => function ($data) { return is_callable($data); }|));?>EXPECTED:--------------<?php$schema = array( 'options' => array( ServiceInstruction::VALIDATOR => function ($data) { return is_callable($data); }*****));?>With bracket notation that would be:--FILE--<?php$schema = [ 'options' => [ ServiceInstruction::VALIDATOR => function ($data) { return is_callable($data); }|]];?>EXPECTED:--------------<?php$schema = [ 'options' => [ ServiceInstruction::VALIDATOR => function ($data) { return is_callable($data); }*****]];?>Please take a look at the attached unit tests files, those asterisks (*****) may be misleading when you read them, they are placed only to make the difference visible.(In reply to)I see now, sorry for the confusion.I tried to reproduce cases from Natalia's description with version PDT 3.3.0.201407051616 and it looks OK for me. Can anyone check it also?In editor everything is ok, but I'm unable to put it as PDTT tests.Ok, right now I see the difference. First test case assume that after new line and bracket indentation empty line will have indentation +1 and now it is 0. Like this:<?phpfoo(function (){****|})?>Second case with array I think isn't covered. During test new indentation for this test case is level +1 but it should be level 0 like in test case. Actually it looks that indentation for this bracket is done with second array as base. For me it looks like this:<?php$schema = array( 'options' => array( ServiceInstruction::VALIDATOR => function ($data) { return is_callable($data); }) ); <- this should be not indented?>I used previous patch that was reverted and apply all changes without removing extension point. I also fix some small problems which I found after applying changes.Patch:Merged :Thank you Michal!In case of this example:<?php$schema = array( 'options' => array( ServiceInstruction::VALIDATOR => function ($data) { return is_callable($data); })|);?>When hitting enter I get:<?php$schema = array( 'options' => array( ServiceInstruction::VALIDATOR => function ($data) { return is_callable($data); }) );?>Reopen	16.0
id=387976	REOPENED	PDT	Code Assist	unspecified	PC Windows Vista	P3 normal	PHP Core	2012-08-24 07:45 EDT by	Zhongwei Zhao	2016-06-14 05:24 EDT (	3 users	Preconditions:No files are opened in editor.Scenario:Create a simple local php project.Open index.php and type in the file:<?phpclass FirstClass { }Save the changes.Close index.php.Create index2.php in the same project.Type in the opened index2.php:<?phpclass SecondClass { }Close index2.php.You have no files opened in editor.Open index.php.Open index2.php.Select the lines from 4 to 2 in index2.php.1. Apply ctrl+shift+c2. Select index.php in editor, select the lines from 4 to 2 in index.php, then apply ctrl+shift+cActual:1. No effect.2. You get ctrl+shift+c working in this file.Expected:1. The comment tags // should be applied to the selected lines with code (line 4 and line 2)Reproducible: Always.No issues are generated in the log.Reproduced on Win 7, Win XP, Mac Mountain Lion.	fixedVerified. Closing.reopen this bug because it introduce another bug:If this issue has been fixed, the ticket should remain closed, and in any case issue 386879 is now closed (although it seems to persist for me).Reproducible for me in Eclipse 4.5.2 on openSUSE 13.2.	5.0
id=465407	REOPENED	PDT	Code Assist	unspecified	PC Windows 7	P3 normal	PHP Core	2015-04-24 07:26 EDT by	deep1 xkiller	2016-10-26 09:01 EDT (	2 users	CreatedAutocomplete error. multi screenshotwhen I start typing the word "<sty" showing autocomplete suggestion for <style> tag. BUT.. when I hit enter it showing <<style>. Sure It is a bug.--------------------<<style><!----></style>	CreatedAutocomplete error. multi screenshot (see the arrow)I cannot reproduce on current eclipse (Luna SR2). Also works correctly on Mars M6.Results for php and html editor is always : <style type="text/css"></style>Have you something in logs, or any non-standard settings?No answer since year, probably fixed indirectly.Please reopen with further information.This is a very old problem and indeed it still reproduces, not only with <style> but almost anything - <html>, <script>, <table>.Just open an empty php file and on the top (before the <?php tag) start typing and using the suggestionsCreatedScreenshot	5.0
id=476040	REOPENED	PDT	Code Formatter	3.6.0	All All	P3 normal	PHP Core	2015-08-27 08:57 EDT by	Dawid Pakula	2015-09-15 06:24 EDT (	0 users	Formatter preset: PSRCurrent formatting:$this->call1() ->call2() ->call3([ 'paramName' => 'paramValue']) ->call4();Expected:$this->call1() ->call2() ->call3([ 'paramName' => 'paramValue' ]) ->call4();	New Gerrit change created:Gerrit changewas merged to [master].Commit:fixedreopen, bug have to be resolved in more complex way, especially in autoedit.I'll revert patch.New Gerrit change created:Gerrit changewas merged to [master].Commit:	6.0
id=200760	REOPENED	PDT	Debugger	1.0	Macintosh Mac OS X - Carbon (unsup.)	P3 enhancement	PHP Debug	2007-08-22 01:18 EDT by	Ingo Renner	2009-06-17 09:19 EDT (	1 user	Build ID: I20070625-1500would be cool to have the posibility to profile scripts with TPTP	*** This bug has been marked as a duplicate of***How can the older entry (lower ID) be a duplicate of the younger (highwer ID) it's rather the other way...(In reply to)What's the difference? But if you insist...***has been marked as a duplicate of this bug. ***	4.0
id=225299	REOPENED	PDT	Debugger	1.0.2	All All	P3 enhancement	PHP Debug	2008-04-02 06:47 EDT by	David Kelsey	2015-05-08 16:53 EDT (	3 users	for xdebug and php, we need to determine whether a line that a breakpoint is placed on is actually valid. Examples where it might not be valid are- Comments- blank lines- html statements- <?php ?> tags- lines which compile out (see next section) for which we may wish to actually just shift the breakpoint rather than disallow it.---- start of info -----I can't do much about this. For PHP this code translates to:compiled vars: !0 = $arrayline # op fetch ext return operands------------------------------------------------------------------------------- 3 0 EXT_STMT 1 INIT_ARRAY ~0 'http', 'scheme' 2 ASSIGN !0, ~0 5 3 EXT_STMT 4 RETURN 1As you can see, PHP sees everything only on line 3.--- end of info ----Some of this capability may already be available in PDT and may be common concepts, so a discussion with other people in PDT may be required. Also the above issue could also be sensitive to versions of PHP so this will also need to be considered	Tested on 2.1-SR1- Comments - works- blank lines - works- html statements - works- <?php ?> tags - works- shifting - - worksworks as expected...closingI doubt this is fixed as I have not put any code into the xdebug component to address this. If a breakpoint is placed on a comment line or a split line which doesn't contain the line termination ';' character then xdebug will not stop on those lines.You're in doubt or the case the issue just reproduced?Can you provide more test cases for reproduction?ThanksSo on my tests using the latest code base from branch R2_1_Galileo, using XDebug as the debugger, if I set a breakpoint on a line with just a comment, or I set a breakpoint on a split line that doesn't contain the end of line character ";" eg<?phpecho "start";// put a breakpoint hereecho "next";$array = array ( <-- breakpoint placed on this line"scheme" => "http");echo "end";?>then when I debug the script the program doesn't break at any of the breakpoints.Note that for blank lines, the breakpoint does shift to the next non blank line as does the <?php and no breakpoint can be set on ?>, also I cannot set breakpoints on html lines so these scenarios have been addressed.So in the final 2 situations are:- In the case of PHP comments we should do what Java does and set a breakpoint on the subsequent line that contains php code.- In the case of split lines, I do not know whether the zend debugger handles this already. XDebug doesn't and probably won't in the near future. So either the IDE can shift the breakpoint to appear on the line with the line end character ";", or if that doesn't fit in with what other PDT committers want the IDE to do, then the xdebug code could potentially shift the breakpoint itself when it sends the information to the xdebug server. But this is a discussion I need to have with other PDT committers.I hope this clarifies the requirement.This still hapens with PDT 3.4.0. As breakpoints can be set on invalid lines, I consider this as a bug. Importance P3 is inappropriate.	6.0
id=386462	REOPENED	PDT	Debugger	unspecified	PC Windows Vista	P3 normal	PHP Debug	2012-08-01 23:28 EDT by	Zhongwei Zhao	2012-08-06 07:48 EDT (	1 user	This is very easily reproduced even with a small piece of code, for example:<?phpecho "aaaaaa";echo "bbbbbb";echo "cccccc";Start Debug as CLI - Debug perspective opens and debugger stops at first lineClick on the Debug Output view to make it visible (the focus remains on the view)Click Step Into (F5) - debugger moves to the second line. That means you have to see the aaaaaa in the Debug Output, but it is not there!!!Click again Step Into (F5) - debugger moves to the third line. That means you have to see the bbbbbb as well, but still nothing appearsMove the focus to the Debug view - suddenly the Debug Output refreshes with aaaaaabbbbbbI noticed that depending on the current focus in some cases output is refreshed, on others not.That was caught by the automation tests (that means regression, because this used to work on Studio 9)	fixedReproduced both on Windows and Linux using the exact same flow. Reopening	2.0
id=474115	REOPENED	PDT	Core	3.5.0	PC Windows 7	P3 major	PHP Core	2015-08-03 03:45 EDT by	Laurent Lyaudet	2016-07-17 18:29 EDT (	5 users	CreatedError popupHi,I have a big update script in my project.It is impossible to edit it with Eclipse.Steps to reproduce :1) create a PHP file using one of the two scripts given below.2) add the generated file to your project3) open the PHP file in eclipse (freezes ~5mins)4) try to edit it (freezes ~5mins and an error popup appears - see attached file)Maybe there is some buffer or hashmap which size is fixed to some small/medium value and doesn't depend of size of parsed file.Let me know if I can help further.Best regards, Laurent Lyaudetfirst script :<?php$sTexte = "<?php\n\$array = array();\n";for($i = 0; $i < 40000; ++$i){ $sTexte .= "\$array []= \"It's a big string you know. Of course I know.\";\n";}$sTexte .= '?>';file_put_contents('testArray.php', $sTexte);?>second script :<?php$sTexte = "<?php\n\$array = array(\n";for($i = 0; $i < 40000; ++$i){ $sTexte .= " \"It's a big string you know. Of course I know.\",\n";}$sTexte .= ");\n?>";file_put_contents('testArray2.php', $sTexte);?>	It looks more like DLTK issue. Problem is around hashmap inside org.eclipse.dltk.internal.core.ModelCache.(In reply to Michal Niewrzal from)Yes and no. We generate 40k local fields here.True, I will look at it.For this case we can exclude ArrayVariableReference from Assignment processing in PHPSourceElementRequestor. This information is not used anywhere, at least I think so :) With this we still need to work with editor stability because from time to time PDT is freezing. It is not related to this issue, but more to file size (2MB+). One file like this can consume huge amounts of memory.New Gerrit change created:Gerrit changewas merged to [master].Commit:I think I fixed main problem with freezes and now it should be usable. If you will face something else related to performance just reopen this issue.Looks OK now, closingI'll reopen this one, see my comment for:"Sadly I still see UI freezes when you take sample file testArray.php from bug report 474115. Just click on "$array" and wait on highlighter to highlight all "$array" occurrences, UI will freeze for several minutes."Some additional infos: problems about UI freezes with sample file testArray.php lies in method PHPStructuredEditor#OccurrencesFinderJob.run(IProgressMonitor progressMonitor) when calling following code:((IAnnotationModelExtension) annotationModel).replaceAnnotations(fOccurrenceAnnotations, annotationMap);If I take code (and adapt it) from JDT method JavaEditor#OccurrencesFinderJob.run(IProgressMonitor progressMonitor), it's even worse. So it's maybe a general problem in eclipse. Any good solution is welcome ;)	10.0
id=402829	REOPENED	PDT	Debugger	3.1.2	PC Windows XP	P3 trivial	PHP Debug	2013-03-10 00:35 EST by	Toshihiro Izumi	2015-06-05 07:20 EDT (	4 users	Steps to reproduce:1. Prepare a php script (e.g. <?php var_dump($argv);) and a run configuration with PHP Script Arguments, make sure it works.2. Add a PHP Executable.3. Open the run configuration, switch Runtime PHP to Alternate PHP and select the added executable.4. Run it. => No arguments, only the script path.Another situation,1. Start eclipse, add a php executable, run a php script with arguments.Unless restarting eclipse after adding a php executable, the problem occurs always.(in other words, if user restarts eclipse, this issue won't occur)	Hi Toshihiro,I can not reproduce this bug.merged to master:thanks Wojtek!The bug still exists. After I changed the default executable I could not see the arguments dumped. After restarting eclipse and running the same config again (no changes, only restart of eclipse) they were passed.Reopening	4.0
id=293227	REOPENED	PDT	Debugger	unspecified	PC Windows 7	P3 enhancement	PHP Debug	2009-10-23 19:31 EDT by	None	2015-04-19 12:44 EDT (	7 users	User-Agent: Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US; rv:1.9.1.3) Gecko/20090824 Firefox/3.5.3Build Identifier: 20090920-1017I am remote debugging a php web page using XAMPP and XDebug. Whenever I close the debugging session another web browser windows pops up containing the single message "DEBUG SESSION ENDED". There should be a way to hide/prevent this window. Its a minor thing, but annoying to have to close it every time I end a debug session. I searched the bug list but did not see that anyone has reported this. I know that other people would like this to be optional as well according to this post on the eclipse forums:I am reporting this because is did not appear that anyone else has.Reproducible: AlwaysSteps to Reproduce:1.Start remote debugging session.2.Stop remote debugging session.3.Witness extra browser window popup with message.	I suffer the same results, I'm on Windows XP. XDebug 2.0.3+, running as zend_extension. Several other sites suggests this is the result of the changing xdebug protocol from v2.0.2>v2.0.3 and thereafter. Debugger feels buggy with 2.0.3+.My server won't install <2.0.3 because of some zend-errors when install (pecl install xdebug, and adding zend_extension and others to my php.ini).This has already been now on Ubuntu 9.10, PHP 5.2.10, Eclipse 3.5 PDT with Xdebug v2.0.4.The URL has to be sent through Firefox in order to get the cookie removed. The Eclipse API that is used to talk to the browser (whichever one is registered in the eclipse preferences: internal, external etc) sends the URL and with firefox it creates a new tab. As far as I know there is no way round this. If you disconnect rather than stop a debug session, then the URL is not sent however the debug cookie will still remain in firefox. You can use alternative add-ons to firefox to manage the cookie.If you use the internal browser on windows then you can avoid this problem.Sorry but I don't see any other alternative to the problem at this time.Patch proposal:Merged:Thank you Bartek!Verified. ClosingI just upgraded to PDT 3.4 and can confirm that this is solved. Unfortunately, when I reload the page debugged after stopping the debugger, the debugger automatically starts again, as might be expected from David's comment.Should I open a new ticket to track this?(In reply to Filipus Klutiero from)We reverted this changes:Thank you Dawid. I suppose this ticket should be reopened then.(In reply to Filipus Klutiero from)Reopened for now, but we probably should mark this bug as WONTFIX.Thank you.I am not knowledgeable about debugger internals, but I do not think this is really unfixable. Xdebug should be able to ignore certain cookies. Of course, Eclipse would need to be able to tell Xdebug to ignore those, so the protocol needs to provide for that.The documentation of Xdebug remote debugging atis incomplete, so there may be a way to do that already, but I do not see it.	11.0
id=476668	REOPENED	PDT	Debugger	3.4.0	PC Windows 7	P3 normal	PHP Debug	2015-09-04 12:18 EDT by	Bartlomiej Laczkowski	2015-09-09 13:58 EDT (	0 users	The problem occurs while performing the following scenario (its final effect is pretty annoying and surprising for the user) :1. Create project 'xxx' with 'index.php' file.2. Create project 'yyy' with another 'index.php' file (different content than in the previous one).3. Deploy project 'xxx' to the PHP server with XDebug or Zend Debugger on board.4. Close project 'xxx' in PDT.5. Trigger debug session (index.php for xxx project on the server) with the use of e.g. some browser toolbar/extension for debuggerResult: 'index.php' file from 'yyy' project is found and opened in editor as a "perfect match" for a debug session (if related PHP server configuration exists the persistent path mapping will also be added)Expected: As the path of a project in PDT is not a prefix of URL/path of corresponding structure on the server, a mapping dialog should appear to give user a possibility to decide if the file is the "perfect match".	New Gerrit change created:Gerrit changewas merged to [master].Commit:Fixed.New Gerrit change created:Gerrit changewas merged to [master].Commit:After some thought I think that the previous patch proposal is a little bit aggressive so I've decide to revert it for now. I will try to find some less invasive solution...	6.0
id=458078	REOPENED	PDT	Debugger	3.3.2	PC Windows 7	P3 major	PHP Debug	2015-01-21 14:21 EST by	Bartlomiej Laczkowski	2015-02-17 10:38 EST (	5 users	Steps to reproduce:1. Create PHP project with simple echo.php file2. Deploy the file to a server with XDebug installed3. Put the breakpoint anywhere in echo.php file4. Start debugging the deployed script via Debug as -> PHP Web Application5. Press 'Resume' after the debugger hits the breakpointResult: Debug session is done but 'Remote Launch' element in Debug view is still active (has running state). User has to terminate/stop the session manually.Expected: 'Remote launch' element should be inactive (should have terminated state).	Patch proposal:Merged:Thanks!Hi,actually I find the fact not terminating a debug session a very useful functionnality!I can navigate between web pages, without ending my current debug session, and that's really *GREAT*!I can easily test this way Ajax calls, POST datas between web pages, etc...You're removing something very useful (in my point of view), so wouldn't it be possible to configurate automatic session termination using some project or global configuration?Or simply reverse this patch for now, waiting for a better solution?Or apply automatic session termination only for PHP Cli applications (but not for PHP Web Applications)?Thierry.Hi Thierry,Well... You are totally right. I missed the fact that XDebug session is running all the time in the background (although sending some info back from the server that the session has been stopped). Thanks for pointing that out. In this case it seems like this fix does not make sense at all, I will revert the changes.Maybe the option/preference for choosing the automatic termination would be useful in this case? As a default the option should be as it was before the fix.@Bartlomiej : Yes, good idea, it would be a good compromise!Would you have time to implement this feature? If not, a simple reverse would be a good first step ;)(In reply to Thierry BLIND from)I will make the time :) ReportedIf not terminated session is valuable behavior (like Thierry said) for XDebug web launch maybe it should stay as it was before this patch? What is use case for automatic session closing? Maybe this option fromis not necessary? I'm just thinking loud;)(In reply to Michal Niewrzal from)It might be useful when you don't want to terminate the session manually every time when debugging with XDebug. Let's assume that someone is debugging simple one-script web page - in this case you don't have to go back to Debug view, select the launch and terminate it. What's more re-launch of debug session will give you error message that session is already running and at the end of the day you have to terminate it manually. I think that user should decide what is the best option...@Michal, @Bartlomiej :Making it an option is still a good idea, of course ;)But I also think loudly:finally, wouldn't it be less stressful to just revert this patch for now?So Bartlomiej could work on a new option (about automatic termination) without having to worry about the 3.4 release schedule.Thierry.@Thierry, @Michal: OK, change will be reverted.I will think carefully about this option. It seems like this would be similar to 'Debug First Page Only' & 'Debug All Pages' that are in Zend Debugger options for web launches.Opened a bug before noticing the comments in this one:I can confirm this is not exactly a desired behavior.Looking forward to the revert fix. I also agree that a general option (and possibly per-debug-config one as well) would be viable here.***has been marked as a duplicate of this bug. ***Patch is reverted. Tomorrow nightly PDT version with this change will be available for download.We will back to this topic when Bartlomiej will create patch for.Thanks for feedback :)	14.0
id=503034	REOPENED	PDT	Debugger	unspecified	PC Windows 10	P3 blocker	PHP Debug	2016-10-03 03:22 EDT by	a3149931 a3149931	2017-02-06 19:32 EST (	5 users	Created"Awesome" PDT debuggerIn the nightly build x-debug now looks like this. wtf? :(------------!ENTRY org.eclipse.core.jobs 4 2 2016-10-03 11:16:38.376!MESSAGE An internal error occurred during: "Label Job".!STACK 0java.lang.NullPointerException at org.eclipse.debug.internal.ui.model.elements.VariableLabelProvider.getValueText(VariableLabelProvider.java:170) at org.eclipse.php.internal.debug.ui.views.variables.PHPVariableLabelProvider.getValueText(PHPVariableLabelProvider.java:50) at org.eclipse.debug.internal.ui.model.elements.VariableLabelProvider.getColumnText(VariableLabelProvider.java:116) at org.eclipse.debug.internal.ui.model.elements.VariableLabelProvider.getLabel(VariableLabelProvider.java:96) at org.eclipse.debug.internal.ui.model.elements.ElementLabelProvider.getLabel(ElementLabelProvider.java:315) at org.eclipse.debug.internal.ui.model.elements.ElementLabelProvider.retrieveLabel(ElementLabelProvider.java:218) at org.eclipse.debug.internal.ui.model.elements.ElementLabelProvider$LabelUpdater.run(ElementLabelProvider.java:165) at org.eclipse.debug.internal.ui.model.elements.ElementLabelProvider$LabelJob.run(ElementLabelProvider.java:74) at org.eclipse.core.internal.jobs.Worker.run(Worker.java:55)!ENTRY org.eclipse.core.jobs 4 2 2016-10-03 11:16:38.377!MESSAGE An internal error occurred during: "has children update".!STACK 0java.lang.NullPointerException at org.eclipse.debug.internal.ui.model.elements.VariableContentProvider.hasChildren(VariableContentProvider.java:65) at org.eclipse.debug.internal.ui.model.elements.ElementContentProvider.updateHasChildren(ElementContentProvider.java:229) at org.eclipse.debug.internal.ui.model.elements.ElementContentProvider$3.run(ElementContentProvider.java:206) at org.eclipse.core.internal.jobs.Worker.run(Worker.java:55)--------------	Thanks for the report. I'm increasing severity to blocker because I'm afraid it might also affect stable version, not sure why now. Could you tell us which PHP and XDebug version are you using?New Gerrit change created:PHP 5.6.10 + php_xdebug-2.3.2-5.6-vc11-x86_64.dll@Dawid: Did you notice any problem like this while working with the XDebug in some most recent PDT versions? I've spent some time on trying to reproduce it with some bigger projects like magento2 or concrete5 that I generally use to test debuggers and didn't notice such issue.@a3149931: Could you possibly provide some simple test case (maybe some small extract of your code if it's possible) that we can use to reproduce this issue?(In reply to Bartlomiej Laczkowski from)No, but I'm mostly debug PHP 7.0 with XDebug 2.4.* right now.(In reply to a3149931 a3149931 from)I still have one large php 5.6 project. I'll try downgrade xdebug to this version, maybe problem is in xdebug and we not handle it correctly.Could you update your xdebug to latest 2.4 ?This is big and old (since 2010) project based on ip.board 3.4.x + not all parts of this project can kill a debugger (sometimes it works)... so unfortunately this is not possible :( But I can try run any tool to determine where is the problem...Ok, I try to update it on this weekend.Bug still hereYes! See last comment in #311127 :)=>(bugzilla ...)Gerrit changewas merged to [master].Commit:Thank you for pointing out Filipus comment from, it helped a lot. Fix should be available in the next nightly build, please confirm if the fix does the job. Thanks for the report!Createdexceptions logged in eclipseHi,I reopen, I now have some exceptions logged when my php server is not launched (see attachement). Exceptions appear 1 or 2 minutes after eclipse is started.Thierry.------------------------------------------------------------------------------eclipse.buildId=4.5.2.M20160212-1500java.version=1.8.0_66java.vendor=Oracle CorporationBootLoader constants: OS=win32, ARCH=x86, WS=win32, NL=fr_FRFramework arguments: -product org.eclipse.epp.package.jee.productCommand-line arguments: -os win32 -ws win32 -arch x86 -product org.eclipse.epp.package.jee.productorg.eclipse.php.debug.coreErrorThu Oct 13 15:21:25 CEST 2016class org.eclipse.php.internal.debug.core.xdebug.dbgp.session.DBGpSession : Unexpected null from readResponse waiting for Init------------------------------------------------------------------------------eclipse.buildId=4.5.2.M20160212-1500java.version=1.8.0_66java.vendor=Oracle CorporationBootLoader constants: OS=win32, ARCH=x86, WS=win32, NL=fr_FRFramework arguments: -product org.eclipse.epp.package.jee.productCommand-line arguments: -os win32 -ws win32 -arch x86 -product org.eclipse.epp.package.jee.productorg.eclipse.php.debug.coreErrorThu Oct 13 15:22:00 CEST 2016Incompatible debugger version.The remote debugger version might not match the expected protocol version (2012121702).------------------------------------------------------------------------------eclipse.buildId=4.5.2.M20160212-1500java.version=1.8.0_66java.vendor=Oracle CorporationBootLoader constants: OS=win32, ARCH=x86, WS=win32, NL=fr_FRFramework arguments: -product org.eclipse.epp.package.jee.productCommand-line arguments: -os win32 -ws win32 -arch x86 -product org.eclipse.epp.package.jee.productorg.eclipse.php.debug.coreErrorThu Oct 13 15:22:03 CEST 2016Socket error (length is negative): possibly Server is SSL, Client is not..(In reply to Thierry BLIND from)OK, I will take a look at the first log message as the next ones are related to Zend Debugger and this is something different. Thanks for reporting!@Thirry: One more thing, do you run PHP CLI or Web Xdebug session?Thank you Bartlomiej!Of course I have no errors at all when I launch my php server before starting eclipse ;)When debugging, I'm using Web Xdebug session.Thierry.(In reply to Thierry BLIND from)I took a look at the place where such exceptions can be logged and it looks like this is a completely different issue and I think that it is not related to the patch for this bug. It generally looks like the debug daemon thread that listens on port 9000 for Xdebug incoming session is getting something that is not "init" message from Xdebug. This is especially weird because as you said that your web server is down and it happens after a few minutes (we just simply wait on 9000 and it looks like some "not Xdebug" session data was sent to it after this time). Could you possibly check if this behaviour is the same in i.e. latest official PDT 4.1 release so we can close this issue and report another one?Ok I'll tell you tomorrow! :)Hi Bartlomiej,you're right, it seems not related to this patch, I can't reproduce my bug since I restarted my PC :( If problem occur again, I'll open a separate bug report, sorry for the inconvenience! And thank you for your fast answer ;)Thierry.Thanks for a patch and sorry for the late reply. Now I don't see any error popup, but unfortunately debugger still fully unuseful :( (variables are empty, see animation)Created"Awesome" PDT debugger 2Sorry I updated the CC List for this bug by mistake :/	21.0
id=484197	REOPENED	PDT	Debugger	3.4.0	PC All	P3 normal	PHP Debug	2015-12-11 06:43 EST by	Bartlomiej Laczkowski	2016-02-18 11:48 EST (	2 users	Run As/Debug As -> PHP Web Application command in project's context menu is only available when server assigned to the project is local. In case of remote server this option is not visible. This option should be visible for both scenarios.	New Gerrit change created:Gerrit changewas merged to [master].Commit:Fixed.Reopened by Ilina	4.0
id=190676	REOPENED	PDT	Core	0.7	PC All	P3 enhancement	PHP UI	2007-06-03 03:35 EDT by	Michael Spector	2012-07-30 14:48 EDT (	2 users	Desired behaviour:- mark undefined functions as Errors- if the class, has __call() give the function a different highlighting color and link it's definition to __call- perhaps show these functions in the outline with a new symbol	duplicate*** This bug has been marked as a duplicate of***Sorry not exactly the same.	2.0
id=203070	REOPENED	PDT	Editor	unspecified	PC Windows XP	P3 enhancement	PHP UI	2007-09-12 10:12 EDT by	Matthijs Tempels	2009-12-30 08:01 EST (	2 users	It would be nice to have the option to automatically remove empty lines at the end / bottom of a file while saving it..	I see this option in 2.1.0RC3 (may be it was fixed already)Tested on 2.2.1SR1.Not fixed.Only white spaces removed.Nothing happens with empty lines.	3.0
id=206805	REOPENED	PDT	General UI	1.0	All All	P3 enhancement	PHP UI	2007-10-18 14:42 EDT by	Sean	2016-09-15 13:32 EDT (	3 users	When customizing the PHP perspective there is no option to add "Undo" and "Redo" buttons to the toolbar. This is an enhancement request to allow those buttons to be added to the toolbar, mainly because they would provide useful feedback on whether the "Undo" and "Redo" actions can currently be used in the editor.	This buttons are available by default since years.Hi DawidI was also unable to find a way to add those and they are not visible anywhere.I might be blind dough so any hint will be appreciated :)Dawid, both me and Michal could not see such buttons.You have both right. My mistake ;)	4.0
id=290144	REOPENED	PDT	General UI	unspecified	PC Mac OS X - Carbon (unsup.)	P3 major	PHP UI	2009-09-22 11:23 EDT by	Bastian Feder	2016-06-28 04:25 EDT (	3 users	User-Agent: Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10.5; de; rv:1.9.0.3) Gecko/2008092414 Firefox/3.0.3Build Identifier: 20090619-0625if you choose a dir in Validator-settings-dialog it won't be shown in the input field nor used as (include|exclude) Group rule.Reproducible: AlwaysSteps to Reproduce:1. choose "Validation" from preferences Menu2. choose "settings" at the validator of your choice 3. select a Group4. click "add Rule"5. click "Folder or Filename" and "Next >"6. click "Browser Folder"7. choose a directory	Createdvalidator settings dialog where bug accoursCarbon is no longer supported and on cocoa working correctly.Marking as fixed.I am not really sure how this works but simply following the steps described and selecting any file/directory the field remains empty. And it does not seem to be OSX specific - I see the same on Windows.On OSX if I run browse file and select file (double click) I see file name in "File or folder". Same for browse folder.Can you attach screenshot?After that I'll move this to WTP (this page is not from PDT).OK, with FILE I now see it working (not sure what I did yesterday), but for FOLDER the screenshot will look just the same as the one attached by Bastian, no need to duplicate it (just that mine is on Windows). So maybe just move it	5.0
id=323030	REOPENED	PDT	Editor	2.2	PC Windows XP	P3 normal	PHP UI	2010-08-18 10:17 EDT by	Kalin	2010-09-27 23:13 EDT (	2 users	Build Identifier: 2.2.0.v20100621Precondition:PHP project outline view is not opened in PHP Perspective.Have the following code in php file:<?phpclass A { public function example() { } const test = "free string";}class B extends A { public function example() { }}Open PHP Project outline view.Go to Constants node and double click on testExpected:the constant test only should be highlighted in editor.Actual:Unexpectedly big area of code was highlighted.See the attached screenshot.Reproducible: Always	Createdscreenshotcould not reproduce this bug in latest pdt code.[Petyo Tanchev]Reproduced on PDT Core Plug-in 2.2.1v20100823-1000PDT UI Plug-in 2.2.1v20100822-1700Createdpatch	4.0
id=302612	REOPENED	PDT	Outline Views	unspecified	PC Windows 7	P3 normal	PHP UI	2010-02-11 13:12 EST by	None	2016-06-15 10:40 EDT (	4 users	Build Identifier: I20100129-1300If a method has a long signature the tooltip will run off the end of the page.Is it possible to have it aligned to the edge of the window so it doesn't run off?See attached screenshots for an example.Reproducible: AlwaysSteps to Reproduce:1. Open outline view2. Mouseover a method with a long signature3. The end of the tooltip will run off the screw	CreatedObscured tooltipCreatedThe full method signatureIt is a common behavior(bug?) for eclipse outline view,so change to p3.not trivial at all ;)Tooltips in Outline are not available in latest version.Michal, it seems that tooltips are not available in Linux, but I have them working on Windows ... maybe there is something wrong with Linux? Although I'm not sure if it is a PDT issue	6.0
id=464997	REOPENED	PDT	Editor	3.4.0	All All	P3 enhancement	PHP UI	2015-04-20 06:43 EDT by	Dawid Pakula	2016-05-28 12:12 EDT (	1 user	CreatedPDT (top) vs JDT (botton) code assistPHP/WTP code assist positions are now on white background.JDT code assist window have same (dark) background like other ui elements.Screenshot attached.	I see that on mars m6 this window is themed correctly. So I'm marking as fxied.On RC3 / RC4 is again unreadable.Somebody know how to force dark version?What do you mean? I checked RC2 and after switching to dark theme CA dialog is also dark.I have white on RC2. It highly depends to bundle load order so there is a risk, that after update will be black again :P	5.0
id=494859	REOPENED	PDT	Editor	4.0.0	PC All	P3 normal	PHP UI	2016-05-29 16:12 EDT by	Michal Niewrzal	2016-06-03 09:47 EDT (	0 users	Initial size should be saved after resize like CA dialog.	New Gerrit change created:Gerrit changewas merged to [master].Commit:It seems to be working somewhat randomly. Sometimes changes are saved, most of the time not	3.0
id=346169	REOPENED	PTP	Remote Tools	4.0.6	All Linux	P3 enhancement	Project Inbox	2011-05-17 18:17 EDT by	Corey Ashford	2011-05-25 19:07 EDT (	2 users	Build Identifier: I20110512-2000If I creat a new Remote C/C++ project using RDT, and then specify that I want to use Remote Tools as the provider, I get to the point of needing to specify a new remote host. I click on New...I am then presented with a dialog where I can enter the Target name, Host, User, and I choose "Public key based authentication". I am them prompted to specify the "File with private key". If I then click Browse, I cannot go to where my private key is located, presumably because it's in a hidden directory, starting with a ".".My private key is located in directory /home/corey/.ssh but this directory is not available in the file browser.I think the code needs to change the filter that is used so that it doesn't exclude directories beginning with a ".".The work-around is to type the path in by hand.Reproducible: AlwaysSteps to Reproduce:See details.	This is a property of the file browser. On Mac OS X, you have to enable hidden files, and on Linux (Ubuntu) you right click anywhere in the browser and select "Show hidden files". I don't know about Windows.(In reply to)Thank you for that information. I am able to display hidden files by right-clicking on any particular file or folder, and adding a check to "Show Hidden Files", but right-clicking in other spots doesn't work (at least under Fedora 14).Is there a programmatic way to turn on "Show Hidden Files" by default when Eclipse launches the file chooser? If so, I think it would be a good idea to do that, since it's quite likely, at least on Linux machines, that the private key will be in a hidden directory.(In reply to)No, there is no specific option for this. The only way may be to call setFilterExtensions() with something like "*.*", ".*" but this would require more investigation since it may not work, or may work differently on different platforms.I'll reopen this as an enhancement for a future version.(In reply to)Maybe we could just check whether $HOME/.ssh exists and if so set the folder for the dialog to this folder. Under Linux (and I suppose MacOS) that will usually be the folder the user wants to select the key from. And if the dialog is already in the folder, this issue with the folder being hidden is avoided.An alternative would be to get rid of that field completely and use the Eclipse wide configuration for the SSH key (General->Network Configuration->SSH2). Wouldn't this make more sense anyhow?(In reply to)Yes, this would be the preferred option.(In reply to)I agree. If you add a link from the Remote Host configuration dialog to that preference page, that would be even better. This is the first time I had heard of that general setting, and I would not have known to go there to configure it.	6.0
id=318164	REOPENED	PDT	Templates	2.2	PC Windows XP	P3 normal	PHP UI	2010-06-28 07:30 EDT by	Kir	2016-08-09 09:32 EDT (	13 users	Build Identifier: I20100608-0911In PDT 2.2 we can't create template for new php file.Reproducible: AlwaysSteps to Reproduce:1. Open Window->Preferences->PHP->Editor->Templates2. Try to create new template3. Try to find "newPhp" in "context" field	in pdt 2.2 we removed the newPHP templates. it was replaced with code templates (under PHP | Editor) to customize your new php content(In reply to)Thx for answer.Try to add new one. You can't.We use 10 additional templates.fixed in head,now there is a new button only for new php file context.Additional new php file templates will not be supported at this point.(aligning with JDT)And how can i add my templates?It's so cool, what i can't add my migration, controller and model template in eclipse ^_^ (sarcazm)you could modify eclipse home/plugins/org.eclipse.php.ui/templates/phpdefault-templates.xml to add your templates,this is workaround,because we do not supply this feature any more,thanks!Seriously?SERIOUSLY??You REMOVE support for custom new file templates?? That's just-- I mean... Wow I don't even have words for this...I'm not usually one to do useless rants like this, but I hope someone sees this. The fact that you removed this feature [since thie last time I actively used PDT] has just reduced the attractivity of PDT by about 30%.I mean, it was WORKING before -- using the newPhp Editor templates -- and it is still working in other editors (like the HTML editor). So if you don't want to maintain the New File Templates dialog with add/remove buttons (which, tbh, would just be copy/pasting most of it from either the editor templates page or from another plugin), why don't you just return to the way things were?Is there any REASON for this (besides "aligning with JDT", which is not a valid reason to justify such a regressive step)?Reopening, we need to revise this.I think that JDT can be used without templates because it have a diferente new file for each type content they have; for example, for new class or a new enum. But for php, you don't have a new file for a class, for html5 page, etc. and so this isn't a valid aproach.In my opinion, we need to mantain the posibility to create new file templates, they are very very usefull. For example, I have one for each web proyect so I don't need to rewrite or copy the page structure each time I need to add a new page.***has been marked as a duplicate of this bug. ******has been marked as a duplicate of this bug. ***Is anyone able to provide information to the location of the file mentioned in? I suspect that it has been moved/changed since the comment was posted nearly 6 years ago, as I am unable to find said file. Additionally, as mentioned in the linked, importing a template file with a new id-attribute does absolutely nothing.I feel for PHP this is definitely a beneficial feature that should have never been removed. PHP files can serve very different purposes if that file is intended for a Model Class, Controller Class, View Script, Shell Script, etc.Until this bug is resolved, I am willing to go through the work suggested inbut unfortunately I cannot find where these default templates are stored these days.Thank You,Darren FeltonEclipse for PHP DevelopersVersion: Mars.2 Release (4.5.2)Build id: 20160218-0600File you cannot find is in <your_eclipse>/plugins/org.eclipse.php.ui*.jar/templates. Update file and repack zip, new template should be visible in new php file wizard.Thank you Michal Niewrzal.This file was located in a slightly different location for me, most likely because I used the Windows installer to get my copy of Eclipse, rather than downloading a copy which runs stand-alone in it's own directory. For those who are in my same situation, on Windows 10, the file is here:%USERPROFILE%\.p2\pool\plugins\org.eclipse.php.ui_*.jarFiles to edit:- templates\phpdefault-templates.properties- templates\phpdefault-templates.xml	14.0
id=465855	REOPENED	PDT	Editor	3.5.0	PC Linux	P3 normal	PHP UI	2015-04-29 15:55 EDT by	Jorrit Schippers	2015-06-12 11:03 EDT (	1 user	Createdeclipse installation informationI use the nightly dltk and PDT versions on Ubuntu 14.10 64-bit using the 32-bit Sun JVM version 1.6. I update the PDT plugin regularly.Since a couple weeks or months (I don't remember) the IDE hangs sometimes when I save a PHP file. The program is unresponsive and Ubuntu applies a semitransparent overlay to indicate that the program doesn't respond. After about 10 seconds the delay is over.I'll attach files that hopefully lead to a cause for this problem, but perhaps my JVM is too old?	Createdeclipse log file, containing an exception that might be of interestCreatedvisualvm thread dump, the main thread seems to be waiting on somethingBased on logs I see you haven't nightly DLTK, but ancient 5.0 dltk h2 index (current nightly is 5.2, 5.1.1 is latest stable with many h2 improvements).Can you upgrade?DLTK update sites:DLTK 5.1.1 (stable):DLTK 5.2 (nightly)PDT update sites:Latest stable (3.4)Latest nightly (3.5)Thank you very much for your quick comment and insight. I stumbled upon a link to a feed of nightly DLTK versions, but it seemed to be an outdated link.Thanks for the DLTK links. Where could I have found those on eclipse.org? The DLTK subsite seems to be very outdated.I'll mark this bug as INVALID.List of recent and upcoming releases are available in pmi :update site will be at:}you can also use unofficial community repository:it contain PDT/DLTK nightlies and many other pluginsThanks, I did not know about.After upgrading DLTK, I still have this issue. I will attach a new thread dump and eclipse installation info.Creatednew thread dumpCreatednew eclipse installation informationIs there anything I can do to help investigage this problem?Might be related to, SVN decorator works in similar way like GIT decorator. If you are using workspace from previous version, you should close all projects and reopen.Did you activated any mylyn task? If yes can you try without any context?And last, can you attach example file? Thank youThanks for your response.I will close all projects and reopen them. I am using activated Mylyn tasks all the time, I will try to see if not having them activated makes any difference.If that doesn't give results, I'll attach a file.Reopening and closing didn't help. Not using Mylyn tasks didn't help. I imported the project in a new workspace and I noticed different behavior: when I save a file about 500 PHO files are rebuilt. Perhaps this causes the freeze in my other workspace. I tried disabling the builders in the project settings and noticed weird behavior: the builders automatically get readded, causing builders to appear multiple times. I'll attach a screenshot.I think attaching a single file doesn't help, I tried copying a file to a workspace with a simple project and the bug did not appear there. The freeze occurs in a very large project with thousands of PHP files.Createdscreenshot of builders problemScript project build cannot be disabled due. On save only changed file should rebuild. Can do more thread dumps? And maybe have you additional error logs?Today I realized that I still run Kepler, while Juno is released and Mars is coming later this month. I think I try again later this month with a fresh installation.I have received the freeze more often, the thread dumps were similar, at least for the main thread.Based on current dump I see that it's related to mylyn. After deactivate task, please restart eclipse (DLTKEdititngMonitor is still active after first activation).	17.0
id=441192	REOPENED	PTP	EMS	8.0.1	PC Linux	P3 normal	Project Inbox	2014-08-05 11:43 EDT by	Aaron Luchko	2014-09-02 17:46 EDT (	2 users	I created a synchronization configuration and selected the 'Manually specify environment configuration commands' checkbox.However, as far as I can tell these commands are not being run. As a test I entered 'touch BAR' as the manual configuration command and no file BAR was created.The remote system is RHEL 6.1 with a zsh terminal. I've confirmed the actual build command does successfully execute on the remote system (though I need to set the environment configuration in the build script).	Manual environment lines seem to be working with the remote build and with the PBS scheduler. Please provide specific instructions to reproduce this bug if it is encountered in the future.I performed the following on a Fedora 20 system with an updated Luna Release (4.4.0)Build id: 20140612-06001. Open eclipse and go to File > New, then in the New Project Wizard select SVN > Checkout Projects from SVN a) Create New Repository, URL=b) Select Trunk, then Next, and select New Project Configured with New Project Wizard c) Finish2) In the resulting New Project Wizard select Remote > Sychronized C/C++ Project: a) Enter the project name, apache. b) Select New Connection and set the host to localhost (and username/pw to your account) c) Set the Remote Directory to /home/<username>/newfolder d) Set Project Type to Makefile project with no local toolchain and a remote toolchain of ​--Other Toolchain--​. e) Click ​Finish​ and proceed with the checkout.3) Set the Sychronization environment code. Go to project properties and Sychronize a) Select the localhost connection and check the 'Use an environment management system to customize the remote build environment' followed by the 'Manually specify environment configuration commands' b) Enter "touch foo" in the text box c) Click OK4) From the Project menu select Build Project5) Note that the file "foo" does not exist in either copy of the project.Greetings. Please note that the environment configuration operations take place in your home directory for the remote system unless you manually specify a directory change. When I tried your example my 'foo' showed up in the /home/wspear directory, not any of the project directories.	3.0
id=472225	REOPENED	PTP	Remote Tools	9.0.1	PC Linux	P3 normal	Project Inbox	2015-07-08 17:07 EDT by	Andrew Bennett	2016-01-28 17:46 EST (	2 users	Steps to reproduce: Go to Window > Preferences > Remote Development > Remote Connections > Add/EditStack Trace:java.lang.NullPointerException at org.eclipse.remote.internal.ui.preferences.ConnectionsPreferencePage.addConnection(ConnectionsPreferencePage.java:246) at org.eclipse.remote.internal.ui.preferences.ConnectionsPreferencePage.access$3(ConnectionsPreferencePage.java:236) at org.eclipse.remote.internal.ui.preferences.ConnectionsPreferencePage$EventHandler.widgetSelected(ConnectionsPreferencePage.java:175) at org.eclipse.swt.widgets.TypedListener.handleEvent(TypedListener.java:248) at org.eclipse.swt.widgets.EventTable.sendEvent(EventTable.java:84) at org.eclipse.swt.widgets.Display.sendEvent(Display.java:4481) at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1327) at org.eclipse.swt.widgets.Display.runDeferredEvents(Display.java:3819) at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3430) at org.eclipse.jface.window.Window.runEventLoop(Window.java:827) at org.eclipse.jface.window.Window.open(Window.java:803) at org.eclipse.ui.internal.dialogs.WorkbenchPreferenceDialog.open(WorkbenchPreferenceDialog.java:211) at org.eclipse.ui.internal.OpenPreferencesAction.run(OpenPreferencesAction.java:63) at org.eclipse.jface.action.Action.runWithEvent(Action.java:473) at org.eclipse.jface.action.ActionContributionItem.handleWidgetSelection(ActionContributionItem.java:595) at org.eclipse.jface.action.ActionContributionItem.access$2(ActionContributionItem.java:511) at org.eclipse.jface.action.ActionContributionItem$5.handleEvent(ActionContributionItem.java:420) at org.eclipse.swt.widgets.EventTable.sendEvent(EventTable.java:84) at org.eclipse.swt.widgets.Display.sendEvent(Display.java:4481) at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1327) at org.eclipse.swt.widgets.Display.runDeferredEvents(Display.java:3819) at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3430) at org.eclipse.e4.ui.internal.workbench.swt.PartRenderingEngine$4.run(PartRenderingEngine.java:1127) at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:337)	The previous problem can be solved by adding the right stuff to the feature and product, then adding required plugins to the product.launch. Another problem wih the remote development preference pages still exists. Steps to reproduce: Go to Window > Preferences > Remote Development > Remote ShellStack Trace:java.lang.ClassNotFoundException: org.eclipse.ptp.internal.remote.terminal.TerminalPrefsPage cannot be found by org.eclipse.ptp.remote.terminal_2.0.0.201506101404 at org.eclipse.osgi.internal.loader.BundleLoader.findClassInternal(BundleLoader.java:439) at org.eclipse.osgi.internal.loader.BundleLoader.findClass(BundleLoader.java:352) at org.eclipse.osgi.internal.loader.BundleLoader.findClass(BundleLoader.java:344) at org.eclipse.osgi.internal.loader.ModuleClassLoader.loadClass(ModuleClassLoader.java:160) at java.lang.ClassLoader.loadClass(ClassLoader.java:357) at org.eclipse.osgi.internal.framework.EquinoxBundle.loadClass(EquinoxBundle.java:573) at org.eclipse.core.internal.registry.osgi.RegistryStrategyOSGI.createExecutableExtension(RegistryStrategyOSGI.java:174) at org.eclipse.core.internal.registry.ExtensionRegistry.createExecutableExtension(ExtensionRegistry.java:905) at org.eclipse.core.internal.registry.ConfigurationElement.createExecutableExtension(ConfigurationElement.java:243) at org.eclipse.core.internal.registry.ConfigurationElementHandle.createExecutableExtension(ConfigurationElementHandle.java:55) at org.eclipse.ui.internal.WorkbenchPlugin$1.run(WorkbenchPlugin.java:293) at org.eclipse.swt.custom.BusyIndicator.showWhile(BusyIndicator.java:70) at org.eclipse.ui.internal.WorkbenchPlugin.createExtension(WorkbenchPlugin.java:288) at org.eclipse.ui.internal.dialogs.WorkbenchPreferenceNode.createPage(WorkbenchPreferenceNode.java:48) at org.eclipse.jface.preference.PreferenceDialog.createPage(PreferenceDialog.java:1300) at org.eclipse.ui.internal.dialogs.FilteredPreferenceDialog.createPage(FilteredPreferenceDialog.java:355) at org.eclipse.jface.preference.PreferenceDialog.showPage(PreferenceDialog.java:1187) at org.eclipse.ui.internal.dialogs.FilteredPreferenceDialog.showPage(FilteredPreferenceDialog.java:608) at org.eclipse.jface.preference.PreferenceDialog$9$1.run(PreferenceDialog.java:675) at org.eclipse.swt.custom.BusyIndicator.showWhile(BusyIndicator.java:70) at org.eclipse.jface.preference.PreferenceDialog$9.selectionChanged(PreferenceDialog.java:670) at org.eclipse.jface.viewers.StructuredViewer$3.run(StructuredViewer.java:877) at org.eclipse.core.runtime.SafeRunner.run(SafeRunner.java:42) at org.eclipse.ui.internal.JFaceUtil$1.run(JFaceUtil.java:50) at org.eclipse.jface.util.SafeRunnable.run(SafeRunnable.java:173) at org.eclipse.jface.viewers.StructuredViewer.firePostSelectionChanged(StructuredViewer.java:874) at org.eclipse.jface.viewers.StructuredViewer.handlePostSelect(StructuredViewer.java:1243) at org.eclipse.jface.viewers.StructuredViewer$5.widgetSelected(StructuredViewer.java:1269) at org.eclipse.jface.util.OpenStrategy.firePostSelectionEvent(OpenStrategy.java:265) at org.eclipse.jface.util.OpenStrategy.access$5(OpenStrategy.java:259) at org.eclipse.jface.util.OpenStrategy$1$2.run(OpenStrategy.java:440) at org.eclipse.swt.widgets.RunnableLock.run(RunnableLock.java:35) at org.eclipse.swt.widgets.Synchronizer.runAsyncMessages(Synchronizer.java:135) at org.eclipse.swt.widgets.Display.runAsyncMessages(Display.java:3794) at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3433) at org.eclipse.jface.window.Window.runEventLoop(Window.java:827) at org.eclipse.jface.window.Window.open(Window.java:803) at org.eclipse.ui.internal.dialogs.WorkbenchPreferenceDialog.open(WorkbenchPreferenceDialog.java:211) at org.eclipse.ui.internal.OpenPreferencesAction.run(OpenPreferencesAction.java:63) at org.eclipse.jface.action.Action.runWithEvent(Action.java:473) at org.eclipse.jface.action.ActionContributionItem.handleWidgetSelection(ActionContributionItem.java:595) at org.eclipse.jface.action.ActionContributionItem.access$2(ActionContributionItem.java:511) at org.eclipse.jface.action.ActionContributionItem$5.handleEvent(ActionContributionItem.java:420) at org.eclipse.swt.widgets.EventTable.sendEvent(EventTable.java:84) at org.eclipse.swt.widgets.Display.sendEvent(Display.java:4481) at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1327) at org.eclipse.swt.widgets.Display.runDeferredEvents(Display.java:3819) at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3430) at org.eclipse.e4.ui.internal.workbench.swt.PartRenderingEngine$4.run(PartRenderingEngine.java:1127) at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:337) at org.eclipse.e4.ui.internal.workbench.swt.PartRenderingEngine.run(PartRenderingEngine.java:1018) at org.eclipse.e4.ui.internal.workbench.E4Workbench.createAndRunUI(E4Workbench.java:156) at org.eclipse.ui.internal.Workbench$5.run(Workbench.java:654) at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:337) at org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:598) at org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:150) at org.eclipse.ui.internal.ide.application.IDEApplication.start(IDEApplication.java:139) at org.eclipse.equinox.internal.app.EclipseAppHandle.run(EclipseAppHandle.java:196) at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:134) at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:104) at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:380) at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:235) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:497) at org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:669) at org.eclipse.equinox.launcher.Main.basicRun(Main.java:608) at org.eclipse.equinox.launcher.Main.run(Main.java:1515) at org.eclipse.equinox.launcher.Main.main(Main.java:1488)The Remote Shell is a page from the Parallel Tools Platform. The TerminalPrefsPage class referenced in the stack trace was removed from PTP months ago. As far as I can tell, the PTP locations in the Mars target are up to date, so I think this may be a PTP bug, rather than an issue with ICE.This was a PTP bug that is now fixed.Andrew: I there a PTP bug-report? I'm experiencing this using PTP 9.0.1.201509091505Not that I was able to find. After updating the version of PTP we were using the first issue resolved itself. We are using PTP 9.0.020150610 and do not experience the first problem. I just checked and the error when using `Window > Preferences > Remote Development > Remote Shell` still occurs. I forgot that second issue even came up, I just found it when I mis-clicked once. I just played around a bit and haven't been able to resolve it with different versions either. If you do file a bug report you should link to this one, though.This is still visible in 9.0.2.201512081413. Andrew, or someone with sufficient permissions: Could you reopen this bug and assign it to PTP. I'm no friend of duplicating bugs. ;)Seefor more details.I just downloaded the Mars.2 RC1 Parallel Package and this preference page is no longer present.I then downloaded the Mars.1 Parallel Package (which does have the preference page) and updated the PTP components fromand restarted Eclipse. The preference page is no longer present.	8.0
id=424336	REOPENED	PTP	RDT.sync	8.0	PC Windows XP	P3 normal	Project Inbox	2013-12-18 08:49 EST by	David Wootton	2014-08-19 11:01 EDT (	2 users	I have a synchronized project containing several large core files (70MB each) where core files are not excluded by filtering. When synchronization starts, I get a progress monitor but synchronization is taking a long time due to sending core files across a slow connection.I click cancel in the progress monitor but nothing happens except for the cancel button switching to disabled state, I have to kill the Eclipse session manually and restart. When I restart Eclipse the synchronization project seems to be in a corrupted state and I have to recreate the project.	Could you try this experiment again with Eclipse Luna? Cancelling seems to work better in Luna, probably because of improvements to JGit.Canceling now seems to work in Luna.John, can you try canceling when the progress message is "Synchronizing: Merging changes locally"? I just tried this and after about 10 minutes, I get a popup showing:Synchronization error for project: xxxorg.eclipse.jgit.errors.TransportException: ssh://none/..../.ptp-sync push cancelled.Confirmed. I did not get the error message, but the merge didn't stop. "Committing local changes" is also not cancelable. Both are local file operations done by JGit. So reopening the bug until we fix the problem for all steps.	4.0
id=378882	REOPENED	CDT	cdt-core	7.0	PC Windows 7	P3 normal	Chris Recoskie	2012-05-08 14:04 EDT by	Chris McGee	2016-07-07 11:24 EDT (	16 users	CreatedSample EFS provider pluginI am using EFS as part of a very popular resource management system. Some of my customers are using it in conjunction with both JDT and CDT.Eclipse EFS allows filesystem providers to create virtual hierarchies for projects from a variety of sources (e.g. Zip, Http):When using CDT in conjunction with a project that is managed by a non-local filesystem provider it falls over trying to populate the virtual folders for the includes. Also, when it invokes the compiler it invokes it in non-existent directories and/or provides invalid paths to the source code files.Attached to this bugzilla is a zip of a sample EFS provider (very basic) that uses its own URI scheme but has a one-to-one mapping back to files in the local filesystem. Note that the "path" of the URI cannot be used directly to go to the local filesystem because it has special segments in it.Here are the steps to reproduce the problems:1) Compile and install the provided plugin (or just use a runtime-workbench)2) Create both a CDT and JDT projects with some sample content3) Delete the CDT project (do not delete contents on disk)4) Right click on the JDT project->Load Project5) Pick the directory on the local filesystem where the CDT project resides6) Delete the JDT project (do not delete contents on disk)7) Right-click on the CDT project->Load Project8) Pick the directory on the local filesystem where the JDT project residesRight-click on each project and show properties. Notice that in the "Location:" field they have special "foo" URI's and not the default path locations. They are now managed by the special EFS provider.In the JDT project, you can navigate, make changes and build the project without any problems. However, in the CDT project, the "includes" folder is missing and whenever I build it there are compiler errors due to missing paths:Internal Builder: Cannot run program "g++" (in directory "foo\C:\Users\cbmcgee\Downloads\eclipse-cpp-indigo-SR2-incubation-win32-x86_64(1)\eclipse\runtime-New_configuration\aproject\Debug"): CreateProcess error=267, The directory name is invalid.CDT should not be assuming that it can directly use the path portion of the URI directly. Instead, it should probably use something like IResource.getRawLocation().toFile() to get the file on the local file system.	EFSExtension is probably what you want to investigate. We created this this extension point to handle exactly this scenario.Createdpatch-v01I noticed that UNCPathConverter.toPath is not giving EFS a chance to resolve a path with a custom protocol. This patch attempts to fix this issue.I run autotools test cases, and the patch doesn't seem to break anything.I also tested that the scenario with a CDT project under Jazz source control. Navigating the project through "Open declaration" works with the patch.Createdpacth-v02In the previous patch egit included some meaningless classpath changes. Corrected now.Dough, Chris - is the patch OK? Will you push the patch to head and 8.1.1?Can you push this change request to Gerrit. Instructions are here:. It's much easier to review and get submitted that way.(In reply to)Hi Doug,Here is the change in Gerrit:Will you review it, please?Chris, Doug,Did you have a chance to look into the fix?I approved the change in Gerritt, it has been merged to master.Thanks Chris very much. Will it be also available in CDT 8.1.1?You had only submitted the patch in Gerritt against master, so that is the only place it was applied.Applied to cdt_8_1 as well.Thanks Chris :)CreatedAn update of the Sample EFS provider plug-inJust to have it available - I've attached an update to the Sample EFS Provider Plug-in. It is a binary bundle and you can drop it into your environment to run.Re-opening as this is still an issue in Eclipse 4.4.2 with CDT 8.6. The steps in the original description still apply and the test bundle incan be used for testing.(In reply to DJ Houghton from)Have you tested with CDT 8.8?Surya will try CDT 8.8 today and post his results here.I tried with Eclipse Mars and CD 8.8. I still see the issue. The .cpp automatically added this line - #include "foo/C:/Download/RTCClient/502/Testing2/CDT_Project/Hello2.h"Which is not correct.The sample EFS provider has been posted to a github project with source code and update site:It's never going to work unless you have an EFSExtension to go with your filesystem. This should be closed in my opinion. The extension point is there for those with weird custom filesystems to provide support for them.This is an urgent issue for one of our customers.I am not an Eclipse expert, but the following has been suggested:As part of its attempt to get a pathname, CDT is looking inside a URL to get a pathname, which happens to work in some cases, but which isn't part of the API.There is an Eclipse API that is defined to return the pathname (IResource.getLocation). Would it be possible, for CDT to try the IResource.getLocation call before looking inside the URL (and use the IResource.getLocation result, if it is non-null). This would then ensure a valid pathanme for any IResource implementation that supports the IResource.getLocation call, and do no harm for those that do not.For the above mentioned problematic files there is no "location" information since they are outside the eclipse workspace.Looking at the code the only viable and safe approach is to implement the mentioned EFSExtension point.WRT, my understanding is that EFS resources are logically within the Eclipse workspace, and in this particular EFS provider, the resources also exist on the local file system, and so there is a local path to each of these resources. Unless their is a bug in their EFS provider (which they would fix, if that is the case), getLocation applied to these EFS resources will return the correct local path. Marko: Let's have a phone conversation, and then report back our conclusions to this thread.	21.0
id=251496	REOPENED	PDT	Code Assist	2.0.0	PC Windows XP	P3 normal	Michael Spector	2008-10-20 23:36 EDT by	Loc Truong	2014-07-02 07:45 EDT (	5 users	Build ID: I20080617-2000Steps To Reproduce:1. type priv2. press CTRL + enterMore information:Not sure if this is a problem with RSE or PDT. I've been always having problems with this since eclipse 3.3 and old RSE.TM with RSE version 3.0.1PDT is pdt-runtime-I200809241021.	You need extra package to make RSE working, which is called: DLTK RSE integration. It's specified in "handy extras" section on PDT download page.Verified with RSE updated - code assist pops-up as expected (PDT build N20081022).Closing[Sylvia Tancheva]I've installed Dynamic Languages Toolkit - Remote Development Support (Incubation) but it doesn't work. Any idea ? Or you can direct me to the exact package.(In reply to)Can you explain what actions are you doing, e.g. creating remote folder, remote project etc...?I'm opening files from remote ftp folders. They are not remote projects but remote connections. I'm not sure if I have to make them remote projects to use code assistance ?Lucius is correct - if you open the files in the Editor directly from the RSE Code Assist doesn't work.(It works in linked folders, etc. though.)Reopening the bug[Sylvia]***has been marked as a duplicate of this bug. ***Partially fixed (there's still no completion for PHP internal functions)Here's my solution to the problem:I just deleted the RemoteSystemsTempFiles project in the PHPExplorer View and than recreated it as a PHP Project (New->PHP Project, ofcourse it has to be named again RemoteSystemsTempFiles). This worked for me, now code completion is ok, hope this helps.Rightclick on the project then chooseConfigure > Add PHP Support...***has been marked as a duplicate of this bug. ***	11.0
id=249879	REOPENED	PDT	Debugger	1.0.4	PC Linux	P3 enhancement	Michael Spector	2008-10-06 18:17 EDT by	Udo Rader	2008-10-23 12:17 EDT (	0 users	Createdscreenshot showing the mapping in questionBuild ID: M20080221-1800Steps To Reproduce:I have the following configuration:some vhost definition:[...]DocumentRoot /some/where/over/the/rainbow/[...]eclipse workspace/home/udo/wa/fooproject location inside workspacebarProject/srcand finally a symlink from /home/udo/wa/foo/barProject/src to /some/where/over/the/rainbow/bar like below:% ls -l /some/where/over/the/rainbow/lrwxrwxrwx 1 udo prog 39 2008-09-24 21:05 bar -> /home/udo/wa/foo/barProject/src/Inside barProject/src there is on file named "test.php", so that a valid URL on the vhost would be:Now I have configured Xdebug to debug scripts on the vhost, with the following URL mapping (see also the attached screenshot):Server /bar => Workspace barProject/srcWhen I finally right click on test.php and choose "Debug As => PHP Web Page" a completely wrong URL is suggested, despite the mapping configuration:This is quite annoying if you have to debug many individual scripts (like I have).More information:	The Path Mapper does not map between URL and local resources. It maps from local file name to remote file name, which is not a part of URL.For example: /barProject/src is mapped to /var/www/bar, but /var/www/bar has nothing to do with URL.Hmm, so it is a pretty useless feature then? How would I use it in a reasonable way (I honestly can't think of a way do so)?There's a help page in PDT called "Path Mapping". Please read it.Thanks!(In reply to)well, I already RTFM :-)So I am reopening the case and changing the severity to "enhancement".It just would be nice to have an URL<->FS mapping feature.	4.0
id=251978	REOPENED	PDT	Code Assist	2.0.0	All All	P3 enhancement	Michael Spector	2008-10-24 05:15 EDT by	Anton Danilchenko	2010-08-01 09:21 EDT (	2 users	Ubuntu 8.10b + Eclipse3.4.1 + PDT I20081020Please, write next code:for ( $iPos=0; [type here name of you new variable $i, press Ctrl+Space] )Problem: variable no show in dropdown menu.P.S. In Ubuntu not show elementary functions (print, echo, strpos, fopen and other). In project settings I set as enable "PHP library". This library contain many functions, but in my code this functions not shows. Please, HELP!Thanks!	The problem is that for statement is not complete - we don't have it in AST nodes yet. May be we should add error recovery for this statement as well as we do it for functions/classes.for ($iPos=0; $i|) // <-- press ctrl+spaceActual: not show autocomplete. Show error message in parserExpected: show autocomplete and not show parser error on this stepFixed?closeFollowing Michael's comment ... As the for statement is not complete you do not get assist for the variable.If you complete the statement, i.e. for ($iPos=0; ;), then you can get CA for the variable in both second and third position in the for statement:for ($iPos=0; $i|; $i|)I will reopen it as an enhancement.[Sylvia Tancheva]	5.0
id=466178	REOPENED	Oomph	P2 Management	1.5.0	PC Windows NT	P3 normal	Eike Stepper	2015-05-02 04:33 EDT by	Abel Hegedus	2016-07-06 11:16 EDT (	1 user	Createdprofile does not exist exceptionIn some cases, clicking on Analyze in the Bundle Pool Management window of the Eclipse Installer will result in an empty Bundle Pool Analysis window. There is no feedback that an exception happened in the background which made the analysis unable to finish.Looking at the configuration/<timestamp>.log, the exception thrown can be seen though in some cases, even that does not help too much.I observed this behavior with the following exceptions:Root exception:org.eclipse.oomph.p2.P2Exception: Profile does not exist: <profile_id> at org.eclipse.oomph.p2.internal.core.ProfileImpl.getDelegate(ProfileImpl.java:198) at org.eclipse.oomph.p2.internal.core.ProfileImpl.getDelegate(ProfileImpl.java:186) at org.eclipse.oomph.p2.internal.core.ProfileImpl.getProperty(ProfileImpl.java:302) at org.eclipse.oomph.p2.internal.core.AgentAnalyzer$AnalyzedProfile.<init>(AgentAnalyzer.java:687) at org.eclipse.oomph.p2.internal.core.AgentAnalyzer$AnalyzedBundlePool.addProfile(AgentAnalyzer.java:433)It turned out that <profile_id> was duplicated (see [459019]) in .p2/profiles.info although only a single directory exists in .p2\org.eclipse.equinox.p2.engine\profileRegistry\After deleting the line with the wrong case from profiles.info, the following exception occurs on analysis:Root exception:java.lang.NullPointerException at org.eclipse.oomph.p2.internal.core.LazyProfile.snapshot(LazyProfile.java:271) at org.eclipse.equinox.internal.p2.engine.SimpleProfileRegistry.getProfile(SimpleProfileRegistry.java:182) at org.eclipse.oomph.p2.internal.core.ProfileImpl.getDelegate(ProfileImpl.java:195) at org.eclipse.oomph.p2.internal.core.ProfileImpl.getDelegate(ProfileImpl.java:186) at org.eclipse.oomph.p2.internal.core.ProfileImpl.getProperty(ProfileImpl.java:302) at org.eclipse.oomph.p2.internal.core.AgentAnalyzer$AnalyzedProfile.<init>(AgentAnalyzer.java:687) at org.eclipse.oomph.p2.internal.core.AgentAnalyzer$AnalyzedBundlePool.addProfile(AgentAnalyzer.java:433)The full traces are attached.	Creatednull pointer exception1. I have no idea how to find the offending entry/profile and get the analysis to work.2. I initially wanted to get into the analysis to see how many unused bundles I have and do some cleanup if necessary.Based onI think the only way to return null from getDelegate() is through the last line of getDelegate(boolean loadOnDemand).I'm going to make the analyzer more tolerant against invalid profiles. And add an ErrorDialog in case of dialog initialization problems.Fixed in master:Thanks for the fast response. The error dialog is helpful, but I still get the same exception as before and no information on which profile causes the error.Do you have any suggestions on rooting out the issue?In order to help find out the root cause of your problem I've changed the LazyProfile.getDelegate(boolean) to throw a P2Exception in case of problems. This way we can see the ID and directory of the offending profile. Can you please update and try again?Thanks a lot, Eike!The exception is now:Caused by: org.eclipse.oomph.p2.P2Exception: Profile '<profile_id>' could not be loaded from C:\Users\<user>\.p2\org.eclipse.equinox.p2.engine\profileRegistry\<profile_id>.profile at org.eclipse.oomph.p2.internal.core.LazyProfile.getDelegate(LazyProfile.java:73)The profile_id matches the remaining entry from the two that had different case. However, the case matches the name of the directory that it tries to load.Should I keep this reproducible or simply delete the offending profile?***has been marked as a duplicate of this bug. ***Moving all unresolved bugzillas to 1.2.0...Moving all unresolved bugzillas to 1.3.0...Moving all unresolved bugzillas to 1.4.0...Moving all unresolved bugs to version 1.5.0.	13.0
id=511406	REOPENED	Oomph	Utilities	unspecified	All All	P3 normal	Eike Stepper	2017-01-31 12:59 EST by	Carsten Reckord	2017-02-24 03:11 EST (	0 users	(This is a copy of, with the pertinent info from the discussion summarized)Oxygen currently ships with an incomplete org.apache.httpcomponents.httpclient 4.5.2 bundle that does not include the fluent API among others (see). This leads to the following NoClassDefFoundError in USS:java.lang.NoClassDefFoundError: org/apache/http/client/fluent/Executor at org.eclipse.userstorage.internal.Session.<init>(Session.java:72) at org.eclipse.userstorage.internal.StorageService.openSession(StorageService.java:407) at org.eclipse.userstorage.internal.StorageService.getSession(StorageService.java:399) at org.eclipse.userstorage.internal.StorageService.retrieveBlob(StorageService.java:272) at org.eclipse.userstorage.internal.Storage.retrieveBlob(Storage.java:369) at org.eclipse.userstorage.internal.Blob.getContents(Blob.java:108) at org.eclipse.userstorage.internal.Blob.getContentsUTF(Blob.java:129) (and likely in org.eclipse.oomph.setup.sync as well, since org.eclipse.oomph.setup.internal.sync.SyncUtil is using org.apache.http.client.fluent.Executor)While Oomph's setup.core feature ships with a (complete) HttpClient 4.3.2 version, the version constraints in the USS and Oomph bundle manifests still allow a binding to the broken 4.5.2 version. From:osgi> ss httpcomponents"Framework is launched."id State Bundle23 RESOLVED org.apache.httpcomponents.httpclient_4.5.2.v20161115-164324 RESOLVED org.apache.httpcomponents.httpcore_4.4.4.v20161115-1643246 RESOLVED org.apache.httpcomponents.httpclient_4.3.6.v201511171540247 RESOLVED org.apache.httpcomponents.httpcore_4.3.3.v201411290715The Marketplace Client installed the 4.3.x versions. The 4.5.2/4.4.4 versions were included with the Eclipse platform build. The bundle org.eclipse.userstorage_1.0.0 does the following Require-Bundle:org.apache.httpcomponents.httpclient;bundle-version="[4.0.0,5.0.0)"	New Gerrit change created:New Gerrit change created:These two changes restrict the HttpClient version range to the known good 4.3.x versions in Oomph and USS respectively.Of course those changes should be reverted in time for M6 onceis fixed in Orbit, so that Oomph and USS can work with the same HttpClient 4.5.2 used by Platform.Gerrit changewas merged to [master].Commit:Gerrit changewas merged to [master].Commit:New Gerrit change created:Gerrit changewas merged to [master].Commit:Given this was merged, I assume this is fixed.(In reply to Carsten Reckord from)I think we should leave it open as a reminder to revert the commit soon...When will the fixed version inbecome a version inso that builds will be able to pick up the fixed version and we can eliminate the hacks.	10.0
id=501158	REOPENED	TCF	Agent	1.4	PC Linux	P3 major	Project Inbox	2016-09-09 12:00 EDT by	xavier pouyollon	2016-10-03 11:44 EDT (	0 users	Hi Eugene,With vxWorks7 for ARM64, I have many crawl issue when the libc is used because it can not find an epilogue (200 instructions not enough, too complex code).What usually happens at top frame:Epilogue not found==> In trace_instructions, I reach Function Epilogue not found.It does "invalidate" all registers, especially r29.I did a small "hack": trace(LOG_STACK, "Stack crawl: Function epilogue not found"); for (i = 0; i < REG_DATA_SIZE; i++) { if (i != 29) reg_data[i].o = 0; }==> Way better !I know it's far from perfect. I'm even wondering how it can work correctly but the backtrace is deeper and fairly accurate (duplicate of printf but I reach the main function...)Any suggestions ? Probably the best would be to have the crawler to also analyze the prolog when the func_start can be determined.Thanks !	I'm not sure why the "hack" helps - it does not make much sense. It would help a lot if you could provide a test case for Linux.Hi Eugene,Yes, in that current state, I agree.However, I have something in progress - which has much sense - that gives way better backtraces with vxWorks 7. I'll send you a patch soon.Hi Eugene,Patch available here:With it, I get really good backtraces when vxWorks in build without debug infos. Without the patch, I had at most 2 levels. Now, I go back up to vxTaskEntry.I take advantage that standard code should construct linked frames.Thanks !The patch does not work when current PC is in prologue or epilogue. This results in broken step over and step out. Also, stepping needs CFA value. I re-worked the code to workaround these problems. It seems working pretty well now.Fixed.Thanks!Hi Eugene,With vxWorks 7 generated prolog, I saw no issue even in prolog and stepping was working !Yes, right ! I had stepping working. Luck probably ?I'll try with vxWorks. A quick test seems OK. I'll reopen the defect if I see a problem.Thanks !To see the problems, I had to disable instruction tracing by putting #if 0/#endif around the loop. Otherwise, "Stack crawl: Function epilogue not found" never happens, and everything works fine.BTW, there is at least one case where the new code makes the trace worse than before: leaf function with frame pointer optimized away.Hi Eugene,I was using vxWorks without debug infos and was entering "Stack crawl: Function epilogue not found" every time.Good to know.All I can say is that with the new code, the backtrace is way better with vxWorks 7 ! Accurate backtrace up to vxTaskEntry. Because vxWorks 7 compiler generates code that link the frames.Best Regards,Xavier.Hi Eugene,With my proposal, I had an accurate backtrace with vxWorks 7 when stopped at the prolog of fioFormatV.fioFormatVprintffunc_b()With your latest change, I have:fioFormatVfunc_b()printf is missing. Sorry, I've missed that when I tried your proposal (Probably was booting mu build...)Here is the prolog of fioFormatVffffffff801ba3b8: 0xa9ba6ffc stp x28, x27, [sp, #-96]!ffffffff801ba3bc: 0xa90167fa stp x26, x25, [sp, #16]ffffffff801ba3c0: 0xa9025ff8 stp x24, x23, [sp, #32]ffffffff801ba3c4: 0xa90357f6 stp x22, x21, [sp, #48]ffffffff801ba3c8: 0xa9044ff4 stp x20, x19, [sp, #64]ffffffff801ba3cc: 0xa9057bfd stp x29, x30, [sp, #80]ffffffff801ba3d0: 0x910143fd add x29, sp, #0x50ffffffff801ba3d4: 0xd10843ff sub sp, sp, #0x210ffffffff801ba3d8: 0x2a1f03e8 mov w8, wzrffffffff801ba3dc: 0xb9003fe8 str w8, [sp, #60]In my proposal, I was always taking advantage of standard code should construct linked frames when epilog not foundI see you don't do that for the prolog. Probably your compiler generates something different for you...Do you see a fix that could work for both of us ?Thanks !Xavier.Hello again,Sorry, I was wrong.For the backtrace stopped at the first instruction of fioFormatV, my proposal works only because we enter this part :{ ..../* Retrieve chained fp and return address. * See page 16 & 30 of the following document: **/ } cpsr_data.o = 0; if (org_sp.v != 0 && org_lr.v != 0 && org_pc.v != org_lr.v) { reg_data[31] = org_sp; pc_data = org_lr; }So the issue might be around this in the new patch if (pc_data.o == 0 && org_regs[REG_ID_SP].v != 0 && org_regs[REG_ID_LR].v != 0 && org_pc.v != org_regs[REG_ID_LR].v) { pc_data = org_regs[REG_ID_LR]; }Best Regards,Xavier.Hi again (again :-))what about adding a small loop around the code you've added to detect the prolog / epilogue instructions ? Not great but I don't see a better approach...Best Regards,Xavier.You are looking in the wrong direction. "Stack crawl: Function epilogue not found" means instruction tracing failed, and *that* need to be fixed.Assuming presence of frame link is wrong. According to ABI, the link is optional, so using it as main method of stack tracing is really bad idea. It can be used as a last resort, when everything else failed, but even that is arguable.I cannot do much without a test case. If you are serious about fixing stack crawl, I suggest you to get a cheap ARM 64 Linux machine ans use it for testing. For example, this one:Hi Eugene,I totally agree. Especially in my case where I'm stopped at the first instruction of fioFormatV. When stopped at prolog, we should use LR as return @, not the linked frames which are not constucted yet.Currently, this stack issue is seen here as low priority but I'd like to get it fixed anyway.So far, the best I can give you is the fioFormatV prolog. All generated vxWorks7 ARM64 look pretty similar. If we could the get prolog analysis fixed, that would be great.Best Regards,Xavier.	12.0
id=380607	REOPENED	TCF	Debug	1.0	PC Linux	P3 normal	Project Inbox	2012-05-25 00:24 EDT by	Pawel Piech	2014-02-25 06:04 EST (	1 user	I've been getting an intermittent test failure reports in this test. I cannot reproduce it on my system so there's likely a race condition which is causing the test to mis-behave.	CreatedPath with more diagnostic output.This patch adds a printout of the state of the debug view upon failure so it should help figure out why it craps out.I think you have attached a wrong patch - it is for org.eclipse.debug.uiCreatedCorrect patch..Sorry about that, here's the correct one.Committed.Thanks!CreatedFix attempt at failing test.The failing test output (below), shows that the routine that waits for a step to complete didn't wait properly and compared the thread label prematurely. I believe that the routine which launches the process is responsible and needs an additional check to make sure that the debug view finished updating before starting to step the process. The attached patch should take care of that.Debug view dump: :org.eclipse.debug.internal.core.LaunchManager@247aa859 test (TCF Agent) /home/jenkins/workspace/TCF and TE - Debug Tests/tests/plugins/org.eclipse.tcf.debug.test/data/agent/linux/x86_64/agent P31017.31017 (Breakpoint: Trace/breakpoint trap) 0x000000000041e0c0 [agent] tcf_test_func0(): tcf/main/test.c, line 166 0x000000000041e11c [agent] test_proc(): tcf/main/test.c, line 189 0x0000000000404747 [agent] main(): tcf/main/main.c, line 206 0x00007fb9658dd76d [libc-2.15.so] __libc_start_main() 0x0000000000404409 [agent]Eugene, please apply the fix. We'll see after a few builds if it takes care of the intermittent test failure. Thanks!CreatedCorrect fix attempt patch.(wrong one again)I have committedThanks!Looks like my last attempt didn't solve the problem, the test sill fails intermittently :-(CreatedAnother fix attempt.I've adjusted the previous fix and added a couple of infastructure tests as well. I've also noticed an additional intermittent failure and adjusted the formatting of the stack frame label to try to address it. This patch depends on patch inThis bug has been REOPENED since 2012, but looking at the comments the issue might actually be fixed.I would like to mark this FIXED, any concerns ?	11.0
id=506266	REOPENED	TCF	Agent	1.4	PC Linux	P3 normal	Project Inbox	2016-10-20 05:57 EDT by	christophe cleraux	2017-01-18 12:13 EST (	2 users	CreatedElf file exhibiting the problem.This happens when trying to display a variable on a VxWorks agent, but I guess it can happen all the time.Using the following C++ code:---8<---class CBase{public: CBase() { m_nIndex = 5; } virtual int SetValue(int); static const CBase zero; int m_nIndex;};int CBase::SetValue(int){ return 0;}const CBase CBase::zero;int main(int argc, char **argv){ CBase* pBase = new CBase; return 0;}---8<---build and debug the generated RTP. if you open the variable view, or add pBase to the expression view, the connection will drop.Looking at the logs one can see that a kind of recursion happen when trying to get pBase definition.I guess the debugger enter an infinite loop when trying to dig into the "kind of" recursive class definition.I guess the static definition of the inner class is not well taken into account by the debugger.Maybe the AT_containing_type tag is not correctly handled here?	Hello Eugene,Please find attached the Linux version of it so you can replicate it with the open-source agent.What happens for me: - I start the agent with -L- option.In the debug view, I put pBase in the expression and see from the agent:TCF 15:43:51.028: Peer TCP:127.0.0.1:49599: Command: C 4393 Expressions create ...TCF 15:43:51.044: Peer TCP:127.0.0.1:49599: Command: C 4394 Expressions evaluate ...TCF 15:43:51.060: context: read memory ctx 0x1d79c40, id P20940.20940, address 0x6010a0, size 16TCF 15:43:51.063: Peer TCP:127.0.0.1:49599: Command: C 4395 Expressions create ...TCF 15:43:51.079: Peer TCP:127.0.0.1:49599: Command: C 4396 Expressions evaluate ...TCF 15:43:51.095: context: read memory ctx 0x1d79c40, id P20940.20940, address 0x6010a0, size 16TCF 15:43:51.098: Peer TCP:127.0.0.1:49599: Command: C 4397 Expressions create ...TCF 15:43:51.113: Peer TCP:127.0.0.1:49599: Command: C 4398 Expressions evaluate ...TCF 15:43:51.130: context: read memory ctx 0x1d79c40, id P20940.20940, address 0x6010a0, size 16TCF 15:43:51.133: Peer TCP:127.0.0.1:49599: Command: C 4399 Expressions create ...TCF 15:43:51.151: Peer TCP:127.0.0.1:49599: Command: C 4400 Expressions evaluate ...TCF 15:43:51.166: context: read memory ctx 0x1d79c40, id P20940.20940, address 0x6010a0, size 16TCF 15:43:51.169: Peer TCP:127.0.0.1:49599: Command: C 4401 Expressions create ...TCF 15:43:51.186: Peer TCP:127.0.0.1:49599: Command: C 4402 Expressions evaluate ...TCF 15:43:51.201: context: read memory ctx 0x1d79c40, id P20940.20940, address 0x6010a0, size 16TCF 15:43:51.203: Peer TCP:127.0.0.1:49599: Command: C 4403 Expressions create ...TCF 15:43:51.220: Peer TCP:127.0.0.1:49599: Command: C 4404 Expressions evaluate ...TCF 15:43:51.235: context: read memory ctx 0x1d79c40, id P20940.20940, address 0x6010a0, size 16TCF 15:43:51.238: Peer TCP:127.0.0.1:49599: Command: C 4405 Expressions create ...TCF 15:43:51.255: Peer TCP:127.0.0.1:49599: Command: C 4406 Expressions evaluate ...TCF 15:43:51.271: context: read memory ctx 0x1d79c40, id P20940.20940, address 0x6010a0, size 16And the IDE crashes with a StackOverFlow error !The error log shows this:java.lang.StackOverflowError at java.util.HashMap.hash(HashMap.java:338) at java.util.HashMap.put(HashMap.java:611) at org.eclipse.tcf.internal.debug.ui.model.TCFModel.addNode(TCFModel.java:1278) at org.eclipse.tcf.internal.debug.ui.model.TCFNode.<init>(TCFNode.java:93) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.<init>(TCFNodeExpression.java:104) at org.eclipse.tcf.internal.debug.ui.model.TCFChildrenSubExpressions.getField(TCFChildrenSubExpressions.java:92) at org.eclipse.tcf.internal.debug.ui.model.TCFChildrenSubExpressions.findFields(TCFChildrenSubExpressions.java:119) at org.eclipse.tcf.internal.debug.ui.model.TCFChildrenSubExpressions.startDataRetrieval(TCFChildrenSubExpressions.java:342) at org.eclipse.tcf.util.TCFDataCache.validate(TCFDataCache.java:201) at org.eclipse.tcf.util.TCFDataCache.validate(TCFDataCache.java:220) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1615) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631).......... at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806).....org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendValueText(TCFNodeExpression.java:1806) at org.eclipse.tcf.internal.debug.ui.model.TCFNodeExpression.appendCompositeValueText(TCFNodeExpression.java:1631) at <repeat>Thanks !Xavier.CreatedLinux processCreatedLinux sourceYes, infinite recursion...Fixed.Thanks!Works great now, many thanks !It can be reproduced by expanding the variable pBase 10+ times.CreatedReproduce the problem by expanding pBase 10+ timesThe bug is actually still there, but one has to expand the variable multiple times(In reply to Boshuai FU from)I cannot reproduce. It works fine for me. Also, you screenshot suggests you are not running the latest version of the software.(In reply to Eugene Tarassov from)I checked the fix of commit 6f1f84282096b928e916b724a5dcb88c20c3ae84 for, it has been merged to our environment. And it has different result:1 The original problem can be triggered when just trying to display a variable, no need to expand it;2 The problem current: Need to expend the variable 10+ times to trigger the bug.Thanks(In reply to Eugene Tarassov from)Hello Tarassov,I have produce the bug by expending the variable 10+ times, and check the fix code which have merged into my tools. Could you help check it again? Thanks a lot.CreatedExpanding pBase 20 timesI cannot reproduce. Attached is screenshot of pBase expanded 20 time - works fine. I even tried to expand it several hundred times - still works fine.	12.0
id=502218	REOPENED	TCF	Target	1.5	All All	P3 normal	Project Inbox	2016-09-26 23:09 EDT by	Aijun Shi	2016-09-28 03:56 EDT (	1 user	AssertionFailedException when ProcessLauncher dispose.org.eclipse.core.runtime.AssertionFailedException: assertion failed: Must not dispose during launch at org.eclipse.core.runtime.Assert.isTrue(Assert.java:110) at org.eclipse.tcf.te.tcf.processes.core.launcher.ProcessLauncher.dispose(ProcessLauncher.java:142) at com.windriver.te.tcf.core.vxw.steps.DisposeProcessRootNodesStep$1.run(DisposeProcessRootNodesStep.java:63) at org.eclipse.tcf.protocol.Protocol$3.run(Protocol.java:219) at org.eclipse.tcf.EventQueue.run(EventQueue.java:95) at java.lang.Thread.run(Thread.java:745)	Aijun,you are not allowed to call process launchers dispose method before the launcher completed the launch of the process you have asked for. This does not look like an open source issue as you call ProcessLauncher.dispose() explicitly from your code. If you can reproduce with pure open source, please feel free to reopen the bugzilla.Uwe,Martin.O found a defect.When launch a program hang, TCF cannot dispose it.It's not easy to reproduce by pure open source.However, the obvious error is that we should not ship Assert statements with soft release.New Gerrit change created:The asserts are there for a reason because they shall tell you when use an API wrong. It is not an acceptable fix to remove asserts anywhere in the code. You need to dig deeper and find the reason why you call dispose before ProcessLauncher.launch(...) complete (either successful or with error).If I get you right, than you say that on launching a process on the remote, the TCF agent never respond for whatever reason, in example because the program to launch hangs. Did you tried to cancel the process launch on TCF protocol level in such case? For me, it sounds more like you need to have a way to cancel the process launch TCF command. Just disposing the client side launcher won't reset the TCF agent into a clean state.(In reply to Uwe Stieber from)Hi Uwe,Thanks your suggestion.I try it again.We did call ProcesLauncher.cancel() before ProcesLauncher.dispose(), but dispose() assert out cause from callback is not done.I think cancel() should mark callback done and set status.Cancel by ::::::::::::::callback.done(this, Status.CANCEL_STATUS);::::::::::::::Do you agree this modification?Hi Aijun,>I like this modification much better. I thinks thats the right way to go. Please go ahead and test the change in you environment. If it works, please push the change to gerrit and add me as reviewer.New Gerrit change created:New Gerrit change created:(In reply to Uwe Stieber from)It works in my ENV. Thanks Uwe.New Gerrit change created:New Gerrit change created:Gerrit changewas merged to [master].Commit:	13.0
id=319360	REOPENED	Buckminster	Core	unspecified	All All	P3 enhancement	Thomas Hallgren	2010-07-09 06:04 EDT by	Markus Kuppe	2010-08-03 06:17 EDT (	2 users	For testing purposes it is sometimes required to spawn a host and a consumer in parallel. This should be supported by Bucky by e.g. taking a comma separated listed of .launch files as an argument the launch command.	Thinking about it, the host&consumer example might require something more sophisticated/different in that the host process can be seen as a support process for the consumer and thus be taken down once the consumer terminates.Looking at the current implementation org.eclipse.buckminster.core.commands.Launch.internalRun(IProgressMonitor), this might even be implemented more easily as in this scenario a single process return value is acceptable contrary to the case where two (or more) generic launch configs are executed concurrently.As an alternate implementation strategy, the Job FW might be of interested as it comes with support for rules which in turn might help model support processes.CreatedA new command "bglaunch" which spawns .launch in the backgroundTerminates the spawned process on System.exitOne can see the command in action e.g. as part of the ECF build [0]. [1] shows the use case for "--ignoremissing".[0][1]CreatedSame functionality as the background bundle, but written as a new command in buckminster.coreCreatedmylyn/context/zipComment onSame functionality as the background bundle, but written as a new command in buckminster.corePatch applied to helios-maintenance, rev 11513.Thanks!-I have some comments and questions regarding the new command:* The BackgroundLaunch command declares its own "-l" argument, but it also calls super.getOptionDescriptors(), so it inherits the "-l" argument from the Launch command. This is redundant.* In calling super.getOptionDescriptors(), it also inherits the --stdout and --stderr arguments, but it ignores them if they are given. So it is effectively not possible to redirect stdout/stderr for processes launched in the background.* It replicates some of the logic already found in the Launch command. Adding support for stdout/stderr capture will replicate even more code.Why did you choose to implement a separate command instead of adding a new flag (--background) to the regular Launch command? We can also add the --ignoremissing flag. Since we haven't officially relased the BackgroundLaunch command, I think there's still a chance to merge it into the regular Launch command. What do you think?I think that sounds like a worth while improvement. Markus, what do you think?(In reply to)Definitely an inconsistency.We (ECF) don't need stdout/stderr functionality for a background launch. Do you guys think it's worth keeping?I suggest we create a common abstract parent class like AbstractLaunchCommand instead and have both LaunchCommand as well as BackgroundLaunchCommand inherit from it.Separating background launch and launch buys us the freedom to add parameters that might not make sense for the other one. E.g. what does something like a "keeprunning" flag mean for the regular launch. Additionally it keeps the implementation free from to much control flow.Btw. IMO "--ignoremissing" should be made available for both bglaunch as well as launch.If this finds approval by you, I'd be willing to write a new patch.IMO, launching a process in the background is not so much different from regular launching. In UNIX terms, it's just about adding the "&" at the end. Everything else, e.g. stdout/stderr redirection is the same in both cases.As I see it, the only difference code-wise is that the foreground version waits for the processes to finish. If something goes wrong, the launched processes must be terminated before returning from the Launch command. The background version performs process termination in the VM shutdown hook.Thomas, which version do you prefer?In either case, a new patch is highly appreciated! I'll reopen the issue to reflect the ongoing work.(In reply to)I'm in favor of one single launch command with a --background option since that seems to cover all needs. It's easier to document and easier to understand.CreatedAbstractLaunch patch(In reply to)But how do you address conflicting/inconsistent parameters between background and regular launch, e.g. "keeprunning"?Patch that adds: - a common superclass AbstractLaunch- "keeprunning" flag to BackgroundLaunch (untested)(In reply to)Add some code to the already existing consistency check at the beginning of internalPerform, i.e.if (launchName == null && !ignoreMissing) throw new UsageException(Messages.Launch_No_launch_config);if(keeprunning && !background) throw new UsageException(Messages.Launch_keeprunning_only_for_background);(In reply to)And once more parameters get added to launch the list of conditions will become longer and longer. Not to mention different permutations that might be acceptable.Anyway, you have a much better perspective WRT maintainability, thus I will rewrite my patch to use a single Launch class (tomorrow).Createdmerges BackgroundLaunch and LaunchPatch does not implement "keeprunning". Need to define the streamlistener behavior first when the background process continues running after the host process terminates.	17.0
id=491074	REOPENED	Thym	iOS	2.0.0	PC Mac OS X	P3 enhancement	Project Inbox	2016-04-05 07:39 EDT by	Pavol Srna	2016-06-27 09:58 EDT (	3 users	Createdscreenshot.png	This is the expected behavior with 2.0.0. We will have an up-to-date copy of the platforms as they are created by Cordova CLI.Gorkem,I would stick with how osx handles this. e.g. In finder it is kind of a 'package/file', you can double click on it and it opens in xcode. You can right click and 'Show Package Contents'.I would at least expect that I can open xcodeproj in xcode from eclipse.I understand that it is not a bug in a real sense. But how could we improve eclipse.thym UX? Contributing to a 'open with' action or similar? Would it make sense?Aha, I see. We can probably implement a filter for it. we also havefor the actions.(In reply to Gorkem Ercan from)IMO, if the action is there; then it's fine to leave this folder visible. If we really think it's worth making the folder look different, then an icon decorator could be enough.I would lean towards an icon decorator, but I don't have a really strong opinion about that.	6.0
id=209748	REOPENED	Target Management	Terminal	2.0.1	PC All	P3 normal	dsdp.tm.core-inbox	2007-11-14 00:11 EST by	Michael Scharf	2011-04-04 04:35 EDT (	1 user	currently the selection is shown in blue even if the terminal canvas does not have the selection	Michael do you know what needs to be done here, and could you do it any time soon?I marked it as WONTFIX: On windows neither the text editor not the standard console do change color of the selection of the widget does not have the focus.So, the terminal has the standard behavior...Hmm, after reading, it might make sense to keep it open. But I changed the platform form Windows XP to All....Clearing target milestone and assignee since it looks like this depends on.	4.0
id=130089	REOPENED	CDT	cdt-core	3.0.2	PC Linux-GTK	P3 normal	Thomas Fletcher	2006-03-02 04:10 EST by	Jaak Simm	2009-02-23 13:12 EST (	10 users	Everything works fine, except for closing c/c++ editor windows. When I close c/c++ editor window it waits 3-4 seconds before the closing is completed. During that time all GUI components are locked.That only happens when closing c/c++ editor windows (both, .c, .cpp and .h files are slow). Java and text editors close instantly, even if they are used to display .c/.h/.cpp files. Also opening c/c++ files has no such delay.When closing all windows simultaneously (using close all) it takes proportionally more time, meaning 3-4 seconds per c/c++ editor.I have used CDT also on other computers running linux, with slightly different Java/eclipse/cdt versions, but haven't encountered such bug before.My current versions:Sun Java - 1.5.0_06-b05Eclipse - 3.1.2CDT - 3.0.2	One more thing I forgot.Namely, eclipse is not using much cpu or mem when closing (eclipse's cpu use stays below 10%), thus the delay cannot be a pure resource issue.***has been marked as a duplicate of this bug. ***I noticed the same slowdown from the version 3.0.1 (Eclipse 3.1.1) to the version 3.0.2 (Eclipse 3.1.2).Users complain about the fact that closing (even saving) in C/C++ is damnslow with Eclipse, they are asking me the possibility of going back to the previous versions.Have you seen this problem with the current HEAD cdt builds? Arethese projects specifically configured or does it happen even if youhave a .c/.h/.cpp file in a simple project that you are opening/closing.If these are C/C++ projects, what does the configuration look like?I'll take a look with 3.1, but I don't see the same problem here.The problem also occurs if the .c/.h file is in a simple project. It occurs independent of what perspective is used, java or c/c++.Havent tried HEAD cdt builds yet.I saw this problem in both Managed Make and no Managed Make C++ project.We are using Linux, Eclipse 3.1.2 and CDT 3.0.2 .I'll try in 2 weeks (I'm away from office) with the CDT Head.try having some number of editors opened and use the "Close All" menu item... it takes forever! this causes a very bad user experience.We grabbed the SDK-N20060412-0010-linux, cdt3.0.2-RC1 nightly and the sdk same. The problem still exists. It seems like it's doing work in the gui thread instead of just closing the window and handing off the close up work.(In reply to)FYI, I'm observing this on Windows XP, with Eclipse SDK Version: 3.1.2 Build id: M20060118-1600CDT 3.0.2java.runtime.name=Java(TM) 2 Runtime Environment, Standard Editionjava.runtime.version=1.5.0_06-b05I'll take this one for a ride and see if we can get'er done for releaseSome basic tracing points the the following stack trace as a starting pointfor investigation (boy is there ever a deep tree of disposal!), culminatingwith the TextViewer class doing a setDocument(null) that takes some time. Time to dig into that now ...TextViewer$1.widgetDisposed(DisposeEvent) line: 1452TypedListener.handleEvent(Event) line: 101EventTable.sendEvent(Event) line: 66StyledText(Widget).sendEvent(Event) line: 925StyledText(Widget).sendEvent(int, Event, boolean) line: 949StyledText(Widget).sendEvent(int, Event) line: 934StyledText(Widget).notifyListeners(int, Event) line: 706StyledText.handleDispose(Event) line: 4936StyledText$7.handleEvent(Event) line: 4803EventTable.sendEvent(Event) line: 66StyledText(Widget).sendEvent(Event) line: 925StyledText(Widget).sendEvent(int, Event, boolean) line: 949StyledText(Widget).sendEvent(int) line: 930StyledText(Widget).release(boolean) line: 740Canvas(Composite).releaseChildren(boolean) line: 636Canvas.releaseChildren(boolean) line: 117Canvas(Widget).release(boolean) line: 743Composite.releaseChildren(boolean) line: 636Composite(Widget).release(boolean) line: 743Composite.releaseChildren(boolean) line: 636Composite(Widget).release(boolean) line: 743Composite.releaseChildren(boolean) line: 636Composite(Widget).release(boolean) line: 743Composite.releaseChildren(boolean) line: 636Composite(Widget).release(boolean) line: 743Composite(Widget).dispose() line: 412EditorPane(PartPane).dispose() line: 167EditorReference(WorkbenchPartReference).dispose() line: 639WorkbenchPage.disposePart(WorkbenchPartReference) line: 1497WorkbenchPage.handleDeferredEvents() line: 1308WorkbenchPage.deferUpdates(boolean) line: 1292WorkbenchPage.closeEditors(IEditorReference[], boolean) line: 1262WorkbenchPage.closeEditor(IEditorReference, boolean) line: 1321EditorPane.doHide() line: 54EditorStack(PartStack).close(IPresentablePart) line: 498EditorStack.close(IPresentablePart[]) line: 205PartStack$1.close(IPresentablePart[]) line: 105TabbedStackPresentation$1.handleEvent(TabFolderEvent) line: 81DefaultTabFolder(AbstractTabFolder).fireEvent(TabFolderEvent) line: 267DefaultTabFolder(AbstractTabFolder).fireEvent(int, AbstractTabItem) line: 276DefaultTabFolder.access$1(DefaultTabFolder, int, AbstractTabItem) line: 1DefaultTabFolder$1.closeButtonPressed(CTabItem) line: 67PaneFolder.notifyCloseListeners(CTabItem) line: 580PaneFolder$3.close(CTabFolderEvent) line: 187CTabFolder.onMouse(Event) line: 2107CTabFolder$1.handleEvent(Event) line: 292EventTable.sendEvent(Event) line: 66CTabFolder(Widget).sendEvent(Event) line: 925Display.runDeferredEvents() line: 3346Display.readAndDispatch() line: 2966Workbench.runEventLoop(Window$IExceptionHandler, Display) line: 1914Workbench.runUI() line: 1878Workbench.createAndRunWorkbench(Display, WorkbenchAdvisor) line: 419PlatformUI.createAndRunWorkbench(Display, WorkbenchAdvisor) line: 143IDEApplication.run(Object) line: 95PlatformActivator$1.run(Object) line: 78EclipseAppLauncher.runApplication(Object) line: 92EclipseAppLauncher.start(Object) line: 68EclipseStarter.run(Object) line: 376EclipseStarter.run(String[], Runnable) line: 169NativeMethodAccessorImpl.invoke0(Method, Object, Object[]) line: not available [native method]NativeMethodAccessorImpl.invoke(Object, Object[]) line: not availableDelegatingMethodAccessorImpl.invoke(Object, Object[]) line: not availableMethod.invoke(Object, Object...) line: not availableMain.invokeFramework(String[], URL[]) line: 336Main.basicRun(String[]) line: 280Main.run(String[]) line: 977Main.main(String[]) line: 952Looks like this is down to a reconciler problem. When the document is cleared,one of the listeners on the document change is the reconciler.AbstractReconciler$Listener.inputDocumentAboutToBeChanged(IDocument, IDocument) line: 272CSourceViewer(TextViewer).fireInputDocumentAboutToBeChanged(IDocument, IDocument) line: 2411CSourceViewer(TextViewer).setDocument(IDocument) line: 2466CSourceViewer(SourceViewer).setDocument(IDocument, IAnnotationModel, int, int) line: 521CSourceViewer(ProjectionViewer).setDocument(IDocument, IAnnotationModel, int, int) line: 370CSourceViewer(SourceViewer).setDocument(IDocument) line: 453This call in the listener does the following (from AbstractReconciler):public void inputDocumentAboutToBeChanged(IDocument oldInput, IDocument newInput) { if (oldInput == fDocument) { if (fDocument != null) fDocument.removeDocumentListener(this); if (fIsIncrementalReconciler) { synchronized (fDirtyRegionQueue) { fDirtyRegionQueue.purgeQueue(); } if (fDocument != null && fDocument.getLength() > 0) { DocumentEvent e= new DocumentEvent(fDocument, 0, fDocument.getLength(), null); createDirtyRegion(e); fThread.reset(); fThread.suspendCallerWhileDirty(); } } fDocument= null; } }The suspendCallerWhileDirty() after the reset is where things get hung up.The C/C++ implementation of this is in the CReconcilerA couple of options working within the framework:-1 Don't have an incremental reconciler (bypasses this call)-2 Make the reconciler faster in all cases -3 Put some additional logic in to handle the special case for terminationLooking at trialing a few options right now.Small changes make a significant improvement but with different tradeoffs:1- If we make the reconciler non-incremental, then this problem goes away nearentirely and you get near instant document closes. The downside of this isthat the reconciler activities become more heavy weight such that if youare making tons of changes to non-code sections (ie comments) then the reconciler will run vs today where it would not.2- If we adjust the delay time of the reconciler thread to 0 then the reconciler thread should only run "on demand". Using this setting seems to be full of peril and gets us into bad race conditions where we wait foreveron the queue ... looks like a hole in the API design since you have to wait's in a row on start-up. Not a good suggestion.3- Adjust the delay time down from 1s to something more reasonable, like thedefault of 500ms. This only marginally improves the situation (from practicalobservation) since we are still waiting for the reconciler thread to wake upand service the request.4- Use some sort of reflection to get access to the private member variable(short term) to be able to signal the queue ourselves rather than wait forthe thread to wake up.For now, I'm going to suggest that we don't use an incremental reconcilerand that we reduce the delay to the 500ms. I don't know that the practical savings are by a longer time and the scanning of the text doesn't save usmuch in the real world cases where people are actually editing code.Much better than having frustrated users.Thomas,I don't know anything about the implementation, but in the last comment you seem to have ignored the "Put some additional logic in to handle the special case for termination" possible solution that you mentioned in your previous comment.If there is really nothing to reconcile because the editor is being closed (and again I may be saying a bestiality here, given that I'm not quite sure what the reconcilier is supposed to do), having special logic seems reasonable...I'd like to stress the fact that the problem is extremely evident when more than one editor is closed in one shot. Note that htis happens not only when you use "Close All", but also when you quit Eclipse. If the 500ms are per-editor, given that having 20 editors open is not uncommon in mid-sized projects, that results in more than 10 seconds....The code for detecting that there are no changes to process is alreadyin the reconciler (stragegy) code itself. The problem is that the listenerwho is asynchronously signalling the reconciler that the editor is doesn'tcare about the state of the change, just that a change has occured. Whatis killing us right now is the synchronization time between the signallinglistener and the reconciler thread, not the work of reconciling (which earlyouts because of a "no change" situation).It would be straightforward to change this ... but this code is coming fromthe eclipse.org side of things which means that since others deal with thisproblem without circumventing API, it is a constraint we should be able to deal with as well.Patch submitted to dinglis to make the reconciler non-incremental and reduce the timeone while we further investigate a platform driven solutionfor CDT 4.0My bad .. patch committed myself. Leaving PR open for CDT 4.0CreatedUse MonoReconcilerI noticed that the reconciler does not reconcile at all now.In the course of debugging this, I found that the CReconciler is actually trying to mimic the behaviour of the MonoReconciler (ie. it uses a single reconciling strategy), therefore I would like to propose this patch to use a plain MonoReconciler instead of the CReconicler. This seems more appropriate and makes the reconciler work again. It also avoids the workaround for.Looks good to me, I was going to leave changing the reconciler to the MonoReconciler for CDT 4.0, but I'm happy to roll with this. We canthen delete the CReconciler class as well.Patch committed as provided and the old CReconciler removed.One less piece of code in the CDT!***has been marked as a duplicate of this bug. ***Yes, it looks like to improve performance we need to register our ownresource listeners and run the reconciler as soon as the content changes.This is what the Java editors do to maintain a consistant state.Any estimate on when a build will be available with the patch? Or perhaps some instructions on how to build it?This should be in the nightlies now. The PR isn't closed because thereis some further tuning to be done that won't be done in time for 3.1.I am not sure to perfectly grasp the history of this bug:I upgraded to CDT 3.1 yesterday and still need wait for 2 seconds when closing a c++ source file. I understood that there were some further changes to do after CDT 3.1 to get completely rid of this bug but I wonder if it is normal not to see any improvement in CDT 3.1 regarding the previous release.(In reply to)There is still a performance degredation if the file has been modifiedin that we have to reconcile with the working copy before closing. Thisis on the TODO list for 4.0 to push it all into a background task thatruns regularly (ala JDT).Thank you for your immediate reply, that's really nice.In the tests I made yesterday, I tried to close a file without modifying it. And it was pretty slow, too.Anyway, Eclipse/CDT is a wonderful tool. Keep on that way and thank you all for your work.LATER/REMIND are deprecated. Changing to reopened milestone '--'	28.0
id=286863	REOPENED	Target Management	RSE	3.1	PC Windows Vista	P3 normal	dsdp.tm.rse-inbox	2009-08-17 15:53 EDT by	CDE Administration	2010-05-26 15:21 EDT (	4 users	<response_by> Carolina Wada at 2009.08.17.14.34.50 </response_by>Hi,The description truncated.Could you please check ?Steps to reproduce the problem:Under the Remote Systems tab click the white arrow on the right to display the menuClick on New ConnectionClick Linux then click NextEnter TestConnection2 next to Connection nameClick NextCheck the box next to ssh.filesCheck the box next to dstore.files and click NextCheck the box next to processes.shell.linux	Created14000200_PTB.jpg<cde:tctdetail>Testcase: 14.000.200Project: WSW35Component: Xfer - Target Management/RSEPriority: 2Subject: TVT pt_BR: Truncation in Description of Shell Process ServiceArticle ID: 629Originator:</cde:tctdetail>Does resizing the window help at all?<response_by> Carolina Wada at 2009.08.20.07.17.46 </response_by>Hi,The text looks like cutted but the window didn't look small ...Can be a problem with the text ?Please let me know if you have any concern.Best regards,Carolina WadaI don't have time to look at this now so I'll defer to 3.2.<response_by> Matthew McClintock at 2009.08.20.13.44.17 </response_by>The string in question appears to be displayed correctly. This string can be found in the following PII file:eclipse/plugins/org.eclipse.rse.subsystems.processes.shell.linux/org/eclipse/rse/internal/subsystems/processes/shell/linux/LinuxShellProcessResources.propertiesLinuxRemoteProcessService_description= listing processes on the remote target through a contributed shell serviceThe pt_BR translation for this sting is "processos de listagem no destino remoto atrav?s de um servi?o de shell contribu?do".It appears that this translation is displayed correctly in the screenshot that you posted. If you feel that the translation is incomplete, please translate and return the PII file.Thank you,Matthew McClintock<response_by> Carolina Wada at 2009.08.28.11.58.08 </response_by>Hi,I check the source and the translation and it's ok.I clicked in Shell Process Service instead of process.shell.linuxBest regards,Carolina Wada[Added by CDE: Completed by the CDE Bridge]Reopen to continue the investigation in 3.2.	9.0
id=246845	REOPENED	Target Management	RSE	3.0	All All	P3 normal	dsdp.tm.rse-inbox	2008-09-10 07:09 EDT by	Lavir the Whiolet	2012-11-19 04:56 EST (	1 user	I use DStoreConnectorService to transfer data to my server. It does not have "getPassword()" method (or something similar to it).	I'd think that this is by design, since we don't want to expose the password to the outside that easily.Dave would you want to mark this as WONTFIX?(In reply to)Yes, not returning the password is by design.Martin -- that is correct.Please tell what concrete reasons to hide password getting as implementation details?Please correct me if I am wrong:AuthenticatingService (and DStoreConnectorService in particular) fully handles credentials. It ensures that its user's miner will be launched with correct credentials, but how it does that is its internal problem. It may use client machine's operating system's means, it may pop up the credentials dialog, it may not use authentication at all - it's its internal problem. The connector service's user is not required even to know anything about credentials.Its protected contract is intended to be far more flexible. It says: "if you want to create your own connector service you can take me as a base and change any aspect you want. Please be advised that I internally use credentials provider so if you are going to authenticate to your server in a way other than mine then you can use this and even override its getting".So if one needs very login and password from the connector service then he just creates its own connector service and furnishes required methods for it. Am I right?I have found a solution:ICredentialsProvider credentialsProvider; { Method m = AuthenticatingConnectorService.class.getDeclaredMethod("getCredentialsProvider", new Class[0]); m.setAccessible(true); credentialsProvider = (ICredentialsProvider) m.invoke(connService, new Object[0]);}ICredentials credentials = credentialsProvider.getCredentials();socket.writeString(credentials.getUserId());socket.writeString(credentials.getPassword());Please verify it.When I first saw this "solution", I wasn't sure whether I should laugh or cry (that's why I didn't respond for a long time). I admit that I wrote very similar code in my young and wild days, when some library that I had to use had some interesting information in a protected or private field.But clearly this is not intended use of the API, and clearly we won't ever make such API so "WONTFIX" is the more correct solution. What made me laugh was the request to "verify" the "fix". Clearly it works if you just make a method accessible that does what you want but wouldn't normally be accessible. As a provider and maintainer who made the method not accessible on purpose, I'm not going to verify this however. That's somehow similar like asking a jeweller to verify that I just successfully drilled a hole into his treasure safe, and claim that this is a valid way of getting its contents :-)I was pondering filing a bug that our credentials are not safe since you just got them without authentication, but then Java as a Platform is not safe unless a SecurityManager is active and there is work ongoing in OSGi/Equinox to support Eclipse running in safe mode. If we were running in safe mode, your code would not work because then you cannot setAccessible(true) via reflection.So I'm just closing this WONTFIX again.I'm tired to hint, I would say openly.I haven't seen any concrete reasons why this should be left untouched but I suspect there is an explicit misunderstanding of "protected", "private" and other modifiers' meaning. I feel it the duty to remind that "protected" modifier means not "protected from hackers' attacks" (and this is widespread mistake) but "protected from misusage by any other classes developers"; just as "private" means "protected from misusage by developers of any other classes and subclasses".There's no difference between public, private, protected or any other methods for the hacker. If the hacker would get access to running Java machine (!) or to application's JAR (!) on client (!) then he will be able to get access to all methods and fields which he wants, one way or another. But thanks to Java's protectability it is easier to hack the server or even server-client channel than client application. And C++ built modules have all methods accessible equally, with all access modifiers erased in them.This must be fixed because it violates two supportable software programming principles: orthogonality (if my guess is true then "security" aspect of RSE is mixed here with other aspects) and KISS (API must be simple and convenient and implementation must be just simple). If I'm not right then just KISS principle is violated.In short: current API is not "stupid" simple (as KISS prescribes) and if it is such by security reasons then securing measures taken are inadequate.Just forgot to reopen.	10.0
id=287079	REOPENED	Target Management	RSE	3.1	PC Windows Vista	P3 trivial	dsdp.tm.rse-inbox	2009-08-19 10:24 EDT by	CDE Administration	2010-05-26 15:23 EDT (	4 users	<response_by> Moravia IT at 2009.08.18.12.42.43 </response_by>Build: 20090817-0200-nl2-win32Language: PolishSteps:1. Under the Remote Systems tab expand Local -> Local Files -> My Home2. Right Click on folder and click User Action -> Work With User Actions3. Under New click on File Action4. Press the F1 key to bring up the help dialogProblem Description:Text in the help dialog / tooltip mentions selecting "New" node to create new action, but after selecting "New" node, the panel is empty. User has to select subnode of "New" node to be able to create new action. Could you please update the text in tooltip?Thanks,Kamil<response_by> Matthew McClintock at 2009.08.19.08.51.39 </response_by>This article was reassigned from Category:''TVT/Testing,Inbox''.	Created14.000.530_new_action_PLK.JPG<cde:tctdetail>Testcase: 14.000.530 - RSE - USER ACTIONSProject: WSW35Component: Xfer - Target Management/RSEPriority: 4Subject: PLK: small error in tooltip in new user action panelArticle ID: 641Originator:</cde:tctdetail>We'll look to get this fixed next release.<response_by> Moravia IT at 2009.08.25.05.03.27 </response_by>Thank you, I will defer this. Closing.Kamil[Added by CDE: Completed by the CDE Bridge]This does seem like a valid bug, I cannot quite understand why it has been closed?The translation verification tester had a different process. He just meant this cannot be resolved in this release. Reopening.I see. It looks like there are 3 more that were closed accidentally with target milestone=3.2:,,. Could you please investigate these as well, and reopen if appropriate.Thanks, those are valid defects deferred to 3.2. I've reopened them.	9.0
id=287075	REOPENED	Target Management	RSE	3.1	PC Windows Vista	P3 minor	dsdp.tm.rse-inbox	2009-08-19 10:13 EDT by	CDE Administration	2010-05-26 15:22 EDT (	4 users	<response_by> Moravia IT at 2009.08.18.11.54.45 </response_by>Build: 20090817-0200-nl2-win32Language: PolishSteps:1. Under the Remote Systems tab expand TestConnection2. Expand Files -> MyStuff3. If prompted for a username and password enter tester01 and all4one4. Right click on test.c and click Compile -> Work With Compile Commands5. Press the F1 key to bring up the help dialogProblem A Description:Text in the tooltip refers to "New" node in list of compile commands. The problem is that the node is called "New command" - not "New". Please make the tooltip consistent with UI.Problem B Description:The tooltip also fails to mention that the "New" node is visible only if there is defined a souce type.Thanks,Kamil<response_by> Matthew McClintock at 2009.08.19.08.50.36 </response_by>This article was reassigned from Category:''TVT/Testing,Inbox''.	Created14.000.440_new_command_node_in_compile_commands_list.JPG<cde:tctdetail>Testcase: 14.000.440 - RSE - COMPILE COMMANDSProject: WSW35Component: Xfer - Target Management/RSEPriority: 3Subject: PLK: inconsistency between UI and tooptipArticle ID: 640Originator:</cde:tctdetail>We'll look to get this fixed next release.<response_by> Moravia IT at 2009.08.25.04.55.50 </response_by>Thanks, in that case I'm deferring this defect. Closing.Kamil[Added by CDE: Completed by the CDE Bridge]Reopen to continue the investigation in 3.2.	6.0
id=308180	REOPENED	Target Management	RSE	unspecified	PC Linux	P3 normal	dsdp.tm.rse-inbox	2010-04-06 06:42 EDT by	Harendra	2011-04-27 03:50 EDT (	5 users	Build Identifier: 20100329When you connect to remote linux system using RSE ssh terminal you see dbcs characters in garbled form.Reproducible: AlwaysSteps to Reproduce:OS:Ubuntu Linux 9.04,Redhat Enterprise Linux 5.4JVM:JRE 1.6.0 IBM Linux build pxi3260sr7-20091215_02 (SR7)Steps to recreate problem:1. Connect to your linux system with RSE.2. Open SSH Terminal and list files in the folder containing dbcs file/folder names.Expected result: You see that all the dbcs characters are garbled.	CreatedScreenshotI think this is a limitation of terminal support. Martin, Dave, Dave, please correct me if I am wrong. Thanks.This is caused by a simple encoding mismatch. It seems that rse terminal has fixed encoding value of ISO-8859-15. It is the encoding used for european languages but in order to correctly display dbcs/surrogate characters the encoding needs to be changed to Unicode (in linux). If the terminal encoding can be changed dynamically based on locale or give users the option to set desired encoding this problem should be solved.Since this affects all the dbcs character and the potential fix is pretty simple it is recommended to fix this bug.If you open the Terminal from the RSE System View, it should use the encoding set in the host (select host, right-click > Properties).In other words, I think that this should work today. Please check the encoding set in your host properties. By default, it uses the encoding on your host -- you need to set it manually to the encoding of the target. If your connection uses dstore, dstore is capable of auto-detecting the encoding of the target. This is not so easy with SSH. So I believe for RSE 3.2 we'll keep the requirement for users to manually set their encoding if using an SSH only connection.Command from Kentaroh:It seems that this symptom caused by a encoding mismatch. The Linux relies on UTF-8 encoding, but I think that the ssh assumes that the encoding is always ISO-8859-1/15. If you have a chance to fix this symptom, please check this encoding mismatch.I cannot fix anything that I cannot reproduce. Please attach a screenshot of the host properties, showing the encoding set there.CreatedTerminal showing half of DBCS character.@Martin, I tried your way and it seems to work. But I had explicitly specify theencoding as UTF-8. In other words ssh terminal did not automatically detect theremote encoding. This may not be such a big problem though.However I ran into another problem which I had reported last year too. The double bytecharacters are rendered as only half a character(See screenshot). This maybe the font problem.CreatedCorrectly displayed dbcs characters in bash terminal.Looking at this again in the context of.Apparently there had been two problems -- (1) encoding had to be specified in the RSE host properties; and, (2) in the proportional font, DBCS characters are much wider than ASCII.Issue (2) is a valid issue, because when computing the necessary box width for the terminal grid, the terminal only examines the first 256 characters so it assumes that the character box can be very narrow. In case of a font like the one shown here, we would need to increase the box width.The problem here is, that on some fonts the characters > 256 are invalid, so their width must not be taken into account when computing the box width. Perhaps we'll need to make the box width configurable by the user.The similar or same problem happens with Eclipse V3.7/4.1 in Windows XP/7. All DBCS characters are corrupted. Configuration: RSEServer: OS - Window XP SP3 32Bit, Japanese environmentJDK - J2RE 1.5.0 IBM Windows 32 build pwi32dev-20080315 (SR7)Eclipse/RSE:Version: 3.7.0Build id: I20110412-1532Version 4.1.0Build id: I20110412-2200CreatedScreenshot (windows 7, Eclipse 4.1)	12.0
id=312545	REOPENED	Target Management	RSE	3.1	PC Windows XP	P3 major	dsdp.tm.rse-inbox	2010-05-12 04:33 EDT by	van Tol	2010-07-01 09:41 EDT (	3 users	Build Identifier: 20100218-1602In RSE (using PDT), when rightclicking a folder and choosing 'create remote project', after a while - maybe because it's a large project - the build and validate dialog hangs, eclipse hangs also.During the freeze, on the remote server log files are written, like:-May 11 16:48:39 remoteserver sshd[8581]: [ID 800047 auth.error] error: select: Invalid argument-May 11 16:49:30 remoteserver last message repeated 468227 timesThen i have to kill eclipse because it won't respond anymoreReproducible: AlwaysSteps to Reproduce:1.using a ssh connection 2.create remote project (probably large)3.wait... during build and validate dialog (php project) it freezes (every time)	I am using the TM 3.1.2 versionI assume that it hangs during the EFS deep project refresh -- EFS and large remote file trees have been known for a long time to cause issues:Dave, Chris - how are you handling large remote projects in RDT? Do you think that this is specific to the apparent problem with SSH (which might have run out of file descriptors; in this casewould be a proper fix); or do we need something generic, e.g. a progress bar + cancel button for the EFS deep refresh? Or an improvement on Eclipse Core/Resources side, such as discussed onandwhich also came up in the context ofBTW, combining RSE remote filtering with EFS might also have a chance of improving the situation, related to the e4 semantic file system:I'm decreasing severity since (a) this is a known issue with workaround and (b) the submitter didn't care answering with a week so I assume it's not that severe after all.Let us know if you have good arguments why this is severe for you.(In reply to)Sorry for not responding earlier. I think it is a severe bug because it makes eclipse freeze. Even the cancel button does nothing.however I didn't know that this issue was listed at known issues, so sorry for raising this bug.Personally RSE works fine for me, i just don't get the nice codecompletion i wanted which you get with 'create remote project' and that is only annoying for me at one project of mine.Anyway, thanks for the responseWell, the "create remote project" _should_ work when the remote file tree is small. So perhaps an acceptable workaround is creating a symlink on the remote which points to only those subset(s) of files that you need.Also, the performance issue you raise is valid, and I agree that cancel should be possible. While it's not critical, it is a major usability problem, so I'm re-opening it.(In reply to)There is nothing special we do in RDT to avoid the refresh when creating the project. We did however ask the platform team to make progress reporting for the refresh more verbose, so that when the New Remote C/C++ Project Wizard is running, it gives a better indication that something is still going on, and that it's not stuck. See.I have not played much with the "Create Remote Project" action, but if it still suffers from a lack of verbosity in its progress reporting, maybe it could be improved to take advantage of the changes done for. I would think that this action ought to be doing its work in a Job, whose progress monitor would be passed into the refresh.	6.0
id=287074	REOPENED	Target Management	RSE	3.1	PC Windows Vista	P3 trivial	dsdp.tm.rse-inbox	2009-08-19 10:13 EDT by	CDE Administration	2010-05-26 15:22 EDT (	4 users	<response_by> Moravia IT at 2009.08.18.13.04.56 </response_by>Build: 20090817-0200-nl2-win32Language: PolishSteps:1. Under the Remote Systems tab expand Local -> Local Files -> My Home2. Right Click on folder and click User Action -> Work With User Actions3. Under New click on File Action4. Click on the bottom Edit Button5. Press the F1 key to bring up the help dialogProblem Description:Thext in help dialog mentions "New" node, but in build this is "New named type" node. Could you please update text of help dialog?Thanks,Kamil<response_by> Matthew McClintock at 2009.08.19.08.52.17 </response_by>This article was reassigned from Category:''TVT/Testing,Inbox''.	Created14.000.570_new_named_type_PLK.JPG<cde:tctdetail>Testcase: 14.000.570 - RSE - USER ACTIONSProject: WSW35Component: Xfer - Target Management/RSEPriority: 4Subject: PLK: inconsistency in tooltip help for new named typeArticle ID: 642Originator:</cde:tctdetail>We'll look to get this fixed next release.<response_by> Moravia IT at 2009.08.25.05.05.12 </response_by>Thank you, I will defer this defect. Closing.Kamil[Added by CDE: Completed by the CDE Bridge]Reopen to continue the investigation in 3.2.	6.0
id=368641	REOPENED	Target Management	RSE	unspecified	PC Linux	P3 normal	dsdp.tm.rse-inbox	2012-01-16 02:07 EST by	Yevgeny Shifrin	2012-01-16 11:18 EST (	0 users	Build Identifier: 20110615-0604By default, files should be opened using eclipse internal editor.Mail thread:Hi,The new behavior is really annoying.Why the default behavior was changed to using external editor? Is there a bug for this issue? Please let me know if you want me to open a bug for this.Thanks,Yevgeny From:[] On Behalf Of Beth TibbittsSent: Tuesday, June 28, 2011 6:02 PMTo: PTP User listSubject: Re: [ptp-user] External editors in IndigoI set the file associations within Eclipse to open stuff within the internal editors instead of external editors.one example is *.psf (project set files) which my Mac thinks are Photoshop files so it tries to use photoshop.Bring up the Preferences Dialog, and in upper left search bar type "file assoc" (because I can never remember where it is)If there isn't a file extension/filetype for the type of file, add one. then while it's selected, make sure there's an "associated editor" in the bottompane that you want it to open with....BethBeth Tibbitts Eclipse Parallel Tools PlatformIBM STG - High Performance Computing ToolsMailing Address: IBM Corp., 745 West New Circle Road, Lexington, KY 40511 Greg Watson ---06/28/2011 09:27:34 AM---I set the finder preference to use Eclipse to open files ending in .c, .h, etc. That seems to work. From: Greg Watson <> To: PTP User list <> Date: 06/28/2011 09:27 AM Subject: Re: [ptp-user] External editors in Indigo Sent by:________________________________________I set the finder preference to use Eclipse to open files ending in .c, .h, etc. That seems to work. Use "Get Info" (command-I) on one of the files, set the "Open with:" option, then click on "Change All...".GregOn Jun 28, 2011, at 8:52 AM, David E Hudak wrote:_______________________________________________ptp-user mailing listThis e-mail message is intended for the recipient only and contains information which is CONFIDENTIAL and which may be proprietary to ECI Telecom. If you have received this transmission in error, please inform us by e-mail, phone or fax, and then delete the original and all copies thereof. Reproducible: Always	I think that this is a duplicate ofin Eclipse Platform, which is as old as 2006.As of today, Eclipse Preferences and extension points provide a way associating file extensions with editors. If a file extension is not registered with Eclipse, the operating system's default action is performed (typically opening in some external editor). This is often not the expected behavior, andseeks to improve the situation.In my understanding there's nothing that RSE does differently than Eclipse Platform, and nothing that's "new behavior".Please let me know if you disagree.We _could_ theoretically do things differently in RSE than in Eclipse Platform but I don't think that would be a good idea.*** This bug has been marked as a duplicate of***Hi,Thank you for looking into this issue.In my case I do have CDT installed. So why when opening ".h" file from RSE connection it uses external editor?Thanks,Yevgeny	2.0
id=315848	REOPENED	Target Management	RSE	unspecified	PC Linux	P3 major	dsdp.tm.rse-inbox	2010-06-04 17:57 EDT by	Ryan Ware	2010-06-04 19:00 EDT (	0 users	Build Identifier: I20100520-1744I've been trying to get the rseserver daemon running on and off for the past couple of days with no success. The root cause seems to be that the system call at auth.pl:96 does with the following error:Exception in thread "main" java.lang.NoClassDefFoundError: org/eclipse/dstore/core/server/ServerCaused by: java.lang.ClassNotFoundException: org.eclipse.dstore.core.server.Server at java.net.URLClassLoader$1.run(Unknown Source) at java.security.AccessController.doPrivileged(Native Method) at java.net.URLClassLoader.findClass(Unknown Source) at java.lang.ClassLoader.loadClass(Unknown Source) at sun.misc.Launcher$AppClassLoader.loadClass(Unknown Source) at java.lang.ClassLoader.loadClass(Unknown Source)Could not find the main class: org.eclipse.dstore.core.server.Server. Program will exit.I've been trying to root cause this behavior with no success. I've tried using the standard openjava that comes with Fedora 12 (both the 32-bit and 64-bit openjava packages on Fedora 12 x86_64) as well as Sun's 1.6 release; all with the same behavior.I've primarily done this with 3.2RC3. However, I've gone back and tried this with the 3.0 release and get the same behavior.I _am_ able to use the server.pl script which executes fine.Reproducible: AlwaysSteps to Reproduce:1. Modify auth.pl:96 adding '>& file' to get the output of the java command.2. perl ./daemon.pl 4075 10000-100103. Connect via RSE from a remote system.4. check 'file'.	auth.pl is not meant to be called directly - it is internal, and needs to be called with proper parameters and environment (CLASSPATH) set.Only daemon.pl and server.pl are the end-user callable scripts.Oops, I did not read to the end :(The problem seems to be valid.Are you aware that daemon.pl must be run as root ?Just root-caused this. It's a permissions issue. The full, expanded system call from auth.pl comes out to be: su -p rrware -c '/usr/bin/java -Duser.home=/home/rrware -cp /root/rseserver:/root/rseserver/dstore_extra_server.jar:/root/rseserver/dstore_core.jar:/root/rseserver/dstore_miners.jar:/root/rseserver/clientserver.jar -DA_PLUGIN_PATH=/root/rseserver/ -DDSTORE_SPIRIT_ON=true org.eclipse.dstore.core.server.Server 10000-10010 120000 1274895413522'If you look at the passed in CLASSPATH, it points to the rseserver directory I had in /root. /root isn't accesible by anyone. When I moved the rseserver directory to /rseserver with global read and execute permissions, things work as expected.You can close this as not a bug. Thank you for the prompt response though!Should we update docs in any way?I would update the doc to say something like:rseserver scripts, jar's and other files must be readable by the local user ID's intended to access the dstore server.In the troubleshooting section, you may want to put information with the specific error I included here showing what the root cause is.	6.0
id=438338	REOPENED	Target Management	RSE	unspecified	Macintosh Mac OS X	P3 normal	dsdp.tm.rse-inbox	2014-06-27 03:30 EDT by	Ashutosh Mantry	2014-07-16 01:45 EDT (	2 users	Hi,My local system is Mac and remote system is linux. There is a maven project in my remote system. When I try to use RSE on my local system and ssh to remote linux, then the auto-complete for that maven project does not work. It contains java files in src folder. It says the compilation unit is not in the build path of java project. Please help me fix this. It urgent.Thanks	Please help me with this. Its urgentCan you elaborate the problem with the help of the guideline ?Which view/editor you are trying to use where auto complete is not working ?Ok, so when i go to RSE perspective(under Window-> Open Perspective) and connect to remote linux box, it lists the files present in my root box under My Files. Now there is a maven project there. The source file in that maven project is a java file. I am able to edit that file and the changes are reflected in the remote box as well. However, the auto-complete feature for that java file is not working. It says compilation unit is not in the build path of java project.I even tried to edit a simple java file ( and not a java file under maven project) but the auto-complete still does not work.Please let me know if you require some other info.ThanksJava tooling works on a Java project. It does not work on a *.java file that's outside such a project.That should not be the case, because referring to my"I even tried to edit a simple java file ( and not a java file under maven project) but the auto-complete still does not work."Even if I create a simple java project in my remote linux box, and I do RSE from my local box to remote box, even then the auto-complete does not work.Secondly, when I install eclipse in my remote linux box then auto-complete works for a *.java file under a maven project, differing from.Thanks*** This bug has been marked as a duplicate of***I have already tried all the steps mentioned in the duplicate bug and then at the end I have raised this ticket.The problem does not seem to go. I have Dynamic Languages Toolkit - Core framework as well as Remote Development Support.I will again mention the steps that I am doing:Remote linux box: ABCFirst I switch over to RSE perspective > New ConnectionABC appears under remote Systems.ABC > Sftp files > My Home > Random_projectRandom_project is a simple java project having Random_project.java. When I open this and try to edit it, the auto-complete does not work. It says "This compilation unit is not under build path of java project"ThanksAny updates here ??Thanks(In reply to Ashutosh Mantry from)When using RSE to edit remote files, note that the remote folders are not projects. The project associated with remote files is a hidden one called the "RemoteSystemTempFiles" project. I'm guessing that the java content assist probably requires that the containing project has a java nature. What happens if you add the java project nature to the RemoteSystemTempFiles project?I have already tried that. I added the following to .project file under RemoteSystemTempFiles project:<nature>org.eclipse.jdt.core.javanature</nature>But this does not seem to work.It does not have any effect.Thanks(In reply to Ashutosh Mantry from)If you want to get more than just template content assist entries, I think you'll also need a .classpath file in the RemoteSystemTempFiles project. For example:<?xml version="1.0" encoding="UTF-8"?><classpath> <classpathentry kind="con" path="org.eclipse.jdt.launching.JRE_CONTAINER/org.eclipse.jdt.internal.debug.ui.launcher.StandardVMType/JavaSE-1.7"/></classpath>With that said, if you're looking for project-specific content assist support, then you should probably create an actual java project for this. If you need to include remote source files, you can create linked folders via RSE and then later make them java source folders.Currently, there is no .classpath file in the RemoteSystemTempFiles project. Should I create one ? If yes, what would be its value. Is it the one mentioned in.It would be great if you can elaborate a bit more on youror any steps on how it needs to be done.Thanks	13.0
id=415565	REOPENED	WindowBuilder	Core	unspecified	PC Windows 7	P3 normal	Project Inbox	2013-08-21 07:24 EDT by	Simon Bergmann	2013-08-23 04:35 EDT (	2 users	CreatedError LogError shows at loading designer and saving project.When saving the project, which have changed more than 5 components, eclipse freezed (save-state ~60%). while saving the project never get saved, because it freezed until i pressed CTRL+Print to open my own app in c# "Screen'Up" (its using low-level keyboard hook for global hotkey).I used JTable (i think thats a problem), JButton, JLabel, JPanel, JTabbedPanel, JTextField.Windows 7 Professional 64bit, JRE 7 64bit, JDK 7 64bit, Eclipse 4.2 64bit, Eclipse 4.3 64Bit (both Eclipse version have the extactly same problem).	Moving to WindowBuilderUnable to reproduce. Please provide a test case that will reproduce this.Createdmost of them generated from swing designerEclipse 4.2 or 4.3 with Software from(for eclipse 4.2 change 4.3 to 4.2), all select items installed.load the admin.java (this case causes the error) from attachments, open it with windowbuilder, the errorlog shows an error.	4.0
id=461845	REOPENED	WindowBuilder	Core	unspecified	PC Windows NT	P3 enhancement	Project Inbox	2015-03-10 11:48 EDT by	Ed Willink	2015-03-12 10:02 EDT (	1 user	Install Window Builder from the mars staging site using Install New Software... and everything proceeds fine. But when you try to Open With Window Builder you get a message saying that it doesn't work - no relevant support.Suggest: the message enumerate the GUI styles that are installed.Going back to try the install again, there is something else called SWT Designer. Ah! Install that and everything is better.Suggest (or rather insist since it is a new Mars guideline): prefix all Window Builder components with "Window Builder" so that they are obviously part of Window Builder in the P2 install.	WindowBuilder is just a framework (like GEF or RCP) that can be used to create UI builders. It does not edit anything by itself, but it has been used to create several different UI builders. It does not require SWT Designer when used as a pure framework.SWT Designer and Swing Designer are actual end user tools for editing UIs and can be loaded independently of each other. Both require the WindowBuilder framework as a prereq but are not part of WindowBuilder itself.Seeand"Optional/extra extensions extend the base feature name. C/C++ development tools - IBM XLC Compiler Support C/C++ development tools - Visual C++ Support"I am aware that Window Builder is a good tool so I install it and its useless. I hadn't installed the real product.The guiidelines recommend that I seeWindow Builder SDKWindow Builder SWT ...Window Builder Swing ...Your current feature naming just wastes users time by forcing them into a needless debug cycle.	2.0
id=473441	REOPENED	Tracecompass	State system	1.0.0	PC Windows 7	P3 normal	Project Inbox	2015-07-23 17:42 EDT by	Patrick Tasse	2015-08-14 11:50 EDT (	2 users	An IllegalStateException sporadically occurs while opening a large trace for the first time and building its state system while the Control Flow & Resources views are open and concurrently querying the state system. It is more easily triggered when zooming completely out so that the (current) full range of the trace is visible.Debugging shows that:- the queryHistoryRange() end time is the latest returned value of getCurrentEndTime()- the querySingleState() time is that end time- the attribute being queried has been created a while ago in the trace- the attribute being queried had a state change at the end time or very close to it (a few events ago)Exception in thread "org.eclipse.tracecompass.analysis.os.linux.views.resources build" java.lang.IllegalStateException: Incoherent interval storage at org.eclipse.tracecompass.internal.statesystem.core.StateSystem.querySingleState(StateSystem.java:614) at org.eclipse.tracecompass.statesystem.core.StateSystemUtils.queryHistoryRange(StateSystemUtils.java:226) at org.eclipse.tracecompass.analysis.os.linux.ui.views.resources.ResourcesView.getEventList(ResourcesView.java:254) at org.eclipse.tracecompass.analysis.os.linux.ui.views.resources.ResourcesView.buildEventList(ResourcesView.java:189) at org.eclipse.tracecompass.tmf.ui.views.timegraph.AbstractTimeGraphView$BuildThread.run(AbstractTimeGraphView.java:452)	During our trouble-shooting today showed that in the run() method of class ThreadedHistoryTreeBackend there might be a time period where a interval was removed from the buffered blocking queue (BBQ) but has not sent the interval to the History Tree yet. When a query happens a the same time that particular interval won't be found in the BBQ.Here is the relevant code: currentInterval = intervalQueue.take(); while (currentInterval.getStartTime() != -1) { /* Send the interval to the History Tree */ getSHT().insertInterval(currentInterval); currentInterval = intervalQueue.take(); }The solution that we discussed was to remove the interval from the queue only after it was send to the history tree.New Gerrit change created:Gerrit changewas merged to [master].Commit:New Gerrit change created:Gerrit changewas merged to [dev-1.x].Commit:Merged to master and dev-1.xWe still need a unit test or test case that reproduces the error pattern that was fixed by this patch. Right now, it's very scary to do any change to the BufferedBlockingQueue because it might bring this bug back. This is not very good from a maintenance pov...Let's close this bug only once we have such test.	7.0
id=390101	REOPENED	Target Management	RSE	unspecified	PC Windows XP	P3 normal	dsdp.tm.rse-inbox	2012-09-21 09:09 EDT by	Vlado Hucko	2013-02-27 02:34 EST (	3 users	I testing Eclipse IDE for C/C++ DevelopersVersion: Juno Service Release 1Build id: 20120912-1957 RSE SSH Services 3.0.400.201205300905-7A4FEc7F7BF7RJ77g7R org.eclipse.rse.ssh.feature.group Eclipse TM ProjectWork with RSE / remoter System Explorer - connect over ssh to server...Problem is: In Remote Shell /popup menu on directory - Launch shell/ not work commands - after send command - output screen is death and command not execute...Thx-- Configuration Details --Product: Eclipse 1.5.1.20120828-0743 (org.eclipse.epp.package.cpp.product)Installed Features: org.eclipse.platform 4.2.1.v20120814-120134-9JF7BHVGFyMveli1uW7bOH0pz0eAYo1X9VOP5mO	Are you able to launch a terminal? Does this happen with any connection or just a particular one?I downloaded the 32bit windows version of this:With that I wasn't able to reproduce this. All the the SSH feature is the same there it's not at the same level as what you're using. I also tried in a June development environment with the latest RSE code but things worked in that environment too. Could you post a link to where you picked up this service release?I downloaded your link - distr. work OK.Before I make mistake - after dwnl, unzip and run eclipse - I installedRSE. Finally in eclipse was RSE 2x /in About eclipse - installation details/:- in EPP CPP Feature- in rootThx.Vlado Hucko sen.Today I download Eclipse Juno CDT /for W32 bit/ - unpacked...-- Configuration Details --Product: Eclipse 1.5.1.20120828-0743 (org.eclipse.epp.package.cpp.product)Installed Features: org.eclipse.platform 4.2.1.v20120814-120134-9JF7BHVGFyMveli1uX6aTH0q-eAap6PAgOP5mO... and problem is here:"Work with RSE / remoter System Explorer - connect over ssh to server...Problem is: In Remote Shell /popup menu on directory - Launch shell/ not work commands - after send command - output screen is death and command not execute..."I return to previous version:-- Configuration Details --Product: Eclipse 1.5.0.20120131-1544 (org.eclipse.epp.package.cpp.product)Installed Features: org.eclipse.platform 4.2.0.v20120608-135145-9JF7BHV8FyMteji0Oi_ePMz0xuZ8TVo7lV0z0ecbthere shell work OK...Same problem. Eclipse SDK Version: 4.2.1, Build id: M20120914-1800How to solve:1. Right click on SSH-connection -> Open in New Window2. In new window - voila - there is "Terminal view" - new terminals appears in it.This problem also actual to Ssh Shells.	4.0
id=453759	REOPENED	WindowBuilder	Swing	unspecified	PC Windows 7	P3 normal	Project inbox	2014-12-01 09:40 EST by	Christian Haeussler	2015-01-08 13:26 EST (	2 users	CreatedWindowBuilder Error ReportEclipse Build Identifier: 4.3.0.M20130911-1000WindowBuilder Build Identifier: 1.6.1.r43x201309092314.201411241124I've delete a empty panel on a WindowBuilder generated class and WindowBuilder give me this error: java.lang.IndexOutOfBoundsException: Index: 0, Size: 0In the attachment you will find the log report generated with windowBuilder.Reproducible: Always	Can't reproduce using incomplete test case. Reporter is also using an old version of WB. Please try again with the latest WB build. If it is reproducible, please provide a complete, self-contained test case.CreatedWindowBuilder Error Report with Ver 1.8.0Hi Eric,i try with the new version (1.8.0).But the problem is still exists!Thanks,ChrisCan't reproduce using incomplete test case. The code provided would not compile on my end due to a large number of missing dependencies.Please provide a complete, self-contained test case including all dependencies. Or simplify the example so that it does not require any non-JDK dependencies.	4.0
id=398953	REOPENED	PDT	Debugger	3.2.0	PC Mac OS X	P3 normal	Wojciech Galanciak	2013-01-24 04:43 EST by	Wojciech Galanciak	2015-02-18 04:17 EST (	2 users	Steps:1) Create ZF project.2) Deploy it to zs6 (with full Debug Mode and new debugger protocol support).3) Enable Debug Mode on this target.4) Trigger a debug session. It stops in the first line of index.php.5) Set breakpoint in Zend_Application_Bootstrap_Bootstrap::run().Expected is that debugger would stop in Zend_Application_Bootstrap_Bootstrap::run() but instead of that session is terminated.	CreatedpatchPatch applied to master.Thanks Wojtek!I still reproduce this behavior on latest PDT (3.3.1). Reopening	3.0
id=358202	REOPENED	Xtend	Backlog	2.2.0	PC Mac OS X - Carbon (unsup.)	P3 enhancement	Project Inbox	2011-09-20 04:35 EDT by	Sebastian Zarnekow	2012-11-08 04:22 EST (	3 users	A declaration view similar to Java's declaration view would be interesting. This view could inject all the infered types into the Xtend code.	It would probably make sense to define some of the generic supporting code in the xtext.ui plug-in as this could be useful to many Xtext based DSLs.Createdproposed patch(In reply to)+1 this should go into Xtext. The patch doesn't seem to have any Xtend dependencies so far.pushed to masterThe declaration view should refer to services from the declaring language, using IUiResourceServiceProvider. Every language has different syntax coloring, and it should be possible to provide contributions for non-Xtext languages (e.g. Java / JDT).	5.0
id=365877	REOPENED	Xtend	Backlog	2.2.0	All All	P3 normal	Project Inbox	2011-12-07 08:11 EST by	Vlad Dumitrescu	2012-11-08 04:42 EST (	2 users	If the java file generated from an xtend file is deleted, the builderdoesn't catch the change and doesn't recompile. This means that one hasto explicitly do a "clean" or "build" on the project after doing a "gitclone" or "git clean", which is less than user-friendly IMHO.	I think that's ok, since JDT does not recompile manually deleted classfiles either. Please reopen if I missed your point.If I have a Java project open and do a "git clean -fdx" in the console and refresh the project, then it is rebuilt. This doesn't happen with the java files generated by xtend.In the case of JDT it's transparent, since there are no compile errors. Also as soon as one file get's a change everything is build again. With Xtend, any Java sources 'referencing' Xtend files get markers. We should investigate to make this smoother.	3.0
id=362461	REOPENED	Xtend	Core	2.2.0	PC Mac OS X - Carbon (unsup.)	P3 enhancement	Project Inbox	2011-10-31 06:26 EDT by	Sebastian Zarnekow	2014-07-16 04:53 EDT (	2 users	Find references on an unnamed extension does not yield any results. It would be great if the called methods would be revealed.	This has been fixed in the meantime.class Z { extension String def Integer dummy() { 42.substring.length } }JJust tried to fined references on the keyword extension and got an error dialog with: 'Element '_string' does not exist anymore'Steps to reproduce:1) Create a new class2) Paste the extension field and the method (don't save)3) Find references on the keyword 'extension'The problem is the unsaved state. An error dialog pops up with regular fields as well. We should at least catch the error and tell the user to save the editor for now.see also	5.0
id=391758	REOPENED	Xtend	Core	2.4.0	PC Windows 7	P3 normal	Project Inbox	2012-10-12 06:38 EDT by	Stefan Oehme	2013-05-27 06:07 EDT (	3 users	The problem is most easily explained with an example. Let's take the fold-Function:<T, R> fold(Iterable<T> iterable, R seed, (R,T)=>R function)When I write iterable.fold(anArrayList)[functionReturningList]the compiler complains that my function should return ArrayList instead. I.e. the seed wins when determining R. To get around this I have to explicitly cast anArrayList to List. This ruins an otherwise readable line of code.I worked around this by defining my own version of fold like so:<T, R, S extends R> fold(Iterable<T> iterable, S seed, (R,T)=>R function)However, the compiler should be able to correctly determine R without a third type variable.	Thanks for the report. I can reproduce the issue.The following works now.val (List<String>,String)=>List<String> functionReturningList = [a, b| a += b return a]#['foo'].fold(newArrayList, functionReturningList)added a test case.This is still an issue with the more natural stylestrings.fold(newArrayList) [ list , b | list += b return list.sublist(1)]	3.0
id=371960	REOPENED	Xtend	Core	unspecified	All All	P3 enhancement	Project Inbox	2012-02-17 23:06 EST by	Harshad RJ	2014-07-13 11:52 EDT (	6 users	Build Identifier: It would be nice to be able to quickly create constructors which do nothing other than initialise fields.Example syntax could be like this:class Person(val String name, var Float age) { def incrementAge(Float x) { age += x }}would get translated to this Java:class Person { final String name; float age; Person(final String name, final float age) { this.name = name; this.age = age; } void incrementAge(final float x) { age += x; } // optionally also generate this, ala Scala @Override String toString() { return String.format("Person[name=%s, %.3f]", name, age); }}Notice that the above example handles both vals and vars, and also generates a toString, similar to case classes in Scala.Reproducible: Always	Sven, what syntax do you have in mind for the solution based on annotation processing?Nothing concrete, yet.But maybe something like this:@Initializable class Person { String name int age}Maybe it's generally preferable to have a constructor accepting an initializer, instead of a constructor declaring all fields. This would emulate named parameters and be more backwards compatible:new((Person)=>void init) { init.apply(this)}so you can write:new Person[ age = 42 it.name = name]I think that most people will want to have their own annotations for this kind of problem.Something like @MyEntity which does everything you need in your specific context. The stuff we provide through API shouldn't hide too many things away.What do others think?I'd prefer a classic constructor. An initializer expression would not allow to use final fields in the class which renders equals and hashcode implementations with value semantics impossible since they may not use mutable fields in order to work with Java's collections. It's probably a good idea to use constructor params for the final fields and an additional initializer for the mutable fields (the interop of initializers with plain Java is unfortunately slightly cumbersome, though).This would be very handy! It's similar to C#'s Object Initializers:* The syntax is clear.* I'm free to initialize the object in many ways without constructor modifications.* It's easy to immediately see which fields are used.Are you aware of the with-operator =>new Person => [ age = 42 it.name = name](In reply to)Thanks, it works! It wasn't mentioned in the docs:Given that the with-operator only adds two more characters than the proposed change, I am inclined to close this one.Missing documentation handled inSince the actual ticket is about a shorthand notation for constructors, I think we should leave that open until we have a story for that one. Manually implemented constructors are still sort of verbose compared to the proposed solution and an annotation is still pending.Maybe something likeclass Person { String name Float age new (@This name, @This age) { this.age = age.assertNotNegative }}orclass Person { new (@This String name, @This Float age) { this.age = age.assertNotNegative }}What do others think?Reopened according to pending question inWouldn't it be sufficient to make some fields final?class Person { @NotNull val String name; float age;}would create these constructors: void Person(@NotNull String name) { this.name = name; } void Person(@NotNull String name, float age) { this(name); this.age = age; }That said, I'm not a big fan of constructors. They work well for simple value objects but quickly get in the way. I prefer Groovy's syntax: val john = new Person( name: "John", age: 42 )or Python: john = new Person(name="John", age=42)or Java DSLs: val john = new Person().name("John").age(42)but I can live with the "with-operator".(In reply to)You're not setting "name" in your examples. That's a typo, I guess?I guess the most frequent case of setting all final fields is solved by @FinalFieldsConstructor. And for mutable properties we have the with-operator.	12.0
id=397256	REOPENED	Xtend	Core	2.4.0	PC Mac OS X	P3 normal	Project Inbox	2012-12-30 14:53 EST by	Jan Koehnlein	2013-01-02 03:26 EST (	2 users	Usually, I can declare fields just using type and name. For function or procedure types I have to explicitly state 'val' or 'var'.	Was caused by a preceeding constructor call without parentheses, so the closures parameter types were interpreted as parameters.We should do something about these situations. We could include the whitespace (i.e. newlines) to tell the user, that the text is parsed differently than it looks like.Same for situations likeif (guard) return // early exitsome_expressionwhich is parsed as if (guard) return some_expression	3.0
id=408385	REOPENED	Xtend	Core	2.4.1	PC Mac OS X	P3 enhancement	Project Inbox	2013-05-18 06:08 EDT by	Jan Koehnlein	2013-05-18 06:43 EDT (	0 users	Xtend's template expressions have already a sophisticated way to distinguish between newlines in template code and in the output. But when I want to use a control structure like IF without adding a newline in the output it gets ugly. E.g. instead of''' public class <<name>> <<IF extends != null>> extends <<extends.name>><<ENDIF>>'''I'd like to put the IF in a new line for better readability''' public class <<name>> <<<this linebreak goes into the output>>> <<IF extends != null>> extends <<extends.name>> <<ENDIF>>'''which adds a newline in the output because of the first line as desired in most other usecases. The workaround is to put the newline inside the <<>> like in''' public class <<name>> << IF extends != null >>extends <<extends.name>> << ENDIF >>'''but this gets pretty hard to read. I'd prefer to have a 'suppress newline' token, similar to Xpand's <<->>, maybe <<SKIPEOL>> or a single line comment for templates.	Same holds for newlines before the closing ''', e.g.if (condition) ''' some Template <<<newline goes to output>>>''' else ''' other Template <<<newline goes to output>>>'''Oh, I just found <<<<<< is a single line comment. Sorry for the noise<<<<<< doesn't work: It resets the current indentation E.g. def foo() ''' <<''>><<<<<< ''' // the preceding WS goes into the outputor def foo() ''' <<''>><<<<<< <<''>><<<<<< preceeding WS also goes into output. ''' // the preceding WS goes into the output	3.0
id=443939	REOPENED	WindowBuilder	Swing	unspecified	PC Windows 8	P3 normal	Project inbox	2014-09-12 08:32 EDT by	Goetz Heller	2014-09-17 00:54 EDT (	1 user	SwingBuilder crashes whenever code has been modified in the source tab and I click on the design tab. The Message is as follows:BEGIN_MSG>>>Internal ErrorWindowBuilder encountered unexpected internal error. This could be caused by a WindowBuilder bug or by a misconfiguration issue, conflict, partial update, etc.java.lang.Error: new JFrame()Show stack trace. Hide stack trace. Stack trace:java.lang.NullPointerException at java.beans.MethodRef.get(Unknown Source) at java.beans.PropertyDescriptor.getWriteMethod(Unknown Source) at org.eclipse.wb.internal.core.model.JavaInfoUtils.addExposedChildred_Method(JavaInfoUtils.java:447) at org.eclipse.wb.internal.core.model.JavaInfoUtils.addExposedChildren(JavaInfoUtils.java:429) at org.eclipse.wb.internal.swing.model.component.ComponentInfo.createExposedChildren(ComponentInfo.java:109) at org.eclipse.wb.internal.swing.model.component.ContainerInfo.createExposedChildren(ContainerInfo.java:143) at org.eclipse.wb.core.model.JavaInfo.initialize(JavaInfo.java:423) at org.eclipse.wb.internal.swing.model.component.ContainerInfo.initialize(ContainerInfo.java:114) at org.eclipse.wb.core.model.JavaInfo.setObject(JavaInfo.java:1288) at org.eclipse.wb.internal.core.model.JavaInfoEvaluationHelper$3.evaluationSuccessful(JavaInfoEvaluationHelper.java:271) at org.eclipse.wb.core.eval.AstEvaluationEngine.evaluate0(AstEvaluationEngine.java:179) at org.eclipse.wb.core.eval.AstEvaluationEngine.evaluate(AstEvaluationEngine.java:61) at org.eclipse.wb.internal.core.model.JavaInfoEvaluationHelper.evaluateExpression(JavaInfoEvaluationHelper.java:630) at org.eclipse.wb.internal.core.model.JavaInfoEvaluationHelper.evaluate(JavaInfoEvaluationHelper.java:502) at org.eclipse.wb.internal.core.parser.JavaInfoParser.evaluateNode(JavaInfoParser.java:1309) at org.eclipse.wb.internal.core.parser.JavaInfoParser.access$1(JavaInfoParser.java:1300) at org.eclipse.wb.internal.core.parser.JavaInfoParser$ExecutionFlowParseVisitor$3.run(JavaInfoParser.java:602) at org.eclipse.wb.internal.core.utils.execution.ExecutionUtils.runRethrow(ExecutionUtils.java:119) at org.eclipse.wb.internal.core.parser.JavaInfoParser$ExecutionFlowParseVisitor.postVisit(JavaInfoParser.java:592) at sun.reflect.GeneratedMethodAccessor33.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) at java.lang.reflect.Method.invoke(Unknown Source) at org.eclipse.wb.core.eval.ExecutionFlowUtils$1.intercept(ExecutionFlowUtils.java:399) at org.eclipse.jdt.core.dom.ASTVisitor$$EnhancerByCGLIB$$55689ef6.postVisit(<generated>) at org.eclipse.jdt.core.dom.ASTNode.accept(ASTNode.java:2714) at org.eclipse.jdt.core.dom.ASTNode.acceptChild(ASTNode.java:2759) at org.eclipse.jdt.core.dom.Assignment.accept0(Assignment.java:313) at org.eclipse.jdt.core.dom.ASTNode.accept(ASTNode.java:2711) at org.eclipse.jdt.core.dom.ASTNode.acceptChild(ASTNode.java:2759) at org.eclipse.jdt.core.dom.ExpressionStatement.accept0(ExpressionStatement.java:145) at org.eclipse.jdt.core.dom.ASTNode.accept(ASTNode.java:2711) at org.eclipse.wb.core.eval.ExecutionFlowUtils.visitStatement0(ExecutionFlowUtils.java:354) at org.eclipse.wb.core.eval.ExecutionFlowUtils.visitStatement(ExecutionFlowUtils.java:315) at org.eclipse.wb.core.eval.ExecutionFlowUtils.visitStatement0(ExecutionFlowUtils.java:336) at org.eclipse.wb.core.eval.ExecutionFlowUtils.visitStatement(ExecutionFlowUtils.java:315) at org.eclipse.wb.core.eval.ExecutionFlowUtils.visit(ExecutionFlowUtils.java:247) at org.eclipse.wb.core.eval.ExecutionFlowUtils.access$1(ExecutionFlowUtils.java:235) at org.eclipse.wb.core.eval.ExecutionFlowUtils$1.endVisit(ExecutionFlowUtils.java:442) at org.eclipse.wb.core.eval.ExecutionFlowUtils$1.intercept(ExecutionFlowUtils.java:391) at org.eclipse.jdt.core.dom.ASTVisitor$$EnhancerByCGLIB$$55689ef6.endVisit(<generated>) at org.eclipse.jdt.core.dom.MethodInvocation.accept0(MethodInvocation.java:241) at org.eclipse.jdt.core.dom.ASTNode.accept(ASTNode.java:2711) at org.eclipse.jdt.core.dom.ASTNode.acceptChild(ASTNode.java:2759) at org.eclipse.jdt.core.dom.ExpressionStatement.accept0(ExpressionStatement.java:145) at org.eclipse.jdt.core.dom.ASTNode.accept(ASTNode.java:2711) at org.eclipse.wb.core.eval.ExecutionFlowUtils.visitStatement0(ExecutionFlowUtils.java:354) at org.eclipse.wb.core.eval.ExecutionFlowUtils.visitStatement(ExecutionFlowUtils.java:315) at org.eclipse.wb.core.eval.ExecutionFlowUtils.visitStatement0(ExecutionFlowUtils.java:336) at org.eclipse.wb.core.eval.ExecutionFlowUtils.visitStatement(ExecutionFlowUtils.java:315) at org.eclipse.wb.core.eval.ExecutionFlowUtils.visit(ExecutionFlowUtils.java:247) at org.eclipse.wb.core.eval.ExecutionFlowUtils.visit(ExecutionFlowUtils.java:228) at org.eclipse.wb.core.eval.ExecutionFlowUtils$1.endVisit(ExecutionFlowUtils.java:421) at org.eclipse.wb.core.eval.ExecutionFlowUtils$1.intercept(ExecutionFlowUtils.java:389) at org.eclipse.jdt.core.dom.ASTVisitor$$EnhancerByCGLIB$$55689ef6.endVisit(<generated>) at org.eclipse.jdt.core.dom.ClassInstanceCreation.accept0(ClassInstanceCreation.java:316) at org.eclipse.jdt.core.dom.ASTNode.accept(ASTNode.java:2711) at org.eclipse.jdt.core.dom.ASTNode.acceptChild(ASTNode.java:2759) at org.eclipse.jdt.core.dom.VariableDeclarationFragment.accept0(VariableDeclarationFragment.java:263) at org.eclipse.jdt.core.dom.ASTNode.accept(ASTNode.java:2711) at org.eclipse.jdt.core.dom.ASTNode.acceptChildren(ASTNode.java:2782) at org.eclipse.jdt.core.dom.VariableDeclarationStatement.accept0(VariableDeclarationStatement.java:267) at org.eclipse.jdt.core.dom.ASTNode.accept(ASTNode.java:2711) at org.eclipse.jdt.core.dom.ASTNode.acceptChildren(ASTNode.java:2782) at org.eclipse.jdt.core.dom.Block.accept0(Block.java:137) at org.eclipse.jdt.core.dom.ASTNode.accept(ASTNode.java:2711) at org.eclipse.jdt.core.dom.ASTNode.acceptChild(ASTNode.java:2759) at org.eclipse.jdt.core.dom.TryStatement.accept0(TryStatement.java:250) at org.eclipse.jdt.core.dom.ASTNode.accept(ASTNode.java:2711) at org.eclipse.jdt.core.dom.ASTNode.acceptChildren(ASTNode.java:2782) at org.eclipse.jdt.core.dom.Block.accept0(Block.java:137) at org.eclipse.jdt.core.dom.ASTNode.accept(ASTNode.java:2711) at org.eclipse.jdt.core.dom.ASTNode.acceptChild(ASTNode.java:2759) at org.eclipse.jdt.core.dom.MethodDeclaration.accept0(MethodDeclaration.java:635) at org.eclipse.jdt.core.dom.ASTNode.accept(ASTNode.java:2711) at org.eclipse.jdt.core.dom.ASTNode.acceptChildren(ASTNode.java:2782) at org.eclipse.jdt.core.dom.AnonymousClassDeclaration.accept0(AnonymousClassDeclaration.java:144) at org.eclipse.jdt.core.dom.ASTNode.accept(ASTNode.java:2711) at org.eclipse.jdt.core.dom.ASTNode.acceptChild(ASTNode.java:2759) at org.eclipse.jdt.core.dom.ClassInstanceCreation.accept0(ClassInstanceCreation.java:314) at org.eclipse.jdt.core.dom.ASTNode.accept(ASTNode.java:2711) at org.eclipse.jdt.core.dom.ASTNode.acceptChildren(ASTNode.java:2782) at org.eclipse.jdt.core.dom.MethodInvocation.accept0(MethodInvocation.java:239) at org.eclipse.jdt.core.dom.ASTNode.accept(ASTNode.java:2711) at org.eclipse.jdt.core.dom.ASTNode.acceptChild(ASTNode.java:2759) at org.eclipse.jdt.core.dom.ExpressionStatement.accept0(ExpressionStatement.java:145) at org.eclipse.jdt.core.dom.ASTNode.accept(ASTNode.java:2711) at org.eclipse.wb.core.eval.ExecutionFlowUtils.visitStatement0(ExecutionFlowUtils.java:354) at org.eclipse.wb.core.eval.ExecutionFlowUtils.visitStatement(ExecutionFlowUtils.java:315) at org.eclipse.wb.core.eval.ExecutionFlowUtils.visitStatement0(ExecutionFlowUtils.java:336) at org.eclipse.wb.core.eval.ExecutionFlowUtils.visitStatement(ExecutionFlowUtils.java:315) at org.eclipse.wb.core.eval.ExecutionFlowUtils.visit(ExecutionFlowUtils.java:247) at org.eclipse.wb.core.eval.ExecutionFlowUtils.visit(ExecutionFlowUtils.java:228) at org.eclipse.wb.core.eval.ExecutionFlowUtils.visit(ExecutionFlowUtils.java:191) at org.eclipse.wb.internal.core.parser.JavaInfoParser.parseRootMethods(JavaInfoParser.java:312) at org.eclipse.wb.internal.core.parser.JavaInfoParser.parse(JavaInfoParser.java:268) at org.eclipse.wb.internal.core.parser.JavaInfoParser.access$9(JavaInfoParser.java:238) at org.eclipse.wb.internal.core.parser.JavaInfoParser$1.runObject(JavaInfoParser.java:153) at org.eclipse.wb.internal.core.parser.JavaInfoParser$1.runObject(JavaInfoParser.java:1) at org.eclipse.wb.internal.core.utils.execution.ExecutionUtils.runDesignTime(ExecutionUtils.java:159) at org.eclipse.wb.internal.core.parser.JavaInfoParser.parse(JavaInfoParser.java:151) at org.eclipse.wb.internal.core.editor.DesignPage.internal_refreshGEF(DesignPage.java:534) at org.eclipse.wb.internal.core.editor.DesignPage.access$9(DesignPage.java:522) at org.eclipse.wb.internal.core.editor.DesignPage$8$1.run(DesignPage.java:449) at org.eclipse.swt.widgets.Synchronizer.syncExec(Synchronizer.java:187) at org.eclipse.ui.internal.UISynchronizer.syncExec(UISynchronizer.java:156) at org.eclipse.swt.widgets.Display.syncExec(Display.java:4734) at org.eclipse.wb.internal.core.editor.DesignPage$8.run(DesignPage.java:446) at org.eclipse.jface.operation.ModalContext.runInCurrentThread(ModalContext.java:466) at org.eclipse.jface.operation.ModalContext.run(ModalContext.java:374) at org.eclipse.jface.dialogs.ProgressMonitorDialog.run(ProgressMonitorDialog.java:527) at org.eclipse.wb.internal.core.editor.DesignPage.internal_refreshGEF_withProgress(DesignPage.java:465) at org.eclipse.wb.internal.core.editor.DesignPage.internal_refreshGEF(DesignPage.java:415) at org.eclipse.wb.internal.core.editor.UndoManager.refreshDesignerEditor(UndoManager.java:381) at org.eclipse.wb.internal.core.editor.UndoManager.activate(UndoManager.java:90) at org.eclipse.wb.internal.core.editor.DesignPage.handleActiveState_True(DesignPage.java:263) at org.eclipse.wb.internal.core.editor.DesignPage.handleActiveState(DesignPage.java:241) at org.eclipse.wb.internal.core.editor.multi.DefaultMultiMode.showPage(DefaultMultiMode.java:125) at org.eclipse.wb.internal.core.editor.multi.DefaultMultiMode$1.widgetSelected(DefaultMultiMode.java:63) at org.eclipse.swt.widgets.TypedListener.handleEvent(TypedListener.java:248) at org.eclipse.swt.widgets.EventTable.sendEvent(EventTable.java:84) at org.eclipse.swt.widgets.Display.sendEvent(Display.java:4353) at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1061) at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1085) at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1070) at org.eclipse.swt.widgets.Widget.notifyListeners(Widget.java:782) at org.eclipse.swt.custom.CTabFolder.setSelection(CTabFolder.java:3110) at org.eclipse.swt.custom.CTabFolder.onMouse(CTabFolder.java:1794) at org.eclipse.swt.custom.CTabFolder$1.handleEvent(CTabFolder.java:283) at org.eclipse.swt.widgets.EventTable.sendEvent(EventTable.java:84) at org.eclipse.swt.widgets.Display.sendEvent(Display.java:4353) at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1061) at org.eclipse.swt.widgets.Display.runDeferredEvents(Display.java:4172) at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3761) at org.eclipse.e4.ui.internal.workbench.swt.PartRenderingEngine$9.run(PartRenderingEngine.java:1151) at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:332) at org.eclipse.e4.ui.internal.workbench.swt.PartRenderingEngine.run(PartRenderingEngine.java:1032) at org.eclipse.e4.ui.internal.workbench.E4Workbench.createAndRunUI(E4Workbench.java:148) at org.eclipse.ui.internal.Workbench$5.run(Workbench.java:636) at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:332) at org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:579) at org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:150) at org.eclipse.ui.internal.ide.application.IDEApplication.start(IDEApplication.java:135) at org.eclipse.equinox.internal.app.EclipseAppHandle.run(EclipseAppHandle.java:196) at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:134) at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:104) at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:382) at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:236) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) at java.lang.reflect.Method.invoke(Unknown Source) at org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:648) at org.eclipse.equinox.launcher.Main.basicRun(Main.java:603) at org.eclipse.equinox.launcher.Main.run(Main.java:1465)Full context stack trace:java.lang.Error: new JFrame() at org.eclipse.wb.core.eval.AstEvaluationEngine.evaluate(AstEvaluationEngine.java:71) at org.eclipse.wb.internal.core.model.JavaInfoEvaluationHelper.evaluateExpression(JavaInfoEvaluationHelper.java:630) at org.eclipse.wb.internal.core.model.JavaInfoEvaluationHelper.evaluate(JavaInfoEvaluationHelper.java:502) at org.eclipse.wb.internal.core.parser.JavaInfoParser.evaluateNode(JavaInfoParser.java:1309) at org.eclipse.wb.internal.core.parser.JavaInfoParser.access$1(JavaInfoParser.java:1300) at org.eclipse.wb.internal.core.parser.JavaInfoParser$ExecutionFlowParseVisitor$3.run(JavaInfoParser.java:602) at org.eclipse.wb.internal.core.utils.execution.ExecutionUtils.runRethrow(ExecutionUtils.java:119) at org.eclipse.wb.internal.core.parser.JavaInfoParser$ExecutionFlowParseVisitor.postVisit(JavaInfoParser.java:592) at sun.reflect.GeneratedMethodAccessor33.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) at java.lang.reflect.Method.invoke(Unknown Source) at org.eclipse.wb.core.eval.ExecutionFlowUtils$1.intercept(ExecutionFlowUtils.java:399) at org.eclipse.jdt.core.dom.ASTVisitor$$EnhancerByCGLIB$$55689ef6.postVisit(<generated>) at org.eclipse.jdt.core.dom.ASTNode.accept(ASTNode.java:2714) at org.eclipse.jdt.core.dom.ASTNode.acceptChild(ASTNode.java:2759) at org.eclipse.jdt.core.dom.Assignment.accept0(Assignment.java:313) at org.eclipse.jdt.core.dom.ASTNode.accept(ASTNode.java:2711) at org.eclipse.jdt.core.dom.ASTNode.acceptChild(ASTNode.java:2759) at org.eclipse.jdt.core.dom.ExpressionStatement.accept0(ExpressionStatement.java:145) at org.eclipse.jdt.core.dom.ASTNode.accept(ASTNode.java:2711) at org.eclipse.wb.core.eval.ExecutionFlowUtils.visitStatement0(ExecutionFlowUtils.java:354) at org.eclipse.wb.core.eval.ExecutionFlowUtils.visitStatement(ExecutionFlowUtils.java:315) at org.eclipse.wb.core.eval.ExecutionFlowUtils.visitStatement0(ExecutionFlowUtils.java:336) at org.eclipse.wb.core.eval.ExecutionFlowUtils.visitStatement(ExecutionFlowUtils.java:315) at org.eclipse.wb.core.eval.ExecutionFlowUtils.visit(ExecutionFlowUtils.java:247) at org.eclipse.wb.core.eval.ExecutionFlowUtils.access$1(ExecutionFlowUtils.java:235) at org.eclipse.wb.core.eval.ExecutionFlowUtils$1.endVisit(ExecutionFlowUtils.java:442) at org.eclipse.wb.core.eval.ExecutionFlowUtils$1.intercept(ExecutionFlowUtils.java:391) at org.eclipse.jdt.core.dom.ASTVisitor$$EnhancerByCGLIB$$55689ef6.endVisit(<generated>) at org.eclipse.jdt.core.dom.MethodInvocation.accept0(MethodInvocation.java:241) at org.eclipse.jdt.core.dom.ASTNode.accept(ASTNode.java:2711) at org.eclipse.jdt.core.dom.ASTNode.acceptChild(ASTNode.java:2759) at org.eclipse.jdt.core.dom.ExpressionStatement.accept0(ExpressionStatement.java:145) at org.eclipse.jdt.core.dom.ASTNode.accept(ASTNode.java:2711) at org.eclipse.wb.core.eval.ExecutionFlowUtils.visitStatement0(ExecutionFlowUtils.java:354) at org.eclipse.wb.core.eval.ExecutionFlowUtils.visitStatement(ExecutionFlowUtils.java:315) at org.eclipse.wb.core.eval.ExecutionFlowUtils.visitStatement0(ExecutionFlowUtils.java:336) at org.eclipse.wb.core.eval.ExecutionFlowUtils.visitStatement(ExecutionFlowUtils.java:315) at org.eclipse.wb.core.eval.ExecutionFlowUtils.visit(ExecutionFlowUtils.java:247) at org.eclipse.wb.core.eval.ExecutionFlowUtils.visit(ExecutionFlowUtils.java:228) at org.eclipse.wb.core.eval.ExecutionFlowUtils$1.endVisit(ExecutionFlowUtils.java:421) at org.eclipse.wb.core.eval.ExecutionFlowUtils$1.intercept(ExecutionFlowUtils.java:389) at org.eclipse.jdt.core.dom.ASTVisitor$$EnhancerByCGLIB$$55689ef6.endVisit(<generated>) at org.eclipse.jdt.core.dom.ClassInstanceCreation.accept0(ClassInstanceCreation.java:316) at org.eclipse.jdt.core.dom.ASTNode.accept(ASTNode.java:2711) at org.eclipse.jdt.core.dom.ASTNode.acceptChild(ASTNode.java:2759) at org.eclipse.jdt.core.dom.VariableDeclarationFragment.accept0(VariableDeclarationFragment.java:263) at org.eclipse.jdt.core.dom.ASTNode.accept(ASTNode.java:2711) at org.eclipse.jdt.core.dom.ASTNode.acceptChildren(ASTNode.java:2782) at org.eclipse.jdt.core.dom.VariableDeclarationStatement.accept0(VariableDeclarationStatement.java:267) at org.eclipse.jdt.core.dom.ASTNode.accept(ASTNode.java:2711) at org.eclipse.jdt.core.dom.ASTNode.acceptChildren(ASTNode.java:2782) at org.eclipse.jdt.core.dom.Block.accept0(Block.java:137) at org.eclipse.jdt.core.dom.ASTNode.accept(ASTNode.java:2711) at org.eclipse.jdt.core.dom.ASTNode.acceptChild(ASTNode.java:2759) at org.eclipse.jdt.core.dom.TryStatement.accept0(TryStatement.java:250) at org.eclipse.jdt.core.dom.ASTNode.accept(ASTNode.java:2711) at org.eclipse.jdt.core.dom.ASTNode.acceptChildren(ASTNode.java:2782) at org.eclipse.jdt.core.dom.Block.accept0(Block.java:137) at org.eclipse.jdt.core.dom.ASTNode.accept(ASTNode.java:2711) at org.eclipse.jdt.core.dom.ASTNode.acceptChild(ASTNode.java:2759) at org.eclipse.jdt.core.dom.MethodDeclaration.accept0(MethodDeclaration.java:635) at org.eclipse.jdt.core.dom.ASTNode.accept(ASTNode.java:2711) at org.eclipse.jdt.core.dom.ASTNode.acceptChildren(ASTNode.java:2782) at org.eclipse.jdt.core.dom.AnonymousClassDeclaration.accept0(AnonymousClassDeclaration.java:144) at org.eclipse.jdt.core.dom.ASTNode.accept(ASTNode.java:2711) at org.eclipse.jdt.core.dom.ASTNode.acceptChild(ASTNode.java:2759) at org.eclipse.jdt.core.dom.ClassInstanceCreation.accept0(ClassInstanceCreation.java:314) at org.eclipse.jdt.core.dom.ASTNode.accept(ASTNode.java:2711) at org.eclipse.jdt.core.dom.ASTNode.acceptChildren(ASTNode.java:2782) at org.eclipse.jdt.core.dom.MethodInvocation.accept0(MethodInvocation.java:239) at org.eclipse.jdt.core.dom.ASTNode.accept(ASTNode.java:2711) at org.eclipse.jdt.core.dom.ASTNode.acceptChild(ASTNode.java:2759) at org.eclipse.jdt.core.dom.ExpressionStatement.accept0(ExpressionStatement.java:145) at org.eclipse.jdt.core.dom.ASTNode.accept(ASTNode.java:2711) at org.eclipse.wb.core.eval.ExecutionFlowUtils.visitStatement0(ExecutionFlowUtils.java:354) at org.eclipse.wb.core.eval.ExecutionFlowUtils.visitStatement(ExecutionFlowUtils.java:315) at org.eclipse.wb.core.eval.ExecutionFlowUtils.visitStatement0(ExecutionFlowUtils.java:336) at org.eclipse.wb.core.eval.ExecutionFlowUtils.visitStatement(ExecutionFlowUtils.java:315) at org.eclipse.wb.core.eval.ExecutionFlowUtils.visit(ExecutionFlowUtils.java:247) at org.eclipse.wb.core.eval.ExecutionFlowUtils.visit(ExecutionFlowUtils.java:228) at org.eclipse.wb.core.eval.ExecutionFlowUtils.visit(ExecutionFlowUtils.java:191) at org.eclipse.wb.internal.core.parser.JavaInfoParser.parseRootMethods(JavaInfoParser.java:312) at org.eclipse.wb.internal.core.parser.JavaInfoParser.parse(JavaInfoParser.java:268) at org.eclipse.wb.internal.core.parser.JavaInfoParser.access$9(JavaInfoParser.java:238) at org.eclipse.wb.internal.core.parser.JavaInfoParser$1.runObject(JavaInfoParser.java:153) at org.eclipse.wb.internal.core.parser.JavaInfoParser$1.runObject(JavaInfoParser.java:1) at org.eclipse.wb.internal.core.utils.execution.ExecutionUtils.runDesignTime(ExecutionUtils.java:159) at org.eclipse.wb.internal.core.parser.JavaInfoParser.parse(JavaInfoParser.java:151) at org.eclipse.wb.internal.core.editor.DesignPage.internal_refreshGEF(DesignPage.java:534) at org.eclipse.wb.internal.core.editor.DesignPage.access$9(DesignPage.java:522) at org.eclipse.wb.internal.core.editor.DesignPage$8$1.run(DesignPage.java:449) at org.eclipse.swt.widgets.Synchronizer.syncExec(Synchronizer.java:187) at org.eclipse.ui.internal.UISynchronizer.syncExec(UISynchronizer.java:156) at org.eclipse.swt.widgets.Display.syncExec(Display.java:4734) at org.eclipse.wb.internal.core.editor.DesignPage$8.run(DesignPage.java:446) at org.eclipse.jface.operation.ModalContext.runInCurrentThread(ModalContext.java:466) at org.eclipse.jface.operation.ModalContext.run(ModalContext.java:374) at org.eclipse.jface.dialogs.ProgressMonitorDialog.run(ProgressMonitorDialog.java:527) at org.eclipse.wb.internal.core.editor.DesignPage.internal_refreshGEF_withProgress(DesignPage.java:465) at org.eclipse.wb.internal.core.editor.DesignPage.internal_refreshGEF(DesignPage.java:415) at org.eclipse.wb.internal.core.editor.UndoManager.refreshDesignerEditor(UndoManager.java:381) at org.eclipse.wb.internal.core.editor.UndoManager.activate(UndoManager.java:90) at org.eclipse.wb.internal.core.editor.DesignPage.handleActiveState_True(DesignPage.java:263) at org.eclipse.wb.internal.core.editor.DesignPage.handleActiveState(DesignPage.java:241) at org.eclipse.wb.internal.core.editor.multi.DefaultMultiMode.showPage(DefaultMultiMode.java:125) at org.eclipse.wb.internal.core.editor.multi.DefaultMultiMode$1.widgetSelected(DefaultMultiMode.java:63) at org.eclipse.swt.widgets.TypedListener.handleEvent(TypedListener.java:248) at org.eclipse.swt.widgets.EventTable.sendEvent(EventTable.java:84) at org.eclipse.swt.widgets.Display.sendEvent(Display.java:4353) at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1061) at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1085) at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1070) at org.eclipse.swt.widgets.Widget.notifyListeners(Widget.java:782) at org.eclipse.swt.custom.CTabFolder.setSelection(CTabFolder.java:3110) at org.eclipse.swt.custom.CTabFolder.onMouse(CTabFolder.java:1794) at org.eclipse.swt.custom.CTabFolder$1.handleEvent(CTabFolder.java:283) at org.eclipse.swt.widgets.EventTable.sendEvent(EventTable.java:84) at org.eclipse.swt.widgets.Display.sendEvent(Display.java:4353) at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1061) at org.eclipse.swt.widgets.Display.runDeferredEvents(Display.java:4172) at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3761) at org.eclipse.e4.ui.internal.workbench.swt.PartRenderingEngine$9.run(PartRenderingEngine.java:1151) at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:332) at org.eclipse.e4.ui.internal.workbench.swt.PartRenderingEngine.run(PartRenderingEngine.java:1032) at org.eclipse.e4.ui.internal.workbench.E4Workbench.createAndRunUI(E4Workbench.java:148) at org.eclipse.ui.internal.Workbench$5.run(Workbench.java:636) at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:332) at org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:579) at org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:150) at org.eclipse.ui.internal.ide.application.IDEApplication.start(IDEApplication.java:135) at org.eclipse.equinox.internal.app.EclipseAppHandle.run(EclipseAppHandle.java:196) at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:134) at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:104) at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:382) at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:236) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) at java.lang.reflect.Method.invoke(Unknown Source) at org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:648) at org.eclipse.equinox.launcher.Main.basicRun(Main.java:603) at org.eclipse.equinox.launcher.Main.run(Main.java:1465)Caused by: java.lang.NullPointerException at java.beans.MethodRef.get(Unknown Source) at java.beans.PropertyDescriptor.getWriteMethod(Unknown Source) at org.eclipse.wb.internal.core.model.JavaInfoUtils.addExposedChildred_Method(JavaInfoUtils.java:447) at org.eclipse.wb.internal.core.model.JavaInfoUtils.addExposedChildren(JavaInfoUtils.java:429) at org.eclipse.wb.internal.swing.model.component.ComponentInfo.createExposedChildren(ComponentInfo.java:109) at org.eclipse.wb.internal.swing.model.component.ContainerInfo.createExposedChildren(ContainerInfo.java:143) at org.eclipse.wb.core.model.JavaInfo.initialize(JavaInfo.java:423) at org.eclipse.wb.internal.swing.model.component.ContainerInfo.initialize(ContainerInfo.java:114) at org.eclipse.wb.core.model.JavaInfo.setObject(JavaInfo.java:1288) at org.eclipse.wb.internal.core.model.JavaInfoEvaluationHelper$3.evaluationSuccessful(JavaInfoEvaluationHelper.java:271) at org.eclipse.wb.core.eval.AstEvaluationEngine.evaluate0(AstEvaluationEngine.java:179) at org.eclipse.wb.core.eval.AstEvaluationEngine.evaluate(AstEvaluationEngine.java:61) ... 142 more<<<END_MSGJava Version is 1.8.0_20Eclipse Juno (4.4.0) Build id: 20140612-0600OS: Windows 8.1	Unable to reproduce based on the information provide. Please provide a test case as well as all associated logs.CreatedApplication which demonstrates some Swing techniques.SwingBuilder problem showed up right from the beginning. You simply need to open the source file with SwingBuilder in designer view, switch to code view and change something, then switch back to designer view. When trying to parse the code, SwingBuilder will crash (at least, on my system).Project exhibiting bug added	3.0
id=436279	REOPENED	Xtend	Core	2.6.0	PC Linux	P3 normal	Project Inbox	2014-05-31 08:15 EDT by	Victor Noël	2014-06-01 12:15 EDT (	2 users	Hi,I got this very surprising behaviour of xtend with the java generated code:class BugsIfElse { def test() { val r = if (true) { 1 } else { 2 }.m } def m(int x) { x + 5 } }generates to:@SuppressWarnings("all")public class BugsIfElse { public void test() { int _xifexpression = (int) 0; if (true) { _xifexpression = 1; } else { _xifexpression = this.m( 2); } final int r = _xifexpression; } public int m(final int x) { return (x + 5); }}As you can see, the call to m is applied to the content of the else block, and not to the result of the complete if/else block.	you call m on the block expression. That's how the precedence is defined.You need to use parenthesis if you want to apply m on the if expression's result. def test() { val r = (if (true) { 1 } else { 2 }).m }Hi,I know that yes, but the "bug" is that it is very surprising and can lead to errors not seen by the user.It doesn't seem natural at all!Maybe we could add a warning about it or prevent such situation from happening?Maybe we could optionally validate MemberFeatureCalls in else-branches that have a block expression as their target? That validation could be refined if more of these irritations come up.Reopened to discuss that issue.	3.0
id=436567	REOPENED	Xtend	Core	2.6.0	PC Mac OS X	P3 enhancement	Project Inbox	2014-06-04 08:27 EDT by	Sven Efftinge	2016-06-10 05:56 EDT (	3 users	Currently when the code runs through the synthetic dispatch method the editor jumps for each case to the corresponding signature, which is annoying.	pushed to review:improved for trace as primary source; dispatcher method marked as synthetic and can be filtered out by step filtering (Filter synthetic methods)pushed to review:rolled back:Synthetic methods are not accessible from Java.A request to JDT has been created to provide step filtering customization:Eventually we could make use of the new step filter extension point.	5.0
id=439506	REOPENED	Xtend	Core	2.6.0	PC Windows 7	P3 enhancement	Project Inbox	2014-07-14 03:23 EDT by	Stefan Oehme	2014-07-18 12:10 EDT (	0 users	I often find myself combining data from Iterables which are correlated by their index.<A, B> Iterable<Pair<A,B>> zip(Iterable<? extends A> first, Iterable<? extends B> second)The nth Pair is obtained by taking the nth element from both Iterables. The resulting Iterable is truncated to the length of the shorter Iterable. This could of course be generalized for a variable number of Iterables, but we don't have n-Tuples yet.Zipping an Iterable with the indices of its elements is especially useful for replacing a traditional for-loop with map/reduce/filter. <T> Iterable<Pair<T, Integer>> zipWithIndex(Iterable<? extends T> iterable)	Merged into masterWe decided to remove zip again for now, since the API isn't really nice without tuples and destructuring syntax. We renamed zipWithIndex() to just indexed() and flipped the type arguments around, since it makes sense for the index to be the key.	2.0
id=444437	REOPENED	Xtend	Core	2.8.0	PC Mac OS X	P3 normal	Project Inbox	2014-09-18 05:15 EDT by	Sven Efftinge	2016-06-10 05:56 EDT (	2 users	Currently during code generation the source tree is passed in and there's no way to navigate to the target Java tree.I think we should change this to be the same as in ValidationParticipant.	Pushed to reviewI'm not convinced by this change. Also it appears to be incomplete, unfortunately.This is how the CodeGenerationParticipant is currently described:/** * Invoked by the compiler during the code generation phase. * * @param annotatedSourceElements the immutable source representation (i.e. the Xtend AST) of the annotated elements * @param context a {@link TransformationContext} providing useful services. */void doGenerateCode(List<? extends T> annotatedSourceElements, @Extension CodeGenerationContext context);Emphasize is on the parameter name 'annotatedSourceElements' and the described semantics.Changing that will introduce the problem that there may no longer be any target elements, since the AA processor may have removed all associations. Also it's not clear what the type parameter T should be in case the processor created different kinds of elements and doesn't have a primary generated Java element. This problem also applies to the validation participant.I'd rather add #getAllGeneratedJavaElements to the Tracibility service and pass the source elements to both the validation participant and the code generation participant. This would make the contract for the impl clearer.You are right about the problematic corner cases, so passing in the annotated source elements would be correct. I'd like to skip the 'All' and go with getGeneratedJavaElements. Also Tracability#getPrimaryGeneratedJavaElement(Element) is typed to Element which makes it super inconvenient to work with. We should change it to be parameterized i.e. what goes in goes out, which means we cannot rely on the fuzzy contract to consider the first associated element being the primary. Instead we need to mark the element that was translated from the primary Xtend compiler explicitly. As a result it could be that getPrimaryJavaElement returns null while getJavaElements doesn't return an empty list.(In reply to Sven Efftinge from)How would that parametrization look like? I think anything can be marked as 'primary' element, being it a class inferred from an formal parameter or a field inferred from a method.Should that be <E extends Element> E getPrimaryGeneratedJavaElement(Element in, Class<E> c). Or the unsafe version of <E extends Element> E getPrimaryGeneratedJavaElement(Element in)?(In reply to Sebastian Zarnekow from)I meant that only the XtendCompiler marks elements as primary.So I think it could be <E extends Element> E getPrimaryGeneratedJavaElement(E in)(In reply to Sven Efftinge from)I see, there wouldn't be an AA API that allows to mark an element as primary. I'm not sure how this aligns with other features like find references, where we use the "primary" element on the JVM side to find the references to a declaration.(In reply to Sebastian Zarnekow from)I think having an explicit API is the way to go as suggested in.	7.0
id=458727	REOPENED	Xtend	Core	2.7.3	PC Windows 7	P3 normal	Project Inbox	2015-01-29 07:03 EST by	Joerg Reichert	2015-02-25 03:01 EST (	3 users	follwing Xtend file package other/** * Demonstration for PlantUML. * <p> * Example of use: * <p> * <img src="Other.png"> *//* * @startuml * Bob -> Alice : hello * Alice --> Bob : OK * @enduml */class Other { }is generated topackage other;/** * @startuml * Bob -> Alice : hello * Alice --> Bob : OK * @enduml */@SuppressWarnings("all")public class Other {}	Preliminary scheduled for 2.8. Could you propose a patch?Yes, I can try to submit a patch.Current work around is to just reorder the comments.The patch would be to distinguish between the two type of comments and only take the first JavaDoc comment ahead. For single line comments this already works:/** * jd */// slclass A {}is compiled to/** * jd */public class A {}The patch should be fairly simple. I assume only a few regular expressions need to be adjusted to only support /** */ style comments as JavaDoc.Gerrit changewas merged to [master].Commit:Merged into master. Thanks JörgSorry, my bad. The commit seems to have been reverted.	6.0
id=461239	REOPENED	Xtend	Core	2.7.3	PC Windows 7	P3 normal	Project Inbox	2015-03-02 15:47 EST by	Stephan Herrmann	2016-06-10 05:56 EDT (	2 users	In my parent pom I have this in the <build> section: <plugin> <groupId>org.apache.maven.plugins</groupId> <artifactId>maven-toolchains-plugin</artifactId> <version>1.0</version> <executions> <execution> <phase>validate</phase> <goals> <goal>toolchain</goal> </goals> </execution> </executions> <configuration> <toolchains> <jdk> <id>JavaSE-1.7</id> </jdk> </toolchains> </configuration> </plugin>A toolchains.xml with matching entries exists in ${user.dir}/.m2Additionally, in <pluginManagement> I tell tycho to respect the BREE of each individual plugin being built (some plugins still use JavaSE-1.6): <plugin> <groupId>org.eclipse.tycho</groupId> <artifactId>tycho-compiler-plugin</artifactId> <version>0.21.0</version> <configuration> <useJDK>BREE</useJDK> </configuration> </plugin>A module pom, inheriting from this parent pom, uses the xtend-maven-plugin (2.7.3) with no specific configuration other than setting an outputDirectory.This plugin has a BREE of JavaSE-1.6 (and a corresponding toolchains.xml entry exists for this, too).When running the Maven build on Java 8, xtend-maven-plugin *could* decide to use the global default jdk as per the maven-toolchains-plugin configuration (1.7), it *should* actually consult the individual plugin's BREE (1.6), but it creates code using API from Java 8 (java.util.function.Consumer), which later fails the Java compiler in the same build (which recognizes the BREE).When running the build on Java 7, all is well. But if one of my plugins would move up to Java 8, may become impossible.Strange enough, the problem is reproducible in one project (DSL), and does not occur in another project with similar structure. I'm still looking for any relevant differences ...	(In reply to Stephan Herrmann from)I found the difference, not a configuration difference though. The second project simply didn't contain any code pattern that would cause xtend to use Java 8 API.Inserting this snippet causes the same bug also in the second project:static class Person { String name; Integer age } private static def mapAll(Map<String, Integer> map, EList<Person> values) { values?.forEach(v|map.put(v.name, v.age)) map}Could you also attach your toolchains.xml?Preliminary scheduled for 2.8 for investigation.(In reply to Stefan Oehme from)Today I don't have access to that project. The toolchains.xml has entries for JavaSE-1.6 and JavaSE-1.7, which both are recognized and respected by tycho.One thing I remember: despite the element name <jdkHome> this thing needs to point to a JRE in order to be picked up correctly. So, if xtend-maven-plugin expects a path to a JDK indeed, this could already explain: different maven plugins differently interpreting this path? In that case I wouldn't know, who's right and who's wrong...We expect a JDK layout by default, just like the maven-java-compiler. You can explicitly specify a different layout by adding something like:<bootClassPath> <includes> <include>lib/*</include> <include>lib/ext/*</include> <include>lib/endorsed/*</include> </includes></bootClassPath>to the configuration of your toolchain. This is respected both by xtend and tycho.It's unfortunate that Tycho uses the wrong layout by default, the property is clearly named "jdkHome".(In reply to Stefan Oehme from)Thanks! I'll try it tomorrow and report back here.(In reply to Stephan Herrmann from)Hi Stephan, did you find the time to look into this?(In reply to Sebastian Zarnekow from)Sorry, not yet. Re-scheduling for tomorrow.The hint fromindeed works around the problem, thanks!It's a pity indeed, that tycho uses a default layout which is incompatible with xtend-maven-plugin - and probably wrong (but maybe they have reasons?). Do you know if a bug has been filed against tycho?When I was searching for a solution I took me a while to find any official documentation for xtend-maven-plugin. The help bundled with Eclipse doesn't seem to know about this, and also onI found nothing.Given the importance of tycho in Eclipse land, maybe you want to add a warning about this incompatibility to the documentation?Changing this into a documentation ticket. Thanks for reporting back =)Either we do this eventually I we close this as won't fix. Unfortunately I don't know what's exactly to be done.(In reply to Sebastian Zarnekow from)A word on the incompatibility with tycho's default plus a hint a lawould go a long way already, IMHO.Plus, of course, (a findable link to) documentation for all configuration options of xtend-maven-plugin :)I was asked via email, how to make this work for Java 8. From that email I see that the info in this bug can still be misunderstood:The suggestion inassumes that jdkHome in your toolchains.xml actually points to a JRE, and the includes tell xtend where to find the necessary libraries, *despite* the non-standard reference.Consistency can easily be checked by inspecting that folders lib/ lib/ext/ and lib/endorsed/ actually exist below the path given as jdkHome.Right?	13.0
id=463069	REOPENED	Xtend	Core	2.8.0	PC Linux	P3 normal	Project Inbox	2015-03-25 06:16 EDT by	Christoph Kulla	2016-11-16 09:29 EST (	5 users	When using the xtend-maven-plugin I get a lot of warnings for failing downloads from oss.sonatype.org. This happens because I'm behind a proxy and can not reach oss.sonatype.org. We have internal mirrors of all required maven and p2 repositories. Why is the xtend maven plugin downloading stuff from sonatype snapshots? I don't have the repo configured anywhere in my project. So I wonder why it tries to do this. Is there a way to get around these downloads so I get rid of the warnings in my log?[INFO] --- xtend-maven-plugin:2.8.0:compile (default) @ XXX.util ---Downloading:Downloading:[WARNING] Could not transfer metadata com.google.guava:guava/maven-metadata.xml from/to central snapshots (): oss.sonatype.org: No address associated with hostname[WARNING] Could not transfer metadata com.google.guava:guava/maven-metadata.xml from/to sonatype-nexus-snapshots (): oss.sonatype.orgDownloading:Downloading:[WARNING] Could not transfer metadata org.eclipse.xtend:org.eclipse.xtend.core/maven-metadata.xml from/to central snapshots (): oss.sonatype.org[WARNING] Could not transfer metadata org.eclipse.xtend:org.eclipse.xtend.core/maven-metadata.xml from/to sonatype-nexus-snapshots (): oss.sonatype.orgDownloading:Downloading:[WARNING] Could not transfer metadata org.eclipse.xtext:org.eclipse.xtext.xbase/maven-metadata.xml from/to central snapshots (): oss.sonatype.org[WARNING] Could not transfer metadata org.eclipse.xtext:org.eclipse.xtext.xbase/maven-metadata.xml from/to sonatype-nexus-snapshots (): oss.sonatype.orgDownloading:Downloading:[WARNING] Could not transfer metadata org.eclipse.xtext:org.eclipse.xtext/maven-metadata.xml from/to central snapshots (): oss.sonatype.org[WARNING] Could not transfer metadata org.eclipse.xtext:org.eclipse.xtext/maven-metadata.xml from/to sonatype-nexus-snapshots (): oss.sonatype.orgDownloading:Downloading:[WARNING] Could not transfer metadata org.eclipse.xtext:org.eclipse.xtext.util/maven-metadata.xml from/to central snapshots (): oss.sonatype.org[WARNING] Could not transfer metadata org.eclipse.xtext:org.eclipse.xtext.util/maven-metadata.xml from/to sonatype-nexus-snapshots (): oss.sonatype.org[WARNING] Failure to transfer com.google.guava:guava/maven-metadata.xml fromwas cached in the local repository, resolution will not be reattempted until the update interval of central snapshots has elapsed or updates are forced. Original error: Could not transfer metadata com.google.guava:guava/maven-metadata.xml from/to central snapshots (): oss.sonatype.org: No address associated with hostname[WARNING] Failure to transfer com.google.guava:guava/maven-metadata.xml fromwas cached in the local repository, resolution will not be reattempted until the update interval of sonatype-nexus-snapshots has elapsed or updates are forced. Original error: Could not transfer metadata com.google.guava:guava/maven-metadata.xml from/to sonatype-nexus-snapshots (): oss.sonatype.orgDownloading:Downloading:[WARNING] Could not transfer metadata org.eclipse.emf:org.eclipse.emf.ecore/maven-metadata.xml from/to central snapshots (): oss.sonatype.org[WARNING] Could not transfer metadata org.eclipse.emf:org.eclipse.emf.ecore/maven-metadata.xml from/to sonatype-nexus-snapshots (): oss.sonatype.orgDownloading:Downloading:[WARNING] Could not transfer metadata org.eclipse.emf:org.eclipse.emf.common/maven-metadata.xml from/to central snapshots (): oss.sonatype.org[WARNING] Could not transfer metadata org.eclipse.emf:org.eclipse.emf.common/maven-metadata.xml from/to sonatype-nexus-snapshots (): oss.sonatype.orgDownloading:Downloading:[WARNING] Could not transfer metadata org.eclipse.xtext:org.eclipse.xtext.dependencies/maven-metadata.xml from/to central snapshots (): oss.sonatype.org[WARNING] Could not transfer metadata org.eclipse.xtext:org.eclipse.xtext.dependencies/maven-metadata.xml from/to sonatype-nexus-snapshots (): oss.sonatype.orgDownloading:Downloading:[WARNING] Could not transfer metadata org.eclipse.xtext:org.eclipse.xtext.xbase.lib/maven-metadata.xml from/to central snapshots (): oss.sonatype.org[WARNING] Could not transfer metadata org.eclipse.xtext:org.eclipse.xtext.xbase.lib/maven-metadata.xml from/to sonatype-nexus-snapshots (): oss.sonatype.org[WARNING] Failure to transfer org.eclipse.emf:org.eclipse.emf.ecore/maven-metadata.xml fromwas cached in the local repository, resolution will not be reattempted until the update interval of central snapshots has elapsed or updates are forced. Original error: Could not transfer metadata org.eclipse.emf:org.eclipse.emf.ecore/maven-metadata.xml from/to central snapshots (): oss.sonatype.org[WARNING] Failure to transfer org.eclipse.emf:org.eclipse.emf.ecore/maven-metadata.xml fromwas cached in the local repository, resolution will not be reattempted until the update interval of sonatype-nexus-snapshots has elapsed or updates are forced. Original error: Could not transfer metadata org.eclipse.emf:org.eclipse.emf.ecore/maven-metadata.xml from/to sonatype-nexus-snapshots (): oss.sonatype.org[WARNING] Failure to transfer org.eclipse.emf:org.eclipse.emf.common/maven-metadata.xml fromwas cached in the local repository, resolution will not be reattempted until the update interval of central snapshots has elapsed or updates are forced. Original error: Could not transfer metadata org.eclipse.emf:org.eclipse.emf.common/maven-metadata.xml from/to central snapshots (): oss.sonatype.org[WARNING] Failure to transfer org.eclipse.emf:org.eclipse.emf.common/maven-metadata.xml fromwas cached in the local repository, resolution will not be reattempted until the update interval of sonatype-nexus-snapshots has elapsed or updates are forced. Original error: Could not transfer metadata org.eclipse.emf:org.eclipse.emf.common/maven-metadata.xml from/to sonatype-nexus-snapshots (): oss.sonatype.orgDownloading:Downloading:[WARNING] Could not transfer metadata org.eclipse.emf:org.eclipse.emf.ecore.xmi/maven-metadata.xml from/to central snapshots (): oss.sonatype.org[WARNING] Could not transfer metadata org.eclipse.emf:org.eclipse.emf.ecore.xmi/maven-metadata.xml from/to sonatype-nexus-snapshots (): oss.sonatype.orgDownloading:Downloading:[WARNING] Could not transfer metadata org.antlr:antlr-runtime/maven-metadata.xml from/to central snapshots (): oss.sonatype.org[WARNING] Could not transfer metadata org.antlr:antlr-runtime/maven-metadata.xml from/to sonatype-nexus-snapshots (): oss.sonatype.orgDownloading:Downloading:[WARNING] Could not transfer metadata org.eclipse.xtend:org.eclipse.xtend.lib/maven-metadata.xml from/to central snapshots (): oss.sonatype.org[WARNING] Could not transfer metadata org.eclipse.xtend:org.eclipse.xtend.lib/maven-metadata.xml from/to sonatype-nexus-snapshots (): oss.sonatype.orgDownloading:Downloading:[WARNING] Could not transfer metadata org.eclipse.xtext:org.eclipse.xtext.common.types/maven-metadata.xml from/to central snapshots (): oss.sonatype.org[WARNING] Could not transfer metadata org.eclipse.xtext:org.eclipse.xtext.common.types/maven-metadata.xml from/to sonatype-nexus-snapshots (): oss.sonatype.orgDownloading:Downloading:[WARNING] Could not transfer metadata org.eclipse.emf:org.eclipse.emf.codegen/maven-metadata.xml from/to central snapshots (): oss.sonatype.org[WARNING] Could not transfer metadata org.eclipse.emf:org.eclipse.emf.codegen/maven-metadata.xml from/to sonatype-nexus-snapshots (): oss.sonatype.org	To be investigated for 2.8.2We have a repository declaration towards sonatype snapshots in our parent POM. I guess it was added because at some point we were linking against some EMF snapshots. But it definitely should not be in the published POM on Maven Central.(In reply to Stefan Oehme from)I would not say 'definitely should not' here. It's pretty common to share extra repository entries, especially when a plugin depends on some artifacts from 3rd party bits which are not in maven central.We still run builds and tests against snapshot repositories, as well as some of our users. We can probably hide them when releasing, but they should _definitely_ stay in place for snapshot builds.(In reply to Dennis Huebner from)This is discouraged by Sonatye. Everything that goes on Central should have all its dependencies on Central. The only reason for this not being enforced is backwards compatibility. SeeIf a user depends on our Snapshots, then he already has that repository declared. So there is no reason for us to declare it again. On the other hand, if we declare it, we are forcing that repository on all our clients, slowing down builds for everyone.In short: Yes, we can build against Sonatype Snapshots, but we should not declare it in our published POMs.(In reply to Stefan Oehme from)That is not true.Users are working with 2.8.0 and would like to try out a new version 2.9.0-SNAPSHOT. This fails due to a missing sonatype snapshot repo.As already said in #c3, I will try to hide them from the release pom.Moved repository declaration to a profile. Pushed to maintenance branch.Will be merged into master soon.Still see this witch xtend 2.8.300:00:47.648 [INFO] --- xtend-maven-plugin:2.8.3:compile (default) @ xxx ---00:00:47.738 Downloading:00:00:47.800 [WARNING] Could not transfer metadata com.google.guava:guava/maven-metadata.xml from/to sonatype-nexus-snapshots (): oss.sonatype.org: unknown error00:00:47.832 Downloading:00:00:47.835 [WARNING] Could not transfer metadata org.eclipse.xtend:org.eclipse.xtend.core/maven-metadata.xml from/to sonatype-nexus-snapshots (): oss.sonatype.org00:00:47.841 Downloading:00:00:47.841 [WARNING] Could not transfer metadata org.eclipse.xtext:org.eclipse.xtext.xbase/maven-metadata.xml from/to sonatype-nexus-snapshots (): oss.sonatype.org00:00:47.842 Downloading:00:00:47.843 [WARNING] Could not transfer metadata org.eclipse.xtext:org.eclipse.xtext/maven-metadata.xml from/to sonatype-nexus-snapshots (): oss.sonatype.org00:00:47.845 Downloading:00:00:47.846 [WARNING] Could not transfer metadata org.eclipse.xtext:org.eclipse.xtext.util/maven-metadata.xml from/to sonatype-nexus-snapshots (): oss.sonatype.org00:00:47.856 Downloading:00:00:47.856 [WARNING] Could not transfer metadata org.eclipse.emf:org.eclipse.emf.ecore/maven-metadata.xml from/to sonatype-nexus-snapshots (): oss.sonatype.org00:00:47.861 Downloading:00:00:47.862 [WARNING] Could not transfer metadata org.eclipse.emf:org.eclipse.emf.common/maven-metadata.xml from/to sonatype-nexus-snapshots (): oss.sonatype.org00:00:47.871 Downloading:00:00:47.872 [WARNING] Could not transfer metadata org.eclipse.xtext:org.eclipse.xtext.dependencies/maven-metadata.xml from/to sonatype-nexus-snapshots (): oss.sonatype.org00:00:47.875 Downloading:00:00:47.876 [WARNING] Could not transfer metadata org.eclipse.xtext:org.eclipse.xtext.xbase.lib/maven-metadata.xml from/to sonatype-nexus-snapshots (): oss.sonatype.org00:00:47.880 [WARNING] Failure to transfer org.eclipse.emf:org.eclipse.emf.ecore/maven-metadata.xml fromwas cached in the local repository, resolution will not be reattempted until the update interval of sonatype-nexus-snapshots has elapsed or updates are forced. Original error: Could not transfer metadata org.eclipse.emf:org.eclipse.emf.ecore/maven-metadata.xml from/to sonatype-nexus-snapshots (): oss.sonatype.org00:00:47.881 [WARNING] Failure to transfer org.eclipse.emf:org.eclipse.emf.common/maven-metadata.xml fromwas cached in the local repository, resolution will not be reattempted until the update interval of sonatype-nexus-snapshots has elapsed or updates are forced. Original error: Could not transfer metadata org.eclipse.emf:org.eclipse.emf.common/maven-metadata.xml from/to sonatype-nexus-snapshots (): oss.sonatype.org00:00:47.883 Downloading:00:00:47.884 [WARNING] Could not transfer metadata org.eclipse.emf:org.eclipse.emf.ecore.xmi/maven-metadata.xml from/to sonatype-nexus-snapshots (): oss.sonatype.org00:00:47.891 Downloading:00:00:47.892 [WARNING] Could not transfer metadata org.antlr:antlr-runtime/maven-metadata.xml from/to sonatype-nexus-snapshots (): oss.sonatype.org00:00:47.896 Downloading:00:00:47.897 [WARNING] Could not transfer metadata org.eclipse.xtend:org.eclipse.xtend.lib/maven-metadata.xml from/to sonatype-nexus-snapshots (): oss.sonatype.org00:00:47.901 Downloading:00:00:47.901 [WARNING] Could not transfer metadata org.eclipse.xtext:org.eclipse.xtext.common.types/maven-metadata.xml from/to sonatype-nexus-snapshots (): oss.sonatype.org00:00:47.908 Downloading:00:00:47.909 [WARNING] Could not transfer metadata org.eclipse.emf:org.eclipse.emf.codegen/maven-metadata.xml from/to sonatype-nexus-snapshots (): oss.sonatype.org00:00:49.946 [INFO] Using toolchain JDK[/usr/lib/jvm/java-7-oracle]00:00:56.930 [INFO] 00:00:56.931 [INFO] --- maven-resources-plugin:2.4.1:resources (default-resources) @ xxx ---Any news on this?I'm not sure what we can do here in 2.8.4.In 2.8.3, the Snapshot repository URLs were moved in an own profile "snapshot-build" see:(In reply to Dennis Huebner from)Which dependencies do we consume from that repository?is related to this..	11.0
id=471869	REOPENED	Xtend	Core	2.9.0	All All	P3 enhancement	Project Inbox	2015-07-05 07:29 EDT by	Mark Jeronimus	2015-12-09 06:40 EST (	2 users	Tested with:- Stable 2.8.3,- Milestone 2.9.0.v201505«something», and - Beleeding Edge 2.9.0.v201507030734When an Xtend class contains the @Inline annotation, any class using that class can't be compiled using Xtend.class DoubleValue { double d new(double d) { this.d = d println("foo " + foo(this)); } @Inline("123") // This causes error def double foo(DoubleValue dd) { return this.d + dd.d }}Compiling this class causes the error "null - See error log for details" on line 1 of the file.When removing the println from this class, the class compiles fine. Any other class using DoubleValue still can't be compiled, giving the same error on line 1 of the file.When removing only the @Inline line, everything compiles and runs as expected.Full stack trace:org.eclipse.xtext.builder.BuilderParticipant - Error during compilation of 'platform:/resource/temp/src/test/Hewll0World.xtend'.java.lang.ClassCastException: org.eclipse.xtext.common.types.impl.JvmCustomAnnotationValueImpl cannot be cast to org.eclipse.xtext.common.types.JvmStringAnnotationValue at org.eclipse.xtext.xbase.compiler.FeatureCallCompiler.appendInlineFeatureCall(FeatureCallCompiler.java:905) at org.eclipse.xtext.xbase.compiler.FeatureCallCompiler.appendFeatureCall(FeatureCallCompiler.java:855) at org.eclipse.xtext.xbase.compiler.FeatureCallCompiler.featureCalltoJavaExpression(FeatureCallCompiler.java:538) at org.eclipse.xtext.xbase.compiler.FeatureCallCompiler._toJavaStatement(FeatureCallCompiler.java:149) at org.eclipse.xtext.xbase.compiler.FeatureCallCompiler.doInternalToJavaStatement(FeatureCallCompiler.java:108) at org.eclipse.xtext.xbase.compiler.XbaseCompiler.doInternalToJavaStatement(XbaseCompiler.java:358) at org.eclipse.xtend.core.compiler.XtendCompiler.doInternalToJavaStatement(XtendCompiler.java:354) at org.eclipse.xtext.xbase.compiler.AbstractXbaseCompiler.internalToJavaStatement(AbstractXbaseCompiler.java:473) at org.eclipse.xtext.xbase.compiler.XbaseCompiler._toJavaStatement(XbaseCompiler.java:381) at org.eclipse.xtext.xbase.compiler.XbaseCompiler.doInternalToJavaStatement(XbaseCompiler.java:322) at org.eclipse.xtend.core.compiler.XtendCompiler.doInternalToJavaStatement(XtendCompiler.java:354) at org.eclipse.xtext.xbase.compiler.AbstractXbaseCompiler.internalToJavaStatement(AbstractXbaseCompiler.java:473) at org.eclipse.xtext.xbase.compiler.AbstractXbaseCompiler.compile(AbstractXbaseCompiler.java:294) at org.eclipse.xtext.xbase.compiler.AbstractXbaseCompiler.compile(AbstractXbaseCompiler.java:274) at org.eclipse.xtext.xbase.compiler.JvmModelGenerator.compile(JvmModelGenerator.java:1363) at org.eclipse.xtend.core.compiler.XtendGenerator.compile(XtendGenerator.java:245) at org.eclipse.xtext.xbase.compiler.JvmModelGenerator.generateExecutableBody(JvmModelGenerator.java:1329) at org.eclipse.xtext.xbase.compiler.JvmModelGenerator._generateMember(JvmModelGenerator.java:991) at org.eclipse.xtext.xbase.compiler.JvmModelGenerator.generateMember(JvmModelGenerator.java:2130) at org.eclipse.xtext.xbase.compiler.JvmModelGenerator$2.apply(JvmModelGenerator.java:317) at org.eclipse.xtext.xbase.compiler.JvmModelGenerator$2.apply(JvmModelGenerator.java:1) at org.eclipse.xtext.xbase.lib.ObjectExtensions.operator_doubleArrow(ObjectExtensions.java:139) at org.eclipse.xtext.xbase.compiler.LoopExtensions.forEach(LoopExtensions.java:34) at org.eclipse.xtext.xbase.compiler.JvmModelGenerator.generateMembersInBody(JvmModelGenerator.java:321) at org.eclipse.xtend.core.compiler.XtendGenerator.generateMembersInBody(XtendGenerator.java:827) at org.eclipse.xtext.xbase.compiler.JvmModelGenerator._generateBody(JvmModelGenerator.java:276) at org.eclipse.xtext.xbase.compiler.JvmModelGenerator.generateBody(JvmModelGenerator.java:2102) at org.eclipse.xtext.xbase.compiler.JvmModelGenerator.generateType(JvmModelGenerator.java:221) at org.eclipse.xtext.xbase.compiler.JvmModelGenerator._internalDoGenerate(JvmModelGenerator.java:211) at org.eclipse.xtext.xbase.compiler.JvmModelGenerator.internalDoGenerate(JvmModelGenerator.java:2085) at org.eclipse.xtext.xbase.compiler.JvmModelGenerator.doGenerate(JvmModelGenerator.java:192) at org.eclipse.xtend.core.compiler.XtendGenerator.doGenerate(XtendGenerator.java:103) at org.eclipse.xtend.core.compiler.XtendGenerator.doGenerate(XtendGenerator.java:119) at org.eclipse.xtext.generator.GeneratorDelegate.doGenerate(GeneratorDelegate.java:33) at org.eclipse.xtext.builder.ParallelBuilderParticipant.handleChangedContents(ParallelBuilderParticipant.java:136) at org.eclipse.xtext.builder.ParallelBuilderParticipant.handleChangedContents(ParallelBuilderParticipant.java:125) at org.eclipse.xtext.builder.ParallelBuilderParticipant.doGenerate(ParallelBuilderParticipant.java:293) at org.eclipse.xtext.builder.ParallelBuilderParticipant$1.run(ParallelBuilderParticipant.java:259) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) at java.lang.Thread.run(Thread.java:745)	Hi Mark, @Inline is not API and shouldn't be used by anyone (we might remove it some day). That's why it has the @Beta annotation. It is intentional, or at least we know that it doesn't work with Xtend sources.That said we might reconsider that decision or have an alternative recommendation if you tell us why you wanted to use @Inline.Well, three of the features I miss most in Java are-Operator Overloading,-Inlining, and-StructsI thought all these were (at least syntactically*) covered by Xtend when I discovered it a few days ago so I started coding in it right away trying out these new features.Why I particularly want method inlining? Because I want to make data containers in my library for high-performance scientific computing. Currently I inline manyally as much as possible, but this greatly hurts readability and maintainability. On the other hand, making everything function calls hurts performance measurably. Consider a Complex class with public real and imaginary fields and a Mul method.With inlining: c.mulEquals(another)without inlining: val temp = c.re c.re = c.re * another.re - c.im * another.im c.im = temp * another.im + c.im * another.reAbout the @beta. I have been peeking inside source code of many Xtend and Xtext library files, either out of curiosity or out of necessity (finding out where my compile errors come from). I have yet to find a class not tagged with @beta, so I inferred that everything is beta until some major later release.* For speed, I like real structs like unsafe low level memory access, but that will never happen in a JVM. The closest alternatives are Bean classes, @accessible comes to the rescue.Hi Mark,it is simply not true that everything is annotated with @Beta. Actually most of what comes with 'org.eclipse.xtext.xbase.lib' is public (no @Beta). But I understand that it is not clear to figure what kind of '@Beta' we have here. Most often it is some kind of "we want to make this public one day". In the case of @Inline it is not like that. It's really something we invented to make the generated code for the common libs prettier, but especially the value string is a bit too grown and unclear (see the description of all the parameters) to make it public API.Also note, that it is not that we somehow explicitly disabled it for Xtend source. It is just that the annotation values that come from Java code are provided in a different form and we only implemented it for Java-backed annotation values, as we only needed it for that.I am converting this into an enhancement request, and leave it open so others could find it and vote (CC) or comment.	3.0
id=476774	REOPENED	Xtend	Core	2.8.4	PC Mac OS X	P3 normal	Project Inbox	2015-09-07 05:36 EDT by	Jan Koehnlein	2015-09-14 10:42 EDT (	2 users	Convert boolean foo = true & false; // becomes var foo = trueSame for '|', '^'. Sometimes such code is converted into broken Xtend with a missing bitwiseOr/And/Xor operator.	Common case fixed.Need more info about here. An example code would be nice.void foo(int i) { if ((i > 0) & (i <= 127)) System.out.println("Dennis!");}still converted to if ((i > 0).bitwiseAnd((i <= 127))) ...(In reply to Jan Koehnlein from)There is no chance to detect that left/right side expression evaluates to boolean. The only way to detect this, is having a boolean variable declaration or a usage of BooleanLiteral.See org.eclipse.xtend.core.javaconverter.JavaASTFlattener.isBooleanType(Expression)Then how about adding bitwiseOr/And/Xor(boolean, boolean) to the Xbase library?(In reply to Jan Koehnlein from)That would be great! :)But I suppose there where reasons for not having it implemented in org.eclipse.xtext.xbase.lib.BooleanExtensions.(In reply to Dennis Huebner from)The method name would be wrong or only a somewhat bad compromise.	6.0
id=488449	REOPENED	Xtend	Core	2.9.1	PC Mac OS X	P3 normal	Project Inbox	2016-02-25 06:23 EST by	Miro Spoenemann	2016-09-14 13:16 EDT (	1 user	class Test { def test() { val List<Integer> list = newArrayList list += 'foo'.split(',').map[trim] }}This code is accepted without errors by Xtend, leading to a Java error.	is that a problem is collection extensions. should that bepublic static <E> boolean operator_add(Collection<? super E> collection, Iterable<? extends E> newElements) { return addAll(collection, newElements);}GitHub Pull Request 6 created by [cdietrich]fixed in xtext 2.11reopened, reverted fix. has negative impacts on type inference	4.0
id=205442	REOPENED	Target Management	RSE	3.0	PC Windows XP	P3 normal	Xuan Chen	2007-10-04 10:17 EDT by	Xuan Chen	2008-01-17 00:58 EST (	1 user	Search a string in a Archive folder does not work.It is for both DStore and Windows.Right click on a folder inside an archive file, and select Search...The Search dialog is up. Input the string want to search and leave File name pattens as "*"Make sure Search arvhice files and Search Subfolders checkboxes are both checked.Click on Search button.But no result is shown on the Remote Search view. (it should have results)	*** This bug has been marked as a duplicate of***Reopen this bug to track the problem with search in dstore archive file.Search in Local archive file has been fixed through.This problem may related to.With the current fix for this problem, I was able to get search results if # of results is very samll, for example, 2.But for most of the case, I still did not get anything. I added a trace statement in DStoreSearchService#search():if (statusStr.equals("done")) //$NON-NLS-1${ if (status.getNestedSize() > 0){ System.out.println("no need to sleep"); config.setStatus(IHostSearchConstants.FINISHED); } else { // need to wait until we have all results on client try { Thread.sleep(4000); System.out.println("sleep for 4000"); System.out.println("nested side is: " + status.getNestedSize()); } catch (Exception e) { } config.setStatus(IHostSearchConstants.FINISHED); } (I've already changed the sleep time from 2000 to 4000).I could see the following been printed out:sleep for 4000nested side is: 0But if I set a breakpoint on line "Thread.sleep();", breakpoint hit, and then I let it run again, I got the result currectly.And in this case, I only have 11 matches, and they are all in one file.I added the following trace statements:DataElement#addNestedData(), at the end of the method:if (getAttribute(DE.A_TYPE).equals("status")){ if (getParent() != null && getParent().getType().equals("Search")) { System.out.println("this is the status for search, it just updated its nested data, which size is" + _nestedData.size()); System.out.println("current time is " + System.currentTimeMillis()); }}DStoreSearchService#search():if (statusStr.equals("done")) //$NON-NLS-1${ if (status.getNestedSize() > 0){ System.out.println("no need to sleep"); config.setStatus(IHostSearchConstants.FINISHED); } else { // need to wait until we have all results on client try { Thread.sleep(2000); System.out.println("sleep for 2000"); System.out.println("nested side is: " + status.getNestedSize()); } catch (Exception e) { } config.setStatus(IHostSearchConstants.FINISHED); }}DStoreFileSubSystemSearchResultConfiguration#DelayedDomainListenerRemover#run():public void run(){ try { sleep(5000); } catch (Exception e) { } _status.getDataStore().getDomainNotifier().removeDomainListener(_config); System.out.println("Remove demain listener DelayedDomainListenerRemover()"); System.out.println("Remove demain listener time is : " + System.currentTimeMillis()); _config.setStatus(IHostSearchConstants.FINISHED);}And the trace I got for the case where remote search is the following:************************************************inside search of DStoreSearchService(), and before checking the status string, time is: 1200549002689sleep for 2000nested side is: 0Remove demain listener DelayedDomainListenerRemover()Remove demain listener time is : 1200549007689Remove demain listener DelayedDomainListenerRemover()Remove demain listener time is : 1200549007689this is the status for search, it just updated its nested data, which size is1current time is 1200549014501********************************************So we could see the time diff between we first check search status, to search status finished updating its nested data is:1200549014501 - 1200549002689 = 11812.In this case, either of the waiting time -- before removing domain listener (5000), or the waiting time before we check the size of the nested data of status (2000), is enough.If I changed the time waiting before we check the size of the nested data of search status to 20000, we did get the right results in the Remote Search view.	4.0
id=472602	REOPENED	Xtend	Core	2.8.3	PC Windows 8	P3 normal	Project Inbox	2015-07-14 05:53 EDT by	John Kozlov	2016-06-10 05:57 EDT (	2 users	The compilation of this code fails with an error: "Type mismatch: cannot convert from B to A"import java.util.function.Functioninterface Supplier<A> { def A get(); def <B> Supplier<B> map(Function<A, B> f) { [| val A a = get val B b = f.apply(a) return b ] }}	Preliminary scheduled for 2.8.4GitHub Pull Request 403 created by [szarnekow]A first part of the fix will be available with 2.8.4. It'll allow to implement the map function if you use a local variable before the lambda expression:def <B> Supplier<B> map(..) { val thiz = this return [ val a = thiz.get val b = f.apply(a) return b ]}Workaround with 2.8.3: Use an anonymous class and a local variable, e.g.val thiz = thisreturn new C<B>() { override get() { val a = thiz.get val b = f.apply(a) return b }}I'll create a follow-up ticket for the remaining issues which will be addressed with 2.9GitHub Pull Request 404 created by [szarnekow]There is still a problem:interface Function<A, B> { def B apply(A a) def <C> F<A, C> andThen(Function<B, C> f) { val thiz = this return [a| val B b = thiz.apply(a) val C c = f.apply(b) // Type mismatch: cannot convert from B to C c ] }}see(In reply to Sven Efftinge from)The hover on f.apply(b) indicated a wrong type, too:C F.apply(C a)It should beC F.apply(B a)	7.0
id=269633	REOPENED	PDT	Code Assist	2.1	PC Linux-GTK	P3 major	Zhongwei Zhao	2009-03-22 17:25 EDT by	Anton Danilchenko	2011-05-15 22:59 EDT (	2 users	Type code:inclu|;In position | press ctrl+space and select "include".Actual result: include();; // double ";"Expected result: include();Recomendation: if set one symbol ; don't insert another.	I type code:chd|In position | press Ctrl + space.Actual result: chdir()Expected result: chdir(); // with ; in end positionReproduced in PDT 2.1 RC3CreatedpatchIs this a bug?The chdir() is not always at the end of the line. So the ";" is not necessary to be added. Current behavior is same as JDT.What about the original bug description?If there is already one ; there should not be added a second ;.This happens also if "Completion Overwrites" is selected.For example you have:inclu|blabla;On the place of the | press ctrl+space.blabla is marked for replacement (without the ;) and when you select the include from the list you end up with:include '|';; i.e. with 2x ;	6.0
id=385130	REOPENED	LDT	LuaDevelopmentTools	unspecified	PC Mac OS X	P4 enhancement	Benjamin Cabé	2012-07-15 17:44 EDT by	Benjamin Cabé	2012-10-29 11:40 EDT (	0 users	Highlighting bold (** and __), italic (* and _), and "code" (`) elements in doc comments would be nice	Fixed in b2f6d16.We may want to reconsider the way `code` elements are higlighted (underlined at the moment)Also, note that the lists beginning by '*' may sometimes cause highlighting issues (but to be honest I don't think it is a big deal)Support of markdown contains too many bugs :- problem with list reported below.- **bold** and *italic* on several lines change render of "--" too.- `code` should works only on 1 line contrary to **bold** and *italic*.- change color of luadocumentor comment in preference don't change markdown tag color.So, I deactivate this feature (in ) and reopen the bug.(oups I missed commit reference) deactivate in 6b3a545fab39cda927b812d04a34687636f9787f	3.0
id=321228	REOPENED	PDT	Editor	unspecified	All All	P3 major	Dawid Pakula	2010-07-29 10:02 EDT by	michel kollenhoven	2016-11-10 09:28 EST (	7 users	i get the following error,note syntax highlight is not working correct(colors shift 2/3 chars from where it should be)also keyword expantion is not working eigtherWhat steps will reproduce the problem?nothing happands all the time if you need more info (other errors, traces, stacks, my php code, a list of my plugins anything) contact me(i might be still here)if i did somthing wrog point me to the doc's-- Error Details --Date: Thu Jul 29 15:47:33 CEST 2010Message: nullSeverity: ErrorProduct: Eclipse 1.3.0.20100617-0520 (org.eclipse.epp.package.php.product)Plugin: org.eclipse.wst.sse.uiSession Data:eclipse.buildId=I20100608-0911java.version=1.6.0_21java.vendor=Sun Microsystems Inc.BootLoader constants: OS=win32, ARCH=x86, WS=win32, NL=nl_NLFramework arguments: -product org.eclipse.epp.package.php.productCommand-line arguments: -os win32 -ws win32 -arch x86 -product org.eclipse.epp.package.php.productException Stack Trace:org.eclipse.jface.text.BadLocationException at org.eclipse.wst.sse.core.internal.text.GenericPositionManager.addPosition(GenericPositionManager.java:84) at org.eclipse.wst.sse.core.internal.text.BasicStructuredDocument.addPosition(BasicStructuredDocument.java:870) at org.eclipse.wst.sse.ui.internal.style.SemanticHighlightingPresenter.updatePresentation(SemanticHighlightingPresenter.java:471) at org.eclipse.wst.sse.ui.internal.style.SemanticHighlightingPresenter$1.run(SemanticHighlightingPresenter.java:404) at org.eclipse.swt.widgets.RunnableLock.run(RunnableLock.java:35) at org.eclipse.swt.widgets.Synchronizer.runAsyncMessages(Synchronizer.java:134) at org.eclipse.swt.widgets.Display.runAsyncMessages(Display.java:4041) at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3660) at org.eclipse.ui.internal.Workbench.runEventLoop(Workbench.java:2629) at org.eclipse.ui.internal.Workbench.runUI(Workbench.java:2593) at org.eclipse.ui.internal.Workbench.access$4(Workbench.java:2427) at org.eclipse.ui.internal.Workbench$7.run(Workbench.java:670) at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:332) at org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:663) at org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:149) at org.eclipse.ui.internal.ide.application.IDEApplication.start(IDEApplication.java:115) at org.eclipse.equinox.internal.app.EclipseAppHandle.run(EclipseAppHandle.java:196) at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:110) at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:79) at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:369) at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:179) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) at java.lang.reflect.Method.invoke(Unknown Source) at org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:619) at org.eclipse.equinox.launcher.Main.basicRun(Main.java:574) at org.eclipse.equinox.launcher.Main.run(Main.java:1407)	Does it only happen in the PHP Editor?(In reply to)yes i think it does, html, css, javascript looks finemaybe this trace(also result of problem i think) will help you:GL---------8<--------eclipse.buildId=I20100608-0911java.version=1.6.0_21java.vendor=Sun Microsystems Inc.BootLoader constants: OS=win32, ARCH=x86, WS=win32, NL=nl_NLFramework arguments: -product org.eclipse.epp.package.php.productCommand-line arguments: -os win32 -ws win32 -arch x86 -product org.eclipse.epp.package.php.productErrorFri Jul 30 14:31:21 CEST 2010Index out of boundsorg.eclipse.dltk.core.ModelException: Index out of boundsat org.eclipse.dltk.internal.core.Openable.codeSelect(Openable.java:564)at org.eclipse.dltk.internal.core.AbstractSourceModule.codeSelect(AbstractSourceModule.java:85)at org.eclipse.dltk.internal.core.AbstractSourceModule.codeSelect(AbstractSourceModule.java:76)at org.eclipse.php.internal.ui.actions.PHPEditorResolvingAction.getSelectedElement(PHPEditorResolvingAction.java:101)at org.eclipse.php.internal.ui.actions.PHPEditorResolvingAction.run(PHPEditorResolvingAction.java:42)at org.eclipse.jface.action.Action.runWithEvent(Action.java:498)at org.eclipse.jface.action.ActionContributionItem.handleWidgetSelection(ActionContributionItem.java:584)at org.eclipse.jface.action.ActionContributionItem.access$2(ActionContributionItem.java:501)at org.eclipse.jface.action.ActionContributionItem$5.handleEvent(ActionContributionItem.java:411)at org.eclipse.swt.widgets.EventTable.sendEvent(EventTable.java:84)at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1053)at org.eclipse.swt.widgets.Display.runDeferredEvents(Display.java:4066)at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3657)at org.eclipse.ui.internal.Workbench.runEventLoop(Workbench.java:2629)at org.eclipse.ui.internal.Workbench.runUI(Workbench.java:2593)at org.eclipse.ui.internal.Workbench.access$4(Workbench.java:2427)at org.eclipse.ui.internal.Workbench$7.run(Workbench.java:670)at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:332)at org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:663)at org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:149)at org.eclipse.ui.internal.ide.application.IDEApplication.start(IDEApplication.java:115)at org.eclipse.equinox.internal.app.EclipseAppHandle.run(EclipseAppHandle.java:196)at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:110)at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:79)at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:369)at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:179)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)at java.lang.reflect.Method.invoke(Unknown Source)at org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:619)at org.eclipse.equinox.launcher.Main.basicRun(Main.java:574)at org.eclipse.equinox.launcher.Main.run(Main.java:1407)Createdscreen shot of markuphi i have attached a screen shot of the invalid markupincluding the stack traces form this sessionthis happed after restating eclipse(from file)good luck and let me know if any debugging is required-----------------8<------!SESSION 2010-08-03 12:19:38.101 -----------------------------------------------eclipse.buildId=I20100608-0911java.version=1.6.0_21java.vendor=Sun Microsystems Inc.BootLoader constants: OS=win32, ARCH=x86, WS=win32, NL=nl_NLFramework arguments: -product org.eclipse.epp.package.php.productCommand-line arguments: -os win32 -ws win32 -arch x86 -product org.eclipse.epp.package.php.product!ENTRY org.eclipse.wst.sse.ui 4 4 2010-08-03 12:44:58.241!MESSAGE null!STACK 0org.eclipse.jface.text.BadLocationException at org.eclipse.wst.sse.core.internal.text.GenericPositionManager.addPosition(GenericPositionManager.java:84) at org.eclipse.wst.sse.core.internal.text.BasicStructuredDocument.addPosition(BasicStructuredDocument.java:870) at org.eclipse.wst.sse.ui.internal.style.SemanticHighlightingPresenter.updatePresentation(SemanticHighlightingPresenter.java:471) at org.eclipse.wst.sse.ui.internal.style.SemanticHighlightingPresenter$1.run(SemanticHighlightingPresenter.java:404) at org.eclipse.swt.widgets.RunnableLock.run(RunnableLock.java:35) at org.eclipse.swt.widgets.Synchronizer.runAsyncMessages(Synchronizer.java:134) at org.eclipse.swt.widgets.Display.runAsyncMessages(Display.java:4041) at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3660) at org.eclipse.ui.internal.Workbench.runEventLoop(Workbench.java:2629) at org.eclipse.ui.internal.Workbench.runUI(Workbench.java:2593) at org.eclipse.ui.internal.Workbench.access$4(Workbench.java:2427) at org.eclipse.ui.internal.Workbench$7.run(Workbench.java:670) at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:332) at org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:663) at org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:149) at org.eclipse.ui.internal.ide.application.IDEApplication.start(IDEApplication.java:115) at org.eclipse.equinox.internal.app.EclipseAppHandle.run(EclipseAppHandle.java:196) at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:110) at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:79) at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:369) at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:179) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) at java.lang.reflect.Method.invoke(Unknown Source) at org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:619) at org.eclipse.equinox.launcher.Main.basicRun(Main.java:574) at org.eclipse.equinox.launcher.Main.run(Main.java:1407)!ENTRY org.eclipse.wst.sse.ui 4 4 2010-08-03 12:45:13.898!MESSAGE null!STACK 0org.eclipse.jface.text.BadLocationException at org.eclipse.wst.sse.core.internal.text.GenericPositionManager.addPosition(GenericPositionManager.java:84) at org.eclipse.wst.sse.core.internal.text.BasicStructuredDocument.addPosition(BasicStructuredDocument.java:870) at org.eclipse.wst.sse.ui.internal.style.SemanticHighlightingPresenter.updatePresentation(SemanticHighlightingPresenter.java:471) at org.eclipse.wst.sse.ui.internal.style.SemanticHighlightingPresenter$1.run(SemanticHighlightingPresenter.java:404) at org.eclipse.swt.widgets.RunnableLock.run(RunnableLock.java:35) at org.eclipse.swt.widgets.Synchronizer.runAsyncMessages(Synchronizer.java:134) at org.eclipse.swt.widgets.Display.runAsyncMessages(Display.java:4041) at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3660) at org.eclipse.ui.internal.Workbench.runEventLoop(Workbench.java:2629) at org.eclipse.ui.internal.Workbench.runUI(Workbench.java:2593) at org.eclipse.ui.internal.Workbench.access$4(Workbench.java:2427) at org.eclipse.ui.internal.Workbench$7.run(Workbench.java:670) at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:332) at org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:663) at org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:149) at org.eclipse.ui.internal.ide.application.IDEApplication.start(IDEApplication.java:115) at org.eclipse.equinox.internal.app.EclipseAppHandle.run(EclipseAppHandle.java:196) at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:110) at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:79) at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:369) at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:179) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) at java.lang.reflect.Method.invoke(Unknown Source) at org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:619) at org.eclipse.equinox.launcher.Main.basicRun(Main.java:574) at org.eclipse.equinox.launcher.Main.run(Main.java:1407)!ENTRY org.eclipse.wst.sse.ui 4 4 2010-08-03 12:45:21.024!MESSAGE null!STACK 0org.eclipse.jface.text.BadLocationException at org.eclipse.wst.sse.core.internal.text.GenericPositionManager.addPosition(GenericPositionManager.java:84) at org.eclipse.wst.sse.core.internal.text.BasicStructuredDocument.addPosition(BasicStructuredDocument.java:870) at org.eclipse.wst.sse.ui.internal.style.SemanticHighlightingPresenter.updatePresentation(SemanticHighlightingPresenter.java:471) at org.eclipse.wst.sse.ui.internal.style.SemanticHighlightingPresenter$1.run(SemanticHighlightingPresenter.java:404) at org.eclipse.swt.widgets.RunnableLock.run(RunnableLock.java:35) at org.eclipse.swt.widgets.Synchronizer.runAsyncMessages(Synchronizer.java:134) at org.eclipse.swt.widgets.Display.runAsyncMessages(Display.java:4041) at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3660) at org.eclipse.ui.internal.Workbench.runEventLoop(Workbench.java:2629) at org.eclipse.ui.internal.Workbench.runUI(Workbench.java:2593) at org.eclipse.ui.internal.Workbench.access$4(Workbench.java:2427) at org.eclipse.ui.internal.Workbench$7.run(Workbench.java:670) at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:332) at org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:663) at org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:149) at org.eclipse.ui.internal.ide.application.IDEApplication.start(IDEApplication.java:115) at org.eclipse.equinox.internal.app.EclipseAppHandle.run(EclipseAppHandle.java:196) at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:110) at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:79) at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:369) at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:179) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) at java.lang.reflect.Method.invoke(Unknown Source) at org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:619) at org.eclipse.equinox.launcher.Main.basicRun(Main.java:574) at org.eclipse.equinox.launcher.Main.run(Main.java:1407)!ENTRY org.eclipse.jface.text 2 0 2010-08-03 12:46:00.526!MESSAGE !STACK 0java.lang.NullPointerException at org.eclipse.dltk.ui.text.completion.ProposalInfo.extractScriptdoc(ProposalInfo.java:106) at org.eclipse.dltk.ui.text.completion.ProposalInfo.computeInfo(ProposalInfo.java:84) at org.eclipse.dltk.ui.text.completion.ProposalInfo.getInfo(ProposalInfo.java:67) at org.eclipse.dltk.ui.text.completion.AbstractScriptCompletionProposal.getAdditionalProposalInfo(AbstractScriptCompletionProposal.java:440) at org.eclipse.jface.text.contentassist.AdditionalInfoController$3.run(AdditionalInfoController.java:106) at org.eclipse.core.internal.jobs.Worker.run(Worker.java:54)!ENTRY org.eclipse.jface.text 2 0 2010-08-03 12:46:01.463!MESSAGE !STACK 0java.lang.NullPointerException at org.eclipse.dltk.ui.text.completion.ProposalInfo.extractScriptdoc(ProposalInfo.java:106) at org.eclipse.dltk.ui.text.completion.ProposalInfo.computeInfo(ProposalInfo.java:84) at org.eclipse.dltk.ui.text.completion.ProposalInfo.getInfo(ProposalInfo.java:67) at org.eclipse.dltk.ui.text.completion.AbstractScriptCompletionProposal.getAdditionalProposalInfo(AbstractScriptCompletionProposal.java:440) at org.eclipse.jface.text.contentassist.AdditionalInfoController$3.run(AdditionalInfoController.java:106) at org.eclipse.core.internal.jobs.Worker.run(Worker.java:54)!ENTRY org.eclipse.jface.text 2 0 2010-08-03 12:46:10.182!MESSAGE !STACK 0java.lang.NullPointerException at org.eclipse.dltk.ui.text.completion.ProposalInfo.extractScriptdoc(ProposalInfo.java:106) at org.eclipse.dltk.ui.text.completion.ProposalInfo.computeInfo(ProposalInfo.java:84) at org.eclipse.dltk.ui.text.completion.ProposalInfo.getInfo(ProposalInfo.java:67) at org.eclipse.dltk.ui.text.completion.AbstractScriptCompletionProposal.getAdditionalProposalInfo(AbstractScriptCompletionProposal.java:440) at org.eclipse.jface.text.contentassist.AdditionalInfoController$3.run(AdditionalInfoController.java:106) at org.eclipse.core.internal.jobs.Worker.run(Worker.java:54)***has been marked as a duplicate of this bug. ***this might also be of interest might happen when the same file is open twice(is possible, is this correct behavior?)(it its a separate bug et me know)----------------8<-----------java.lang.ArrayIndexOutOfBoundsException at java.lang.System.arraycopy(Native Method) at java.lang.AbstractStringBuilder.append(Unknown Source) at java.lang.StringBuffer.append(Unknown Source) at org.eclipse.jface.text.GapTextStore.get(GapTextStore.java:164) at org.eclipse.wst.sse.core.internal.text.StructuredDocumentTextStore.get(StructuredDocumentTextStore.java:66) at org.eclipse.wst.sse.core.internal.text.BasicStructuredDocument.get(BasicStructuredDocument.java:1210) at org.eclipse.dltk.internal.ui.editor.DocumentAdapter.getContents(DocumentAdapter.java:303) at org.eclipse.dltk.internal.core.AbstractSourceModule.getSource(AbstractSourceModule.java:301) at org.eclipse.php.internal.core.codeassist.PHPSelectionEngine.internalASTResolve(PHPSelectionEngine.java:155) at org.eclipse.php.internal.core.codeassist.PHPSelectionEngine.select(PHPSelectionEngine.java:97) at org.eclipse.dltk.internal.core.Openable.codeSelect(Openable.java:578) at org.eclipse.dltk.internal.core.AbstractSourceModule.codeSelect(AbstractSourceModule.java:85) at org.eclipse.dltk.internal.core.AbstractSourceModule.codeSelect(AbstractSourceModule.java:76) at org.eclipse.php.internal.ui.editor.highlighters.InternalClassHighlighting.isInternalClass(InternalClassHighlighting.java:60) at org.eclipse.php.internal.ui.editor.highlighters.InternalClassHighlighting.access$0(InternalClassHighlighting.java:57) at org.eclipse.php.internal.ui.editor.highlighters.InternalClassHighlighting$InternalClassApply.visit(InternalClassHighlighting.java:29) at org.eclipse.php.internal.core.ast.nodes.Identifier.accept0(Identifier.java:66) at org.eclipse.php.internal.core.ast.nodes.ASTNode.accept(ASTNode.java:275) at org.eclipse.php.internal.core.ast.nodes.Variable.childrenAccept(Variable.java:120) at org.eclipse.php.internal.core.ast.nodes.Variable.accept0(Variable.java:114) at org.eclipse.php.internal.core.ast.nodes.ASTNode.accept(ASTNode.java:275) at org.eclipse.php.internal.core.ast.nodes.FunctionName.childrenAccept(FunctionName.java:74) at org.eclipse.php.internal.core.ast.nodes.FunctionName.accept0(FunctionName.java:68) at org.eclipse.php.internal.core.ast.nodes.ASTNode.accept(ASTNode.java:275) at org.eclipse.php.internal.core.ast.nodes.FunctionInvocation.childrenAccept(FunctionInvocation.java:86) at org.eclipse.php.internal.core.ast.nodes.FunctionInvocation.accept0(FunctionInvocation.java:80) at org.eclipse.php.internal.core.ast.nodes.ASTNode.accept(ASTNode.java:275) at org.eclipse.php.internal.core.ast.nodes.MethodInvocation.childrenAccept(MethodInvocation.java:82) at org.eclipse.php.internal.core.ast.nodes.MethodInvocation.accept0(MethodInvocation.java:75) at org.eclipse.php.internal.core.ast.nodes.ASTNode.accept(ASTNode.java:275) at org.eclipse.php.internal.core.ast.nodes.ExpressionStatement.childrenAccept(ExpressionStatement.java:73) at org.eclipse.php.internal.core.ast.nodes.ExpressionStatement.accept0(ExpressionStatement.java:67) at org.eclipse.php.internal.core.ast.nodes.ASTNode.accept(ASTNode.java:275) at org.eclipse.php.internal.core.ast.nodes.Block.childrenAccept(Block.java:97) at org.eclipse.php.internal.core.ast.nodes.Block.accept0(Block.java:90) at org.eclipse.php.internal.core.ast.nodes.ASTNode.accept(ASTNode.java:275) at org.eclipse.php.internal.core.ast.nodes.IfStatement.childrenAccept(IfStatement.java:98) at org.eclipse.php.internal.core.ast.nodes.IfStatement.accept0(IfStatement.java:89) at org.eclipse.php.internal.core.ast.nodes.ASTNode.accept(ASTNode.java:275) at org.eclipse.php.internal.core.ast.nodes.Block.childrenAccept(Block.java:97) at org.eclipse.php.internal.core.ast.nodes.Block.accept0(Block.java:90) at org.eclipse.php.internal.core.ast.nodes.ASTNode.accept(ASTNode.java:275) at org.eclipse.php.internal.core.ast.nodes.FunctionDeclaration.childrenAccept(FunctionDeclaration.java:108) at org.eclipse.php.internal.core.ast.nodes.FunctionDeclaration.accept0(FunctionDeclaration.java:97) at org.eclipse.php.internal.core.ast.nodes.ASTNode.accept(ASTNode.java:275) at org.eclipse.php.internal.core.ast.nodes.MethodDeclaration.childrenAccept(MethodDeclaration.java:90) at org.eclipse.php.internal.core.ast.nodes.MethodDeclaration.accept0(MethodDeclaration.java:82) at org.eclipse.php.internal.core.ast.nodes.ASTNode.accept(ASTNode.java:275) at org.eclipse.php.internal.core.ast.nodes.Block.childrenAccept(Block.java:97) at org.eclipse.php.internal.core.ast.nodes.Block.accept0(Block.java:90) at org.eclipse.php.internal.core.ast.nodes.ASTNode.accept(ASTNode.java:275) at org.eclipse.php.internal.core.ast.nodes.ClassDeclaration.childrenAccept(ClassDeclaration.java:118) at org.eclipse.php.internal.core.ast.nodes.ClassDeclaration.accept0(ClassDeclaration.java:104) at org.eclipse.php.internal.core.ast.nodes.ASTNode.accept(ASTNode.java:275) at org.eclipse.php.internal.core.ast.nodes.Program.childrenAccept(Program.java:195) at org.eclipse.php.internal.core.ast.nodes.Program.accept0(Program.java:188) at org.eclipse.php.internal.core.ast.nodes.ASTNode.accept(ASTNode.java:275) at org.eclipse.php.internal.ui.editor.highlighter.AbstractSemanticHighlighting.consumes(AbstractSemanticHighlighting.java:93) at org.eclipse.php.internal.ui.editor.highlighter.AbstractSemanticHighlighting.consumes(AbstractSemanticHighlighting.java:102) at org.eclipse.wst.sse.ui.internal.style.SemanticHighlightingReconciler.reconcile(SemanticHighlightingReconciler.java:127) at org.eclipse.wst.sse.ui.internal.reconcile.DocumentRegionProcessor.endProcessing(DocumentRegionProcessor.java:119) at org.eclipse.wst.sse.ui.internal.reconcile.DirtyRegionProcessor.run(DirtyRegionProcessor.java:682) at org.eclipse.core.internal.jobs.Worker.run(Worker.java:54)b.t.w. are the NullPointerExceptions the same bug or a seperate one?(In reply to)I would think separate, but only the PDT team would know for sure.I'm not sure what circumstances bring about the trace from.This problem still exists (from screen and logs).It produce invalid highlighting, sometimes invalid selection.Stack:org.eclipse.jface.text.BadLocationException at org.eclipse.wst.sse.core.internal.text.GenericPositionManager.addPosition(GenericPositionManager.java:84) at org.eclipse.wst.sse.core.internal.text.BasicStructuredDocument.addPosition(BasicStructuredDocument.java:870) at org.eclipse.wst.sse.ui.internal.style.SemanticHighlightingPresenter.updatePresentation(SemanticHighlightingPresenter.java:476) at org.eclipse.wst.sse.ui.internal.style.SemanticHighlightingPresenter$1.run(SemanticHighlightingPresenter.java:409) at org.eclipse.swt.widgets.RunnableLock.run(RunnableLock.java:35) at org.eclipse.swt.widgets.Synchronizer.runAsyncMessages(Synchronizer.java:135) at org.eclipse.swt.widgets.Display.runAsyncMessages(Display.java:3976) at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3653) at org.eclipse.e4.ui.internal.workbench.swt.PartRenderingEngine$9.run(PartRenderingEngine.java:1113) at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:332) at org.eclipse.e4.ui.internal.workbench.swt.PartRenderingEngine.run(PartRenderingEngine.java:997) at org.eclipse.e4.ui.internal.workbench.E4Workbench.createAndRunUI(E4Workbench.java:140) at org.eclipse.ui.internal.Workbench$5.run(Workbench.java:611) at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:332) at org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:567) at org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:150) at org.eclipse.ui.internal.ide.application.IDEApplication.start(IDEApplication.java:124) at org.eclipse.equinox.internal.app.EclipseAppHandle.run(EclipseAppHandle.java:196) at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:110) at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:79) at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:354) at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:181) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:606) at org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:636) at org.eclipse.equinox.launcher.Main.basicRun(Main.java:591) at org.eclipse.equinox.launcher.Main.run(Main.java:1450) at org.eclipse.equinox.launcher.Main.main(Main.java:1426)This patch resolves syntax coloring problem:BadLocationException is still actual.Hello,it seems that patch 2da229ab265126c4f7211e33cd52ae48ad8b9e6c introduced a regression and is the culprit for.When I remove the following code added to the class PHPStructuredEditor,vanishes :// XXX hide bad locations (invalid sync)if (offset + length > getDocument().getLength()) { length = length - offset + length - getDocument().getLength();}setHighlightRange(offset, length, moveCursor);It's just a workaround, as I don't understand much to this class.Dawid, could you have a look please ?Thank you !You have right. Please wait for #430049Ok, thank you Dawid ! Will redo some tests when you're ready ;)I sliced patch from 430049 and moved to gerrit [1]Be aware, this patch require wtp source editing plugin from Luna (latest snapshot or M7)[1]Patch merged:Closing.I reopen.Happened to me today, with latest PDT snapshot :eclipse.buildId=4.4.2.M20150204-1700java.version=1.6.0_43java.vendor=Sun Microsystems Inc.BootLoader constants: OS=win32, ARCH=x86, WS=win32, NL=fr_FRFramework arguments: -product org.eclipse.epp.package.jee.productCommand-line arguments: -os win32 -ws win32 -arch x86 -product org.eclipse.epp.package.jee.productorg.eclipse.wst.sse.uiErrorThu Jun 18 16:23:10 CEST 2015nullorg.eclipse.jface.text.BadLocationException at org.eclipse.wst.sse.core.internal.text.GenericPositionManager.addPosition(GenericPositionManager.java:84) at org.eclipse.wst.sse.core.internal.text.BasicStructuredDocument.addPosition(BasicStructuredDocument.java:870) at org.eclipse.wst.sse.ui.internal.style.SemanticHighlightingPresenter.updatePresentation(SemanticHighlightingPresenter.java:476) at org.eclipse.wst.sse.ui.internal.style.SemanticHighlightingPresenter$1.run(SemanticHighlightingPresenter.java:409) at org.eclipse.swt.widgets.RunnableLock.run(RunnableLock.java:35) at org.eclipse.swt.widgets.Synchronizer.runAsyncMessages(Synchronizer.java:136) at org.eclipse.swt.widgets.Display.runAsyncMessages(Display.java:4147) at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3764) at org.eclipse.e4.ui.internal.workbench.swt.PartRenderingEngine$9.run(PartRenderingEngine.java:1151) at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:332) at org.eclipse.e4.ui.internal.workbench.swt.PartRenderingEngine.run(PartRenderingEngine.java:1032) at org.eclipse.e4.ui.internal.workbench.E4Workbench.createAndRunUI(E4Workbench.java:148) at org.eclipse.ui.internal.Workbench$5.run(Workbench.java:636) at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:332) at org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:579) at org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:150) at org.eclipse.ui.internal.ide.application.IDEApplication.start(IDEApplication.java:135) at org.eclipse.equinox.internal.app.EclipseAppHandle.run(EclipseAppHandle.java:196) at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:134) at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:104) at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:380) at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:235) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at java.lang.reflect.Method.invoke(Method.java:597) at org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:648) at org.eclipse.equinox.launcher.Main.basicRun(Main.java:603) at org.eclipse.equinox.launcher.Main.run(Main.java:1465) at org.eclipse.equinox.launcher.Main.main(Main.java:1438)Thierry.I haven't seen this bug for a while now. My comment in this bug report was one of my first contribution to pdt :) I close this bug report.Sadly still not solved, but now I found an easier way to reproduce the bug (see my comment at).Thierry.With up-to-date error log:eclipse.buildId=4.6.1.M20160907-1200java.version=1.8.0_66java.vendor=Oracle CorporationBootLoader constants: OS=win32, ARCH=x86, WS=win32, NL=fr_FRFramework arguments: -product org.eclipse.epp.package.jee.productCommand-line arguments: -os win32 -ws win32 -arch x86 -product org.eclipse.epp.package.jee.productorg.eclipse.wst.sse.uiErrorThu Nov 10 15:27:43 CET 2016nullorg.eclipse.jface.text.BadLocationException at org.eclipse.wst.sse.core.internal.text.GenericPositionManager.addPosition(GenericPositionManager.java:84) at org.eclipse.wst.sse.core.internal.text.BasicStructuredDocument.addPosition(BasicStructuredDocument.java:870) at org.eclipse.wst.sse.ui.internal.style.SemanticHighlightingPresenter.updatePresentation(SemanticHighlightingPresenter.java:476) at org.eclipse.wst.sse.ui.internal.style.SemanticHighlightingPresenter$1.run(SemanticHighlightingPresenter.java:409) at org.eclipse.swt.widgets.RunnableLock.run(RunnableLock.java:35) at org.eclipse.swt.widgets.Synchronizer.runAsyncMessages(Synchronizer.java:182) at org.eclipse.swt.widgets.Display.runAsyncMessages(Display.java:4203) at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3819) at org.eclipse.e4.ui.internal.workbench.swt.PartRenderingEngine$4.run(PartRenderingEngine.java:1121) at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:336) at org.eclipse.e4.ui.internal.workbench.swt.PartRenderingEngine.run(PartRenderingEngine.java:1022) at org.eclipse.e4.ui.internal.workbench.E4Workbench.createAndRunUI(E4Workbench.java:150) at org.eclipse.ui.internal.Workbench$5.run(Workbench.java:687) at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:336) at org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:604) at org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:148) at org.eclipse.ui.internal.ide.application.IDEApplication.start(IDEApplication.java:138) at org.eclipse.equinox.internal.app.EclipseAppHandle.run(EclipseAppHandle.java:196) at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:134) at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:104) at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:388) at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:243) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:497) at org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:673) at org.eclipse.equinox.launcher.Main.basicRun(Main.java:610) at org.eclipse.equinox.launcher.Main.run(Main.java:1519) at org.eclipse.equinox.launcher.Main.main(Main.java:1492)	19.0
id=266001	REOPENED	Target Management	RSE	3.0.2	PC Windows XP	P4 trivial	David McKnight	2009-02-24 14:05 EST by	Samuel Wu	2009-03-24 12:46 EDT (	0 users	1. Install RSE 3.0.3 with Eclipse 3.4.12. Create a linux connection and choose dstore as the server launcher3. Expand the Home filter under the Files subsystem4. When be prompted for password, fill in the user ID and password5. When the filter Home is expanded, right click the connection 6. The action Connect and Disconnect are both enabled. Since the connection is already activated, the action Connect should be disabled.	Samuel: Is this a transient issue, i.e. is connect disabled after a while doing something else or does it always remain enabled?Also, is this just a cosmetic issue or does anything bad happen when you call the connect action although it's connected already? (I'm assuming cosmetic for now).Dave: The root cause of this might be that we don't have a "CONNECTING" state in which connect is already disabled but it's not yet fully connected.It remains enabled as far as my test goes. It doesn't seem to do anything when running this Connect action again.Samuel, what subsystems do you have? I would expect that there are some subsystems (i.e. ssh terminals) that have not been connected. As a result, the connect action is for connecting all subsystems not yet connected and the disconnect action is for disconnecting those subsystems that have been connected.I'm marking this as INVALID with the assumption that there are multiple connector services and only one is connected which explains why connect and disconnect are available. If this is not the case please reopen this.Talked with Dave about this. We both agreed that since the connect services are not so straight forward to the end users, it'll be better to use the subsystems to indicate whether a connection is connected. If all the subsystems in a connection are connected, the connection is connected and Connect action is going to be removed from the context menu. In the case where a subsystem has more than one connector service, as long as one is connected, the subsystem is connected.Samuel, your comment is a bit confusing... AFAIK one subsystem can have only one connectorService. The hierarchy is:System + ConnectorService + SubsystemHere is the case.We have a system type which contains two SubSystemConfiguration for command shell subsystem. So there are two items listed under Service tab on the subsystem properties page. That's what I meant by more than one connector service.In 3.0.x, when we connect the File subsystem with Dstore, the context menu of the connection contains both Connect and Disconnect. The explanation given inis that some of the connector service is not connected yet. So both action should be available.But in our case, the command shell subsystem is already connected and the Connect action doesn't do anything.In 3.1, this behavior is changed. The Connect action doesn't show up on the connection context menu under the same situation.I'm reopening this bug and let you decide which is the right behavior.So, can your TWO subsystems of "Command" type be active at the same time?Or is only one active at any one time and you switch to service A or service B?A screenshot may help at this time.CreatedShell subsystem properties pageThere is a checkbox for each of the two services on the Shell subsystem properties page as shown in the screenshot. But I can only select one of the check box at a time, like a radio box. The connected status of the Shell subsystem depends on the selected service. If the selected service is connected, the subsystem is connected. I can select one service and connect it and then switch to another service and connect it. I can only see one shell subsystem in the UI, the selected one.	9.0
id=399147	REOPENED	CDT	cdt-indexer	Next	All All	P3 normal	Nathan Ridge	2013-01-25 21:16 EST by	Nathan Ridge	2017-02-15 23:44 EST (	3 users	For the following code:namespace N{ void foo() {} // invoke 'find references' on 'foo'}using N::foo;performing 'find references' on foo() inside the namespace does not find the using-declaration. I think it should.	New Gerrit change created:The issue here is that using-declarations get bindings of their own, and so the role of the name inside the using-declaration is considered to be a "declaration" for that binding.This is fine, but the name is also a "reference" to the using-declaration's delegate bindings. Recording this relationships fixes the issue.Gerrit changewas merged to [master].Commit:Fixed for 9.3.The change made inis problematic since a PDOMName can participate in only one binding at a time through its BINDING_PREV_OFFSET/ BINDING_PREV_OFFSET pointers.New Gerrit change created:Rolling back the change.Gerrit changewas merged to [master].Commit:New Gerrit change created:Gerrit changewas merged to [master].Commit:(In reply to Sergey Prigogin from)My bad, I failed to appreciate this at the time I wrote the patch. Thank you for correcting it!What do you think about the following revised approach for fixing this bug? - Give a using-declaration an implicit name for each delegate binding, which is a reference to that binding. - Have the implicit names create PDOMNames of their own, which can then participate in the reference lists of their respective bindings.(In reply to Nathan Ridge from)Sounds like a good plan.New Gerrit change created:(In reply to Eclipse Genie from)^ This implements the approach outlined in.(In reply to Nathan Ridge from)It looks like this part happens automatically.New Gerrit change created:New Gerrit change created:New Gerrit change created:	17.0
id=52105	REOPENED	AspectJ	Compiler	1.1.1	PC Windows XP	P4 enhancement	Adrian Colyer	2004-02-15 14:00 EST by	Wes Isberg	2010-01-26 12:45 EST (	3 users	When {public} static final fields are declared on an interface or a class froman aspect, they are not treated as constants in case statements (as static finalfields declared in/on classes are). Perhaps the same result with compile-timeString concantenation, (...others?)You can decide if this is a bug or an undocumented part of the implementationlimitations or semantics. If it's a bug, I can submit a test case.	I think this is a limitation because Java won't allow final fields to be initialized outside of their respective initializer and ITD fields need to be initialized in the defining aspect. final static ITD fields seem bogus to me but we can't take them away. Perhaps they should be "deprecated".What does this mean?I'm not sure it's a limitation imposed by Java or bytecode weaving, but it mightbe a limitation of our implementation. (Not being an expert in any of these, Iam mostly speculating.)If, or since, public static final constant expressions (compile-time constants)must be available to the client when the client is compiled, then the client isin the scope of the code the implementation controls. If that's true, it seemslike ajc can inline the constant into the client. So I don't believe it is alimitation imposed by Java. The problem could lie in separating compilation and weaving or in making thempossible on a per-class basis. Normally weaving surfaces join points and addsmembers and parents. Here we would be asking the weaver to also fold in inlinereferences to compile-time constants, which seems possible but not desirable. Resolution of any constant expression involving a compile-time constant declaredon another type by an aspect would have to be deferred to the weaver. Thecompiler check on constant expressions would have to be updated to permit thisdelayed resolution. The weaver would have to do the re-compilation necessary toresolve the entire constant expression (and update the constant table). Whilenot good, it seems feasible. Nor does it seem to prohibit per-class weaving,since such constants are all defined in aspects which by hypothesis are allavailable to the weaver. So I don't think it is a limitation imposed on anyimplementation that has a separate compiler and weaver and does per-classweaving. It may, however, be a limitation of our implementation.If this behavior stands, I think it shouldn't be deprecated, but that we shouldjust document that fields declared in an aspect on other types are never treatedas compile-time constants. The declarations are very useful, but constantexpressions are rarely required.(wrt initialization scope, AspectJ I think requires that a static final field beinitialized in its declaration, since aspects don't (but should?) have a way todeclare a static initialization block on another type. Workarounds thereinclude defining a static method to do the work, given any static fields thatare defined earlier in the file (though the order relative to fields defined inthe type itself or other aspects is undefined).)This is an undocumented limitation of the current implementation. Constant fields are a surprisingly complicated part of a Java compiler, and it didn't seem to be worth the effort to make ITD fields work with this mechanism. I agree with Matthew that final static ITD's are pretty ugly. Personally, I don't think there's ever a good design reason to use a static ITD, but it's extremely unlikely we'd take away this feature since I'm also sure there are people using it.I'm marking this bug as a P4 enhancement request as a limitation we might consider removing for some future release.We're not going to get to this in AJ 1.5.0. Marking as "LATER" for considerationin 1.5.1 and future release planning.reopened for another look - but not sure what we can do without spending some time thinking it through.review for 1.5.4 - but may not make that release	6.0
id=404295	REOPENED	LDT	LuaDevelopmentTools	unspecified	PC Windows 7	P4 enhancement	Project Inbox	2013-03-25 14:15 EDT by	Pascal Rapicault	2013-10-07 10:49 EDT (	2 users	Lua Development Tools Product (Incubation) 0.9.0.201303011352 When I do completion after requires I would like to be proposed with the names of the files that already export functions.	Hi Pascal,Thanks for your feedback.In lua, a require only means that the code from an other module in the path in loaded. There is many ways to code a module in lua: * it can expose 1 or multiple global vars. * it can return a table containing fields and methods (most popular way) * it can configure an already loaded module. * ... there are infinite possibilitiesSo LDT can't figure out by itself what the module can allow you to do. That why the auto complete proposals are massively based on the Lua Documentation Language you can found here:(see @module tag)That's why we can't have a generic mechanism for auto-complete after a require as you expect.If you are using the standard Lua 5.x Execution Environment (who bring the Lua Documentation of standard lib to your project) following code can be write using auto completion on "require", "print", "string" and "lower".local string = require "string"print(string.lower("COUCOU"))I hope you get my point, and close the bug. If I have misunderstanding your requirement or need more informations feel free to re-open the bug.I don't think we are talking about the same thing.I want the tool to give me the list of files that I can require.For example, when I do local aaa = require |<hit completion here>|I would like the tool to propose me files.I was quite far :)It's a good idea, but it will be implemented after the 1.0 release as our plan is already quite full.Marc	3.0
id=40272	REOPENED	AspectJ	Compiler	unspecified	PC Windows XP	P5 enhancement	Andrew Clement	2003-07-16 17:35 EDT by	Mik Kersten	2009-08-30 02:49 EDT (	1 user	When -O is specified implicit debug option (-g) should be removed.	removed 1.2 targettrying to clear some space in bugzilla - realistically not going to get to this...LATER/REMIND bugs are being automatically reopened as P5 because the LATER and REMIND resolutions are deprecated.	3.0
id=290053	REOPENED	Orbit	releng	unspecified	All All	P4 enhancement	Project Inbox	2009-09-21 14:35 EDT by	Benjamin Muskalla	2017-01-25 15:06 EST (	3 users	I think it would be a great addition to provide a p2 repository in addition to the regular downloads. This way Orbit can easily be consumed in the PDE target provisioning workflow.	There already is a P2 repository. For example,I have to admit, I've never tried using in a PDE target provisioning workflow, though I've wanted to, since we want to "get rid of" the massive zip file someday soon. So, 1) if you find problems doing it, please reopen. 2) if you have success, maybe you contribute a little paragraph on "how to" instructions and we'll provide a "how to" link on one of our pages. Thanks,See also.Thanks for the pointer. But a repo without any hint to it doesn't help anyone ;) So we should really getfixed asap. Will care about some notes in the doc and going to blog about it. On the one hand we should get ppl to use PDE target provisioning and PDE Build+p2 fetch maps.Will report back if everything works fine when the mirrors stop being mad. I see the required files are there on dev.eclipse.org but can't access trough http at the moment.One thing that could be interesting: provide a common URL to latest repository. As user I don't care where my bundles come from (if it's drop 20090825 or 20091010). With p2 and correct version ranges in my bundle dependencies it's ok to get a newer version of an Orbit bundle as long as it satisfies my bundles requirements. So to easily consume orbit it would be good to have one static url to get the latest and greatest bundles instead of changing the orbit repository url everytime orbit provides a new build.I'll reopen based on your suggestion to "One thing that could be interesting: provide a common URL to latest repository". I'm actually not sure if we should do that ... but deserves some thought. A reason why not to: Orbit bundles should 'come to you as a user' from some other project, not directly from Orbit. A reason why to: It might be handy for committers to have an "I-build" generic location, "S-build", and ... maybe, and "R-build" location. Not sure if would work, or be that important since only a few bundles change from build to build (so, it's not like lots of committers have to "update to get the latest" from day to day or even week to week. But, I'll leave open for others to comment. [I did try out the target provisioning use-case and didn't work as expected (see).... I think we need some improvements before publishing URL for "target provisioning" and the p2-build use case I think is covered by the p2 repo maps].David, I just tested the Orbit repository together with the p2 target provisioning.First problem: there are two features you can install (looks like the bundles and the source bundles) but both have the same name. Both are called "Orbit Build feature" which is pretty annoying.Second problem: installing the source bundles works as expected. But the second feature which contains the real bundles cannot be provisioned (Missing requirement: Apache Ant 1.6.5 requires bundle org.eclipse.osgi.0.0.0 but it could not be found). Not sure yet what causes this. Enhancement: Currently orbit ships everything as one big package. I'd rather expect to install specific bundles instead of pulling the whole orbit repository into my target. Thus I'd suggest to separate the bundles (but include the corresponding source bundle).By personal goal would be to have something a like a bundle repository which can be used to put together my target piece by piece.(In reply to)Thanks Benjamin. We're tracking these issues in.On the "common URL to latest repository" issue:This would actually be a very big help for us. We are using Buckminster to build an RCP application that pulls several libraries from the orbit repository. Currently we have to maintain the URLs to the p2 site and the PDE Maps by hand, which can be quite annoying, especially when builds break because of an outdated orbit URL.Note, I openedto enable PDE to select bundle IUs. In 3.6M6 there is a new action (Ctrl+Shift+Alt+A) which provides a nice UI for selecting bundles or packages (which is even a better abstraction). This if you add an Orbit p2 repository to the available software sites it works.However, I agree that having a finer granularity for Orbit is good. But I'm unsure about the consequences. Those features might need proper about/license files.Doing a mass "reset to default assignee" of 21 bugs to help make clear it will (very likely) not be me working on things I had previously planned to work on. I hope this will help prevent the bugs from "getting lost" in other people's queries. Feel free to "take" a bug if appropriate.This bug seems to be from quite a while ago so my understanding of it is that one common repository was needed, but no documented way of finding it.I think these days, most people know to checkto find the latest build types. In addition, I'm in the process of addressingby providing stable repositories (eg.).Once that gets resolved / no major complains, I'll close this bug.	10.0
id=30561	REOPENED	AJDT	UI	unspecified	PC Windows 2000	P5 trivial	Adrian Colyer	2003-01-29 20:43 EST by	Ron Bodkin	2009-08-30 02:48 EDT (	0 users	AJDT 0.5.2 highlights pointcut descriptors when they are used as method names, e.g., it highlights get in aThreadLocal.get();	This is a current limitation. The AJDT editor does not understand semi-keywords.LATER/REMIND bugs are being automatically reopened as P5 because the LATER and REMIND resolutions are deprecated.	2.0
id=57238	REOPENED	AspectJ	Compiler	unspecified	PC Windows XP	P5 normal	Andrew Clement	2004-04-02 09:48 EST by	Andrew Clement	2009-08-30 02:49 EDT (	2 users	I have the following program:aspect Simple { pointcut interesting(A instance): execution(* getString(..)) && this(instance); Object around(A instance) : interesting(instance) { System.err.println("around advice"); C c = new C(); return proceed(c); } public static void main(String[] argv) { B b = new B(); C c = new C(); System.out.println(b.getString()); System.out.println(c.getString()); }}interface A { public String getString();}class B implements A { String s = "hello from B"; public String getString() { return s; }}class C implements A { String s = "hello from C"; public String getString() { return s; }}It compiles but it won't run. I (we) were thinking that because the around advice signature takes an 'A' then we could proceed with an instance of any type implementing A. In the case above although the advice matches on the execution of a method on B - we attempt to create a 'C' (which also implements A) and proceed with that. The class cast exception is because some of the extracted methods in the generated code have parameters of type 'B' rather than 'A'. Here is the relevant code from a decompiled B.class:class B implements A { B() { s = "hello from B"; } public String getString() { return (String)getString_aroundBody1$advice(this, Simple.aspectOf(), this, null); } static final String getString_aroundBody0(B b) { return b.s; } static final Object getString_aroundBody1$advice(Simple this, A instance, AroundClosure ajc_aroundClosure, C c) { System.err.println("around advice"); C c1 = new C(); C c2 = c; C c3 = c1; return getString_aroundBody0((B)c3); } String s;}The classcastexception comes out at the point we try and cast C to a B ready for consumption by getString_aroundBody0(B b). The code that does this seems to be BcelShadow.createMethodGen().Should this even work? Should we be constructing getString_aroundBody0() taking an A rather than a B?	Ignore the decompiled code - the decompilers seem to have trouble consuming the generated around advice method - the signature is all wrong ?!? This doesn't mean there isn't a problem, just that its gonna be hard to investigate!Adrian and I have been discussing what to do...It seems the getString() in our example is extracted into a method called something like:static String getString_adviceBody0(B b) {...}And it is invoked from the advice method with: getString_adviceBody0((B)c);============In fact when proceeding on C we'd like something like this:The method is extracted to static String getString_adviceBody<UNIQUE_ACROSS_TYPES_ID>(A a) {...}and the advice calls c.getString_adviceBody<UNIQUE_ACROSS_TYPES_ID>(c);Notice the extracted form of the method now takes the same parameter as was indicated in the around advice declaration (i.e. A, the common interface type)Notice that now, although the extracted method is static, we invoke it on 'c' which allows us to in fact invoke the variant that exists in the C class rather than the one in the B class. If we call it in this way there is no need to type cast the argument to the extracted method.Finally, because just using a counter on the end of extracted method names could cause problems in the case of two pieces of advice applying to one file and only one piece applying to another - we use a name suffix that relates to the around advice declaration.In our example, this would mean that at the point the extracted method is called, it is called in 'C' rather than 'B' and so returns the right result.of course, Adrian and I are not experts on compilers or type binding so we haven't a clue if any of this would work ;)There are a number of problems with the scheme just described. Chief of which is that there is no virtual dispatch for static methods. So the method: String getString_adviceBody<UNIQUE_ACROSS_TYPES_ID>(A a) {...}would have to be non-static.Secondly, every implementor of the interface would need to be woven to add thegetString_adviceBody method (since you don't know which implementor will be dispatched to in the proceed). Some of these implementors may not even be matched by the pointcut associated with the around advice - so what would trigger their munging? It therefore seems that the dispatch has to happen to the actual orginal method as declared on the interface (getString() in this case), and the around advice body would then need to be smart enough to know not to reapply itself the second time round. But this is a big change, and can it be done in a way that doesn't hurt performance for all the other uses of around advice? And what happens in the case when the target implementor is itself the recipient of other advice - do all the precedence rules work out ok??Note also that although it doesn't give a class cast exception at runtime, proceeding with a subtype of the type receiving the advice (e.g. if you change the sample program to make C extend B) gives the wrong results as B's implementation of getString() will execute rather than C's. The programming and semantics guide are kind of silent on exactly what should happen when you start changing a variable in a proceed argument list that is bound to the target() (or this()) at a join point. It is a very powerful and useful thing to be able to do. Since I can't see an easy implementation right now, it's tempting to document an implementation limitation that you can only proceed with the same concrete type - but that cuts out at least one important use case that I can't easily see another way of implementing: namely using around advice to delegate execution of all methods in an interface to another implementor, without resorting to reflection or listing each method in the interface individually. If I can control all the call sites, I might be able to get close with dynamic proxies (.3/docs/guide/reflection/proxy.html), but if I need to advise executions...bring on the gurus....This code is behaving according to the type model for around advice that I believe Erik and I both have in our heads. However, I can't find this documented anywhere in the language spec, so I'm cc'ing Erik to keep me honest.Joinpoint shadows have a static type signature that is independent of any advice on them. So, in your example, the execution joinpoint on B has the static signature this and target: B args: ()This static signature is used a lot for optimizing matching and residues. The one place that it can be visible is with proceed and the value returned from around.The rule for proceed is that you must call it with arguments that correspond to the static type of the corresponding joinpoint shadow or you'll get a runtime type error. Having this rule makes it a lot easier to think about complicated cases. For example, what happens if A doesn't contain a getString method? What if your advice was on this(instance) && get(* s)? Should it still be possible to substitute a C for a B? Where would the control-flow pick up in that case?The fact that you can write this code and you get runtime type errors instead of compile-time errors is the one known hole in AspectJ's type system. I've heard there are papers showing it's not possible to do any better, but all I know is this is the best we could come up with at the time.There are several small ways to improve the error messages from this situation that are worth doing as time permits. One is to modify the casts that are inserted to instead check the type and throw a special IncompatibleClassForProceed exception. Another important change is to add an xlint warning for cases where such casts are inserted, and to detect cases like this one where the cast is guaranteed to fail and signal them more aggressively.For the particular example you show here you can solve this problem by modifying your advice to read: Object around(A instance) : interesting(instance) { System.err.println("around advice"); C c = new C(); return c.getString(); }Obviously this isn't a completely general solution if you have too many wildcards in play.The current static type of joinpoint shadows is a relatively simple place to be. It might be possible to come up with a more aggressive type model for proceed that enables this kind of change, as well as reducing the corresponding restrictions on the values returned from around advice. However, I don't see how that could be done in time for 1.2.No plans to change the current implementation at the moment...LATER/REMIND bugs are being automatically reopened as P5 because the LATER and REMIND resolutions are deprecated.	6.0
id=36787	REOPENED	AspectJ	Compiler	unspecified	PC Windows 2000	P5 normal	Adrian Colyer	2003-04-23 04:44 EDT by	George Harley	2009-08-30 02:49 EDT (	0 users	I am using AspectJ 1.1rc1. Here is my simple test case...public class Inner1{}public class Inner2 extends Inner1{}public interface NewInterface{}public class Outer extends Inner2 implements NewInterface{ public static void main(String[] args) { Outer outer = new Outer(); }}public aspect InitAspect{ pointcut outerMatch() : initialization(new(..)); before() : outerMatch() { System.out.println(thisJoinPoint.toLongString()); }}As I understand it, the outerMatch() pointcut will match all constructors in the system. The above all compiles nicely but when I run Outer I get the following (please ignore line numbers) ...java.lang.ExceptionInInitializerError: org.aspectj.lang.NoAspectBoundException at InitAspect.aspectOf(InitAspect.java) at InitAspect.<init>(InitAspect.java:14) at InitAspect.ajc$postClinit(InitAspect.java) at InitAspect.<clinit>(InitAspect.java:14) at Inner1.<init>(Inner1.java:14) at Inner2.<init>(Inner2.java:14) at Outer.<init>(Outer.java:14) at Outer.main(Outer.java:18) Exception in thread "main" If I compile the above system with AspectJ 1.0 before running Outer then it all works and I see the following output ...initialization(public Inner1())initialization(public Inner2())initialization(public NewInterface())initialization(public Outer())It would appear that the pointcut is matching the InitAspect itself. The only way I can get my simple test case to work with 1.1rc1 is to modify my outerMatch() pointcut to explicitly remove the aspect from the scope ...pointcut outerMatch() : initialization(new(..)) && !within(InitAspect);When I run this I get the following output (note the subtle change in the order of the matches compared to what I got using AspectJ 1.0 - now the interface match comes after the Outer match)....initialization(public Inner1())initialization(public Inner2())initialization(public Outer())initialization(public NewInterface())Is this behaviour a 1.1 bug or was 1.0 behaving incorrectly ?	The NoAspectBoundException is a correct change in AspectJ-1.1 and is documented in the readme:-11.html#ASPECT_INSTANTIATION_AND_ADVICEThe order of the interface initializers you're seeing is a bug, but I don't believe it is critical, so I'm leaving it as a P3. If it turns out to be easy to fix it should be resolved for 1.1rc2.A test case has been added to ajcTestsFailing.xml.The 1.2 target milestone has been removed. After analysis, this bug is tightlycoupled with the implementation of initialization join points. This implementation is complicated and I'm very wary of changing it to fix a bug this small.We're not going to get to this in AJ 1.5.0. Marking as "LATER" for considerationin 1.5.1 and future release planning. No-one else has run into this issue that I'm aware of in the 2.5 years since itwas first raised so this is not a high-priority problem right now.LATER/REMIND bugs are being automatically reopened as P5 because the LATER and REMIND resolutions are deprecated.	4.0
id=36810	REOPENED	AspectJ	Compiler	unspecified	PC Linux	P5 normal	Adrian Colyer	2003-04-23 14:48 EDT by	Mohamed Mansour	2009-08-30 02:50 EDT (	0 users	According to Jim Hugunin."The bug has to do with a situation where code in a class can run before thatclass's static initializer has completed. We've designed theJoinPoint.StaticPart object initialization code so that it is robust to mostsuch issues, but we've apparently missed a case."I am using AspectJ 1.1rc1public aspect BaseAspect { pointcut methodExec(): execution(* *..*(..)) && !within(BaseAspect); after () returning: methodExec() { thisJoinPoint.getSignature(); }}public abstract class Expression { public static Expression EMPTYSTRING = new Operator();} public class Operator extends Expression { public Operator() { initOperands(); // the bug goes away if you remove this call. } public void initOperands() { } public static void main (String [] args) { Operator t = new Operator(); }}That stack dumpException in thread "main" java.lang.ExceptionInInitializerErrorCaused by: java.lang.NullPointerException at BaseAspect.ajc$afterReturning$BaseAspect$df(BaseAspect.java:10) at Operator.initOperands(Operator.java:8) at Operator.<init>(Operator.java:4) at Expression.<clinit>(Expression.java:2)	I can't figure out any way to avoid this error that doesn't add runtime overhead to any advice that uses thisJoinPointStaticPart. This error is so unusual that I'm doubtful it's acceptable to penalize all advice for this odd case.Note that any program which would show this bug already has the surprising behavior that a properly initialized static final field may be seen to be null. i.e. if you add to Operator the line: static final Object name = "name";And then add to initOperands() the following: System.out.println(name);You'll see that even though name is a static final under this bizarre initialization situation it can be seen to be null.This bug is waiting for a patch to be submitted showing how it can be prevented without adding performance overhead to all advice that uses thisJoinPointStaticPart.We're not going to get to this in AJ 1.5.0. Marking as "LATER" for considerationin 1.5.1 and future release planning.The bug has not been hit by any other user in the last 2.5 years, so low priority.LATER/REMIND bugs are being automatically reopened as P5 because the LATER and REMIND resolutions are deprecated.	3.0
id=39457	REOPENED	AspectJ	Compiler	unspecified	PC Windows XP	P5 enhancement	Adrian Colyer	2003-06-29 21:47 EDT by	Ron Bodkin	2013-04-02 16:22 EDT (	1 user	I have an abstract aspect (e.g., for testing) and would like to expose inter-type declared state to concrete implementations but *not* to the world. Today I have to either open it too wide (with a public) and then use an aspect to close it down (ugly) or restrict the concrete aspects to be in the same package with a default (package-friendly) scope.Protected inter-type declaration should have the obvious semantics: accessible to anything in the same package or to any concrete aspect that extends the abstract one.	Marking as enhancement request. Planning for 1.2 will determine how these enhancements will be prioritized.Still a perfectly valid enhancement request, but we have no immediate plans to support this feature in the short term so moving to "LATER" status where we can pick it up again at some future point.LATER/REMIND bugs are being automatically reopened as P5 because the LATER and REMIND resolutions are deprecated.I'd like this to be added soon. When I introduce an implementation of an interface that needs fields to do its job, the fields are public, which breaks encapsulation. I want to introduce an interface implementation that doesn't affect the public interface that the class exposed prior to introduction, except for the addition of the newly introduced interface's methods.BTW, this is a related bug that I entered as a result of a mailing list discussion:[bump]	6.0
id=236026	REOPENED	Target Management	RSE	3.0	PC Linux-GTK	P4 minor	dsdp.tm.rse-inbox	2008-06-06 08:17 EDT by	Martin Oberhuber	2013-01-11 02:58 EST (	3 users	Run Eclipse on Linux, Help > Software Updates..., point to the TM UPdate Siteand select the WinCE feature.Trying to install it gives following odd messages:Unsatisfied dependency: [org.eclipse.rse.wince.feature.group 0.1.0.v20080604-02-9oA55S5L7E] requiredCapability: org.eclipse.equinox.p2.iu/org.eclipse.rse.subsystems.wince/[0.1.0.v20080604,0.1.0.v20080604]Unsatisfied dependency: [org.eclipse.rse.wince.feature.group 0.1.0.v20080604-02-9oA55S5L7E] requiredCapability: org.eclipse.equinox.p2.iu/org.eclipse.tm.rapi/[0.1.0.v20080522,0.1.0.v20080522]I assume that the error comes from the fact that the rse.wince plugin depends on the tm.rapi bundle, which is marked as "Windows Only" in its Manifest. So, it cannot install on Linux and thus makes the Feature invalid.As a solution, I think that the wince feature.xml needs to be marked as "Windows Only" such that P2 doesn't even try installing it on Linux.-----------Enter bugs above this line-----------TM 3.0RC2 testinginstallation : eclipse-SDK-3.4RC3 (I20080530-1730), cdt-5.0RC3 (200805300802), RSE-3.0RC3aRSE install : RSE 3.0RC3a with P2 from update site (with WinCE)java.runtime : Sun 1.6.0_01-b06 mixed mode, sharingos.name: : Red Hat Enterprise Linux WS release 4 (Nahant Update 3)------------------------------------------------systemtype : Windows-local, Dstore-win, Dstore-linuxtargetos : Red Hat Enterprise Linux WS release 4 (Nahant Update 3)targetuname : Linux parser 2.6.9-34.EL #1 i686 athlon i386 GNU/Linuxtargetvm : Sun Java HotSpot(TM) Client VM (build 1.4.2_12-b03, mixed mode)------------------------------------------------	CreatedPatch forcing wince feature to be windows onlyAttached patch should be fixing the issue, though I'll only be able to test after committing, with an I-build that's promoted to our update site.The feature is now marked as "win32-x86" only; In the org.eclipse.tm.rapi plugin, I changed the host environment specification to ignore the window system, since I assume that it should be running on wpf as well and not only on win32 because there is no window system specific code in it.Rado please review for RC4Dave please review for RC4Looks like the right thing to me.I'm okay with this change.Thanks, patch committed:[236026][releng] Specify RSE-WinCE feature to support win32-x86 only, allow TM-Rapi bundle on any window systemHopefully fixed, somebody will need to verify with a new build.Sorry guys for not being able to review this on time. The patch looks good to me and I will verify it when the next I-build is available.The fix had to be reverted because it caused the regression on. Build support will need to be reviewed for getting this fixed in TM 3.0.1.Bulk update of target milestoneShould check whether it's possible to tweak P2 metadata into hiding the feature. On Classic UM, we can hide the feature on linux by means of site.xmlAlso, perhaps the latest changes in build support (baseos etc) help addressing the issue fromsuch that the feature is generated even on Linux.At least, with 3.4.1 the warning is more manageable on Linux/Solaris.No luck even with the new Orbit-enabled builder, need to defer again until we build a single master-feature.Should check whether this is fixed with p2.Linuxtools has a similar problem, tracked in.It should, Martin. I just verified that I cannot install the latest Linux Tools builds on Windows and it says something like "... cannot be installed into this environment." The p2 fix landed post-M7 so you'll have to get a more recent I-build.Here is the error message I see with Platform 3.6rc2:Cannot complete the install because one or more required items could not be found. Software being installed: RSE WinCE Services (Incubation) 0.2.100.v201005221100-15A7AkF77g7RFZFJ77 (org.eclipse.rse.wince.feature.group 0.2.100.v201005221100-15A7AkF77g7RFZFJ77) Missing requirement: RSE WinCE Services (Incubation) 0.2.100.v201005221100-15A7AkF77g7RFZFJ77 (org.eclipse.rse.wince.feature.group 0.2.100.v201005221100-15A7AkF77g7RFZFJ77) requires 'org.eclipse.tm.rapi [0.2.0.v200905272300]' but it could not be foundThis is not as bad as it used to be, but it is not really good either. I assume we'll want to apply the attached patch after all, such that the feature is limited to Windows OS; but this will require an updated builder such that we don't run intoagain as per.Given that the WinCE feature is not contributed to Helios, I'm reducing severity and assigning a 3.2.1 target milestone, hoping that our new Hudson Builder will be able to handle this properly.(In reply to)Andrew, I'm still running into this issue. See. Can you point me to what the Linux Tools project finally did to address this? My problem is that if I constrain the "supported os" in the feature.xml, my builder won't build that feature any more.We just added os= filters in our feature.xml files. Everything for us is built on build.eclipse.org which is PPC Linux. Our features are all available in the p2 UI for all OSes but fail to install on non-Linux OSes.That's odd. When I added an "os=linux,solaris,macosx,hpux,aix" filter in my feature.xml, it failed to build on build.eclipse.org, see. I had used the plugin.xml editor UI to do so.Did you actually add the filter - in the feature.xml feature description, or - in the feature.xml plugin description? Or probably both?I'm also wondering whether there's a way to tweak p2 metadata such that the feature doesn't even appear... did you explore that?We only have os= filters in our feature.xml files.The p2 UI has no support for filtering based on OS. See:272535: update-site doesn't show errors for features that are filtered based on platform225365: New update site manager does not filter features based on os correctlyThis would be fixed by getting rid of WinCE in Kepler.	20.0
id=47919	REOPENED	AspectJ	Compiler	1.2	PC Windows XP	P5 enhancement	Adrian Colyer	2003-12-02 15:31 EST by	Wes Isberg	2009-08-30 02:48 EDT (	0 users	Making inter-type member or parent declarations on a final class arguablyviolates encapsulation. Bytecode weaving makes this both more likely, and moreproblematic.For such declarations in a non-privileged aspect, the compiler should issue anerror. This gives us a bright-line rule of thumb that encapsulation will bepreserved when not using privileged aspects. However, this is notbackwards-compatible with some existing programs. While it would be easy to fixthe code (if one has the source) by declaring the aspect privileged[1], doing someans one is not protected from or notified about unintended access controlviolations.An alternative to making it an error is to use an XLint message, preferably witha default level of error. Also, supporting "privileged" as a finer-grained access specifier would avoidsome of the problems above, and might be worth considering on its own merits:aspect A { declare privileged parents: FinalTarget implements Runnable; public privileged boolean FinalTarget.run() {...} private fixup(privileged Foo foo) { // parser-eek! foo.privateVariable = null; } ...}In any case, we should document the issue.	The discussions around this issue continue to circulate periodically. It wouldbe nice to give AspectJ programmers who want some level of assurance/control away to get it. Perhaps a -XrespectFinal[Types?] flag in AJ5 M4 that does notallow modifications to final types? (Caution - the issue is quite tricky, wehave to separate out what the 'user' considers a modification - such as an ITD,or maybe execution advice, from modifications that arise out of currentimplementation strategies (e.g. a perthis() aspect where 'this' has a finaltype). It feels like the latter should be allowed even though it touches thebytes of the final class. Otherwise we end up with semantics that are based on acurrent implementation.Let's look at it as part of the M4 milestone.We're not going to get to this in AJ 1.5.0. Marking as "LATER" for considerationin 1.5.1 and future release planning.LATER/REMIND bugs are being automatically reopened as P5 because the LATER and REMIND resolutions are deprecated.	3.0
id=48077	REOPENED	AspectJ	Docs	1.1.1	PC Windows XP	P5 enhancement	Adrian Colyer	2003-12-04 11:08 EST by	Adrian Colyer	2009-08-30 02:48 EDT (	0 users	Create a set of documentation / samples easily available from the website (and in the distribution?) that show how aspectj can be used with popular J2EE environments: tomcat, weblogic, jboss, websphere, ... .	Still a good thing to have, but apart from our documentation on LTW this will have to come from the user community in the near term. The AspectJ team themselves have higher priority items at the moment.LATER/REMIND bugs are being automatically reopened as P5 because the LATER and REMIND resolutions are deprecated.	2.0
id=41789	REOPENED	AspectJ	Compiler	1.1.0	PC Windows NT	P5 enhancement	Adrian Colyer	2003-08-21 08:19 EDT by	Wes Isberg	2009-08-30 02:50 EDT (	0 users	It would be nice to have an option (e.g., -XlistAccessChanges) to emit infomessages listing the changes made to the accessibility of any affected types ormembers. This would enable people to know about and manage the changes whencompiling against libraries built with ajc, e.g., with declare errors.Further, it might be nice to abort access-hoisting with an error if someprohibited types were affected.	This is a perfectly valid request, but we have no immediate plans to implement it and I'm not aware of any other user requests for this feature in the last 2 years so I'm moving it to the "LATER" state for re-consideration in future release planning.LATER/REMIND bugs are being automatically reopened as P5 because the LATER and REMIND resolutions are deprecated.	2.0
id=48785	REOPENED	AspectJ	Compiler	1.1.1	PC Windows XP	P5 enhancement	Adrian Colyer	2003-12-15 15:19 EST by	Wes Isberg	2009-08-30 02:48 EDT (	0 users	Official J2ME support will require some combination of documentation, testing,and perhaps compiler and runtime changes. For a starting point, see the faqentry aspectjandj2me and the mail archives:This bug is for tracking status, esp. whether work is warranted for the nextrelease.	this would be a great feature to have contributed.We're not going to get to this in AJ 1.5.0. Marking as "LATER" for considerationin 1.5.1 and future release planning.LATER/REMIND bugs are being automatically reopened as P5 because the LATER and REMIND resolutions are deprecated.	3.0
id=49758	REOPENED	AspectJ	Compiler	1.1.1	PC Windows XP	P5 enhancement	Adrian Colyer	2004-01-09 03:33 EST by	Wes Isberg	2009-08-30 02:48 EDT (	0 users	As suggested by William Louth on aspectj-users, could the compiler support aflag to only dump unchanged classes? That would permit a simple copy rule forupdating jars and provide the SCM world with concrete de-minimus proof andprotection against aspects gone wild. It might soothe some of the pain if wedon't fully support -outjar.For those interested in contributing a patch on point, Jim suggested how toimplement this: modify the methodorg.aspectj.weaver.bcel.BcelWeaver.dumpUnchanged to do nothing.	We're not going to get to this in AJ 1.5.0. Marking as "LATER" for considerationin 1.5.1 and future release planning.A submitted patch would increase the chances of this getting back into plan...LATER/REMIND bugs are being automatically reopened as P5 because the LATER and REMIND resolutions are deprecated.	2.0
id=54950	REOPENED	AspectJ	Compiler	unspecified	All All	P5 enhancement	Adrian Colyer	2004-03-16 05:03 EST by	Adrian Colyer	2009-08-30 02:48 EDT (	1 user	(From Wes...)Since you're looking at this now, a step back might help,for now or later...It seems like IMessage is not perfect for handling some kindsof messages we have:- error line and defining declare error or warning- one of many conflicting member declarations- (Do any xlint warnings have different structures?)- info from weaver?We're augmenting it by kind (WEAVER_INFO?) and appendage(details, extra source location...), so it is starting to smell.(Details appears vestigial. Extra source location has no contextfor why it is being appended.)One way to work around this now is instead to have differentIMessage implementations (e.g., DeclaredMessage, XLintMessage,ConflictMessage, subclassing Message or EclipseMessage(?)).Further, we might want an ISourceLocation implementation"BinaryLocation" for sources in jar files. (It might eventake on responsibility for pulling associated text froma source path or src.zip.)Doing this means that clients of IMessage and ISourceLocationcontinue to work, but clients that know about BinaryLocationand DeclareMessage, etc. can tailor accordingly. This changeis nice b/c we don't change anything about how we handle messagesper se, and changing to subtypes should make sense in the contextthey are being generated. We can even have a "normal" messagesubtype and audit away direct (non-testing) uses of Message.Two unanswered and deferred questions:(1) Whether we can continue to generate each message incrementallybut easily gather all associated messsages (deow, conflicts).to facilitate message-handling strategies that group relatedmessages. [defer until needed by client/strategy](2) Whether we should delegate to the smarter types for theircommand-line renderings or keep using a renderer. [defer untilneed renderer-less rendering]	Raised so that we don't lose this post 1.2...no immediate plans to change the message handling implementation, but these comments remain valid for consideration if we have to go in there again in the future.LATER/REMIND bugs are being automatically reopened as P5 because the LATER and REMIND resolutions are deprecated.	3.0
id=61535	REOPENED	AspectJ	Compiler	1.2	All other	P5 trivial	Adrian Colyer	2004-05-09 12:48 EDT by	Laurie Hendren	2009-08-30 02:51 EDT (	0 users	Can't handle pattern like *if, public class Test { public static int if1(int x) // 1st before advice should match here { return(x+1); } public static int while1(int x) // 2nd before advice should match here { return(x+1); } public static void main(String args[]) { System.out.println(if1(1)); System.out.println(while1(1)); }}aspect Aspect { before() : call(int if*(int)) && within(Test) // this causes a parse error in ajc { System.out.println("before method starting with if"); } before() : call(int while*(int)) && within(Test) // this is ok { System.out.println("before method starting with while"); }}	Thanks for the simple and clear bug report. This is a valid bug; however, I'm marking it a P4 because it is a little bit hard to fix, and the problem is a minor one. If it was available, I'd mark this with a 1.3 milestone.The parser for name patterns goes to a lot of work to handle all of the standard java keywords as part of a name pattern. To do this, all of the keyword tokens that come out of the jdt's parser are converted to name tokens for our parser (in org.aspectj.weaver.patterns.PatternParser).The one exception to this is the if keyword which we currently use the jdt's grammar and parser to produce a single IfPseudoToken out of 'if' '(' <expr> ')'. Reusing the jdt's java parser (in shadows/org.eclipse.jdt.core/grammars/java_14.g) to parse the if expression is essential to our integration with the jdt.Fixing this bug will require carefully looking at our modified jdt grammar and parser + our custom PatternParser. The case that I think will be hardest to handle is something like, 'call(* *if(x))'. In this case, I don't see how our pseudo token stream code can tell the difference between the pcd 'if(x)' and the name pattern '*if'.This bug is fairly well localized to the two parsers and is the kind of bug that would be much likelier to be fixed with an attached patch.We're not going to get to this in AJ 1.5.0. Marking as "LATER" for considerationin 1.5.1 and future release planning.LATER/REMIND bugs are being automatically reopened as P5 because the LATER and REMIND resolutions are deprecated.	3.0
id=51230	REOPENED	AspectJ	Compiler	1.1.1	PC Windows XP	P5 enhancement	Adrian Colyer	2004-02-05 06:32 EST by	knizhnik	2009-08-30 02:50 EDT (	0 users	It wwill be nice if AspectJ can avoid generation of runtime check for if primitive pointcut if expression can be eveluated at compile time.The most important example is deecting access to self fields. Such optimization is very important for persistence and remoting aspects.If we access field of "foreign" object, then object has to be loaded first.If we access field of this object (most common case), then no extra checks are needed. Pleas notice that exact check is not needed. For example:MyObject o = this;o.foo = 1;It is not critical that here access to "foo" will be not be treated as "this"access.In AspectJ poincut for matching access to non-this fields can be written in the following way:nonSelfGet(Peristent self, Persistent dst): get(* Persistent.*) && target(dst) && this(self) && if(dst != self);Unfortunatelly this pointcut requires runtime check, which makes this optimization completely useless. Instead of two byye code instructionsApsectJ inserts 20 instruction, which cause increase of byte code about 10 times and about 3 times decrease speed: 0: aload_0 1: getfield #27; //Field x:I-------- 0: aload_0 1: astore_1 2: aload_0 3: aload_1 4: invokestatic #110; //Method DynamicTest$CheckFieldAccess.ajc$if_0:(LDynamicTest;LDynamicTest;)Z 7: ifeq 19 10: invokestatic #102; //Method DynamicTest$CheckFieldAccess.aspectOf:()LDynamicTest$CheckFieldAccess; 13: aload_0 14: aload_1 15: invokevirtual #106; //Method DynamicTest$CheckFieldAccess.ajc$before$DynamicTest$CheckFieldAccess$543:(LDynamicTest;LDynamicTest;)V 18: aload_1 19: getfield #27; //Field x:IBut in most cases it is possible to calculate this condtion during compile time! For all "this" accesses (in terms of Java fields access without specifying base object, in terms of byte code - fields of instance method which targt is loaded using aload_0 instruction), specified if condition is always false. So no runtime check needs to be inserted.Also it may be possible to calculate at compile time some other kinds of if conditions, for example instanceof checks. Certainly it is not so important, because most of such checks can be rewritten using other pointcuts which do not require runtime checks. May be there are other useful conditions whichcan not be expressed in other way and which can be calculated at compile time.So I wonder if this change request will be consiidered to be useful and can be easily implemented.	This is a useful optimization idea, but it is unlikely to be implemented any time soon without a patch contributed that implements it. The only reason not to do this optimization is the time required to implement and test it carefully; however, that's a powerful reason not to do it without a contribution.Still a perfectly valid enhancement request, but we have no immediate plans to implement this in the near future so moving to "LATER" status for consideration in future planning activities.LATER/REMIND bugs are being automatically reopened as P5 because the LATER and REMIND resolutions are deprecated.	3.0
id=60936	REOPENED	AspectJ	Compiler	1.2	PC Windows XP	P5 enhancement	Adrian Colyer	2004-05-04 13:44 EDT by	Wes Isberg	2009-08-30 02:49 EDT (	0 users	Given, the compiler message for code like this: interface I {} .. before() : execution(I.new(..)) { .. } // errorcould be: no constructor-execution on interface typeI can't think of a reason why it shouldn't be an error, since it is incorrect. The current behavior (silence) leads developers to believe that their 1.1-eracode still works as usual.	Ordinarily, I'd classify this as a P5 enhancement request. However, the fact that we made this "fix" to the weaver to remove constructor execution join points on interfaces (see) for 1.2 makes this a much harder call. In retrospect, we should have added an error or warning for this case when we made that previous change. It's harder to decide what to do at this point after 1.2rc2 has been built.I think that we should add a warning for any use of <InterfaceType>.new in a signature pattern. This is fairly easy to implement so I think we can have confidence that it won't add surprising new bugs. The implementation goes in SignaturePattern.resolveBindings after the declaringType has been resolved. It needs to check that there is a single getExactType() for declaringType and that type is an interface. It also needs to check that there is no '+' to include subtypes (declaringType.isIncludeSubtypes()). If that's all true, and the kind is CONSTRUCTOR, then a warning should be issued. I'd probably make this an Xlint warning, but can't think of the right type just now.Here's my brief risk analysis:Not making the change: The risk is that programs that were using execution(I.new(..)) will now silently behave differently because there is no join point for them to match. This can be very hard to track down. We know that this shows up in at least one actual AspectJ program in the wild based on the message to users "Previously running program broke with 3.0M8/AJDT 1.1.8" from "Miguel J. T. Pessoa Monteiro"Making the change: I think there's minimal risk that we'll break anything unrelated to this issue. The only risk I see is that we could generate additional incorrect Xlint warnings for valid AspectJ programs. So long as these are warnings, they won't prevent compilation and they will be very visible and hopefully therefore they will be promptly reported and could be fixed in a 1.2.1 release.I've done the implementation. I'm just having trouble getting the words in the xlint message right. I currently have:no constructor join points for interface type XXX [Xlint:noInterfaceCtorJoinpoint]comments? I don't want the user to think there is a way they could mangle their pointcut or their interface definition to 'get at' a ctor jp - so it could be 'interfaces have no exposed constructor join points. Interface type XXX'?This change also causes 7 tests in the harness to fail that were using interface.new() - I'll look at those.Fix checked in. I've used the error message Wes proposed on the lists.Depending on whether we think interface initialization joinpoints exist, I had to implement it slightly differently than described by Jim - implementing the proposed fix meant we produced a lint warning whenever we encountered a I.new(..) pattern - that means initialization(I.new(..)) was no longer allowed. Seven testcases rely on this being a valid join point. So I had to also check that the shadow kind was ConstructorExecution. Here is the complete piece of logic I added to KindedPointcut.resolveBindings:if (kind == Shadow.ConstructorExecution) { // Bug fix 60936 if (signature.getDeclaringType() != null) { World world = scope.getWorld(); TypeX exactType = signature.getDeclaringType().getExactType(); if (signature.getKind() == Member.CONSTRUCTOR && !exactType.equals(ResolvedTypeX.MISSING) && exactType.isInterface(world) && !signature.getDeclaringType().isIncludeSubtypes()) { world.getLint().noInterfaceCtorJoinpoint.signal(exactType.toString(), getSourceLocation()); } }}This works - preventing execution(I.new(..)) but allowing initialization(I.new(..)). I'm not a fan of this inconsistency though so I will append to the list to check if initialization(I.new(..)) should still be valid?Interesting. Java never states that there is a constructor with the declaredtype of I. So if we do, we're adding a definition where there was none. And asAndy points out, it means the same "constructor" signature matches differentlydepending on the constructor-associated join point. It seems the signature isinvalid also for {pre}-initialiation join points, that the seven tests arethereby invalid, and that the correct form is I+.new(..) for all those pcd's.On the other hand, if people use it and it works, what then? Extending the lintwarning to the {pre}initialization join points should provoke feedback ifdisabling it is a problem.The test suite served its purpose well here. Interface initialization join points are an important case to consider.We need to continue to support join points for the initialization of an interface. AspectJ adds instance variables to interfaces through intertype declarations and these variables will often need initialization code. In fact, the only way to write complicated initialization logic for intertype field declarations on an interface is by place after returning advice on its initialization join point.The syntax for these initialization join points is unfortunate. The first proposals for this pcd was to provide initialization(<typepattern>) instead of initialization(<constructor-signature>). Unfortunately, we realized that there was some value in being able to pick out a specific constructor in rare case, and that you could always get the non-specific version with initialization(<typepattern>.new(..)). This was ugly, but we didn't see any fundamental problems at the time.This discussion has shown that interface initializers are an example of a useful joinpoint that can't really be sensibly be captured by initialization(<constructor-signature>).For 1.2 we should stick with Andy's current change to just warn on execution. We could by more agressive and emit the warning for everything except initialization; however, I don't think that would be worthwhile for 1.2. The main problem that we're trying to solve here is the potentially silent implementation change for these interface constructor executions.For 1.3, we should consider adding the form initialization(<typepattern>) to the language and then warning on ALL uses of <interface>.new.Here's a short program that shows how the initialization of an interface is different from the initialization of its topmost implementing class. The code below will print:before: initialization(C())before: initialization(I())initializing I.axafter: initialization(I())initializing C.xafter: initialization(C())------------------------------------------------public class InterfaceInit { public static void main(String[] args) { C c = new C(); } static int GetIntAndPrint(String msg) { System.out.println(msg); return 42; }}class C implements I { int x = InterfaceInit.GetIntAndPrint("initializing C.x");}interface I {}aspect A { private int I.ax = InterfaceInit.GetIntAndPrint("initializing I.ax"); pointcut init(): initialization(new(..)) && !within(A); before(): init() { System.out.println("before: " + thisJoinPointStaticPart); } after() returning: init() { System.out.println("after: " + thisJoinPointStaticPart); }}See Jim's proposal for initialization(typepattern). One to look at in AJ 5 M4 ifwe're going to do this at all...This bug was resolved bar the remaining potential enhancement to support an initialization(<typepattern>) form. We have no plans to implement that in 1.5.0 so moving this bug to LATER status for consideration in future release planning.oops, should have removed target milestone too...LATER/REMIND bugs are being automatically reopened as P5 because the LATER and REMIND resolutions are deprecated.	9.0
id=61573	REOPENED	AspectJ	Docs	1.2	PC Linux	P5 enhancement	Adrian Colyer	2004-05-10 06:24 EDT by	Oege de Moor	2009-08-30 02:50 EDT (	0 users	[This was first pointed out by Aske Christensen (), and thedescription below is due to him.]Java compiles a method invocation into an invocation of the method with the samename whose parameter types most closely match the declared types of the arguments.This can cause different method call signatures to be generated depending onwhether the Java class was compiled separately or together with an aspect.It's not really a compiler bug, but the docs should warn of this behaviour.Consider this program:public class MethodMatch { public static void main(String[] args) { foo((Object)"Object"); foo("String"); } public static void foo(Object o) { System.out.println("An object: " + o); } } public aspect NewFoo { public static void MethodMatch.foo(String s) { System.out.println("A string: " + s); } after(): execution(void main(*)) { System.out.println("Woven"); } } If we just compile the MethodMatch class by itself without weaving any aspects,we get the output:An object: Object An object: String If we now weave the NewFoo aspect into the MethodMatch class file, we get:An object: Object An object: String Woven However, if we compile MethodMatch and NewFoo together, we get:An object: Object A string: String Woven	This is a doc bug as stated by the bug report itself.I see this as a classic issue of separate compilation. If I add a class SuperMethodMatch and declare MethodMatch extends SuperMethodMatch, then I can get this same behavior in pure Java. All that I have to do is add the foo(String) method to SuperMethodMatch and only recompile the super class without recompiling the implementors.Our docs do need a better description of the effects of different kinds of separate compilation in AspectJ; however, I don't think this is too radically different from the issues of separate compilation in Java.Changing this to a P4 enhancement; I'm not going to be able to finesse the language a section like this must have for 1.2.1. In general I am not convinced that typical users will need a warning that binary compatibility is an issue. And enough of a specification of the binary compatibility issues with AspectJ (though there aren't greatly more than those in JLS 13) to satisfy language folks like myself will take morededicated hours than I have right now. So priority downgraded due to too low payoff/work.I'm assigning this to adrian as a placeholder, but I have a feeling this shouldbe copied to a "maybe, someday" list and marked resolved/wontfix orresolved/later to get it out of the bug listAs per Erik's comment, no "typical users" have reported any issue with this in the last year, so I'm moving to LATER as we have no immediate plans to update the docs on this matter at this point in time.LATER/REMIND bugs are being automatically reopened as P5 because the LATER and REMIND resolutions are deprecated.	5.0
id=63304	REOPENED	AspectJ	Compiler	unspecified	PC Windows XP	P5 enhancement	Adrian Colyer	2004-05-20 15:55 EDT by	Ron Bodkin	2013-04-19 15:04 EDT (	3 users	Allow defining type names that can be used anywhere a type pattern can be used in AspectJ (e.g., in ). This will allow reuse and composition of patterns, which is going to be especially important when resolvingand adding support for JSR-175 annotations to AspectJ.It would be *very* beneficial if these type names could be used for inter-type declarations and declare forms like declare soft, instead of requiring these to be restricted to a single type.Example syntax (proposed by Jim): declare typename: PublicFinalType: public final *;It would be conceptually nice if these type names could be used throughout a code base wherever a type is allowed (basically providing a typedef facility for Java), although that would represent a significant non-AOP extension to Java.	Why limit such an addition to just type patterns? How about method,constructor, and field patterns as well? Looking at the AspectJ 1.1 quickreference I'm not seeing a mechanism to use OR-operators ( || ) for thesepatterns, but, why not?For example, if I need to define call() and execution() pointcuts across thesame set of methods, its bad from a maintenance standpoint to have to copy thesignatures multiple times. For example:pointcut fooCalls() : call(... method signature 1 ...) || call ( ... methodsignature 2 ... ) || etc.;pointcut fooExecutions() : call(... method signature 1 ...) || call ( .. methodsignature 2 ... ) || etc.;Why not support a way to define a set of method signatures, attach a name to it,and then do:pointcut fooCalls() : call(fooMethods);pointcut fooExecutions() : execution(fooMethods);Thanks for your consideration of this opinion.We're not going to get to this in AJ 1.5.0. Marking as "LATER" for considerationin 1.5.1 and future release planning.Something like this *should* make it into AJ sooner rather than later though I hope.LATER/REMIND bugs are being automatically reopened as P5 because the LATER and REMIND resolutions are deprecated.Any change in status for this? I'd still like to be able to prevent inheritance within certain packages or types, especially as I use traits more & more:public abstract aspect AbstractExtend { public static class Nothing {} /** * Type expression provided by subaspects to identify types that are not * allowed to use inheritance. */ public abstract type restrictedTypes; public type requiredInheritance: Enum+ && Annotation+; declare parents: (restrictedTypes && !requiredInheritance) extends Nothing;}no change I'm afraid, I'm heads down in JDT Core Java 8 right now.	5.0
id=71793	REOPENED	AspectJ	Compiler	unspecified	PC Windows XP	P5 enhancement	Adrian Colyer	2004-08-11 11:24 EDT by	Eric Bodden	2009-08-30 02:48 EDT (	0 users	This code...public aspect Test { int field; public Test() { field = 0; }..some pieces of advice...}...leads to this exception:org.aspectj.lang.NoAspectBoundException: Exception while initializing aha_Test: org.aspectj.lang.NoAspectBoundException: aha_Test at aha.Test.aspectOf(Test.aj) at aha.Aha.main(Aha.java)Caused by: org.aspectj.lang.NoAspectBoundException: aha_Test at aha.Test.aspectOf(Test.aj) at aha.Test.<init>(Test.aj:21) at aha.Test.ajc$postClinit(Test.aj) at aha.Test.<clinit>(Test.aj:16) ... 1 moreException in thread "main" I assume that something weird happens when I set field in initialization phase!?	whether or not this is a bug depends on exactly what the "some pieces of advice" are. If you are trying to advise a join point that happens before the aspect is constructed (like any field set in the aspect perhaps?) then the behaviour you are seeing is correct. Please confirm or supply a complete test case that reproduces the bug...Thanks, A.Yes, I am having a set-advice on that field. That makes sense, cheers.However, I would wish to have a better error message in that case if possible. (e.g. output, what advice causes this error)I'm moving this to an enhancement request. The exception you see occurs at runtime (obviously) and gives pretty good information already: whilst initializing the "aha_Test" aspect ("aha.Test" would have been better there), an attempt was made to obtain the aha.Test aspect instance, and a NoAspectBoundException was thrown".The enhancement to be considered is that is some cases we know statically that this problem is going to occur - i.e. when weaving advice into an aspect initializer, and that advice has no runtime test associated with it. In such circumstances we could put out a compilation error. Your program would be one such situation I suspect.We're not going to get to this in AJ 1.5.0. Marking as "LATER" for considerationin 1.5.1 and future release planning.LATER/REMIND bugs are being automatically reopened as P5 because the LATER and REMIND resolutions are deprecated.	5.0
id=64069	REOPENED	AspectJ	Compiler	1.2	PC Linux	P5 normal	Adrian Colyer	2004-05-26 07:08 EDT by	Oege de Moor	2009-08-30 02:48 EDT (	1 user	When weaving into source, ITDs for constructors and methodsoverride private members of the same signature: it is as ifthe private member never existed. This is illustratedby the example in Dups.java. The same example, when the classesare compiled separately and using bytecode weaving, gives aClassFormatError upon execution. The situation for fields is different: the compiler flags an error when an ITD tries to introduce a public x where a private x already existed. The error is however flagged only when x is used in theclass. Without any uses, such a clashing field is passed by the compiler,but when the program is run, java throws a ClassFormatError.This behaviour is illustrated in DupField.javaThe above seems to be a bug: the behaviour shouldbe consistent in all situations.Request: make it always legal to introduce a new member by ITD thathas the same name/signature as a private member. Mangle the private member and all its uses. /* --------------------------------------------------------------- Dups.java When weaving into source, ITDs for constructors and methods override private members of the same name. Using bytecode weaving (and separate class files for each of the classes) this example gives a ClassFormatError upon execution.*/aspect Aspect { public A.new() { super(); System.out.println("ITD A()"); } public void A.bar() { System.out.println("ITD bar"); }}class A { void foo() { A a = new A(); bar(); } private A() { super(); System.out.println("private A()"); } private void bar() { System.out.println("private bar"); }}public class Dups { static public void main(String[] args) { new A().foo(); }}/* ------------------------------------------------------------------ DupField.javaThe compiler flags an error when an ITD tries to introduce a public x where a private x already existed. The error is however flagged only when x is used in the class. Without any uses, such a clashing field is passed by the compiler, but when the program is run, java throws a ClassFormatError. This behaviour is illustrated in DupField.java:to see the ClassFormatError, comment out the assignment "x=0" in foo().*/aspect Aspect { public int A.x;}class A { private int x; void foo() { // when the line below is commented, we get a runtime error x=0; // error: The field x is ambiguous }}public class DupField { static public void main(String[] args) { new A(); }}	marked as target 1.2.1The resolution of this bug will be to give an error message when attempting to define an ITD with the same signature as an existing member of the target type. (The JLS does not include visibility as part of the signature).If we did otherwise, consider the situation where a public ITD is made over-the-top of a protected member - eurgh!(unless the target type is an interface of course)ok.... we already do the right thing with protected.The bug report raises an interesting semantic question that the semantics appendix doesn't fully address. There is a case to be made that private member declarations should not pollute the namespace for external aspects wishing to make ITDs on that type (Oege's proposal). This would be equivalent to the behaviour seen when declaring a sub-type of the target type. The case for ruling that this should be disallowed is that ITDs do not have the semantics of a sub-type, but rather the semantics of open class extension (as evidenced by that fact that members in the target class are refered to via 'this' within the body of an ITDM rather than 'super'). In particular, if the target class defines a private method m(), and an aspect makes a public ITDM Target.m(), then a reference to this.m() inside the Target class is ambiguous and there is no way for the programmer to differentiate between the two possibilities. There's also the more obvious point that Java doesn't allow you to define more than one member with the same signature but different visibility in the same type - and we have said that ITDs have 'same type' semantics rather than 'sub-type' semantics. All that said, I wasn't party to the original design discussion on how ITDs should work in this case.... so ***Erik***, please jump in if you believe that we *should* do the mangling thing here....would help if I actually cc'd Erik when asking him a question!With apologies to anyone who is getting fed-up watching me argue with myself....There's one big disadvantage to the "error message" solution which is this: if I write an aspect that makes a public ITD on a target class, that aspect is now required to know the internal, private, details of the target class (to make a choice of distinct name). Worse, subsequent maintenance (adding or renaming a member) of the private members of the target class could break existing aspects. That's more tightly coupled than I'd ideally like things to be. If we *did* mangle, the rule would have to be that from inside the target type, any private member defined in that type hides any ITDs with the same signature.However, as Andy points out, if we do mangle, it's not just a case of renaming the private member and its references, we would also have to ensure that all the original (unmangled) join points still exist.Since the current implementation is broken, we know that no-one is actually doing this. I propose to make this an error in 1.2.1, and if we decide that the mangling really is the right thing to do, the 1.2.1 behaviour will be described as an 'implementation limitation' (as opposed to AspectJ's semantics) and we can look to do the harder thing in 1.3.Fix now available for download in latest aspectj development build. Marking bug as resolved-LATER pending discussion of whether to do mangling in 1.3 or not.This is definitely the consistent with the original AspectJ design: Weconsciously decided to make most open-class collisions conflicts, as per the Java conflict rules (declaration for methods, reference for fields). While Oege is right that it may be a _useful_ mechanism to be able tohave original private members "shadow" inter-type public methods, I'd voteto have the AspectJ successor language have that feature and leave AspectJto not do that shadowing.Fix released as part of AspectJ 1.2.1LATER/REMIND bugs are being automatically reopened as P5 because the LATER and REMIND resolutions are deprecated.	10.0
id=76344	REOPENED	AspectJ	Compiler	unspecified	All All	P5 normal	Adrian Colyer	2004-10-15 07:05 EDT by	Bruno Harbulot	2009-08-30 02:51 EDT (	0 users	Hello,I'd like to suggest that the "privileged" keyword also applies to calls frominner classes within a privileged aspect.I've been using aspects for multithreading and I've got inner classesimplementing "Runnable" that are calling private methods of other classes.For example:public class ComputationalClass { private void compute (int min, int max) { for (int i=min; i<=max; i++) { /* ... */ } } /* ... */}public privileged aspect MultiThread { private final class ComputeRunner implements Runnable { private final ComputationalClass compClass ; /* ... */ public void run() { compClass.myCompute(min, max) ; } } private void ComputationalClass.myCompute (int min, int max) { compute(min, max) ; } /* Then, an "around" piece of advice can intercept calls to ComputationalClass.compute(int, int) and "replace" them by running several ComputerRunners on several Threads. */}Ideally, it would be better not to need to write the inter-type declaration("myCompute"), and give the inner class privileged access toComputationalClass.compute as well.Could a feature like this be envisaged in a future release of AspectJ (althoughthis would change the language specifications)? Bruno.	We're not going to get to this in AJ 1.5.0. Marking as "LATER" for considerationin 1.5.1 and future release planning.LATER/REMIND bugs are being automatically reopened as P5 because the LATER and REMIND resolutions are deprecated.	2.0
id=83333	REOPENED	AspectJ	Compiler	unspecified	PC Windows XP	P5 enhancement	Adrian Colyer	2005-01-20 14:28 EST by	Colbert Philippe	2009-08-30 02:50 EDT (	0 users	In soon to be merge with AspectWerkz, keep all functionalities of both package as much as possible. For instance, keep AspectWerkz's capability to program in XML files as well as by annotations and others. It's important to give the programmer the maximum amount of options given the different uses of aspect programming.	The proposed initial support for XML is documented in the developers notebook:Specifically here:for aj5m4, if not before....The AJDK notebook chapters referenced earlier in this enhancement requestdescribe all of the XML support features we believe we can do for 1.5.0. I'mmarking this request as "LATER" since we may do more in future releases.LATER/REMIND bugs are being automatically reopened as P5 because the LATER and REMIND resolutions are deprecated.	4.0
id=83803	REOPENED	AspectJ	Compiler	1.2.1	PC Windows XP	P5 enhancement	Adrian Colyer	2005-01-27 03:55 EST by	Wes Isberg	2009-08-30 02:50 EDT (	0 users	Another usability proposal...Nicholas Lesiecki suggested (in the email "Changing this, docclarification[...]") a special form of "proceed()" which uses the argumentspassed in to the join point, in the interest of making explicit the intention tonot replace any values or references (even though Java doesn't support "const".) To distinguish this form from a mistake (and show how special it really is), itshould probably be "proceed(..);" (if that's amenable to the parser).	interesting idea... scheduling for proper consideration in aj5m4We're not going to get to this in AJ 1.5.0. Marking as "LATER" for considerationin 1.5.1 and future release planning.LATER/REMIND bugs are being automatically reopened as P5 because the LATER and REMIND resolutions are deprecated.	3.0
id=88620	REOPENED	AspectJ	Compiler	DEVELOPMENT	PC Windows XP	P5 enhancement	Adrian Colyer	2005-03-21 04:24 EST by	Eric Bodden	2009-08-30 02:50 EDT (	0 users	I would like to see pointcut overloading supported in future versions, because I think it's very natural for Java programmers to have this, compared to method overloading.One issue, Gregor raised is the one that people also requested the feature of omitting certain parameters in pointcuts, such as:pointcut foo(Object o1): foo(Object o1, Object o2);If one *does* want to allow this, this is of course an issue:What happens in the casepointcut foo(Object o): foo(Object o, String s);... where ...pointcut foo(Object o, String s): call(* Object.equals(..)) && this(o) && target(s);Problem: Should foo(String s) only match calls to Strings, as foo(Object o, String s) does, or should it omit the constraint introduced by target(s), since s is not bound?So either one could drop this feature of omission altogether or one could find some sensible semantics for this ambiguity. But overloading would be nice anyway IMHO.	this is a perfectly valid feature request but we have no immediate plans to implement it so marking as "LATER" for consideration in future planning cycles.LATER/REMIND bugs are being automatically reopened as P5 because the LATER and REMIND resolutions are deprecated.	2.0
id=92335	REOPENED	AspectJ	Compiler	1.5.0M2	PC Windows XP	P5 enhancement	Adrian Colyer	2005-04-22 02:07 EDT by	Wes Isberg	2009-08-30 02:48 EDT (	0 users	It would be nice to say declare message {level} : {pointcut} : {message} {, {message}}..;e.g., declare message ignore : logging() : AdviceDidNotMatch ;Then (among other things) you could flag pointcuts used to disable/enablefeatures as such, without false positives (i.e., without losing fthe ability tosee advice that you intended to match not match).(I realize this would be ridiculous to implement, but hey, that's what P4+ is for!)	We're not going to get to this in AJ 1.5.0. Marking as "LATER" for considerationin 1.5.1 and future release planning.LATER/REMIND bugs are being automatically reopened as P5 because the LATER and REMIND resolutions are deprecated.	2.0
id=93492	REOPENED	AspectJ	Compiler	unspecified	PC Windows XP	P5 normal	Adrian Colyer	2005-05-03 05:01 EDT by	Rodrigo Gonçalves	2009-08-30 02:49 EDT (	0 users	Hello, After a small discussion with Wes Isberg and Eric Bodden about dummy variables, I learned that Wes’s proposal on the use of “this” designator in type patterns had not been yet submitted as a Request For Enhancement (RFE). I think the afforementioned use of the “this” designator would bring advantages and open new possibilites for AspectJ. By using “this” on type patterns we could refer to the implicit instance and have pointcuts that capture join points solely on the implicit instance. This might cover some of the possible uses of an extension of the pointcut specification syntax to include the specification of dummy variables. Here’s a little example:import static java.lang.System.out;public class Test { private int i = 0; public void f() { this.i = 1; /* or this.i = 1; */ } public static void main(String[] args) { Test t = new Test(); t.f(); t.i = 2; } static private aspect CaptureThis { before() : set(* this.*) { out.println("Found this.set!"); } before() : set(* *.*) { out.println("Found set!"); } }}Regards, Rodrigo Gonçalves	We're not going to get to this in AJ 1.5.0. Marking as "LATER" for considerationin 1.5.1 and future release planning.LATER/REMIND bugs are being automatically reopened as P5 because the LATER and REMIND resolutions are deprecated.	2.0
id=95716	REOPENED	AspectJ	Compiler	DEVELOPMENT	PC Windows 2000	P5 enhancement	Adrian Colyer	2005-05-18 05:09 EDT by	Nitzan Volman	2009-08-30 02:50 EDT (	0 users	Should be a way to access the original field value at a set joint point builtinto the language.a possible solution is to add getOriginalFieldValueAtAFieldSetJoinPoint() method to the thisJoinPoint interface.a usage example would be:after(Object newValue) returning : set( * *) && args(newValue) { Object oldValue = thisJoinPoint.getOriginalFieldValueAtAFieldSetJoinPoint() ; if (!oldValue.equals(newValue) { firePropertyChangeEvent(oldValue,newValue,thisJoinPoint.getSignature()); }}	We're not going to get to this in AJ 1.5.0. Marking as "LATER" for considerationin 1.5.1 and future release planning.LATER/REMIND bugs are being automatically reopened as P5 because the LATER and REMIND resolutions are deprecated.	2.0
id=97192	REOPENED	AspectJ	Compiler	DEVELOPMENT	All All	P5 enhancement	Adrian Colyer	2005-05-30 05:23 EDT by	Alexandre Vasseur	2009-08-30 02:50 EDT (	0 users	As discussed, I am about to commit @AJ support for Java 1.3. This one is relyingon backport175 CodeHaus Jonas and Alex project that backports part of theJSR-175 to Java 1.3I need license check process as per Eclipse rules:Backport is Apache 2.0it depends on and includes in its single jar thru a package renaming:- QDox, which is under The IronSmith Software License, Version 1.1 (this licenseis derived and fully compatible with the Apache Software License - see)- ASM, which is under the BSD licenseAside, backport requires the user to have an Ant installed to use the includedAnt task.Adrian, can you proceed ?I assume I cannot commit my stuff (a test case + the jar in lib/ext/backport) aslong as I don't have approval)	OK, it seems we have to first obtain John Duimovich's approval, and then fill inthe contribution questionnaire atfor review bythe EMO.I'll kick-start the process by contacting John...done thru unofficial channelLATER/REMIND bugs are being automatically reopened as P5 because the LATER and REMIND resolutions are deprecated.	3.0
id=92889	REOPENED	AspectJ	Compiler	1.2.1	PC Windows XP	P5 enhancement	Adrian Colyer	2005-04-27 05:26 EDT by	Dusan Chromy	2012-08-25 08:03 EDT (	2 users	Consider the following code snippet from an aspect, assuming there is a classMain with methods tigger() and foo() and that the foo() method can either becalled directly or from within tigger(): pointcut T() : execution(* Main.tigger()); pointcut F() : execution(* Main.foo()) && !cflow(T()); Object around() : T() || F() { // do something Object z = proceed(); // do something else return z; }As you can see, there is an around advice which does something when eithertigger() or foo() gets executed. So far so good, now assume the advice bodywould like to know if it is being executed on behalf of pointcut T or F?I could not think of any other way than creating two advices, one for T and onefor F. Unfortunately the two advices cannot share the same body, so theprogrammer is forced into copy-paste-and-hack style. The two advices couldof course call a method (which could have a parameter indicating where it iscalled from), however this does not go a long way because in a method you cannot call "proceed" or have access to thisJoinPoint reflections.To solve this I suggest allowing explicit formals binding in pointcuts, like this: pointcut T(boolean flag) : execution(* Main.tigger()) && bind(true); pointcut F(boolean flag) : execution(* Main.foo()) && !cflow(T()) && bind(false); Object around(boolean flag) : T(flag) || F(flag) { if (flag) // do something else // do something different Object z = proceed(); // do something else return z; }The whole process of binding resembles functional programming to me and allowingexplicit binding seems to me as a logical step.	why not just use thisJoinPoint in the body of the advice? Since T and F matchdifferent join points, this would always enable you to distinguish. If T and F*could* both match at some join point, your proposal would break - what shouldthe value of the flag be? Advice executes at join points, not at pointcuts, sothe current thisJoinPoint abstraction is appropriate imho.not sure why this was assigned to me - sending it back to Adrian...Hello Adrian,thanks for your response. I even reassigned the bug to Julie in the false beliefthat the bug report went unnoticed, sorry for that extra bother. A friend ofmine met you on the JAX in Frankfurt, so I see you must be busy these days.I understand it is possible to examine thisJoinPoint in the advice body todistinguish the cases in my example. However, it means the advice must knowabout join point signatures, which is IMHO something that should be captured inpointcuts only. I agree the binding would be impossible if T and F both matchedthe same join point, but that's not really anything new or bad - there alreadyis an "Ambigous binding" error in AspectJ.I admit my example was perhaps too abstract and not very convincing. Let me giveyou a real code example that I wrote just today. We are using AspectJ to doperformance monitoring using Apache's StopWatch class. In some classes, Iintroduce the StopWatch object to the class using inter-type declaration (moreprecisely, I declare the class to extend a base class which has the StopWatch asa member). In other classes, I just create a new StopWatch object for everymethod invocation. This leads to a code with two very similar advices: Object around() : measuredMethod() { StopWatch w = new StopWatch(); try { w.start(); return proceed(); } finally { w.stop(); // output w here } } Object around(StopWatchOwner owner) : measuredMethodWithOwnWatch(owner){ try { owner.getWatch().start(); return proceed(owner); } finally { owner.getWatch().stop(); // output owner.getWatch() here } }As you see, the two advices are almost identical. A clear violation of the DRYprinciple, isn't it? Yet the two cannot be merged, for the sole reason that onepointcut has no arguments and the other one has one. What I would love to do isthis://redefine the pointcut that had originally no arguments pointcut measuredMethod(StopWatchOwner owner) : // whatever joinpoint definition here && bind(null);//and merge the two advices as: Object around(StopWatchOwner owner) : measuredMethod(owner) ||measuredMethodWithOwnWatch(owner) { StopWatch w = (owner == null) ? new StopWatch() : owner.getWatch(); try { w.start(); return proceed(); } finally { w.stop(); // output w here } } What do you think?This example makes a lot more sense, thanks. I don't think we'll have time tothink through all of the potential issues in here in order to make the 1.5.0release - and it's also something that no other user has asked for afaik. I'mgoing to leave this open as an enhancement request but with no target milestoneassigned for the time being, that way we can come back and take another lookonce we've dealt with the 1.5.0 release.We're not going to get to this in AJ 1.5.0. Marking as "LATER" for considerationin 1.5.1 and future release planning.LATER/REMIND bugs are being automatically reopened as P5 because the LATER and REMIND resolutions are deprecated.I second this (old) request. My situation is as follows:I have a logging aspect with several pointcuts and advice:aspect LoggingAspect { pointcut logMe1() : execution(...); pointcut logMe2() : execution(...); pointcut logMe3() : execution(...); Object around() : logMe1() { String logMessage = "log message #1"; logger.log("before " + logMessage); logger.indent(); Object result = proceed(); logger.dedent(); logger.log("after " + logMessage); } Object around() : logMe2() { String logMessage = "log message #2"; logger.log("before " + logMessage); logger.indent(); Object result = proceed(); logger.dedent(); logger.log("after " + logMessage); } Object around() : logMe3() { String logMessage = "log message #1"; logger.log("before " + logMessage); logger.indent(); Object result = proceed(); logger.dedent(); logger.log("after " + logMessage); }}Obviously there is code duplication just because the log message is different. (Actually it is more complicated because sometimes the message is not constant, but needs to be constructed from a "this" object's properties, but let's forget about that for now.)What I would like to have is this:aspect LoggingAspect { pointcut logMe1(String msg) : execution(...) && bind(msg="log message #1"); pointcut logMe2(String msg) : execution(...) && bind(msg="log message #2"); pointcut logMe3(String msg) : execution(...) && bind(msg="log message #3"); Object around(String msg) : logMe1(msg) || logMe2(msg) || logMe2(msg) { logger.log("before " + msg); logger.indent(); Object result = proceed(msg); // maybe even just proceed() // for bound pointcut parameters logger.dedent(); logger.log("after " + msg); }}	7.0
id=99521	REOPENED	AspectJ	Compiler	unspecified	PC Windows XP	P5 enhancement	Adrian Colyer	2005-06-11 18:59 EDT by	Missing name	2009-08-30 02:50 EDT (	1 user	It would be most useful to be able to specify certain additional join points; specifically so that you could have pointcuts just before an object is locked, just after it is locked, just before it is to be released, and just after it is released.	We're not going to get to this in AJ 1.5.0. Marking as "LATER" for considerationin 1.5.1 and future release planning.And there's no better way to indicate that status than to mark it 'fixed??!'{sigh} Thank you for the response...oops, it's not supposed to be marked "FIXED", it should be marked "LATER" as per my previous comment. I'm re-opening to assign the correct status.Now assigning the "LATER" status as I originally intended. You were quite correct, if we mark something "FIXED" we don't revisit it, whereas "LATER" bugs form candidates for next release items.Thanks for the spot.This request seems to be a duplicate of of theIndeed these two requests do appear to be the same, though to be accurate,would be a duplicate of this one. There is certainly a nicely detailed discussion going on in the comments of.LATER/REMIND bugs are being automatically reopened as P5 because the LATER and REMIND resolutions are deprecated.	7.0
id=93451	REOPENED	AspectJ	Compiler	1.5.0M2	PC Linux	P5 normal	Adrian Colyer	2005-05-02 16:20 EDT by	Oliver	2009-08-30 02:49 EDT (	0 users	I just try the pertypewithin to instantiate an aspect per class. This works:public aspect TestAspekt<T> pertypewithin(verwaltung.test.*) { ... after() : execution(* *.*()) { log.debug(thisJoinPoint); }}But when I try to use the generic <T> inside the after advice as described inthe AspectJ developer's notebook it does not work.public aspect TestAspekt<T> pertypewithin(verwaltung.test.*) { ... after(T t) : execution(* *.*()) && this(t) { ...}Each time I try to save this I get an alert box with "NullPointerExceptionthrown: null" (also repeated as reason).	Basic generics will be working in M3, we'll have a look at this (parameterizedaspects with PTW) for 1.5.0 final.We've decided to remove this feature from the language for the 1.5.0 timeframe(a concrete generic pertypewithin aspect). Generic abstract aspects *will* besupported in M4.LATER/REMIND bugs are being automatically reopened as P5 because the LATER and REMIND resolutions are deprecated.	3.0
id=104576	REOPENED	AspectJ	Compiler	DEVELOPMENT	PC Windows XP	P5 enhancement	Adrian Colyer	2005-07-20 16:06 EDT by	Ron Bodkin	2009-08-30 02:50 EDT (	0 users	It would be nice if the AspectJ compiler could inline the if test here. Obviously you can't access this value in an if pcd, but some means to allow this would be nice.after() returning (int retCode) : pcd() { if (retCode<100) { doWork(); }}	This is a valid enhancement request but we have no immediate plans to implement given the other pressures on the project. Marking as "LATER" for consideration in future planning cycles.LATER/REMIND bugs are being automatically reopened as P5 because the LATER and REMIND resolutions are deprecated.	2.0
id=106166	REOPENED	AspectJ	Compiler	DEVELOPMENT	PC Windows XP	P5 enhancement	Adrian Colyer	2005-08-05 11:10 EDT by	Ron Bodkin	2009-08-30 02:50 EDT (	0 users	It would be helpful to allow binding the same value more than once in a pointcut. This should match only if the value is the same in all clauses and might require a runtime check. For example: pointcut callSelf(Object o): call(* *(..)) && this(o) && target(o);It would also then be useful to be able to reference a value that is already bound in a pointcut in a negation clause, i.e., binding in negation would be reasonable as long as there's a bound value that's not negated:pointcut execOnThis(Object o) : execution(* *(..)) && this(o);pointcut topLevelExecOnThis(Object o) : execOnThis(o) && !cflowbelow(execOnThis(o));The motivation for this latter pointcut is to let me capture the execution of a method (like show) only once even if it is dispatching to the superclass implementation, but to still capture executions of the same method on different instances in the same cflow. A workaround is to match on calls (but that isn't always feasible).	We're not going to get to this in AJ 1.5.0. Marking as "LATER" for considerationin 1.5.1 and future release planning.A similar useful idiom would be:aspect Track perthis(trackCtor()) { List tracked; pointcut modifyFieldCalls() : modifyCalls() && target(tracked);...}Today you need: pointcut modifyFieldCalls(List bound) : modifyCalls() && target(bound) && if (tracked==bound);LATER/REMIND bugs are being automatically reopened as P5 because the LATER and REMIND resolutions are deprecated.	3.0
id=99322	REOPENED	AspectJ	Compiler	unspecified	PC Windows XP	P5 enhancement	Adrian Colyer	2005-06-10 05:47 EDT by	Matthew Webster	2009-08-30 02:49 EDT (	0 users	There are few real world examples of pointcuts that do not use something like execution, set/get or handler. A missing "kinded" pointcut is usually an error. A lint warning would aid newbies and old hands alike.	We're not going to get to this in AJ 1.5.0. Marking as "LATER" for considerationin 1.5.1 and future release planning.LATER/REMIND bugs are being automatically reopened as P5 because the LATER and REMIND resolutions are deprecated.	2.0
id=108488	REOPENED	AspectJ	Compiler	1.5.0M3	PC Linux	P5 normal	Adrian Colyer	2005-08-31 13:25 EDT by	Oliver	2009-08-30 02:50 EDT (	0 users	Hi,when I try to translate an existing aspect into the annotation-basedstyle (according the developers notebook) my example doesn't work any more: @Aspect("perthis(this(verwaltung.Person))") public class ArbeitszeitAspekt { // body: see at the end }Here the compiler says "can't do instanceof matching on patterns withwildcards". When I try @Aspect("perthis(this(Person))") ...I get no compiler message but it does not work (even if the aspect isalso in the same package "verwaltung") - I have not the expected output(dead pointcut). @Aspect ...This works (but only as singleton and not an aspect for each Personobject), so the rest of my aspect seems to be ok. Is this a bug (which Ishould report) or do I use the wrong syntax for the perthis statement?kind regardsOliver==== here some additional info ====>Mmy original aspect where I want to stop the time of thePerson.arbeite() execution:public aspect ArbeitszeitAspektOld perthis(this(verwaltung.Person)) { long start; long end; // void around(Person x) : execution(public void Person.arbeite()) && this(x) { start = System.currentTimeMillis(); proceed(x); end = System.currentTimeMillis(); System.out.println("*** Arbeitszeit " + x + ": " + new Date(start) + " - " + new Date(end)); }}And here the body of the aspect (just to complete the example)public class ArbeitszeitAspekt { long start; long end; // @Around("execution(public void verwaltung.Person.arbeite()) && this(x)") public void watchWorkingHours(ProceedingJoinPoint thisJoinPoint, Person x) { start = System.currentTimeMillis(); thisJoinPoint.proceed(new Object[] {x}); end = System.currentTimeMillis(); System.out.println("*** ARBEITSZEIT " + x + ": " + new Date(start) + " - " + new Date(end)); }}	Createdthe ArbeitszeitAspekt which causes the errorCreatedthe Person class which is instrumented by ArbeitszeitAspektthis has to be fixed for M4...looks like an issue in pointcut matchingthe perthis(this(.....)) ends up in doing matching pretty much everywhere (f.e.target type field get / set), leading to an error (bug) in type pattern matchinternal which assumes a MathKind.Dynamic public FuzzyBoolean matchesInstanceof(ResolvedType type) { //XXX hack to let unmatched types just silently remain so if (maybeGetCleanName()/*Simple()*/ != null) return FuzzyBoolean.NO; type.getWorld().getMessageHandler().handleMessage( new Message("can't do instanceof matching on patterns with wildcards", IMessage.ERROR, null, getSourceLocation())); return FuzzyBoolean.NO;I think here we need CleanName and not SimpleName test.When done this way, the aspect is not any more bound - while it is for simplerclause like perthis(execution(....))mhhchanging to CleanName does not help as the stuff commented with ugly //XXX hackalways returns NO hence the bypasschanging to STATIC matching fix the stuff, but then we end up in rendering Bceltest for Literal.NO which interrupt with a BException "bad"I think there is an issue in the pointcut parsing thereAdrian, can you have a look ?WildTypePattern.matchesInstanceoftest will be committed in AtAjSyntaxTest.testPerClause (see testPerThis() asother tests are turned off).I have an idea what's going on here. When a pointcut is parsed, all of the typepatterns within it are "WildTypePatterns". It is only when the pointcut isresolved that these turn into ExactTypePatterns (and a whole bunch of additionalchecks are done). I'm betting that the perthis pointcut is being parsed but notresolved...OK, have confirmed in debugger that the PerClauses read in from the annotationare indeed not being resolved.Now it just remains to find the appropriate point to drive the resolution logic...2 issues there:Adrian spotted that the perClause pointcut was not resolve, which was leading toWildTypePattern not beeing narrowed to ExactTypePatternsThen we ended up in an issue where the ajc$Migth HasAspect interface for thematching type was not applied hence skipping the binding. It happens that thePerThisOrTargetPointcutVisitor that turns the perclause in a type patternmatching for the PerObjectInterfaceTypeMunger to apply is rather weak as ittransform the perthis(this(someType)) in someType+ by using a toString() and atype parsing again.When $ stands in the type (inner class signature), we end up f.E. withSome$Type+ for a type pattern expression which is different from Some.Type+ as auser would write - hence the bug.should be fine for this use case nowclosing for next shipmentLATER/REMIND bugs are being automatically reopened as P5 because the LATER and REMIND resolutions are deprecated.	11.0
id=107530	REOPENED	AspectJ	Compiler	DEVELOPMENT	PC Windows XP	P5 normal	Adrian Colyer	2005-08-20 18:54 EDT by	Mark Addleman	2009-08-30 02:49 EDT (	0 users	I've defined an AspectJ InPath with a JAR file. I get the following exception:Error 2005-08-20 15:51:46.823 NullPointerException thrown: nulljava.lang.NullPointerExceptionat org.aspectj.weaver.ResolvedType.addAndRecurse(ResolvedType.java:246)at org.aspectj.weaver.ResolvedType.addAndRecurse(ResolvedType.java:257)at org.aspectj.weaver.ResolvedType.addAndRecurse(ResolvedType.java:263)at org.aspectj.weaver.ResolvedType.getMethodsWithoutIterator(ResolvedType.java:241)at org.aspectj.weaver.ResolvedType.lookupResolvedMember(ResolvedType.java:332)atorg.aspectj.weaver.ResolvedMemberImpl.accumulateMembersMatching(ResolvedMemberImpl.java:213)atorg.aspectj.weaver.ResolvedMemberImpl.getJoinPointSignatures(ResolvedMemberImpl.java:167)at org.aspectj.weaver.MemberImpl.getJoinPointSignatures(MemberImpl.java:917)at org.aspectj.weaver.patterns.SignaturePattern.matches(SignaturePattern.java:150)at org.aspectj.weaver.patterns.KindedPointcut.matchInternal(KindedPointcut.java:112)at org.aspectj.weaver.patterns.Pointcut.match(Pointcut.java:151)at org.aspectj.weaver.patterns.AndPointcut.matchInternal(AndPointcut.java:61)at org.aspectj.weaver.patterns.Pointcut.match(Pointcut.java:151)at org.aspectj.weaver.ShadowMunger.match(ShadowMunger.java:62)at org.aspectj.weaver.Advice.match(Advice.java:102)at org.aspectj.weaver.bcel.BcelClassWeaver.match(BcelClassWeaver.java:1724)atorg.aspectj.weaver.bcel.BcelClassWeaver.matchInvokeInstruction(BcelClassWeaver.java:1713)at org.aspectj.weaver.bcel.BcelClassWeaver.match(BcelClassWeaver.java:1526)at org.aspectj.weaver.bcel.BcelClassWeaver.match(BcelClassWeaver.java:1355)at org.aspectj.weaver.bcel.BcelClassWeaver.weave(BcelClassWeaver.java:381)at org.aspectj.weaver.bcel.BcelClassWeaver.weave(BcelClassWeaver.java:96)at org.aspectj.weaver.bcel.BcelWeaver.weave(BcelWeaver.java:1368)at org.aspectj.weaver.bcel.BcelWeaver.weaveWithoutDump(BcelWeaver.java:1333)at org.aspectj.weaver.bcel.BcelWeaver.weaveAndNotify(BcelWeaver.java:1110)at org.aspectj.weaver.bcel.BcelWeaver.weave(BcelWeaver.java:997)atorg.aspectj.ajdt.internal.compiler.AjCompilerAdapter.weave(AjCompilerAdapter.java:286)atorg.aspectj.ajdt.internal.compiler.AjCompilerAdapter.afterCompiling(AjCompilerAdapter.java:165)atorg.aspectj.ajdt.internal.compiler.CompilerAdapter.ajc$afterReturning$org_aspectj_ajdt_internal_compiler_CompilerAdapter$2$f9cc9ca0(CompilerAdapter.aj:70)at org.aspectj.org.eclipse.jdt.internal.compiler.Compiler.compile(Compiler.java:367)atorg.aspectj.ajdt.internal.core.builder.AjBuildManager.performCompilation(AjBuildManager.java:728)atorg.aspectj.ajdt.internal.core.builder.AjBuildManager.doBuild(AjBuildManager.java:207)atorg.aspectj.ajdt.internal.core.builder.AjBuildManager.doBuild(AjBuildManager.java:167)atorg.aspectj.ajdt.internal.core.builder.AjBuildManager.incrementalBuild(AjBuildManager.java:148)at org.aspectj.ajde.internal.CompilerAdapter.compile(CompilerAdapter.java:116)atorg.aspectj.ajde.internal.AspectJBuildManager$CompilerThread.run(AspectJBuildManager.java:191)	Can you provide a testcase?Also, what is the full version ID of the AJDT build you are using?(In reply to)Unfortunately, no. It seems to be sporadic. I'll work on it, though.The version is 1.3.0.20050824130753The exception is down in the weaver, so passing over to AspectJ.if the bug is sporadic, that suggests an incremental compilation type issue -does a full build always resolve the issue? Looking at the line of code involved, this NPE can only happen when thegetSuperclass() call on a ResolvedType is returning null. This may be caused bya superclass type that cannot be found on the classpath (resolving to aResolvedType.Missing, which if then asked for *it's* superclass will return null).I'm going to put in some extra defences to catch that situation and put out a"can't find type" message. It probably shouldn't be that the type can't be found- that's the underlying incremental bug I suspect, but at least this will give a non-crashing build and a sensible error message that further problems could bediagnosed from.Extra defences checked in. Compiler will now give a normal error message in thissituation saying that the supertype of {0} could not be found. I'm going toassign the bug the "REMIND" status as there is some underlying problem here thatstill needs to be resolved. If you see any unexpected "can't find type" messagesafter picking up and AJDT with this fix in, please attach the details to thisbug and reopen it.Thanks, A.Now that I understand more about the error, it occurs to me that the followingmay be the problem:I am libraries for which I only have the binary jar files. These libraries havereferences to types that aren't available on my classpath. This doesn't affectnormal Java operations because I don't execute the codepaths requiring themissing types. However, AspectJ seems to need a complete closure over types. This manifests in all sorts of warning/errors in the Problems view and I betthis is somehow related to the NullPointerException.It would be very nice if AspectJ didn't need all the types. Right now, I createstubbed types just to make it happy.That makes sense. We would very much like to reduce the number of situations inwhich AspectJ tries to find all types in the world (or at least it feels likethat ;) ), and it's something we continually try to chip away at....LATER/REMIND bugs are being automatically reopened as P5 because the LATER and REMIND resolutions are deprecated.	8.0
id=107059	REOPENED	AspectJ	Compiler	DEVELOPMENT	PC Linux	P5 normal	Adrian Colyer	2005-08-15 15:37 EDT by	Samuel Gélineau	2009-08-30 02:48 EDT (	0 users	public aspect Bug { before() : call(void (@a *)(..)) { }}/home/user/sgelin3/dev/java/ajc/new_bug/Bug.java [error] Internal compiler errorjava.lang.RuntimeException: bad name:[Lorg.aspectj.weaver.patterns.NamePattern;@530cf2 atorg.aspectj.weaver.patterns.WildTypePattern.maybeGetCleanName(WildTypePattern.java:507) atorg.aspectj.weaver.patterns.WildTypePattern.resolveBindings(WildTypePattern.java:566) atorg.aspectj.weaver.patterns.SignaturePattern.resolveBindings(SignaturePattern.java:79)not that the pointcut causing the crash is incorrect abd should produce anerror. the actual pointcut I intended to write was before() : call(void (@a *).*(..)) {}which works fine.	fix checked into tree, awaiting build.target(@a *) also causes ajc to crash, does your change fix this too?yes.....but ;)it fixes the parser problem, but exposed an unrelated problem whereby we allowedan "any" type pattern with annotation specified to slip through the net whenresolving a pattern and requiring an exact type.The correct behaviour for target(@Foo *) is to issue an error saying that anexact type name must be used with target.The compiler now does this.why such a strict requirement? you could check for the attribute at runtime.pointcuts with binding forms have never allowed patterns (what type should thebound variable have?). If you want to match any target type but with a certainannotation you can use @target instead which does exactly this.M4wupswupsLATER/REMIND bugs are being automatically reopened as P5 because the LATER and REMIND resolutions are deprecated.	9.0
id=165779	REOPENED	AJDT	Core	unspecified	PC Windows XP	P5 enhancement	AJDT-inbox	2006-11-24 09:26 EST by	Helen Beeken	2009-08-30 02:48 EDT (	0 users	Currently the aspectj nature is defined within the ui plugin. It would make more sense for it to be defined in the core plugin in the same way that the builder is.	Agreed, although it's tricky to move because of the migration issues. We want the transition from old nature to new nature to be transparent, without a performance overhead after migration. We also want migrated projects to still work properly on older versions of AJDT which don't define the new nature.As discussed, the current thinking is to define the new nature to behave like the old nature, and for the old nature to no longer have any effect (except possibly the "AJ" image decorator on the project). The core builder can then check for the absence of the new builder whenever the project is built, and add it if required (a nature check is almost zero in performance terms). The old nature will not be removed, so that the project can still be used with older versions of AJDT.Although it makes more sense to define the nature in core, and we've established a way such a migration could be handled, there doesn't currently appear to be a compelling reason to make the move. So given the work involved and the risk of migration problems, I'm closing this as resolve > later - until such time as there is a compelling reason.LATER/REMIND bugs are being automatically reopened as P5 because the LATER and REMIND resolutions are deprecated.	3.0
id=120372	REOPENED	AspectJ	Compiler	1.5.0M5	PC Windows XP	P5 normal	aspectj inbox	2005-12-12 10:31 EST by	Andrew Clement	2009-08-30 02:49 EDT (	1 user	This bug is to track a problem found during debugging. We discovered that the code produced by cglib doesn't weave correctly if applying AspectJ after advice (or any AspectJ construct that is implemented via the 'after' mechanism - cflow/etc). The cglib code generated *is* valid - but AspectJ makes an assumption about it that is not entirely valid (although the assumption holds for all code created by other tools we've seen: javac, the jdtcompiler, etc).The workaround is to avoid weaving of CGLIB generated classes (identified by having CGLIB$$ in their name) - and this is probably correct for most users, as if they weave the proxies they are likely to get unpredictable results (advice running twice for example...)The full discussion is in the referenced bug.There is also a thread on the cglib mailing list where they would accept a patch to alter the generated code such that our assumption holds - I've just not had the time to do this.	not doing any more on this right now - googling on aspectj/cglib will find this bug in the future if the problem crops up.Googling on AspectJ/CGLIB has not found it for me (while 117854 was found)LATER/REMIND bugs are being automatically reopened as P5 because the LATER and REMIND resolutions are deprecated.	3.0
id=122043	REOPENED	AspectJ	Compiler	1.5.0	PC Windows XP	P5 normal	aspectj inbox	2005-12-23 19:15 EST by	Ron Bodkin	2009-08-30 02:50 EDT (	0 users	I ran into a bug in incremental compilation that I'm now having a hard time replicating. I had a Servlet class like this:public class MockServletHangForever extends MockServletCpuHog { protected void doPost(HttpServletRequest request, HttpServletResponse response) { super.doPost(request, response); ...}The AspectJ compiler incrementally accepted this even though the signature of super.doPost is protected void HttpServlet.doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOExceptionOn a full compilation the ajc compiler catches this, of course. And once I have made changes like this, I can't seem to get the incremental compiler to accept it again.However, I discovered this bug because an ant build complained about it and I saw there were no errors in the Eclipse view which had been compiled incrementally!	This kind of thing happens to me in eclipse when I'm only displaying problems for the selected resource and another error in the compile (on another file/resource) halts the process before this error would have been detected. Do you think that might be what happened? If you've seen this since or can replicate it reliably (with all problems shown), please provide more details. Otherwise, would you mind closing or permitting us to close this bug?I haven't seen the bug since. I'm pretty sure I wasn't using a filter to restrict the set of problems shown, although I will admit that after two months I'm not 100% sure.LATER/REMIND bugs are being automatically reopened as P5 because the LATER and REMIND resolutions are deprecated.	3.0
id=137337	REOPENED	AspectJ	Compiler	DEVELOPMENT	PC Windows XP	P5 normal	aspectj inbox	2006-04-18 15:19 EDT by	Ramnivas Laddad	2009-08-30 02:50 EDT (	0 users	This is becoming a big problem on a current project. Quite often (more so after switching to 1.5.1+, it seems), a developer will call me with a problem that an aspect should have taken care of, but clearly isn't. After looking at code, it seems all fine. So in a dismay, I fire a clean compile and the problems goes away.I wanted to see if there is a pattern here, but failed to observe any relationship between the kind of changes leading to the problem. The general characteristics only tell that the classes, and not the aspects are changed beforewe observe this problem.	The most common problem seen is an advice that stops being applied to a join point (method execution) after an incremental compilation, but works fine after a clean build.I do know of a change vaguely in that area during the 1.5.1 timeframe. Can you possibly turn on all the debug that you can for the AJDT event trace view? When you make a change to a class file it should report some information about the decision process it is following - why certain things are being compiled and any knock-on effects of that. Using your knowledge of what the change was, does the list of changes make sense?Ramnivas - is this still happening for you? Did you get a chance to try creating the AJDT event trace that might indicate what is happening? And its *definetly* that the code on the disk is not woven, yes? Not just that the markers are missing?marking up the severity so I can see it in the big list-o-bugs.It hasn't happended in a while (to make matter worse, it used to happen on other developer's machine, and I have less control over its environment). I am still keeping my eyes on this problem.When it happened, however, the problem was advice not getting applied in byte code (and not just missing markers). Basically, the functionality implementedwith aspects was absent, leading to bizzare behavior (and often crash). Onevery occasion, full rebuild solved the problem.any sign of this bug recurring ???Nope. Also, the project has gone into functional QA testing so not much is being changed. That poses the problem of what to do with this bug. May be mark it as "later" and reduce is severity (due to non reoccurance)?I'm ok with that - if you see anything like it again we can resurrect this bug.LATER/REMIND bugs are being automatically reopened as P5 because the LATER and REMIND resolutions are deprecated.	9.0
id=149323	REOPENED	AspectJ	LTWeaving	DEVELOPMENT	PC Windows XP	P5 enhancement	aspectj inbox	2006-06-30 13:33 EDT by	Ron Bodkin	2009-08-30 02:50 EDT (	0 users	I propose adding an attribute noMungers="[false]|true" to the aspect element in the aop.xml definition file, e.g.,...<aspects><aspect name="AbstractNoItd" noMungers="true"/><aspect name="AbstractWithItd"/> <!-- defaults to false --><aspect name="Concrete"/></aspects>This would support an LTW optimization to not load these aspects during register definitions (unless needed for concrete xml-defined aspects). This attribute would be generated when the aop.xml file is generated.More careful testing of the overhead of loading aspects without concrete mungers is needed to assess the performance benefit from this proposal. If it reduces overhead by 10% as my initial quick tests showed, then it's worth considering but after addressing keeping reference types for woven classes and duplicate copies of reference types from common aspect definitions.	Putting user configurable options into files like this is a sign that the programmers are lazy. Why do we have to do it? Why can't we *quickly* determine when first seeing it whether it has 'mungers' in it and do the same thing we are implying with that flag being set to false.This isn't really intended to be user-configurable, it's intended to be generated. The proposed optimization would avoid the time required to load and parse the file to determine the fact that no concrete mungers are defined.This enhancement is a bad idea for 2 reasons:1. Although the flag may be generated it appears in a public configuration file which _could_ be modified by a user with unexpected results: change this flag to make your code go faster (but miss out some of the weaving).2. Information that is required for a performance optimization (that can be obtained elsewhere i.e. the .class file) should not clutter a user configuration file.However we should discuss the performance issues rather than a particular solution. Since the fix forwe disable the weaver if we can’t find any aspect declarations. Are you concerned that classloaders that can only see abstract aspects will not have their weaver disabled? If so there are a couple of solutions we could implement to ensure that the weaver was disabled if no active aspects were found i.e. no concrete mungers.If however you are concerned about the overhead of loading additional non-active abstract aspects for a classloader that has an enabled weaver then the measurements discussed inare not very representative. I have measured the time taken to initialize a weaver for a single concrete aspect (8K) and the same aspect along with 4 non-active abstract ones (44K). The times were 631ms and 671ms respectively. This doesn’t seem excessive and could probably be improved without the need for any new flags. I haven’t looked at footprint yet.That's not so far from 10%. And of course it depends a lot on what the abstract aspects refer to (e.g., how many additional class files need to be loaded and parsed through BCEL). I agree that making something like this user visible isn't ideal, then again the whole aop.xml file and parts like include/exclude are vulnerable to the exact same objection.But let's table this one and focus on higher priority enhancements: if we can load and parse shared aspects once instead of many times (once per loader) then this won't be nearly as important, and that would be far more beneficial.I don't want to save this one for later as I don't intend to implement the enhancement. More importantly I _still_ don't really know what the problem is (this is the second ehancement request for what is possible a bug). Please answer my questions.I've answered both questions before: yes and yes. I think 5-10% overhead is a worthy optimization target, but after bigger targets are addressed.LATER/REMIND bugs are being automatically reopened as P5 because the LATER and REMIND resolutions are deprecated.	7.0
id=140709	REOPENED	AspectJ	LTWeaving	unspecified	PC Windows XP	P5 normal	aspectj inbox	2006-05-08 18:45 EDT by	Ron Bodkin	2009-08-30 02:49 EDT (	0 users	This patch came about from a bug I was seeing that happened because a class was loaded and woven during initializing of the ClassLoaderWeavingAdaptor. The only safe thing to do in this case is to not weave until initialization occurs.	CreatedLoadtime module patchI previously wrote and tested this logic so that the second thread would proceed without being woven. But I think that's a worse approach than the attached patch, which simply synchronizes so that initialization has to complete on the first thread before another thread can get the weaving adaptor.This bug is related to if not a duplicate of.Without further information about which level of AspectJ, which level/version of JDK, which class, stack trace, verbose log or even a testcase I am very reluctant to add synchronization to the weaver. We have had deadlock problems before (,). Also all weaving for a particular class loader is single threaded and all static initialization is static a fail to understand (given the information provided) what actual problem we are trying to solve.It's been a few months since I ran into this issue so my recollection is a bit vague on the particulars. I will test more with recent builds and reopen the problem when I have a concrete test case.LATER/REMIND bugs are being automatically reopened as P5 because the LATER and REMIND resolutions are deprecated.	5.0
id=158957	REOPENED	AspectJ	LTWeaving	DEVELOPMENT	PC Windows XP	P5 normal	aspectj inbox	2006-09-27 08:18 EDT by	Christian Schneider	2009-08-30 02:48 EDT (	0 users	Hello AspectJ team,I'm using AspectJ with some kind of pointcut reuse (achieved by placing certain public pointcuts into an otherwise empty Aspect and referencing these from other aspects). As this feature works in most situations I suppose it is a supported feature of AspectJ. If such a style of pointcut reuse is not intended in AspectJ just ignore this bug report.When trying to apply an advice using LTW for a RMI application that uses dynamic proxies the class-loading fails with a NullPointerException. But interestingly that only happens when the pointcut used in the Aspect is itself referring to a reusable pointcut (which could be the case for complex pointcuts that share common parts). When I inline the reusable pointcut into the pointcut that's used by the advice everything runs fine. The pointcut definition in question could be even some completely unrelated pointcut and LTW's class-loading fails too (which I assume is the case since AspectJ has to intercept the class-loading anyway).I've tested it with the development build: aspectj-DEVELOPMENT-20060925164058Here's the reusable (simplified for testcase purposes :) pointcut definition: public final aspect DemoPointcuts { public static pointcut justATestReferenced() : call(* System.getenv()); // content of this pointcut seems to be unrelated to problem reported. Could be anything you like. }Here's the aspect in question: public final aspect TestcaseToReproducePotentialBug { private pointcut justATest() : DemoPointcuts.justATestReferenced() // NOTE that replacing the previous line with the inline call works fine: call(* System.getenv()) ; after() returning() : justATest() { System.out.println("TEST"); } } And that's the stack-trace for the class-loading process, having RMI dynamic proxies involed:27.09.2006 11:24:47 org.aspectj.weaver.tools.Jdk14Trace errorFATAL: preProcessjava.lang.NullPointerException at org.aspectj.weaver.bcel.BcelWeaver.weaveParentTypeMungers(BcelWeaver.java:1404) at org.aspectj.weaver.bcel.BcelWeaver.weaveParentsFor(BcelWeaver.java:1274) at org.aspectj.weaver.bcel.BcelWeaver.weave(BcelWeaver.java:1103) at org.aspectj.weaver.tools.WeavingAdaptor.getWovenBytes(WeavingAdaptor.java:337) at org.aspectj.weaver.tools.WeavingAdaptor.weaveClass(WeavingAdaptor.java:243) at org.aspectj.weaver.loadtime.Aj.preProcess(Aj.java:76) at org.aspectj.weaver.loadtime.ClassPreProcessorAgentAdapter.transform(ClassPreProcessorAgentAdapter.java:55) at sun.instrument.TransformerManager.transform(TransformerManager.java:122) at sun.instrument.InstrumentationImpl.transform(InstrumentationImpl.java:155) at java.lang.reflect.Proxy.defineClass0(Native Method) at java.lang.reflect.Proxy.getProxyClass(Proxy.java:504) at sun.rmi.server.LoaderHandler.loadProxyClass(LoaderHandler.java:641) at sun.rmi.server.LoaderHandler.loadProxyClass(LoaderHandler.java:588) at java.rmi.server.RMIClassLoader$2.loadProxyClass(RMIClassLoader.java:628) at java.rmi.server.RMIClassLoader.loadProxyClass(RMIClassLoader.java:294) at sun.rmi.server.MarshalInputStream.resolveProxyClass(MarshalInputStream.java:238) at java.io.ObjectInputStream.readProxyDesc(ObjectInputStream.java:1500) at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1463) at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1699) at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1305) at java.io.ObjectInputStream.readObject(ObjectInputStream.java:348) at sun.rmi.server.UnicastRef.unmarshalValue(UnicastRef.java:290) at sun.rmi.server.UnicastRef.invoke(UnicastRef.java:139) at java.rmi.server.RemoteObjectInvocationHandler.invokeRemoteMethod(RemoteObjectInvocationHandler.java:179) at java.rmi.server.RemoteObjectInvocationHandler.invoke(RemoteObjectInvocationHandler.java:132) at $Proxy4.prepareLogin(Unknown Source) at demo.Demo.main(Demo.java:73)Best Regards & keep up the good work,Christian	This has the same symptoms, but perhaps different cause, to"NPE in BcelWeaver using LTW". In this case we are generating a proxy class rather than reflection delegate using Unsafe. Please can you turn on trace, that will go to stderr, so we can find out a bit more about what's going on by specifying the following system properties: -Dorg.aspectj.tracing.enabled=true -Dorg.aspectj.tracing.factory=default -Dorg.aspectj.tracing.messages=trueCreatedverbose debug logsCreatedHighlightsChristian,Thanks for the trace which I think tells me what is going wrong although not why. Attached is an interesting part. Here is a commentary1. We create a weaving adaptor for the proxy loader2. We _start_ to initialize it and register the two aspects: RuntimeExceptionCheck and DemoAspect.3. We seem to create several ReflectionWorld instances while parsing the pointcuts for DemoAspect. This needs investigation and is probably the cause of the bug. This class was written for non-LTW pointcut parsing using reflection and probably needs some adjustment to work properly inside LTWWorld.4. I believe an Error is thrown and control is returned to JMVTI without completing the adaptor initialization: prepareForWeave() has not been called, there is no exit trace and addLibraryAspect() is not the the stack trace for the NPE. We only handle Exceptions today, like the NPE in this report, on the understanding that Errors tend to be fatal. However I think we need to catch Errors and disable the adaptor.5. We attempt to weave class $Proxy5 using the uninitialized weaver.You appear to have a good workaround by not using a pointcut library. You could exclude proxies from weaving by adding <exclude within="$Proxy*"/> to the <weaver> section of aop.xml but that _won’t_ because the problem happens during adaptor initialization. Another approach would be to exclude weaving for proxy loaders inside Aj as we do for reflection delegate loaders on the grounds that these are system classes. I will add more trace and exception handling to ensure we capture the Error and weaver is disabled. I will also investigate the use of ReflectionWorld. I may then ask you to reproduce the problem once more (if I still can’t) with an updated build. In the meantime could you post your aspects so that I can add a testcase to the suite?Matthew,thanks for you in-depth analysis.I've further tested the whole stuff and continously stripped the code in question down. To my own surprise I've eventually found the solution:When stripping down the pointcut library further and further I've noticed that the pointcut library contains unused (i.e. unreferenced) pointcut definitions with execution pointcuts that reference a class from javax.servlet. As I wanted to reuse my pointcut library for the RMI based application I'm working on I simply copied the pointcut library into the app's classpath. Since the RMI based app has nothing to do with web-development its runtime classpath didn't contian the servlet-api which holds the unused javax.servlet class. As soon as I commented-out the unused servlet-related pointcut definition (which works well in a servlet-based environment) the whole stuff ran as expected. On the other hand, when keeping the unused pointcut definition within the pointcut library *and* adding the otherwise not required servlet-api to the runtime classpath of the RMI app the whole stuff ran fine too.So it all boils down to having all referenced compile-time required libraries (i.e. servlet-api) also within the runtime-classpath when the application has LTW aspects that (even when unused at run-time) reference these otherwise compile-time dependencies. As the whole RMI app does not have any dependency (either compile-time or run-time) on servlet-api I didn't add that to the classpath. But as (though unused) parts of the pointcut library I wrote have compile-time dependencies on servlet-api and (in case the pointcuts will be referenced in aspects) also run-time dependencies on the servlet-api I simply have to resolve these dependencies by adding the missing jar to the runtime classpath. The interesting point is the fact that the pointcut definition in question which was referencing the servlet api was not used in any aspect. Neither in an aspect of the RMI app nor within the pointcut library. So I thought that adding servlet api to the classpath is not required. But when LTW comes into play certain things that are otherwise static become dynamic (by design, as it is LTW) so I had to rethink about the classpath. :-)I hope that this information is helpful to you. Maybe the exception message could be clearer for other users. And maybe I've even (by chance) pointed you to some code blocks that should be inspected anyway... So just keep up the good work & Best Regards,ChristianBTW: If you need any further stuff from me or would like me to test a newer dev build against my app without having servlet-api in the classpath, just let me know...While the declaration of an aspect with missing dependencies should fail AspectJ LTW should cope more gracefully and issue a message that helps users to correct their configuration. Could you possibly post the offending aspects to help me reproduce the problem? Thanks again for your co-operation and diagnosis of the problem.In the absence of a testcase to reproduce the problem I suggest prevention of secondary failure. The adaptor should be disabled by default so that if initialization fails for some reason we won't be able to use it. Also I will restore the catch (Throwable) in Aj to report any Errors which we have now discovered are swallowed by JVMTI.sorry for the rather late reply (I was a few days offline while on travel)...The following is the pointcut library that I reuse from different aspects:public aspect Pointcuts { public pointcut anyMethodCall() : call(* *(..)); public pointcut anyMethodExecution() : execution(* *(..)); public pointcut anyPublicMethodExecution() : execution(public * *(..)); public pointcut anyNonPrivateMethodExecution() : execution(!private * *(..)); public pointcut anyConstructorCall() : call(new(..)); public pointcut anyPublicConstructorCall() : call(public new(..)); public pointcut anyNonPrivateConstructorCall() : call(!private new(..)); public pointcut servletGetRequest(javax.servlet.http.HttpServletRequest request, javax.servlet.http.HttpServletResponse response) : execution(void javax.servlet.http.HttpServlet.doGet(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)) && args(request, response);}When I try to use any advice from some other aspect which references one of the non-web-relevant pointcuts defined in the pointcut library AspectJ's LTW tries to load the "Pointcuts" pointcut library. During that initialization process even the javax.servlet classes must be resolveable to AspectJ's LTW runtime classpath though the last pointcut in the above library (the only one that's referencing the javax.servlet classes) is not used. Neither within the pointcuts library or within some advice referencing it. So the dependency is only a compile-time dependency in "normal" non-AOP programming. But in a world of LTW this otherwise compile-time dependency becomes a runtime-dependency.As an aside and suggestion, on the Glassbox project we have to work around these kinds of issues, e.g., by using public pointcut servletRequestExec() : within(HttpServlet+) && !within(HttpJspPage+) && (execution(* HttpServlet.do*(..)) || execution(* HttpServlet.service(..))); before(Object servlet, Object request) : servletRequestExec() && this(servlet) && args(request, *) {...I am testing a converted version of our servlet monitor that uses reflection to allow a shared aspect that handles servlets even though the containing classloader doesn't have that API visible.When weaving of javax..* is allowed with AspectJ, we can instead use this technique to handle the situation: declare parents: javax.servlet.http.HttpServlet implements IHttpServlet; private interface IHttpServlet { /* extract needed methods from HttpServlet */ }Then in advice refer to IHttpServlet instead.I still cannot reproduce this problem even with provided testcase. I might need the aop.xml file being used and the other aspects. I suspect the failure occurs if type resolution for the Servlet classes happens during adaptor initialization when registering the Pointcuts library aspect. However by default we do no resolution of pointcut types until weaving. However we do if completeBinaryTypes=true which is now disabled by default. But even with this re-enabled I can't see a failure.The next thing to try will be a class loader hierarchy using TestServer because the problem may lie in completeBinaryTypes/completeNonLocalType().I am closing this because I don't believe the problem still exists given the number of changes. If a similar problem does occur the weaver will remain disabled and we will get more diagnostic information.LATER/REMIND bugs are being automatically reopened as P5 because the LATER and REMIND resolutions are deprecated.	11.0
id=103104	REOPENED	AspectJ	Compiler	DEVELOPMENT	PC Windows XP	P5 normal	Alexandre Vasseur	2005-07-07 19:29 EDT by	Ron Bodkin	2009-08-30 02:50 EDT (	0 users	It would be very helpful to suppress certain known warnings for load-time weaving. I would like to have the ability to reference an Xlint file or give Xlint directives directly in the aop.xml file.	<weaver options="-Xlint:none" /> works today (or similar), but you cannotprovide finer grained Xlint configurationI want to avoid the file dependancy since the file would have to be somewherepacked in the deployed unit.Is this fine grained configuration possible on command line without using a file ?I believe the command line offers just -Xlint:<level> set default level for crosscutting messages (<level> may be ignore, warning, or error)Unless you want to use a properties file: -Xlintfile <file> specify properties file to set per-message levels (cf org/aspectj/weaver/XlintDefault.properties)I think it would be better if you could specify any settings using aop.xml, but having a well-known name like META-INF/Xlint.properties that it checks would be a reasonable alternative to give the functionality with little effort.committed impl for -Xlint:default, -Xlint:none etc in aop.xml weaver options+ -Xlintfile:pathToResourceVisibleFromClassLoaderOFAOPXMLgive it a try at next snapshotLATER/REMIND bugs are being automatically reopened as P5 because the LATER and REMIND resolutions are deprecated.	4.0
id=106035	REOPENED	AspectJ	Compiler	unspecified	All All	P5 normal	Alexandre Vasseur	2005-08-04 08:46 EDT by	David Knibb	2009-08-30 02:49 EDT (	1 user	The AspectJ weaving adaptor does not read in the XlintDefault.properties file. The fix (I think) is to add the following line to the ClassLoaderWeavingAdaptor below the initialisation of the bcelWorld variable: bcelWorld.getLint().loadDefaultProperties();	see also #103104committed impl for -Xlint:default, -Xlint:none etc in aop.xml weaver options+ -Xlintfile:pathToResourceVisibleFromClassLoaderOFAOPXMLgive it a try at next snapshotLATER/REMIND bugs are being automatically reopened as P5 because the LATER and REMIND resolutions are deprecated.	3.0
id=99861	REOPENED	AspectJ	Compiler	DEVELOPMENT	PC Windows XP	P5 normal	Alexandre Vasseur	2005-06-13 19:19 EDT by	Ron Bodkin	2009-08-30 02:49 EDT (	0 users	The following error now occurs for my project when weaving into Tomcat 5.5.7 with a Sun 1.5.0_02 VM This used to work (with the branch code), and it works fine with JRockIt 1.5.0_02:Found one Java-level deadlock:============================="http-8080-Processor25": waiting to lock monitor 0x009590d4 (object 0x051a2f68, a java.util.WeakHashMap), which is held by "main""main": waiting to lock monitor 0x00959074 (object 0x052e9188, a org.apache.catalina.loader.StandardClassLoader), which is held by "http-8080-Processor25"Java stack information for the threads listed above:==================================================="http-8080-Processor25": at org.aspectj.weaver.loadtime.Aj$WeaverContainer.getWeaver(Aj.java:79) - waiting to lock <0x051a2f68> (a java.util.WeakHashMap) at org.aspectj.weaver.loadtime.Aj.preProcess(Aj.java:55) at org.aspectj.weaver.loadtime.ClassPreProcessorAgentAdapter.transform(ClassPreProcessorAgentAdapter.java:52) at sun.instrument.TransformerManager.transform(TransformerManager.java:122) at sun.instrument.InstrumentationImpl.transform(InstrumentationImpl.java:155) at java.lang.ClassLoader.defineClass1(Native Method) at java.lang.ClassLoader.defineClass(ClassLoader.java:620) at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:124) at java.net.URLClassLoader.defineClass(URLClassLoader.java:260) at java.net.URLClassLoader.access$100(URLClassLoader.java:56) at java.net.URLClassLoader$1.run(URLClassLoader.java:195) at java.security.AccessController.doPrivileged(Native Method) at java.net.URLClassLoader.findClass(URLClassLoader.java:188) at java.lang.ClassLoader.loadClass(ClassLoader.java:306) - locked <0x052e9188> (a org.apache.catalina.loader.StandardClassLoader) at java.lang.ClassLoader.loadClass(ClassLoader.java:251) at java.lang.ClassLoader.loadClassInternal(ClassLoader.java:319) - locked <0x052e9188> (a org.apache.catalina.loader.StandardClassLoader) at org.apache.tomcat.util.collections.MultiMap.<init>(MultiMap.java:52) at org.apache.tomcat.util.http.Parameters.<init>(Parameters.java:71) at org.apache.coyote.Request.<init>(Request.java:140) at org.apache.coyote.http11.Http11Processor.<init>(Http11Processor.java:86) at org.apache.coyote.http11.Http11Protocol$Http11ConnectionHandler.init(Http11Protocol.java:683) at org.apache.tomcat.util.net.LeaderFollowerWorkerThread.getInitData(LeaderFollowerWorkerThread.java:48) at org.apache.tomcat.util.threads.ThreadPool$ControlRunnable.run(ThreadPool.java:673) at java.lang.Thread.run(Thread.java:595)"main": at java.lang.ClassLoader.loadClass(ClassLoader.java:295) - waiting to lock <0x052e9188> (a org.apache.catalina.loader.StandardClassLoader) at java.lang.ClassLoader.loadClass(ClassLoader.java:251) at org.xml.sax.helpers.NewInstance.newInstance(NewInstance.java:49) at org.xml.sax.helpers.XMLReaderFactory.loadClass(XMLReaderFactory.java:187) at org.xml.sax.helpers.XMLReaderFactory.createXMLReader(XMLReaderFactory.java:150) at org.aspectj.weaver.loadtime.definition.DocumentParser.parse(DocumentParser.java:80) at org.aspectj.weaver.loadtime.ClassLoaderWeavingAdaptor.registerDefinitions(ClassLoaderWeavingAdaptor.java:124) at org.aspectj.weaver.loadtime.ClassLoaderWeavingAdaptor.<init>(ClassLoaderWeavingAdaptor.java:96) at org.aspectj.weaver.loadtime.Aj$WeaverContainer.getWeaver(Aj.java:81) - locked <0x051a2f68> (a java.util.WeakHashMap) at org.aspectj.weaver.loadtime.Aj.preProcess(Aj.java:55) at org.aspectj.weaver.loadtime.ClassPreProcessorAgentAdapter.transform(ClassPreProcessorAgentAdapter.java:52) at sun.instrument.TransformerManager.transform(TransformerManager.java:122) at sun.instrument.InstrumentationImpl.transform(InstrumentationImpl.java:155) at sun.misc.Unsafe.defineClass(Native Method) at sun.reflect.ClassDefiner.defineClass(ClassDefiner.java:45) at sun.reflect.MethodAccessorGenerator$1.run(MethodAccessorGenerator.java:381) at java.security.AccessController.doPrivileged(Native Method) at sun.reflect.MethodAccessorGenerator.generate(MethodAccessorGenerator.java:377) at sun.reflect.MethodAccessorGenerator.generateMethod(MethodAccessorGenerator.java:59) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:28) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at java.lang.reflect.Method.invoke(Method.java:585) at org.apache.commons.modeler.BaseModelMBean.invoke(BaseModelMBean.java:503) at com.sun.jmx.mbeanserver.DynamicMetaDataImpl.invoke(DynamicMetaDataImpl.java:213) at com.sun.jmx.mbeanserver.MetaDataImpl.invoke(MetaDataImpl.java:220) at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.invoke(DefaultMBeanServerInterceptor.java:815) at com.sun.jmx.mbeanserver.JmxMBeanServer.invoke(JmxMBeanServer.java:784) at org.apache.catalina.connector.MapperListener.registerWrapper(MapperListener.java:487) at org.apache.catalina.connector.MapperListener.init(MapperListener.java:140) at org.apache.catalina.connector.Connector.start(Connector.java:1011) at org.apache.catalina.core.StandardService.start(StandardService.java:459) - locked <0x05f04b78> (a [Lorg.apache.catalina.connector.Connector;) at org.apache.catalina.core.StandardServer.start(StandardServer.java:683) - locked <0x05fe7210> (a [Lorg.apache.catalina.Service;) at org.apache.catalina.startup.Catalina.start(Catalina.java:537) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at java.lang.reflect.Method.invoke(Method.java:585) at org.apache.catalina.startup.Bootstrap.start(Bootstrap.java:271) at org.apache.catalina.startup.Bootstrap.main(Bootstrap.java:409)Found 1 deadlock.	Createdthread dump (clean EOL)from the dump:Thread-main is starting its job and some reflective invocation leads to creationof JDK proxy that leads to Sun Unsafe.defineClass(...) (explicit class load)This call goes into the VM, and then back in the JVMTI AJ agent that then locksthe AJ aop.xml "definition" repository.The defining ClassLoader is not locked by Sun Unsafe stuff.At some point Thread-x has been started. During its execution this one triggersimplicit class load. This ones goes in the JDK ClassLaoder.loadClass that locksthe defining ClassLoader.This one then reach the JVMTI agent and waits for the AJ repository.Two locks have been obtained in 2 different order hence the deadlock.-----I think I can fix that by enforcing a manual (synchronized(laoder) {}) beforelocking the AJ repository but that s really BAD.I think the issue comes from Unsafe that happens to be broken since it does goesto JVMTI without locking the loader.My assumption is that this should be a SUN JDK bug, easily reproduced outside ofAJ (write a JVMTI agent, write a main that forks a thread that keeps working(say do Class.forName() given a long list of stuff from some jar)), and in themain (after thread fork) call some stuff to gen a proxy and go into the agentthru Sun Unsafe.defineClass.In the agent then lock on whatever object you like. You 'll get the deadlock.JVMTI does not say "don't lock anything" (else give me the link and the quote)so this is Sun bug.Going fine in JRockit is another evidence I guess.In the branch you can perhaps check but perhaps I was not locking the repository(which is not safe).comments ?I'm willing to believe this is a Sun JVMTI implementation bug, but I think it's really important that AspectJ continue to work-around bugs in the Sun VMs. Even if Sun fixes this in a future release, it's still important to support the leading VM, bugs and all.I'm guessing that I didn't see this bug earlier because you weren't locking the repository in an earlier release?Would the work-around add a risk of other deadlocks? Would it materially harm performance?You perhaps can try and check.I don't want a workaround in the long run.It would be interesting to see what is in the Sun bug database and if you findsomething link the Sun bug here.I was going to try the work around but the latest version in CVS head is giving me a verify error. I'm assuming that it's just an instability in the run up to M3 (since other things from the CVS HEAD version are causing me problems too), and I'll wait until things are a little more stable to try again.I am not aware of such a verify errorPlease report a bug so that we can reproduce, track and fix (or refer to it ifyou know it is a known bug)I was able to get everything to build & run today (*), and your proposed work-around fixes the problem on a Sun 1.5.0_02 JVM. The resulting code continues to work on JRockIt 1.5.0_02. I think integrating the workaround into HEAD would make sense. Perhaps if Sun fixes this issue, it could be included only on the specific VM's with the problem.I made this one change to CVS HEAD:Starting at Aj.java:76 static WeavingAdaptor getWeaver(ClassLoader loader) { synchronized (loader) { synchronized (weavingAdaptors) {... } } }(*) Either the verify error was caused by my not seeing error output from ant (a bug I just submitted) or one of the changes checked in today fixed it for me.ok patch is in cvslet the issue open, to see how it goes(ie M3 will ship with this hack hence assigned to M4)raising to P2see 109334 that is a consequence of the horrible hack hereonly option is to fine a Sun 1.5 VM that has not the JSR 163 bug and onlysupport this one and more recent ones.Ron please commentI can't reproduce it from a simpler agent to post a Sun bug report.That said perhaps we can avoid this by having a postInit() method that is calledafter the synchrnoized block, or by having a doNothingWeavingAdaptor() as longas we are in the middle of initializing the adaptor - to avoid this kind ofreentrancy. ie:static WeavingAdaptor getWeaver(ClassLoader loader, IWeavingContextweavingContext) { synchronized (weavingAdaptors) { weavingAdaptor = (WeavingAdaptor) weavingAdaptors.get(loader); if (weavingAdaptor == null) { weavingAdaptor = new ClassLoaderWeavingAdaptor(loader, weavingContext); weavingAdaptors.put(loader, weavingAdaptor); } } // (extract local variable to make this compile off course) weavingAdaptor.postInit();//method to add, that does what <init> does right now // and that has a boolean like "isInit" to avoid multiple initialization // this call will trigger nested classloading but that should be fine. return weavingAdaptor;}this would ensure that no nested loading is done while lock is held.Ron - can you send me detailled instructions / war on how to reproduce that witha Tomcat 5.x? so that I can fix it once for all?I think it would be great to move the initialization out of the synchronized block. Clearly this helps if you load resources from different classloaders. But if you are loading a resource from the same classloader, in the middle of initialization, how will you handle this? Obviously this would still be a big improvement.You can download a buildable project that reproduces the problem (the pre-built jar is of course tied to a specific AspectJ compiler pre-M4 at this stage) from the glassbox inspector open source project:-inspector.dev.java.net/servlets/ProjectDocumentList?folderID=4064&expandFolder=4064&folderID=0. If you put the inspector jar in %TOMCAT_HOME$\shared\lib then Tomcat locks up. I don't believe it depends on any applications being installed other than the standard pre-installed ones.Naturally, if you do the refactoring to pull the init code out, I'd be glad to test it out.D:\>echo %JAVA_HOME%D:\java\jdk1.5.0_03(ie Sun VM)Tomcat 5.5, windowsdrop the jars as you said in shared/libchanged the script as described in readmeI can see message likelog4j:WARN No appenders could be found for logger (glassbox.inspector.config.SimpleConfig).log4j:WARN Please initialize the log4j system properly.So GlassBox is in. So far so good.But HelloWorld JSP or Servlet OOT with Tomcat don't deadlock.Please detail where I should click to have the deadlock.Interesting. It must be loading an application on startup that causes the problem. I have attached a war file from a version of the jpetstore that should just cause it on start-up with no user interaction. You _might_ need to configure a database for this to happen, but I bet not.Bugzilla won't accept the war file. I tried to send to you by email Alex. If that doesn't work please let me know & I'll ftp it somewhere for you.got the war thru email - thx.deployed in Tomcat, restart Tomcatcan see Glassbox jmx messageall startup sequence completes just finego to /jpetstore/can see the home pageclick on "enter the shop"got exceptions due to jdbc driver not therestill no deadlock- if you want I can commit the refactoring of AJ and you can rebuild it from acvs update and see what happens then.Gak. That's weird, I and others have predictably seen this deadlock running in the Tomcat environment. I wonder what's different. Maybe just unrelated chnges in AspectJ are affecting a race condition?Please do check in the refactored change and I'll rebuild, then try first straight the M4 version to see if I still see it on a Sun VM and then the refactored change.I am sorry I mispoke. You need to deploy the inspector to common/lib so it affects Tomcat itself! It works just fine in shared/lib (we changed the install docs to workaround this bug!!). Can you try that. You shouldn't even need the jpetstore.ok can reproducewith my patch it seems to startup fine now but I have BCException as I am usinga newer version of a weaver milestonejust commited a fix in CVS, module "loadtime" (Aj, ClassLoaderWeavingAdaptor .java)can you rebuild AJ and give it a try?This now runs unbelievably slowly on my machine and finally exhausts resources. It has the CPU pegged and after running about 20x as long I get these messages. I think it's in an infinite loop initializing somehow. I will attach the exception that finally occurs and a thread dump 30 seconds after startupIt seems to be incredibly slow reading in the aspects: you can't build up an aspect string byte by byte like this?! I optimized this by using a StringBuffer and it seems much faster and it didn't run out of memory as before. Now I too see BCException even though I did a rebuild. I will investigate this more. See attached patch that improved startup performance by 2 orders of magnitude...Also, is it safe to have a race in initializing the classloader (e.g., on JRockit where the loader isn't locked?) Also, you should rename ExplicitlyInitializedClassLaoderWeavingAdaptor to fix a typo - it says LAODER not loader...Exception:Message: error problem loading XlintDefault.properties, oversubscribed dynamic bit lengths treeorg.aspectj.bridge.AbortException: problem loading XlintDefault.properties, oversubscribed dynamic bit lengths tree at org.aspectj.weaver.tools.WeavingAdaptor$WeavingAdaptorMessageHandler.handleMessage(WeavingAdaptor.java:318) at org.aspectj.bridge.MessageUtil.error(MessageUtil.java:80) at org.aspectj.weaver.Lint.loadDefaultProperties(Lint.java:129) at org.aspectj.weaver.tools.WeavingAdaptor.init(WeavingAdaptor.java:144) at org.aspectj.weaver.tools.WeavingAdaptor.<init>(WeavingAdaptor.java:82) at org.aspectj.weaver.loadtime.ClassLoaderWeavingAdaptor.<init>(ClassLoaderWeavingAdaptor.java:61) at org.aspectj.weaver.loadtime.Aj$WeaverContainer.getWeaver(Aj.java:94) at org.aspectj.weaver.loadtime.Aj.preProcess(Aj.java:65) at org.aspectj.weaver.loadtime.ClassPreProcessorAgentAdapter.transform(ClassPreProcessorAgentAdapter.java:52) at sun.instrument.TransformerManager.transform(TransformerManager.java:122) at sun.instrument.InstrumentationImpl.transform(InstrumentationImpl.java:155) at java.lang.ClassLoader.defineClass1(Native Method) at java.lang.ClassLoader.defineClass(ClassLoader.java:620) at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:124) at org.apache.catalina.loader.WebappClassLoader.findClassInternal(WebappClassLoader.java:1629) at org.apache.catalina.loader.WebappClassLoader.findClass(WebappClassLoader.java:850) at org.apache.catalina.loader.WebappClassLoader.loadClass(WebappClassLoader.java:1299) at org.apache.catalina.loader.WebappClassLoader.loadClass(WebappClassLoader.java:1181) at java.lang.ClassLoader.loadClassInternal(ClassLoader.java:319) at java.lang.Class.getDeclaredConstructors0(Native Method) at java.lang.Class.privateGetDeclaredConstructors(Class.java:2328) at java.lang.Class.getConstructor0(Class.java:2640) at java.lang.Class.newInstance0(Class.java:321) at java.lang.Class.newInstance(Class.java:303) at org.apache.catalina.core.StandardWrapper.loadServlet(StandardWrapper.java:1048) at org.apache.catalina.core.StandardWrapper.load(StandardWrapper.java:925) at org.apache.catalina.core.StandardContext.loadOnStartup(StandardContext.java:3857) at org.apache.catalina.core.StandardContext.start(StandardContext.java:4118) at org.apache.catalina.core.ContainerBase.addChildInternal(ContainerBase.java:759) at org.apache.catalina.core.ContainerBase.addChild(ContainerBase.java:739) at org.apache.catalina.core.StandardHost.addChild(StandardHost.java:524) at org.apache.catalina.startup.HostConfig.deployDescriptor(HostConfig.java:589) at org.apache.catalina.startup.HostConfig.deployDescriptors(HostConfig.java:536) at org.apache.catalina.startup.HostConfig.deployApps(HostConfig.java:471) at org.apache.catalina.startup.HostConfig.start(HostConfig.java:1102) at org.apache.catalina.startup.HostConfig.lifecycleEvent(HostConfig.java:311) at org.apache.catalina.util.LifecycleSupport.fireLifecycleEvent(LifecycleSupport.java:119) at org.apache.catalina.core.ContainerBase.start(ContainerBase.java:1020) at org.apache.catalina.core.StandardHost.start(StandardHost.java:718) at org.apache.catalina.core.ContainerBase.start(ContainerBase.java:1012) at org.apache.catalina.core.StandardEngine.start(StandardEngine.java:442) at org.apache.catalina.core.StandardService.start(StandardService.java:450) at org.apache.catalina.core.StandardServer.start(StandardServer.java:683) at org.apache.catalina.startup.Catalina.start(Catalina.java:537) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at java.lang.reflect.Method.invoke(Method.java:585) at org.apache.catalina.startup.Bootstrap.start(Bootstrap.java:271) at org.apache.catalina.startup.Bootstrap.main(Bootstrap.java:409)Full thread dump Java HotSpot(TM) Client VM (1.5.0_04-b05 mixed mode):"Low Memory Detector" daemon prio=5 tid=0x26d44560 nid=0x1374 runnable [0x00000000..0x00000000]"CompilerThread0" daemon prio=10 tid=0x26d5daf0 nid=0x344 waiting on condition [0x00000000..0x26f7f6cc]"Signal Dispatcher" daemon prio=10 tid=0x26d2bad8 nid=0x1370 runnable [0x00000000..0x00000000]"Finalizer" daemon prio=9 tid=0x00959230 nid=0xea0 in Object.wait() [0x26cff000..0x26cffa68] at java.lang.Object.wait(Native Method) - waiting on <0x051907e8> (a java.lang.ref.ReferenceQueue$Lock) at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:116) - locked <0x051907e8> (a java.lang.ref.ReferenceQueue$Lock) at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:132) at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:159)"Reference Handler" daemon prio=10 tid=0x00957dd8 nid=0x45c in Object.wait() [0x26cbf000..0x26cbfae8] at java.lang.Object.wait(Native Method) - waiting on <0x05190868> (a java.lang.ref.Reference$Lock) at java.lang.Object.wait(Object.java:474) at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:116) - locked <0x05190868> (a java.lang.ref.Reference$Lock)"main" prio=5 tid=0x000365d8 nid=0x3f4 runnable [0x0007e000..0x0007fc3c] at java.lang.String.<init>(String.java:208) at java.lang.StringBuffer.toString(StringBuffer.java:586) - locked <0x053b84c0> (a java.lang.StringBuffer) at org.aspectj.weaver.loadtime.ClassLoaderWeavingAdaptor.readAspect(ClassLoaderWeavingAdaptor.java:425) at org.aspectj.weaver.loadtime.ClassLoaderWeavingAdaptor.registerAspects(ClassLoaderWeavingAdaptor.java:262) at org.aspectj.weaver.loadtime.ClassLoaderWeavingAdaptor.registerDefinitions(ClassLoaderWeavingAdaptor.java:157) at org.aspectj.weaver.loadtime.ClassLoaderWeavingAdaptor.initialize(ClassLoaderWeavingAdaptor.java:110) at org.aspectj.weaver.loadtime.Aj$ExplicitlyInitializedClassLaoderWeavingAdaptor.initialize(Aj.java:130) at org.aspectj.weaver.loadtime.Aj$ExplicitlyInitializedClassLaoderWeavingAdaptor.getWeavingAdaptor(Aj.java:135) at org.aspectj.weaver.loadtime.Aj$WeaverContainer.getWeaver(Aj.java:100) at org.aspectj.weaver.loadtime.Aj.preProcess(Aj.java:65) at org.aspectj.weaver.loadtime.ClassPreProcessorAgentAdapter.transform(ClassPreProcessorAgentAdapter.java:52) at sun.instrument.TransformerManager.transform(TransformerManager.java:122) at sun.instrument.InstrumentationImpl.transform(InstrumentationImpl.java:155) at java.lang.ClassLoader.defineClass1(Native Method) at java.lang.ClassLoader.defineClass(ClassLoader.java:620) at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:124) at java.net.URLClassLoader.defineClass(URLClassLoader.java:260) at java.net.URLClassLoader.access$100(URLClassLoader.java:56) at java.net.URLClassLoader$1.run(URLClassLoader.java:195) at java.security.AccessController.doPrivileged(Native Method) at java.net.URLClassLoader.findClass(URLClassLoader.java:188) at java.lang.ClassLoader.loadClass(ClassLoader.java:306) - locked <0x05299ad0> (a org.apache.catalina.loader.StandardClassLoader) at java.lang.ClassLoader.loadClass(ClassLoader.java:251) at org.apache.catalina.startup.Bootstrap.init(Bootstrap.java:198) at org.apache.catalina.startup.Bootstrap.main(Bootstrap.java:386)"VM Thread" prio=10 tid=0x0003ef50 nid=0xddc runnable"VM Periodic Task Thread" prio=10 tid=0x26d436c0 nid=0x136c waiting on conditionyes I have seen some weird overload - even when only one thred is working.In readAspect() stuff that is used for binary diff in reweavable mode - as faras I understand what has been done in that area, we read stuff bytes by bytesjust to get sort of a hash.I'll check some more what 's happening and will perhaps forward this issue to Andy.[as a reminder, the test app is in my emails and cannot be attached to the bugas it is too big]readAspect was simplifiedclosing this oneLATER/REMIND bugs are being automatically reopened as P5 because the LATER and REMIND resolutions are deprecated.	24.0
id=106504	REOPENED	AspectJ	Compiler	DEVELOPMENT	PC Windows XP	P5 enhancement	Alexandre Vasseur	2005-08-09 11:48 EDT by	Matthew Webster	2009-08-30 02:48 EDT (	0 users	The current AspectJ 5 LTW specification allows simple concrete aspects to be defined in aop.xml. They may extend an abstract aspect and define a single "scoping" pointcut. I think it would be very useful to be able to declare aspect precedence in a similar way allowing aspects to be deployed without any specific precedence leaving any decision to a systems administrator. The syntax might look like this:<aspectj> <aspects> <concrete-aspect name="com.xyz.MyPrecedence" precedence="*..*Security*, Logging+, *" /> </aspects></aspectj>Any potential conflicts are already handled by the compiler.	so in that case we just need to spot:- a <concrete-aspect without extends attribute, and with NO nested pointcut, butwith a precedence clause (else it would be a NOOP aspect)then we just do a codegen for@DeclarePrecedence(your precedence)@Aspect public class ...theName... /*no extends*/ { //nothing}planning for RC1, as precedence attribute is already impl. for regularconcrete-aspect.implLATER/REMIND bugs are being automatically reopened as P5 because the LATER and REMIND resolutions are deprecated.	3.0
id=107953	REOPENED	AspectJ	Compiler	unspecified	Other Linux	P5 normal	Alexandre Vasseur	2005-08-24 21:28 EDT by	John J. Franey	2009-08-30 02:50 EDT (	0 users	Eclipse 3.1, AJDT 1.3.0.20050824175147Platform linux fedora core 4; java jvm 1.5.0-rc-b63Files to be attached.When TranTest class is run, the following exception is received:Exception in thread "main" java.lang.VerifyError: (class: all/mymoney/TransTest,method: go signature: ()V) catch_type not a subclass of ThrowableFor javax.ejb.TransactionAttribute I used glassfish (9.0-b09) lib/j2ee.jar.	CreatedTransTest.java source codeCreatedTransTest.class binaryCreatedaspect file: TransactionManagerSorry, wrong product. Refiled to AJDT.This probably belongs against the compilercompiler now says:"throwing formal 'RuntimeException' must be declared as the last parameter inthe advice signature"(the program should be of the form@AfterThrowing(pointcut="...", throwing="ex")void adviceMethod(RuntimeException ex) {...})catching this error early prevents the downstream error of treating the pointcutformal (attr) as if it were the thrown exception formal, with the resultsdescribed in this report.Alex, I'm assigning to you as I'm not sure this is fully finished: I've putguards in for after throwing and after returning, both in the ajc front-end andin the weaver for javac compiled @Aspects. However, the weaver guards rely ondebug info having been left in the source file in order to find the matchingparameter (not a lot we can do about that I don't think), and have a poor linenumber when the error is issued. I also restricted the extraArg to being thelast parameter in the advice signature, but that may have been stricter thannecessary?***has been marked as a duplicate of this bug. ***raising to P2close for M4extra formal can be anywhere in signature - checks will be doneLATER/REMIND bugs are being automatically reopened as P5 because the LATER and REMIND resolutions are deprecated.	10.0
id=95526	REOPENED	AspectJ	Compiler	DEVELOPMENT	All All	P5 enhancement	Alexandre Vasseur	2005-05-17 05:48 EDT by	Alexandre Vasseur	2009-08-30 02:51 EDT (	0 users	just to track work to be done (M4)	mh, a lot to write actually before hacking that...the weaved model is like:weavedClass { transient xx_mixin_1 = new Aspect$Mixin();// // impl all Mixin ' interface methods using delegation void doSomeFromMixinInterface() { xx_mixin_1.doSomeFromMixinInterface(); }}Some notes:1/ the definition does not give a very good control on that, which makes itrather poor. f.e. in AW we provide:- custom container thru some mixinOf hence can plug any kind of IoC toinstantiate the mixin instance- transient or not control- perclass, singleton, or per instance model- passing "this" to the mixin (per instance instance) or "class" (per classclass) to the mixin constructor if user wants2/ what about AJDT stuffFrom what I see there are NewMethodTypeMunger and alike for ITD. Theimplementation here will require slightly different things, and a fairly deeplevel of bytecode work is required to instantiate properly the xx_mixin_<i> (orwhatever mangled name) mixin instances when the weavedClass as more than onector (hence here the mixinOf approach)That perhaps means some changes in the ASM model to report that properly as well..3/ what about lang.reflect thing ?I can see for now a TODO but obviously there will be 2 different models behindfor code style or @style.4/ last detailsGiven 2/ there might be some issues with- proper name mangling and filtering to hide added shadows (since ITD are weavedfirst, should be visible method jp, but mixinOf and x_mixin_<i> field set / getare probably something we want to hide (or ? and what about ctor call of mixinclass etc depending on mixinOf impl.)- reweavable state (that does contains the type munger list but again this oneis rather different)Comments welcome. I not eager to implement something if we end up with nosupport in AJDT or an impl that is too limited for the users.marking as "enhancement" to make it easier to distinguish between new functionyet to be designed/implemented and bugs that we need to fix.raising to P2 for run in to AJ 5 RC1Note 1 (to update doc soon)will support:@Aspectclass A { @DeclareParents("type pattern") SomeInterfaceType someName;}for declare parents implements semanticsas this avoid mandatory use of aspect nested interface (which is bad)currently working on my box[from email]hi theresome thoughts on @decp.For marker interface (no impl.) I am now using a field within theaspect, whose type is the marker interface (ie not a nested interfacein the aspect). This because it decouples the aspect from the markerinterface (1) and because grabbing nested type from a type is perhapsnot the easiest way (2).So it looks like@Aspect class A { @DeclareParents(typepattern) MarkerIntf stuff;}It s ugly as we have an unused field - but this is the general dealwith @AJ (f.e. pointcut).(see docs - it differs from what is in the doc)now for the ITD that have an implementation we had a proposal (seedocs). But I don't like the fact that we cannot control the way themixin gets created (actually we will have to store it somewhere in asynthetic aspect field, wich sends us back to weaving aspects themself(same as aspectof), or to gen. on the fly a factory class to host themixin field etc. (long time messy in AW).Instead I argue this syntax:@Aspect class A { @DeclareParents(types = typepattern) public static Intf stuff = new IntfImplementation(.....);//stuffcan be IoC - you control it // public static is mandatory // Intf mandatory to be an interface - which is the ITD contract}// the weaved code will simply do delegation for all methods of IntfTarget { // introduced(args) { return A.stuff.introduced(args); } }That said it 's tricky to distinguish between decp marker intf. (fieldnot initialized) and decp with implementation (public static field,initialized), so we could argue for adding another annotation hence@DeclareImplements(...) //markerand @DeclareParents(...) // with implementationwhat do you say ??Side note: I wish we could use A.aspectOf(...) to access the ITDinstance instead of enforcing a public static field, but that wouldmean that sometime (depends on binding) you may getNoAspectBoundException. This is actually sort of contextual ITDs - butthis doesn't seems to exist so far ;-) and I have no use case for thatone - though that is interesting (and can be done later if we want tosupport non public static field @DeclareParents)ok no matter what you say this is now implemented on my box and fairly neet forIoC the mixin instance - which should be a very nice replacement for AW mixincontainer we had.I'll polish and commit next week.all committedTODO:- update docs- test ASM model / AJDT behaviorTODO- test reweavable behaviordone docs, -showWeaveInfo, reweavablecan be closed at next shipmentI am sorry to say that but this implementation is not very useful because mixindoes not have any link to the target instance.I.e. in mixin (implementation of the interface) we cannot access the object weare mixed in...There should be 1:1 association between the mixin and target instances.I guess weaved class should look like this:class Target$$weaved implements SomeIface { transient SomeIface iface = TheAspect.create((Target) this); String something; void doSomething(int howLong) { } public void run() { iface.run(); } public boolean isSuccess() { return iface.isSuccess(); } public String sayHello(String name) { return iface.sayHello(name); }}// related code to provide full context:class Target { String something; void doSomething(int howLong) { }}interface SomeIface { void run(); boolean isSuccess(); String sayHello(String name);}@Aspectclass TheAspect { @DeclareParents("Target") static public SomeIface create(Target target) { return new Mixin(target); }}class Mixin implements SomeIface { private Target target; public Mixin(Target target) { this.target = target; } public void run() { System.out.println(target); } public boolean isSuccess() { return true; } public String sayHello(String name) { return String.format("Hello, %s, from %s", name, target.getClass()); }}I agree with the need for mixin impl. to know about its target. We hadMixinContainer in AspectWerkz for that purpose.Can't you use some dependency injection for that?(In reply to)I think we cannot.Mixin and target are loosely coupled. Target is does not even know that itsubject to mixin operation...What's up with AspectJ mixins? Any plans to support mixins properly?How hard would it be to get it done right?thnx.please write down here any idea you may have for impl.Note that we need to respect javac compilation rules for @AspectJ mixinIn the code you posted, Target is instrumented so the "Mixin" code is irrelevant:class Target { String something; void doSomething(int howLong) { }}interface SomeIface { void run(); boolean isSuccess(); String sayHello(String name);}@Aspectclass TheAspect { @DeclareParents("Target") static public SomeIface create(Target target) { return new Mixin(target); }}Means you want:class Target implements SomeIFace { String something; void doSomething(int howLong) { } void run() { TheAspect.create(this).run(); } boolean isSuccess() { TheAspect.create(this).run(); } String sayHello(String name) { TheAspect.create(this).sayHello(name); }}Obviously you'll need something else than "create(Target)"Also you introduce a coupling between the @DeclareParents type pattern and thecreate(...) argument. This would require compiler checking, else it would be a create(Object o)(In reply to)ok. once again, much simpler :-)interface Iface { void doSomething();}class Mixin implements Iface { Object target; Mixin(Object target) { ... } // ... some impl}@Aspectclass TheAspect { @DeclareParents("Target") static public SomeIface create(Object target) { return new Mixin(target); }}... means I want:class Target$Woven implements Iface { transient Mixin mixin = TheAspect.create(this); public void doSomething() { mixin.doSomething(); }}SUMMARY- no need for compiler checks, leave it up to mixin implementor (though I canimage some sort of compiler support but its not mandatory. So signature is:Aspect.create(Object target)- mixin instance is created only once when target is created. not in every mixincall...- ther is no coupling you mention at all, I used it only for demonstrationpurposes (to make more readable/comprehensible)clear enough? any other questions?sorry, I was a bit too hurry to post this.ERRATA:interface Iface { void doSomething();}@Aspectclass TheAspect { @DeclareParents("Target") // or whatever else static public Iface create(Object target) { return new Mixin(target); // create some instance, link it with target,type cast it, aspect provider is responsible for all this }}... means I want:class Target$Woven implements Iface { transient Iface mixin = TheAspect.create(this); public void doSomething() { mixin.doSomething(); }}hope now its ok...you make a deliberate choice that the field hosting the mixin is transient. Thiscan be debatable and can lead to several issues with Serialization (a lot ofusers in AW have reported specific needs around that).F.e. serialize a Target instance and you end up with NPE... FYI in AW we had transient controlled by the userdo you need that? what for? Also the assumptiontransient Mixin mixin = TheAspect.create(this);cannot be that easily mirrored in bytecode. What will happen is that allconstructor body of Target will be be appended with this field assignment.Now when the constructor calls a 'this(...)' this requires extra heavy logic toavoid multiple create(..) call, or a mixin==null checkOne of our user then reported that the status of the Target instance (ie this)is then unclear in some cases. F.e. when this(..) delegation happen, the mixinwill be instantiated based on the state resulting from the 'this(..)' call onlyand not the one from the current constructor invoked.I am willing to do at best to fit user needs - especially because I know this isfar from what I had implemented in AW (f.e. we had implemented static mixin aswell). Obviously the current implementation avoids all those burden and "simple"is not as simple as it looks like sometimes. It all depends on your use case andwhat you do with the feature.Comments welcome.(In reply to)yes it should be configurableby default, for mixins to be completely transparent, fields introduced by mixinsshould be transient so that they do not change the model of the target.we need transient-by-default for mixin transparency, as mentioned abovehowever, configurable is fine, i would welcome that :-)you are absolutely right, i did not realize this...we would need to copy this to every constructori hope it is feasible (meaning your architecture allows it)i would insert following snippet into every constructor: if (mixin == null) mixin = TheAspect.create(this);or maybe better, wrap it in separate method:// constructorTarget() { initMixin(); // ... rest }// introduced methodprivate void initMixin() { if (mixin == null) mixin = TheAspect.create(this);}this would be fine, wouldn't it?not so extra heavy logic...this is what we primarily need very much....will think about the rest...thnxLATER/REMIND bugs are being automatically reopened as P5 because the LATER and REMIND resolutions are deprecated.	18.0
id=113367	REOPENED	AspectJ	Compiler	DEVELOPMENT	All All	P5 enhancement	Alexandre Vasseur	2005-10-21 12:00 EDT by	Alexandre Vasseur	2009-08-30 02:48 EDT (	0 users	make -1.5 defaultsame for LTW(see test for @AJ ITD with annotated ITD methods f.e. that requires -1.5 inaop.xml weaver options)	i'll take a stab at this tomorrow.as part of the fix for 103417 I had to make LTW autodetect java version and configure world.setBehaveInJava5Way accordingly. So this change is already committed now. If there is nothing more to do under this bug, we could close it - but I'm not sure that this is everything this bug was intended for so I'm leaving it open for now.fix confirmedLATER/REMIND bugs are being automatically reopened as P5 because the LATER and REMIND resolutions are deprecated.	4.0
id=114897	REOPENED	AspectJ	Compiler	DEVELOPMENT	PC Windows XP	P5 normal	Alexandre Vasseur	2005-11-03 05:58 EST by	Matthew Webster	2009-08-30 02:49 EDT (	0 users	-Xreweavable is now the default for the compiler () but this adds overhead and in general makes no sense for LTW. The LTW adaptor should set notReweavable by default but allow -Xreweavable to be set if necessary through aop.xml.	CreatedPatch and modified testcaseUser can now specify -Xreweavable but not -XnotReweavable which is now thedefault. Changed aop.xmls files LTWLog testcase to use new option.done - thanksLATER/REMIND bugs are being automatically reopened as P5 because the LATER and REMIND resolutions are deprecated.	3.0
id=271751	REOPENED	CDT	cdt-indexer	6.0	All All	P5 normal	Project Inbox	2009-04-09 06:32 EDT by	Jens Elmenthaler	2009-10-30 17:38 EDT (	1 user	I have a workspace containing several millions of lines of code, contributedby around a 100 projects.The open-element functions in this case is mostly unusable, because itjust takes too long until any results are available.Notable seems to be, that while Eclipse is busy finding all the stuff,the CPU is not busy.Are there any opportunities to accelerate the search, like optimized cachestructures, parallel search algorithms, etc?What is the problem here, is it the number of projects, or the shere amountof code?The entry point seems to be the following call tree: at org.eclipse.cdt.internal.core.pdom.PDOM.findBindingsForPrefix(PDOM.java:850) at org.eclipse.cdt.internal.core.index.CIndex.findBindingsForPrefix(CIndex.java:513) at org.eclipse.cdt.internal.ui.browser.opentype.ElementSelectionDialog.getElementsByPrefix(ElementSelectionDialog.java:307) at org.eclipse.cdt.internal.ui.browser.opentype.ElementSelectionDialog$UpdateElementsJob.run(ElementSelectionDialog.java:96) at org.eclipse.core.internal.jobs.Worker.run(Worker.java:55)	If you use Open Element for the first time in a session the time is most likely spent on accessing the information on disk. The time will depend on the size of the index + speed of your disk.If using Open Element multiple times it should be much faster, the access to the database is cached. You can tune this cache in the preferences on the indexer page (C/C++ - Indexer - Database cache size)Yes the second access is faster, but still 20s and (sometimes much) more. It seems to depend on the number of hits that are actually found. Especially typing just one letter seems to hurt.Can your fix foralso help here? I was indeed talking aboutthe case not using wildcards (for now at least ;-)(In reply to)No, the query in use (findBindingsForPrefix) is already optimized.LATER/REMIND bugs are being automatically reopened as P5 because the LATER and REMIND resolutions are deprecated.	5.0
id=29111	REOPENED	AspectJ	Compiler	unspecified	PC All	P5 enhancement	Jim Hugunin	2003-01-07 15:35 EST by	Erik Hilsdale	2009-08-30 02:49 EDT (	0 users	The following code doesn't compile:class Foo { }aspect Bar { int Foo.bar[];}instead, programmers are forced to use int[] Foo.bar. This is not particularly Java language compatible.	This syntax might be supported in the future, but it is not considered legal syntax in AspectJ-1.1. Use instead:int[] Foo.bar;To be considered only if a working tested patch is submitted.marking as info because this clairifies the AspectJ-1.1 languageLATER/REMIND bugs are being automatically reopened as P5 because the LATER and REMIND resolutions are deprecated.	4.0
id=109344	REOPENED	AspectJ	Compiler	DEVELOPMENT	PC Windows XP	P5 critical	Alexandre Vasseur	2005-09-12 18:34 EDT by	Ron Bodkin	2009-08-30 02:50 EDT (	1 user	I get the following deadlock fairly predictably when I run with load-time weaving on my Tomcat project using a Sun JVM. As usual, I don’t see any issues on JRockIt ;-) This happens with M3a and also with the Sept. 8 development build.In this case, it looks like one application thread in Tomcat is waiting for the other to get a lock, but they are being loaded and hence woven in the opposite order. Is this actually a Tomcat bug? It seems like a tricky condition to deal with, when the application is synchronizing access and the class loading system adds in new synchronization blocks..Sep 12, 2005 11:40:20 AM org.apache.coyote.http11.Http11Protocol startINFO: Starting Coyote HTTP/1.1 on http-8080Full thread dump Java HotSpot(TM) Client VM (1.5.0_04-b05 mixed mode):"http-8080-Monitor" prio=5 tid=0x272a1940 nid=0x21b8 in Object.wait() [0x2862f000..0x2862fd68] at java.lang.Object.wait(Native Method) - waiting on <0x02c52e50> (a org.apache.tomcat.util.threads.ThreadPool$MonitorRunnable) at org.apache.tomcat.util.threads.ThreadPool$MonitorRunnable.run(ThreadPool.java:559) - locked <0x02c52e50> (a org.apache.tomcat.util.threads.ThreadPool$MonitorRunnable) at java.lang.Thread.run(Thread.java:595)"http-8080-Processor25" daemon prio=5 tid=0x275c93a8 nid=0x1900 waiting for monitor entry [0x285ed000..0x285ef9e8] at org.aspectj.weaver.loadtime.Aj$WeaverContainer.getWeaver(Aj.java:79) - waiting to lock <0x051a1398> (a java.util.WeakHashMap) - locked <0x05291098> (a org.apache.catalina.loader.StandardClassLoader) at org.aspectj.weaver.loadtime.Aj.preProcess(Aj.java:54) at org.aspectj.weaver.loadtime.ClassPreProcessorAgentAdapter.transform(ClassPreProcessorAgentAdapter.java:52) at sun.instrument.TransformerManager.transform(TransformerManager.java:122) at sun.instrument.InstrumentationImpl.transform(InstrumentationImpl.java:155) at java.lang.ClassLoader.defineClass1(Native Method) at java.lang.ClassLoader.defineClass(ClassLoader.java:620) at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:124) at java.net.URLClassLoader.defineClass(URLClassLoader.java:260) at java.net.URLClassLoader.access$100(URLClassLoader.java:56) at java.net.URLClassLoader$1.run(URLClassLoader.java:195) at java.security.AccessController.doPrivileged(Native Method) at java.net.URLClassLoader.findClass(URLClassLoader.java:188) at java.lang.ClassLoader.loadClass(ClassLoader.java:306) - locked <0x05291098> (a org.apache.catalina.loader.StandardClassLoader) at java.lang.ClassLoader.loadClass(ClassLoader.java:251) at java.lang.ClassLoader.loadClassInternal(ClassLoader.java:319) - locked <0x05291098> (a org.apache.catalina.loader.StandardClassLoader) at org.apache.coyote.http11.Http11Protocol$Http11ConnectionHandler.init(Http11Protocol.java:683) at org.apache.tomcat.util.net.LeaderFollowerWorkerThread.getInitData(LeaderFollowerWorkerThread.java:48) at org.apache.tomcat.util.threads.ThreadPool$ControlRunnable.run(ThreadPool.java:673) at java.lang.Thread.run(Thread.java:595)"http-8080-Processor24" daemon prio=5 tid=0x270d8e28 nid=0x1c14 in Object.wait() [0x285af000..0x285afa68] at java.lang.Object.wait(Native Method) - waiting on <0x02c52660> (a org.apache.tomcat.util.threads.ThreadPool$ControlRunnable) at java.lang.Object.wait(Object.java:474) at org.apache.tomcat.util.threads.ThreadPool$ControlRunnable.run(ThreadPool.java:656) - locked <0x02c52660> (a org.apache.tomcat.util.threads.ThreadPool$ControlRunnable) at java.lang.Thread.run(Thread.java:595)"http-8080-Processor23" daemon prio=5 tid=0x27207de0 nid=0x2070 in Object.wait() [0x2856f000..0x2856fae8] at java.lang.Object.wait(Native Method) - waiting on <0x02c52268> (a org.apache.tomcat.util.threads.ThreadPool$ControlRunnable) at java.lang.Object.wait(Object.java:474) at org.apache.tomcat.util.threads.ThreadPool$ControlRunnable.run(ThreadPool.java:656) - locked <0x02c52268> (a org.apache.tomcat.util.threads.ThreadPool$ControlRunnable) at java.lang.Thread.run(Thread.java:595)"http-8080-Processor22" daemon prio=5 tid=0x27036408 nid=0x1698 in Object.wait() [0x2852f000..0x2852fb68] at java.lang.Object.wait(Native Method) - waiting on <0x02c51e70> (a org.apache.tomcat.util.threads.ThreadPool$ControlRunnable) at java.lang.Object.wait(Object.java:474) at org.apache.tomcat.util.threads.ThreadPool$ControlRunnable.run(ThreadPool.java:656) - locked <0x02c51e70> (a org.apache.tomcat.util.threads.ThreadPool$ControlRunnable) at java.lang.Thread.run(Thread.java:595)"http-8080-Processor21" daemon prio=5 tid=0x270b6260 nid=0x1a68 in Object.wait() [0x284ef000..0x284efbe8] at java.lang.Object.wait(Native Method) - waiting on <0x02c51a78> (a org.apache.tomcat.util.threads.ThreadPool$ControlRunnable) at java.lang.Object.wait(Object.java:474) at org.apache.tomcat.util.threads.ThreadPool$ControlRunnable.run(ThreadPool.java:656) - locked <0x02c51a78> (a org.apache.tomcat.util.threads.ThreadPool$ControlRunnable) at java.lang.Thread.run(Thread.java:595)"http-8080-Processor20" daemon prio=5 tid=0x275f3c88 nid=0x1ed8 in Object.wait() [0x284af000..0x284afc68] at java.lang.Object.wait(Native Method) - waiting on <0x02c51680> (a org.apache.tomcat.util.threads.ThreadPool$ControlRunnable) at java.lang.Object.wait(Object.java:474) at org.apache.tomcat.util.threads.ThreadPool$ControlRunnable.run(ThreadPool.java:656) - locked <0x02c51680> (a org.apache.tomcat.util.threads.ThreadPool$ControlRunnable) at java.lang.Thread.run(Thread.java:595)"http-8080-Processor19" daemon prio=5 tid=0x27375238 nid=0x11b8 in Object.wait() [0x2846f000..0x2846fce8] at java.lang.Object.wait(Native Method) - waiting on <0x02c51288> (a org.apache.tomcat.util.threads.ThreadPool$ControlRunnable) at java.lang.Object.wait(Object.java:474) at org.apache.tomcat.util.threads.ThreadPool$ControlRunnable.run(ThreadPool.java:656) - locked <0x02c51288> (a org.apache.tomcat.util.threads.ThreadPool$ControlRunnable) at java.lang.Thread.run(Thread.java:595)"http-8080-Processor18" daemon prio=5 tid=0x26e23ba8 nid=0x2600 in Object.wait() [0x2842f000..0x2842fd68] at java.lang.Object.wait(Native Method) - waiting on <0x02c50dc8> (a org.apache.tomcat.util.threads.ThreadPool$ControlRunnable) at java.lang.Object.wait(Object.java:474) at org.apache.tomcat.util.threads.ThreadPool$ControlRunnable.run(ThreadPool.java:656) - locked <0x02c50dc8> (a org.apache.tomcat.util.threads.ThreadPool$ControlRunnable) at java.lang.Thread.run(Thread.java:595)"http-8080-Processor17" daemon prio=5 tid=0x274aec18 nid=0x1288 in Object.wait() [0x283ef000..0x283ef9e8] at java.lang.Object.wait(Native Method) - waiting on <0x02c509d0> (a org.apache.tomcat.util.threads.ThreadPool$ControlRunnable) at java.lang.Object.wait(Object.java:474) at org.apache.tomcat.util.threads.ThreadPool$ControlRunnable.run(ThreadPool.java:656) - locked <0x02c509d0> (a org.apache.tomcat.util.threads.ThreadPool$ControlRunnable) at java.lang.Thread.run(Thread.java:595)"http-8080-Processor16" daemon prio=5 tid=0x275dc220 nid=0x2090 in Object.wait() [0x283af000..0x283afa68] at java.lang.Object.wait(Native Method) - waiting on <0x02c505d8> (a org.apache.tomcat.util.threads.ThreadPool$ControlRunnable) at java.lang.Object.wait(Object.java:474) at org.apache.tomcat.util.threads.ThreadPool$ControlRunnable.run(ThreadPool.java:656) - locked <0x02c505d8> (a org.apache.tomcat.util.threads.ThreadPool$ControlRunnable) at java.lang.Thread.run(Thread.java:595)"http-8080-Processor15" daemon prio=5 tid=0x26d35b80 nid=0x22d4 in Object.wait() [0x2836f000..0x2836fae8] at java.lang.Object.wait(Native Method) - waiting on <0x02c501e0> (a org.apache.tomcat.util.threads.ThreadPool$ControlRunnable) at java.lang.Object.wait(Object.java:474) at org.apache.tomcat.util.threads.ThreadPool$ControlRunnable.run(ThreadPool.java:656) - locked <0x02c501e0> (a org.apache.tomcat.util.threads.ThreadPool$ControlRunnable) at java.lang.Thread.run(Thread.java:595)"http-8080-Processor14" daemon prio=5 tid=0x272eebf0 nid=0xae8 in Object.wait()[0x2832f000..0x2832fb68] at java.lang.Object.wait(Native Method) - waiting on <0x02c4fd58> (a org.apache.tomcat.util.threads.ThreadPool$ControlRunnable) at java.lang.Object.wait(Object.java:474) at org.apache.tomcat.util.threads.ThreadPool$ControlRunnable.run(ThreadPool.java:656) - locked <0x02c4fd58> (a org.apache.tomcat.util.threads.ThreadPool$ControlRunnable) at java.lang.Thread.run(Thread.java:595)"http-8080-Processor13" daemon prio=5 tid=0x26e42768 nid=0x2150 in Object.wait() [0x282ef000..0x282efbe8] at java.lang.Object.wait(Native Method) - waiting on <0x02c4f960> (a org.apache.tomcat.util.threads.ThreadPool$ControlRunnable) at java.lang.Object.wait(Object.java:474) at org.apache.tomcat.util.threads.ThreadPool$ControlRunnable.run(ThreadPool.java:656) - locked <0x02c4f960> (a org.apache.tomcat.util.threads.ThreadPool$ControlRunnable) at java.lang.Thread.run(Thread.java:595)"http-8080-Processor12" daemon prio=5 tid=0x2761ed38 nid=0x838 in Object.wait()[0x282af000..0x282afc68] at java.lang.Object.wait(Native Method) - waiting on <0x02c4f568> (a org.apache.tomcat.util.threads.ThreadPool$ControlRunnable) at java.lang.Object.wait(Object.java:474) at org.apache.tomcat.util.threads.ThreadPool$ControlRunnable.run(ThreadPool.java:656) - locked <0x02c4f568> (a org.apache.tomcat.util.threads.ThreadPool$ControlRunnable) at java.lang.Thread.run(Thread.java:595)"http-8080-Processor11" daemon prio=5 tid=0x277ca408 nid=0x238c in Object.wait() [0x2826f000..0x2826fce8] at java.lang.Object.wait(Native Method) - waiting on <0x02c4f170> (a org.apache.tomcat.util.threads.ThreadPool$ControlRunnable) at java.lang.Object.wait(Object.java:474) at org.apache.tomcat.util.threads.ThreadPool$ControlRunnable.run(ThreadPool.java:656) - locked <0x02c4f170> (a org.apache.tomcat.util.threads.ThreadPool$ControlRunnable) at java.lang.Thread.run(Thread.java:595)"http-8080-Processor10" daemon prio=5 tid=0x274aee18 nid=0xd88 in Object.wait()[0x2822f000..0x2822fd68] at java.lang.Object.wait(Native Method) - waiting on <0x02c4ed78> (a org.apache.tomcat.util.threads.ThreadPool$ControlRunnable) at java.lang.Object.wait(Object.java:474) at org.apache.tomcat.util.threads.ThreadPool$ControlRunnable.run(ThreadPool.java:656) - locked <0x02c4ed78> (a org.apache.tomcat.util.threads.ThreadPool$ControlRunnable) at java.lang.Thread.run(Thread.java:595)"http-8080-Processor9" daemon prio=5 tid=0x27791e68 nid=0x15d8 in Object.wait()[0x281ef000..0x281ef9e8] at java.lang.Object.wait(Native Method) - waiting on <0x02c4e918> (a org.apache.tomcat.util.threads.ThreadPool$ControlRunnable) at java.lang.Object.wait(Object.java:474) at org.apache.tomcat.util.threads.ThreadPool$ControlRunnable.run(ThreadPool.java:656) - locked <0x02c4e918> (a org.apache.tomcat.util.threads.ThreadPool$ControlRunnable) at java.lang.Thread.run(Thread.java:595)"http-8080-Processor8" daemon prio=5 tid=0x275a2a88 nid=0x177c in Object.wait()[0x281af000..0x281afa68] at java.lang.Object.wait(Native Method) - waiting on <0x02c4e520> (a org.apache.tomcat.util.threads.ThreadPool$ControlRunnable) at java.lang.Object.wait(Object.java:474) at org.apache.tomcat.util.threads.ThreadPool$ControlRunnable.run(ThreadPool.java:656) - locked <0x02c4e520> (a org.apache.tomcat.util.threads.ThreadPool$ControlRunnable) at java.lang.Thread.run(Thread.java:595)"http-8080-Processor7" daemon prio=5 tid=0x271e6a70 nid=0x624 in Object.wait() [0x2816f000..0x2816fae8] at java.lang.Object.wait(Native Method) - waiting on <0x02c4e128> (a org.apache.tomcat.util.threads.ThreadPool$ControlRunnable) at java.lang.Object.wait(Object.java:474) at org.apache.tomcat.util.threads.ThreadPool$ControlRunnable.run(ThreadPool.java:656) - locked <0x02c4e128> (a org.apache.tomcat.util.threads.ThreadPool$ControlRunnable) at java.lang.Thread.run(Thread.java:595)"http-8080-Processor6" daemon prio=5 tid=0x2705eb50 nid=0x1828 in Object.wait()[0x2812f000..0x2812fb68] at java.lang.Object.wait(Native Method) - waiting on <0x02c4dce0> (a org.apache.tomcat.util.threads.ThreadPool$ControlRunnable) at java.lang.Object.wait(Object.java:474) at org.apache.tomcat.util.threads.ThreadPool$ControlRunnable.run(ThreadPool.java:656) - locked <0x02c4dce0> (a org.apache.tomcat.util.threads.ThreadPool$ControlRunnable) at java.lang.Thread.run(Thread.java:595)"http-8080-Processor5" daemon prio=5 tid=0x2736b2c0 nid=0x1c30 in Object.wait()[0x280ef000..0x280efbe8] at java.lang.Object.wait(Native Method) - waiting on <0x02c4d8e8> (a org.apache.tomcat.util.threads.ThreadPool$ControlRunnable) at java.lang.Object.wait(Object.java:474) at org.apache.tomcat.util.threads.ThreadPool$ControlRunnable.run(ThreadPool.java:656) - locked <0x02c4d8e8> (a org.apache.tomcat.util.threads.ThreadPool$ControlRunnable) at java.lang.Thread.run(Thread.java:595)"http-8080-Processor4" daemon prio=5 tid=0x27099e90 nid=0x1960 in Object.wait()[0x280af000..0x280afc68] at java.lang.Object.wait(Native Method) - waiting on <0x02c4d4f0> (a org.apache.tomcat.util.threads.ThreadPool$ControlRunnable) at java.lang.Object.wait(Object.java:474) at org.apache.tomcat.util.threads.ThreadPool$ControlRunnable.run(ThreadPool.java:656) - locked <0x02c4d4f0> (a org.apache.tomcat.util.threads.ThreadPool$ControlRunnable) at java.lang.Thread.run(Thread.java:595)"http-8080-Processor3" daemon prio=5 tid=0x26e28eb0 nid=0x2694 in Object.wait()[0x2806f000..0x2806fce8] at java.lang.Object.wait(Native Method) - waiting on <0x02c4d0f8> (a org.apache.tomcat.util.threads.ThreadPool$ControlRunnable) at java.lang.Object.wait(Object.java:474) at org.apache.tomcat.util.threads.ThreadPool$ControlRunnable.run(ThreadPool.java:656) - locked <0x02c4d0f8> (a org.apache.tomcat.util.threads.ThreadPool$ControlRunnable) at java.lang.Thread.run(Thread.java:595)"http-8080-Processor2" daemon prio=5 tid=0x2743f790 nid=0x2384 in Object.wait()[0x2802f000..0x2802fd68] at java.lang.Object.wait(Native Method) - waiting on <0x02c4ccd0> (a org.apache.tomcat.util.threads.ThreadPool$ControlRunnable) at java.lang.Object.wait(Object.java:474) at org.apache.tomcat.util.threads.ThreadPool$ControlRunnable.run(ThreadPool.java:656) - locked <0x02c4ccd0> (a org.apache.tomcat.util.threads.ThreadPool$ControlRunnable) at java.lang.Thread.run(Thread.java:595)"http-8080-Processor1" daemon prio=5 tid=0x272e3208 nid=0x16e0 in Object.wait()[0x27e2f000..0x27e2f9e8] at java.lang.Object.wait(Native Method) - waiting on <0x02c4c8d8> (a org.apache.tomcat.util.threads.ThreadPool$ControlRunnable) at java.lang.Object.wait(Object.java:474) at org.apache.tomcat.util.threads.ThreadPool$ControlRunnable.run(ThreadPool.java:656) - locked <0x02c4c8d8> (a org.apache.tomcat.util.threads.ThreadPool$ControlRunnable) at java.lang.Thread.run(Thread.java:595)"ContainerBackgroundProcessor[StandardEngine[Catalina]]" daemon prio=5 tid=0x272d4df8 nid=0x1af0 waiting on condition [0x27def000..0x27defa68] at java.lang.Thread.sleep(Native Method) at org.apache.catalina.core.ContainerBase$ContainerBackgroundProcessor.run(ContainerBase.java:1546) at java.lang.Thread.run(Thread.java:595)"RMI LeaseChecker" daemon prio=5 tid=0x2743e560 nid=0xd7c waiting on condition [0x27faf000..0x27fafd68] at java.lang.Thread.sleep(Native Method) at sun.rmi.transport.DGCImpl$LeaseChecker.run(DGCImpl.java:310) at java.lang.Thread.run(Thread.java:595)"RMI RenewClean-[127.0.0.1:4257]" daemon prio=5 tid=0x27351d18 nid=0x1700 in Object.wait() [0x27f2f000..0x27f2fa68] at java.lang.Object.wait(Native Method) - waiting on <0x0a2a1900> (a java.lang.ref.ReferenceQueue$Lock) at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:116) - locked <0x0a2a1900> (a java.lang.ref.ReferenceQueue$Lock) at sun.rmi.transport.DGCClient$EndpointEntry$RenewCleanThread.run(DGCClient.java:500) at java.lang.Thread.run(Thread.java:595)"GC Daemon" daemon prio=2 tid=0x270295c0 nid=0x27ac in Object.wait() [0x27eef000..0x27eefae8] at java.lang.Object.wait(Native Method) - waiting on <0x0a2a19e0> (a sun.misc.GC$LatencyLock) at sun.misc.GC$Daemon.run(GC.java:100) - locked <0x0a2a19e0> (a sun.misc.GC$LatencyLock)"RMI Reaper" prio=5 tid=0x26d55bc8 nid=0x1068 in Object.wait() [0x27eaf000..0x27eafb68] at java.lang.Object.wait(Native Method) - waiting on <0x0a151240> (a java.lang.ref.ReferenceQueue$Lock) at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:116) - locked <0x0a151240> (a java.lang.ref.ReferenceQueue$Lock) at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:132) at sun.rmi.transport.ObjectTable$Reaper.run(ObjectTable.java:336) at java.lang.Thread.run(Thread.java:595)"RMI TCP Accept-0" daemon prio=5 tid=0x2762c008 nid=0x1554 runnable [0x27e6f000..0x27e6fbe8] at java.net.PlainSocketImpl.socketAccept(Native Method) at java.net.PlainSocketImpl.accept(PlainSocketImpl.java:384) - locked <0x0a195830> (a java.net.SocksSocketImpl) at java.net.ServerSocket.implAccept(ServerSocket.java:450) at java.net.ServerSocket.accept(ServerSocket.java:421) at sun.rmi.transport.tcp.TCPTransport.run(TCPTransport.java:334) at java.lang.Thread.run(Thread.java:595)"RMI TCP Accept-7132" daemon prio=5 tid=0x26e2ccc0 nid=0x2128 runnable [0x27daf000..0x27dafd68] at java.net.PlainSocketImpl.socketAccept(Native Method) at java.net.PlainSocketImpl.accept(PlainSocketImpl.java:384) - locked <0x0a151c68> (a java.net.SocksSocketImpl) at java.net.ServerSocket.implAccept(ServerSocket.java:450) at java.net.ServerSocket.accept(ServerSocket.java:421) at sun.rmi.transport.tcp.TCPTransport.run(TCPTransport.java:334) at java.lang.Thread.run(Thread.java:595)"Timer-0" daemon prio=5 tid=0x27300e00 nid=0x2030 in Object.wait() [0x27d6f000..0x27d6f9e8] at java.lang.Object.wait(Native Method) - waiting on <0x0a1513f0> (a java.util.TaskQueue) at java.util.TimerThread.mainLoop(Timer.java:509) - locked <0x0a1513f0> (a java.util.TaskQueue) at java.util.TimerThread.run(Timer.java:462)"Low Memory Detector" daemon prio=5 tid=0x26d15900 nid=0x1ad4 runnable [0x00000000..0x00000000]"CompilerThread0" daemon prio=10 tid=0x0099e968 nid=0x13a8 waiting on condition[0x00000000..0x26f7f8cc]"Signal Dispatcher" daemon prio=10 tid=0x0099f620 nid=0x23c4 waiting on condition [0x00000000..0x00000000]"Finalizer" daemon prio=9 tid=0x00959410 nid=0x1b54 in Object.wait() [0x26cff000..0x26cffc68] at java.lang.Object.wait(Native Method) - waiting on <0x05190898> (a java.lang.ref.ReferenceQueue$Lock) at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:116) - locked <0x05190898> (a java.lang.ref.ReferenceQueue$Lock) at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:132) at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:159)"Reference Handler" daemon prio=10 tid=0x00957f80 nid=0x1520 in Object.wait() [0x26cbf000..0x26cbfce8] at java.lang.Object.wait(Native Method) - waiting on <0x05190918> (a java.lang.ref.Reference$Lock) at java.lang.Object.wait(Object.java:474) at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:116) - locked <0x05190918> (a java.lang.ref.Reference$Lock)"main" prio=5 tid=0x00038678 nid=0xd48 waiting for monitor entry [0x0007e000..0x0007fc3c] at java.lang.ClassLoader.loadClass(ClassLoader.java:295) - waiting to lock <0x05291098> (a org.apache.catalina.loader.StandardClassLoader) at java.lang.ClassLoader.loadClass(ClassLoader.java:251) at org.xml.sax.helpers.NewInstance.newInstance(NewInstance.java:49) at org.xml.sax.helpers.XMLReaderFactory.loadClass(XMLReaderFactory.java:187) at org.xml.sax.helpers.XMLReaderFactory.createXMLReader(XMLReaderFactory.java:150) at org.aspectj.weaver.loadtime.definition.DocumentParser.parse(DocumentParser.java:80) at org.aspectj.weaver.loadtime.ClassLoaderWeavingAdaptor.registerDefinitions(ClassLoaderWeavingAdaptor.java:125) at org.aspectj.weaver.loadtime.ClassLoaderWeavingAdaptor.<init>(ClassLoaderWeavingAdaptor.java:93) at org.aspectj.weaver.loadtime.Aj$WeaverContainer.getWeaver(Aj.java:81) - locked <0x051a1398> (a java.util.WeakHashMap) - locked <0x02d43c78> (a sun.reflect.DelegatingClassLoader) at org.aspectj.weaver.loadtime.Aj.preProcess(Aj.java:54) at org.aspectj.weaver.loadtime.ClassPreProcessorAgentAdapter.transform(ClassPreProcessorAgentAdapter.java:52) at sun.instrument.TransformerManager.transform(TransformerManager.java:122) at sun.instrument.InstrumentationImpl.transform(InstrumentationImpl.java:155) at sun.misc.Unsafe.defineClass(Native Method) at sun.reflect.ClassDefiner.defineClass(ClassDefiner.java:45) at sun.reflect.MethodAccessorGenerator$1.run(MethodAccessorGenerator.java:381) at java.security.AccessController.doPrivileged(Native Method) at sun.reflect.MethodAccessorGenerator.generate(MethodAccessorGenerator.java:377) at sun.reflect.MethodAccessorGenerator.generateMethod(MethodAccessorGenerator.java:59) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:28) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at java.lang.reflect.Method.invoke(Method.java:585) at org.apache.commons.modeler.BaseModelMBean.invoke(BaseModelMBean.java:503) at com.sun.jmx.mbeanserver.DynamicMetaDataImpl.invoke(DynamicMetaDataImpl.java:213) at com.sun.jmx.mbeanserver.MetaDataImpl.invoke(MetaDataImpl.java:220) at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.invoke(DefaultMBeanServerInterceptor.java:815) at com.sun.jmx.mbeanserver.JmxMBeanServer.invoke(JmxMBeanServer.java:784) at org.apache.catalina.connector.MapperListener.registerWrapper(MapperListener.java:487) at org.apache.catalina.connector.MapperListener.init(MapperListener.java:140) at org.apache.catalina.connector.Connector.start(Connector.java:1011) at org.apache.catalina.core.StandardService.start(StandardService.java:459) - locked <0x0728e818> (a [Lorg.apache.catalina.connector.Connector;) at org.apache.catalina.core.StandardServer.start(StandardServer.java:683) - locked <0x073277a8> (a [Lorg.apache.catalina.Service;) at org.apache.catalina.startup.Catalina.start(Catalina.java:537) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at java.lang.reflect.Method.invoke(Method.java:585) at org.apache.catalina.startup.Bootstrap.start(Bootstrap.java:271) at org.apache.catalina.startup.Bootstrap.main(Bootstrap.java:409)"VM Thread" prio=10 tid=0x0003f110 nid=0x2514 runnable"VM Periodic Task Thread" prio=10 tid=0x26d12a88 nid=0x165c waiting on conditionFound one Java-level deadlock:============================="http-8080-Processor25": waiting to lock monitor 0x0095900c (object 0x051a1398, a java.util.WeakHashMap), which is held by "main""main": waiting to lock monitor 0x00958fac (object 0x05291098, a org.apache.catalina.loader.StandardClassLoader), which is held by "http-8080-Processor25"Java stack information for the threads listed above:==================================================="http-8080-Processor25": at org.aspectj.weaver.loadtime.Aj$WeaverContainer.getWeaver(Aj.java:79) - waiting to lock <0x051a1398> (a java.util.WeakHashMap) - locked <0x05291098> (a org.apache.catalina.loader.StandardClassLoader) at org.aspectj.weaver.loadtime.Aj.preProcess(Aj.java:54) at org.aspectj.weaver.loadtime.ClassPreProcessorAgentAdapter.transform(ClassPreProcessorAgentAdapter.java:52) at sun.instrument.TransformerManager.transform(TransformerManager.java:122) at sun.instrument.InstrumentationImpl.transform(InstrumentationImpl.java:155) at java.lang.ClassLoader.defineClass1(Native Method) at java.lang.ClassLoader.defineClass(ClassLoader.java:620) at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:124) at java.net.URLClassLoader.defineClass(URLClassLoader.java:260) at java.net.URLClassLoader.access$100(URLClassLoader.java:56) at java.net.URLClassLoader$1.run(URLClassLoader.java:195) at java.security.AccessController.doPrivileged(Native Method) at java.net.URLClassLoader.findClass(URLClassLoader.java:188) at java.lang.ClassLoader.loadClass(ClassLoader.java:306) - locked <0x05291098> (a org.apache.catalina.loader.StandardClassLoader) at java.lang.ClassLoader.loadClass(ClassLoader.java:251) at java.lang.ClassLoader.loadClassInternal(ClassLoader.java:319) - locked <0x05291098> (a org.apache.catalina.loader.StandardClassLoader) at org.apache.coyote.http11.Http11Protocol$Http11ConnectionHandler.init(Http11Protocol.java:683) at org.apache.tomcat.util.net.LeaderFollowerWorkerThread.getInitData(LeaderFollowerWorkerThread.java:48) at org.apache.tomcat.util.threads.ThreadPool$ControlRunnable.run(ThreadPool.java:673) at java.lang.Thread.run(Thread.java:595)"main": at java.lang.ClassLoader.loadClass(ClassLoader.java:295) - waiting to lock <0x05291098> (a org.apache.catalina.loader.StandardClassLoader) at java.lang.ClassLoader.loadClass(ClassLoader.java:251) at org.xml.sax.helpers.NewInstance.newInstance(NewInstance.java:49) at org.xml.sax.helpers.XMLReaderFactory.loadClass(XMLReaderFactory.java:187) at org.xml.sax.helpers.XMLReaderFactory.createXMLReader(XMLReaderFactory.java:150) at org.aspectj.weaver.loadtime.definition.DocumentParser.parse(DocumentParser.java:80) at org.aspectj.weaver.loadtime.ClassLoaderWeavingAdaptor.registerDefinitions(ClassLoaderWeavingAdaptor.java:125) at org.aspectj.weaver.loadtime.ClassLoaderWeavingAdaptor.<init>(ClassLoaderWeavingAdaptor.java:93) at org.aspectj.weaver.loadtime.Aj$WeaverContainer.getWeaver(Aj.java:81) - locked <0x051a1398> (a java.util.WeakHashMap) - locked <0x02d43c78> (a sun.reflect.DelegatingClassLoader) at org.aspectj.weaver.loadtime.Aj.preProcess(Aj.java:54) at org.aspectj.weaver.loadtime.ClassPreProcessorAgentAdapter.transform(ClassPreProcessorAgentAdapter.java:52) at sun.instrument.TransformerManager.transform(TransformerManager.java:122) at sun.instrument.InstrumentationImpl.transform(InstrumentationImpl.java:155) at sun.misc.Unsafe.defineClass(Native Method) at sun.reflect.ClassDefiner.defineClass(ClassDefiner.java:45) at sun.reflect.MethodAccessorGenerator$1.run(MethodAccessorGenerator.java:381) at java.security.AccessController.doPrivileged(Native Method) at sun.reflect.MethodAccessorGenerator.generate(MethodAccessorGenerator.java:377) at sun.reflect.MethodAccessorGenerator.generateMethod(MethodAccessorGenerator.java:59) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:28) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at java.lang.reflect.Method.invoke(Method.java:585) at org.apache.commons.modeler.BaseModelMBean.invoke(BaseModelMBean.java:503) at com.sun.jmx.mbeanserver.DynamicMetaDataImpl.invoke(DynamicMetaDataImpl.java:213) at com.sun.jmx.mbeanserver.MetaDataImpl.invoke(MetaDataImpl.java:220) at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.invoke(DefaultMBeanServerInterceptor.java:815) at com.sun.jmx.mbeanserver.JmxMBeanServer.invoke(JmxMBeanServer.java:784) at org.apache.catalina.connector.MapperListener.registerWrapper(MapperListener.java:487) at org.apache.catalina.connector.MapperListener.init(MapperListener.java:140) at org.apache.catalina.connector.Connector.start(Connector.java:1011) at org.apache.catalina.core.StandardService.start(StandardService.java:459) - locked <0x0728e818> (a [Lorg.apache.catalina.connector.Connector;) at org.apache.catalina.core.StandardServer.start(StandardServer.java:683) - locked <0x073277a8> (a [Lorg.apache.catalina.Service;) at org.apache.catalina.startup.Catalina.start(Catalina.java:537) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at java.lang.reflect.Method.invoke(Method.java:585) at org.apache.catalina.startup.Bootstrap.start(Bootstrap.java:271) at org.apache.catalina.startup.Bootstrap.main(Bootstrap.java:409)Found 1 deadlock.	On looking more closely, it looks like the original work-around is now causing a deadlock.On the other hand, is it really necessary to hold the lock while reading in definitions? Or if it is, why not use class.forName to ensure the needed classes all get loaded before the lock is acquired.Why not construct the Adaptor with no work, then release the locks and initialize the Adaptor? You would then want to synchronize on the init method and before returning the adaptor... to be thread safe you would need to use something like Doug Lea's concurrency library to lock the newly constructed object inside the other synchronized blocks & yet return it after the others finish.Just some thoughts...obviously this is a consequence of the poor hack of #99861 which consist inlocking the classloader within which we are weaving to bypass some proven bugsin Sun JSR163 implementation.You may try to remove the fix for 99861 in Aj.java, rebuild, get a fresh Sun VMand try again with Tomcat and let us know.depsA thought: might the issue be with Tomcat? Don't Tomcat application classloaders check their own definitions first, with the result that classinter-dependencies across application class loaders are not serialized as theyare under the usual delegation scheme? It would be nice to see this reproducedoutside Tomcat.closing this one see deps.Apologies is this comment is posted twice -- I posted a more in-depth commentyesterday which doesn't seem to have appeared yet.I have experienced this problem whilst advising a multi-threaded applicationon IBM's 5.0 beta SDK and Sun's 5.0. I'm not using tomcat or any other loader. This was on the 3rd Nov development AspectJ build.What is the significance of RESOLVED REMIND? I don't think this has beenresolved. Are there plans to fix it?Thanks,DaveDaveYour detailled comment does not appear. Please post it again.RESOLVED REMIND means that this is FIXED and needs to be marked as FIXED when weship our next official milestone / RC / release (at least I am using this statusfor that purpose).Please post thread dump and possibly app to reproduce the issue you have on thatissue.Hi Alexandre.Thanks for your comment. After you said that you thought it was fixed, I spenta little more time testing. After I tried completely deleting my stable aspectjdirectory and replacing it with the 3rd Nov development build, the issue went away.I guess I need to learn how this all fits together better :-)Good work, and sorry to waste your time!DaveLATER/REMIND bugs are being automatically reopened as P5 because the LATER and REMIND resolutions are deprecated.	9.0
id=29884	REOPENED	AspectJ	Compiler	unspecified	PC Windows 2000	P5 enhancement	Jim Hugunin	2003-01-21 10:07 EST by	Maxim Mossienko	2009-08-30 02:50 EDT (	1 user	In 1.1.b4Consider following code / aspect,aspect, which has 'around' join point for method that contains greater number ofparameters than bound in pointcut, is not working. I found only following statement in 1.1 changes documentation about 1.1b4formals support 'we did not implement the handling of multiple .. wildcards inargs PCDs (rarely encountered in the wild)', it is not clear if this behavior isdescribed.class A { void testA(int B, int C) { } public static void main(String[] argv) { new A().testA(0,1); }}aspect B { pointcut testA(int a): args(a) && execution(void A.testA(int,int)); void around(int a): testA(a) { System.out.println("Before testA"); proceed(a); System.out.println("After testA"); }}	Your pointcut doesn't match because args(a) doesn't match the execution of a method with two arguments. You could use either args(a, int) or args(int, a) depending on whether you want the first or second argument. If the semantics is confusing, please bring this up on the users mailing list.I'll leave this bug around as a feature request for some sort of warning message when a pcd can never match anything.LATER/REMIND bugs are being automatically reopened as P5 because the LATER and REMIND resolutions are deprecated.	2.0
id=160469	REOPENED	AspectJ	IDE	DEVELOPMENT	PC Windows XP	P5 normal	Helen Beeken	2006-10-11 08:59 EDT by	Matt Chapman	2009-08-30 02:50 EDT (	1 user	Testcase: package test;import org.springframework.beans.factory.annotation.Configurable;import org.springframework.transaction.annotation.Transactional;@Configurablepublic class Sample { public Sample() { } @Transactional public void main(String[] args) { System.err.println("Sample"); }}Add spring.jar to classpath and spring-aspects.jar to aspectpath (Spring 2)The AJDE structure model then looks like this: sourceOfRelationship.generated<test{Sample.java[Sample~Sample relationship advised by target beanCreation sourceOfRelationship.generated<test{Sample.java[Sample~main~\[QString; relationship advised by target AnnotationTransactionAspect.class sourceOfRelationship {AnnotationTransactionAspect.class relationship advises target main sourceOfRelationship.generated<org.springframework.beans.factory.aspectj[AnnotationBeanConfigurerAspect.class (binary)}AnnotationBeanConfigurerAspect+beanCreation relationship advises target SampleThe relationship for "main" advised by AnnotationTransactionAspect.class is as expected for binary weaving, but the other relationship comes out as "Sample" (the constructor) advised by beanCreation, which is a pointcut. As pointcutsare not the source of advice, this is incorrect. Expected the constructor to be advised by "AnnotationBeanConfigurerAspect.class"Unfortunately a cut-down version of the spring aspects didn't show the problem.	The reason for the wierdness is that the after returning advice in AbstractBeanConfigurerAspect is on the same line as the concrete pointcut beanCreation in the AnnotationBeanConfigurerAspect. It is this which is causing the confusion. I can now reproduce with a simplified testcase :-)One other thing - if we have source for everything (aspects and Simple class) then the structure model is: sourceOfRelationship in.one.project.generated<pkg*AbstractBeanConfigurerAspect.aj}AbstractBeanConfigurerAspect&afterReturning relationship advises target Simple sourceOfRelationship in.one.project.generated<test{Simple.java[Simple~Simple relationship advised by target afterReturningTherefore, it seems to me that in the binary case we expect the constructor to also be advised by the AbstractBeanConfigurerAspect and not the concrete AnnotationBeanConfigurerAspect.Given the following code:---------------------------------------------------------------public abstract aspect AbstractBeanConfigurerAspect { // advice starts on line 6 after() returning : beanCreation() { } protected abstract pointcut beanCreation(); before() : beanCreation() { } }public aspect AnnotationBeanConfigurerAspect extends AbstractBeanConfigurerAspect { // pointcut is on line 6 protected pointcut beanCreation() : initialization(*.new(..)) && !within(pkg.*);}public class Simple { public Simple() { } }------------------------------------------------------------------In the case when this is all in the same package, the ajde structure model is: sourceOfRelationship in.one.project.generated<pkg*AbstractBeanConfigurerAspect.aj}AbstractBeanConfigurerAspect&before!2 relationship advises target Simple sourceOfRelationship in.one.project.generated<test{Simple.java[Simple~Simple relationship advised by target afterReturning sourceOfRelationship in.one.project.generated<test{Simple.java[Simple~Simple relationship advised by target before sourceOfRelationship in.one.project.generated<pkg*AbstractBeanConfigurerAspect.aj}AbstractBeanConfigurerAspect&afterReturning relationship advises target SimpleWith the aspects in a jar file on the aspect path of the project containing Simple.jave, the ajde structure model is currently: sourceOfRelationship test2.generated<test{Simple.java[Simple~Simple relationship advised by target beanCreation sourceOfRelationship test2.generated<test{Simple.java[Simple~Simple relationship advised by target AnnotationBeanConfigurerAspect.class sourceOfRelationship test2.generated<pkg[AnnotationBeanConfigurerAspect.class (binary)}AnnotationBeanConfigurerAspect+beanCreation relationship advises target Simple sourceOfRelationship {AnnotationBeanConfigurerAspect.class relationship advises target SimpleIn other words - there are two things which need fixing:1. Simple should be advised by AbstractBeanConfigurerAspect and not AnnotationBeanConfigurerAspect2. Can't be advised by a pointcut (although this might be fixed as a side effect of (1).I think the reason this bug is occuring is that the implementation of Advice.getResolvedDeclaringAspect() is wrong. According to the javadoc of the abstract method ShadowMunger.getResolvedDeclaringAspect(): /** * Returns the ResolvedType corresponding to the aspect in which this * shadowMunger is declared. This is different for deow's and advice. */However, the implementation in Advice.java returns 'concreteAspect' (the aspect extending the aspect which defines the advice), even though Advice.getDeclaringAspect() returns the UnresolvedType corresponding to the abstract aspect in which the advice is defined. Note: The method getResolvedDeclaringAspect() is only used within the code which fills in the model for injar aspectsThe fix turns out to be even more simple.....(and nicer :-))When aspects are read in from jar files the advice is looked at and each piece of advice is allocated a declaring type. In other words, the advice knows which aspect it is declared in. In the case of advice within abstract aspects the advice knows it's declared in this abstract one. When we come to add this information to the crosscutting set we concretize each piece of advice. In this process we create a new advice object but fail to pass on the information about which type it was declared in. This is the reason why when we come to fill in the injar hierarchy the advice doesn't have a declaring type. Passing on this information in the concretization step fixes this. Consequently the whole "getResolvedDeclaringAspect" thing is redundant and can be removed. Instead, the declared type can be used both with advice and deow.Createdzip containing fix and testcasesThis zip contains the fix described above and tests:1. pr160469-weaver.txt: apply to the weaver project. 2. pr160469-tests.txt: apply to the tests project3. jar_1\aspects.jar: place the aspects.jar file in the tests\model\pr160469_1 directory4. jar_2\aspects.jar: place the aspects.jar file in the tests\model\pr160469_2 directory(note jar_1 and jar_2 dirs were only created so I could attach everything within the same zip - do not create these directories in the pr160469_1 and pr160469_2 directories)There is one final aspect to this bug which needs further thought.....with the patch inapplied the model entry for the abstract pointcut beanCreation (see) is: beanCreation() [pointcut] TEST_SANDBOX\aspects.jar!pkg\AbstractBeanConfigurerAspect.class:1:However, the line number is incorrect.patches fromare inGetting the pointcut location correct is more involved. Since the pointcut in the abstract aspect is a MatchesNothingPointcut we don't record any information about its location in the class file. Therefore, when we come to read it in we have no idea where in the source file the pointcut was.For the moment it's not worth fixing the line number of the pointcut within the abstract aspect since this is only going to cause a problem if the "uses pointcut/pointcut used by" relationship is reinstated (). With the patch committed inI'm closing this as resolve later.This fix is in the latest aspectj dev build and will be in the next ajdt 1.4 and 1.5 dev builds.Helen, can you please clarify what exactly need to be fixed later? I am not sure why recorded pointcut is MatchesNothingPointcut. One would expect compiler to resolve it from the super classes/aspects, since code is actually woven in.The abstract pointcut beanCreation in AbstractBeanConfigurerAspect (see) never matches any join points because it has no body. It is the concrete pointcut within AnnonationBeanConfigurerAspect that matches.Currently when run within ajdt (or with the -emacssym option) a structure model is created that represents the crosscutting information. It is this information that AJDT uses for populating it's views. Up until the fix forthe relationship information was only known for the current project. This had the limitation within AJDT that you weren't able to navigate to aspects that were on the aspectpath.means that the model is now filled in for aspects on the aspectpath. Currently, we only fill in the information about advice, pointcuts and declare error and declare warning statements. In the case of an abstract pointcut we don't know the correct line number this was in the file since this isn't currently recorded in the class file and so can't set this piece of information correctly. However, the main user of this functionality is AJDT and AJDT only needs to know the line number to enable navigation for relationships. At the moment there is no relationship related to pointcuts and so there is no necessity to ensure the line number for the pointcut is correct. If a relationship relating to pointcuts is introduced in the future we will look at implementing what is required to ensure the line number for abstract pointcuts is correct. At the moment this is a fair amount of work (with the added complication that it could be changing the information saved in the class file) for no gain. Therefore, I closed this bug as "later" to indicate that if there is a use case for the pointcut work we will fix it when that use case becomes clear.I hope this answers your questions :-)Well, almost. I just wonder if you can't record the line number, maybe it is at least possible to record class name that contains an applied aspect.I also wonder if there could be some kind of signature for advice that is applied at given joinpoint, so there will be no need to track down line numbers...iplogLATER/REMIND bugs are being automatically reopened as P5 because the LATER and REMIND resolutions are deprecated.	14.0
id=32398	REOPENED	AspectJ	Compiler	unspecified	PC Windows 2000	P5 enhancement	Jim Hugunin	2003-02-20 15:09 EST by	Ron Bodkin	2009-08-30 02:47 EDT (	0 users	If you write AbstractAspect.aspectOf() you get an error like this:The method aspectOf() is undefined for the type AbstractAspectIt would be helpful for most users to explain why!	A patch to fix this to AjProblemReporter in ajdt.core module would raise the priority.Waiting on patch.LATER/REMIND bugs are being automatically reopened as P5 because the LATER and REMIND resolutions are deprecated.	3.0
id=30766	REOPENED	AspectJ	Compiler	unspecified	PC Windows 98	P5 enhancement	Jim Hugunin	2003-02-01 11:12 EST by	Rafael Chaves	2009-08-30 02:48 EDT (	0 users	AspectJ compiler 1.1beta4AspectJ compiler does not seem to properly accept multiple directory/JAR path entries in the -classpath option.The following command line:ajc -classpath bin;c:\aspectj1.1\lib\aspectjrt.jar -sourceroots src -d bin Generates the following error message:invalid option or directory does not exist: c:\aspectj1.1\lib\aspectjrt.jarWhile inverting the paths:ajc -classpath c:\aspectj1.1\lib\aspectjrt.jar;bin -sourceroots src -d bin produces the same stack trace as.	Try quoting the classpath. I'm not sure how your shell is handling the internal';'. (The message instead suggests that the aspectjrt.jar does not exist, but Iassume you verified that.)I tried this in 1.1beta4 and it worked for me from the DOS command line. (Ithought it would not because the classpath entry is not quoted.) (From a cygwinbash command line, the backslashes need to be escaped and the classpath entriesneed to be quoted.) Here's the DOS command that worked:J:\home\wes\dev\tools\aj>.\bin\ajc -classpathbin;j:\home\wes\dev\tools\aj\lib\aspectjrt.jar -sourceroots doc/examples/bean -d binIf either quoting or correcting the path works for you, feel free to close the bug.I believe that Wes's suggestion of quoting the classpath fixes this bug. This is a result of using a batch file to call the compiler instead of the .exe that java uses. Fixing this bug would be a huge amount of work in return for a very small usability gain. It's being marked as P5 and a request for enhancement.Sorry, I had problems with my connection when trying to add my answer to Wes' comments some time ago, and forgot to try again later.You are right, the problem does not happen when passing the arguments between quotes. Thanks.This should now be resolved as INVALID rather than LATER.LATER/REMIND bugs are being automatically reopened as P5 because the LATER and REMIND resolutions are deprecated.	5.0
id=33636	REOPENED	AspectJ	Compiler	unspecified	PC Windows NT	P5 enhancement	Jim Hugunin	2003-03-02 20:08 EST by	Ramnivas Laddad	2009-08-30 02:51 EDT (	0 users	This bug (or compiler limitation) is seen in 1.1beta4. The same programworks fine in 1.0.6.Test program:public class Test { public static void main(String[] args) { try { foo(); } catch (NullPointerException ex) { } } public static void foo() { }}aspect AfterHandlerAspect { after() : handler(NullPointerException) { System.out.println("Thrown NullPointerException"); }}F:\aspectj\bugs\1.1\b4\after-handler>ajc *.javaOnly before advice is supported on handler join points (compiler limitation)Only before advice is supported on handler join points (compiler limitation)2 warningsIndetical error is issued if I use around() advice instead of after().Why is this compiler limitation? This prevents implementing crosscuttingthat relies on checking the state of thrown exception by a handler block.	This limitation is a result of weaving into bytecodes instead of source code. It is either hard or impossible to reliably find the end of an exception handler in bytecode. We decided that it would be better to make this unimplemented in 1.1 rather than come up with an rushed definition of the end of a handler block that we would be forced to live with forever after. Here are two quick examples of where this is easy and where it's hard/impossible.Your Test class above produces the following bytecode (with javac):Method void main(java.lang.String[]) 0 invokestatic #2 <Method Test.foo()V> 3 goto 7 6 astore_1 7 returnException table: from to target type 0 3 6 <Class java.lang.NullPointerException>This is an example of a common pattern that would let us find the end of most exception handlers. Just before the handler block there is a goto that goes to the instruction just past the end. Checking for this pattern would let us handle 99% of actual exception handlers. However, what should ajc do when this pattern isn't present or when it's wrong?Consider this bytecode:Method void bar() 0 invokestatic #2 <Method Test.foo()V> 3 return 4 astore_0 5 invokestatic #2 <Method Test.foo()V> 8 returnException table: from to target type 0 4 4 <Class java.lang.NullPointerException>It could be produced from either of these two programs:A: public static void bar() { try { foo(); return; } catch (NullPointerException ex) { foo(); } }ORB: public static void bar() { try { foo(); return; } catch (NullPointerException ex) { } foo(); }So, should we consider the foo() to be inside of the catch block or not?You might be able to make the argument that in a case like this it's reasonable to treat the call to foo() as effectively part of the catch block since it can only be called if an exception is caught. However, it's also easy to see how this might be very confusing to a programmer who wrote B.I suspect that this issue could be resolved with some hard thought and analysis of all the possible edge cases; however, this feature was not deemed important enough to delay the 1.1 release until that analysis could be done.-Jimmarking as info because this clarifies a long-standing compiler limitation reagarding around advice on handlers and explains a new limitation in 1.1 regarding after advice on handlersLATER/REMIND bugs are being automatically reopened as P5 because the LATER and REMIND resolutions are deprecated.	3.0
id=113587	REOPENED	AspectJ	Compiler	1.5.0M4	All All	P5 normal	Alexandre Vasseur	2005-10-24 15:59 EDT by	Yoav Landman	2009-08-30 02:48 EDT (	1 user	LTW fails when weaving an external jar with the above error.Attached is a test case containing all required dependencies.Unfortunately I cannot clean up any 3rd party libs, since the bug is onlyreproducible using the jars in question (LTW on my own classes works just fine).Simply run ant on the supplied build file (using JDK 1.5) to see the exception.	CreatedTest caseNOTE:Due to attachment size limit you need to add the following to the lib dir:log4j-1.2.8.jarxerces-2.6.2.jarconcurrent-1.3.4.jaraspectjrt.jarDue to attachment size limit you need to add the following to the lib dir:log4j-1.2.8.jarxerces-2.6.2.jarconcurrent-1.3.4.jaraspectjrt.jarmay be due to include use (aspect does not go in weaver type munging)yes it isproblem: if goes within weaver, then may apply other aspects to the aspectitself, and we don't want that.Perhaps need to detect that (mustNotWeaveButIsAspect) and then force the mungingthru a new BcelPerClauseAspectAdderdoneIClassFileProvider.isApplyAtAspectJMungersOnly()and some custom logic in BcelWeavertry to get a next published build and give it a tryas a workaround, don't use an <include directive that contains your aspect, orcompile the aspect with AJC and not javaC.Createdtest case that throw exceptionjust execute run.sh or run.batWith annotation i have same error with 1.5.3 version, NoSuchMethodError aspectOf(). I have join script to compile and run in test case. the result is:Exception in thread "main" java.lang.reflect.InvocationTargetException at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at java.lang.reflect.Method.invoke(Method.java:597) at Test.main(Test.java:40)Caused by: java.lang.NoSuchMethodError: Test$MyTestAspect.aspectOf()LTest$MyTestAspect; at toto.Toto.getToto(Toto.java:5) ... 5 moreLATER/REMIND bugs are being automatically reopened as P5 because the LATER and REMIND resolutions are deprecated.	8.0
id=40077	REOPENED	AspectJ	Compiler	unspecified	PC Windows XP	P5 enhancement	Jim Hugunin	2003-07-15 01:09 EDT by	Ron Bodkin	2009-08-30 02:50 EDT (	0 users	public aspect BadPCDErr { pointcut badError(Undefined undefined);}producesC:\devel\test\BadPCDErr.java:2 Undefined cannot be resolved (or is not a valid type) for the argument undefined of the method ajc$pointcut$$badError$28pointcut badError(Undefined undefined); ^^^^^^^^^1 error	Moving to P5 as a useful, but low-priority fix. Would increase priority if a small patch was provided.LATER/REMIND bugs are being automatically reopened as P5 because the LATER and REMIND resolutions are deprecated.	2.0
id=45231	REOPENED	AspectJ	Compiler	1.2	PC Windows XP	P5 enhancement	Jim Hugunin	2003-10-20 14:17 EDT by	Ramnivas Laddad	2009-08-30 02:49 EDT (	0 users	Here is a feature request to enhance the "declare soft" construct ina fully backward compatible way.Currently, the "declare soft" construct is used to soften a checkedexception by throwing an org.aspectj.lang.SoftException wrapping inoriginal exception. I will like the possibility of specifying auser-specifiable runtime exception. I intend to use such a feature tospecify a concern-specific runtime exception while softening. Thissimple change will help in multiple ways. Here are a few: 1. The exception call stack will be clearer. I will now have an indication of the concern involved by just looking at name of the exception thrown.2. I can catch specific runtime exception at some higher level to process it in the most meaningful way. Currently, I need to trap the generic SoftException and examine the cause (using getCause()) to check if the checked exception needs to be handled.As it stands now, I almost never use "declare soft" byitself. Typically, I wrap the checked exceptions in question in aconcern-specific runtime exception and use a "declare soft" to avoidexception-related compiler errors. A feature to easily support thisidiom will make the code easy to understand and explain.Possible syntax: declare soft: <Exception to be softened> : <Pointcut> [: <Runtime Exception>];For example:declare soft: RemoteException : call(* PaymentService. *(..) throws RemoteException) : RemoteRuntimeException;declare soft: SystemException : call(* *.*(..) throws SystemException) : TransactionRuntimeException;When the last part ([: <Runtime Exception>]) is omitted, we coulddefault to the current behavior, hence maintaining backwardcompatibility.The runtime exception specified must have a way to set the wrappedexception. This is not a problem for JDK1.4+ as initCause() can alwaysbe used. For the earlier JDKs, we could require that the runtimeexception specified must have the "initCuase(Throwable)" method.	I would like this even more if it were also possible to call a member function that returns a throwable or subtype thereof, which takes a single argument: the original exception. I use this idiom with abstract aspects and for polymorphic exception handling.E.g.,aspect Conversion { declare soft: Exception : call(* model..*(..)) : convertException; ModelException convertException(Throwable cause) { throw new ModelException(cause); }}I know this proposal looks like C# delegates. However using a Java approach with worker objects would require exposing the cause as a special form. Maybe the 3rd part could be any Java expression and target could return the throwable, e.g., declare soft: Exception : call(* model..*(..)) : convertException(target);or declare soft: Exception : call(* model..*(..)) : new RuntimeException(target);This can be solved by always using declare soft according to a standard idiom where it must be paired with an around advice that does the actual change of the exception. This will increase the verbosity of the examples below, but only by a couple of lines. For Ron's example, you can change it to:aspect Conversion { pointcut soften(): call(* model..*(..)); declare soft: Exception: soften(); Object around(): soften() { try { return proceed(); } catch (Exception e) { throw new ModelException(cause); } }}This should probably be added to the FAQ. We can revist this later if thereare a lot more programs out there using declare soft to drive the design.LATER/REMIND bugs are being automatically reopened as P5 because the LATER and REMIND resolutions are deprecated.	3.0
id=38134	REOPENED	AspectJ	Compiler	unspecified	PC Windows NT	P5 enhancement	Jim Hugunin	2003-05-27 04:01 EDT by	Wes Isberg	2009-08-30 02:50 EDT (	0 users	When specifying compiler option "-nowarn" or "-warn:none", warnings for declarewarning and XLint are still emitted.For declare warning, arguably, the compiler options should not apply to theweaver. But it might encourage the use of declare-warning if they could bedisabled at the command line. We should document (at least here) that this is abug to be fixed in later releases (perhaps with a weaver-specific option) orthat the command-line warning constraints do not apply to declare warningstatements.For XLint, the workaround is to set "ignore" as the XLint default or per-messagelevel, so applying the compiler options here is less compelling though still anatural assumption -- again, worth documenting.Tests using tests/harness/{XLint}WarningTest.java added totests/ajcTestsFailing.xml. I could not check whether the compiler options hid a "standard" warning becauseI could find none being issued, presumably intentionally due to the line inorg.aspectj.ajdt.ajc.BuildArgParser 'javaArgList.add("-warn:none");' Might docthat, too, if it's to be our default.	All of the behavior noted below is defined as correct for ajc-1.1.0. I decided that the the ajc-specific warnings should be kept separate from the eclipse-specific ones, and that the eclipse-specific warnings should be silent by default. This gives maximum compatibility with ajc-1.0.This arbitrary decision should be revisited for a future release (1.2?)Resolving as LATER. Caveat added to devguide/ajc.xml.LATER/REMIND bugs are being automatically reopened as P5 because the LATER and REMIND resolutions are deprecated.	3.0
id=41765	REOPENED	AspectJ	IDE	1.1.0	PC Windows XP	P5 enhancement	Mik Kersten	2003-08-20 20:48 EDT by	Ron Bodkin	2009-08-30 02:49 EDT (	1 user	If you run a (swing) application inside ajbrowser, and you close the window on that application, the ajbrowser as a whole closes. I experienced this behavior running the figure editor example.	The AJBrowser only has rudientary support for executing applications, and does not spawn the application in a new VM. As a result, when Swing applications dispose themselves they also dispose AJBrowser. I've documented this limitation in the programming guide.The obvious work-around is to run from the command-line with the same classpath that the browser uses.This should be considered an enhancement request for AJBrowser to run applications in a new VM. I'm lowering the priority of that to P4 for now.No immediate plans to upgrade ajbrowser, so I'm marking this as "LATER" for potential reconsideration in the future.We could also remove the "Run" button from ajbrowser. But this behavior isn'tthat bad and still allows people to run apps, so RESOLVED LATER sounds right.LATER/REMIND bugs are being automatically reopened as P5 because the LATER and REMIND resolutions are deprecated.	4.0
id=35688	REOPENED	AspectJ	Compiler	unspecified	PC Windows NT	P5 enhancement	Jim Hugunin	2003-03-25 20:27 EST by	Chen	2009-08-30 02:50 EDT (	1 user	I tried to use aspectj to weave JACK generated java files. JACK is an agent-oriented extention to Java; JACK files will first be compiled with JACK compiler and corresponding java files will be generated; then I compiled those java files with aspects together. However, ajc gave the error messages below though JACK compiler, which use javac to compile java files, can compile the same files with no problem.can't find type aos.jack.jak.agent.Agent$oBcan't find type aos.jack.jak.agent.Agent$NmPwFollowed are the 3 files that can reproduce the error. You need the Jack JAR file to compile them. I could send it to you if you want./*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=* This code is generated by JAC version 4.0 by Agent Oriented Software.DO NOT ALTER THIS CODE AND DO NOT REMOVE THIS COMMENT *=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*/import aos.jack.jak.agent.DataCreator;import aos.jack.jak.agent.Agent;class Wilson extends Agent { public Test left; void go() { } Wilson(String name) { super(name); boolean __b = getAgentType() == Wilson.class; if (__b) { __init1(); __init2(); } if (__b) startAgent(); } public static void main(String[] args) { args = aos.jack.Kernel.init(args); new Wilson("wilson").go(); } public Class getAgentType() { return Wilson.class; } public void __init1() { super.__init1(); setNamedCreator("left","Test",new DataCreator(true){public Object create() { return __named_data_left(); } },true); } public void __init2() { super.__init2(); getNamedObject("left","Test"); } synchronized private void __init_desc() { addNamedObject("left","Test",Agent.WRITEABLE); } public void init_desc() { newAgentDesc("Wilson"); super.init_desc(); __init_desc(); } synchronized public void __bindNames() { super.__bindNames(); } private Test __named_data_left() { if (left != null) return left; left = new Test(); if (!left.attach(this)) left = null; setNamedObject("left","Test",left); return left; } }/*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=* This code is generated by JAC version 4.0 by Agent Oriented Software.DO NOT ALTER THIS CODE AND DO NOT REMOVE THIS COMMENT *=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*/import aos.jack.jak.beliefset.Tuple;public class Test__Tuple extends Tuple implements aos.apib.Base, java.io.Serializable { public static final __SS streamer = new __SS(); public aos.apib.StreamerSupport getStreamer() { return streamer; } public int hashCode() { streamer.setup(); return aos.apib.Util.hashCode(this); } public boolean equals(Object o) { if (!(o instanceof aos.apib.Base)) return false; return aos.apib.Util.equals(this, (aos.apib.Base)o); } public String tag; public String value;public Test__Tuple(boolean v) { super(); isFree = v; }public String name() { return "Test__Tuple"; }public String toString() { StringBuffer __s = new StringBuffer(); __s.append(tag); __s.append(":"); __s.append(value); return __s.toString(); }public int hash(int __i) { int __r = 0; switch (__i) { case 0: { __r ^= (tag.hashCode() & (~(1 << 31))); return __r; } case 1: { __r ^= (value.hashCode() & (~(1 << 31))); __r ^= (tag.hashCode() & (~(1 << 31))); return __r; } case 2: { __r ^= (value.hashCode() & (~(1 << 31))); return __r; } } return 0; } public Test__Tuple() { streamer.setup(); if (!getStreamer().initialized) return; __init__Test__Tuple(); } void __init__Test__Tuple() { tag = "null"; value = "null"; }static class __SS extends aos.apib.StreamerSupport { Test__Tuple __def = null; public aos.apib.Base getDefaultInstance() { return __def; } private String[] fn = { ":tag", ":value", }; private String[] dn = { ":tag", ":value", }; private boolean[] ftr = { false, false, }; private boolean[] fst = { false, false, }; private boolean[] fhd = { false, false, }; private int[] ft = { 10, 10, }; private aos.apib.EnumInfo[] fe = { null, null, }; private String[] cm = { null, null, }; private aos.apib.StreamerSupport[][] al = { null, null, }; private String[] fsubt = { null, null, }; public __SS() { __type = "Test__Tuple"; __icon = null; __comment = "Auto generated by JAC - The JAC Java Agents Compiler"; __field_names = fn; __display_names = dn; __field_types = ft; __field_static = fst; __field_hidden = fhd; __field_transient = ftr; __field_subtypes = fsubt; __field_comments = cm; __enuminfos = fe; __allowed = al; register(__type, this); } private boolean setup_done = false; protected void setup() { if ( setup_done ) return; setup_done = true; __def = (Test__Tuple)newInstance(); setStreamedType(__def.getClass()); baseclasses = findBaseStreamer(__def.getClass()); } protected void init() { setup(); __def.__init__Test__Tuple(); } public boolean isDummy() { return false; } public aos.apib.Base new_instance() { return new Test__Tuple(); } public aos.apib.Base[] new_array(int n) { return new Test__Tuple[n]; } public boolean read(aos.apib.InStream in, aos.apib.Base o) { int i = -1; while ((i = in.nextField(i, this)) >= 0) if ( !readField( in, o, i ) ) return false; return true; } public boolean readField(aos.apib.InStream in, aos.apib.Base o,int i) { if ( i > __field_names.length ) return getBaseClassStreamer().readField( in, o, i - __field_names.length - 1 ); Test__Tuple v = (Test__Tuple)o; switch (i) { case 0: v.tag = in.getString(true); break; case 1: v.value = in.getString(true); break; case 2: in.readBaseClasses(o, this, 0); break; default: if (i >= 0 && i <= 2) break; in.error("Reader for Test__Tuple: illegal field number:"+i); return false; } return true; } public boolean write(aos.apib.OutStream out, aos.apib.Base o) { Test__Tuple v = (Test__Tuple)o; int i = -1; while ((i = out.nextField(i, this)) >= 0) { switch (i) { case 0: out.putString(v.tag, i, __def.tag, this); break; case 1: out.putString(v.value, i, __def.value, this); break; case 2: out.writeBaseClasses(o, this); break; default: if (i >= 0 && i <= 2) break; out.error("Writer for Test__Tuple: illegal field number:"+i); return false; } } return true; } public boolean isDefault(aos.apib.Base o) { Test__Tuple v = (Test__Tuple)o; if (v.tag != __def.tag) { if (v.tag == null) return false; if (__def.tag == null) return false; if (!v.tag.equals(__def.tag)) return false; } if (v.value != __def.value) { if (v.value == null) return false; if (__def.value == null) return false; if (!v.value.equals(__def.value)) return false; } if (baseclasses != null && baseclasses.length == 1) return baseclasses[0].isDefault(o); return true; } public void findNonApib(aos.apib.OutStream out, aos.apib.Base o) { Test__Tuple v = (Test__Tuple)o; if (baseclasses != null && baseclasses.length == 1) baseclasses[0].findNonApib(out, o); }} };/*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=* This code is generated by JAC version 4.0 by Agent Oriented Software.DO NOT ALTER THIS CODE AND DO NOT REMOVE THIS COMMENT *=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*/import aos.jack.jak.core.Jak;import aos.jack.jak.event.EventRecipient;import aos.jack.jak.beliefset.ClosedWorld;import aos.jack.jak.beliefset.ClosedWorldCursor;import aos.jack.jak.beliefset.BeliefSetCursor;import aos.jack.jak.beliefset.BeliefSetException;import aos.jack.jak.beliefset.Tuple;import aos.jack.jak.beliefset.BeliefSet;import aos.jack.jak.logic.Variable;import aos.jack.jak.logic.ChoicePoint;import aos.jack.jak.cursor.BeliefState;import aos.jack.jak.cursor.Cursor;class Test extends ClosedWorld { static public Test__Tuple __hole = new Test__Tuple(true); public Test__Tuple[][] __tables; public boolean attach(EventRecipient __h) { Object __o = __h; if (!super.attach(__h)) return false; return true; } public BeliefSetCursor get(String __v0, String __v1) throws aos.jack.jak.beliefset.BeliefSetException { Test__Tuple __t = new Test__Tuple(); __Cursor __c = new __Cursor(__t); __t.tag = __v0; __t.value = __v1; __c.init(1,this); return __c; } public BeliefSetCursor get(String __v0, Variable __v1) throws aos.jack.jak.beliefset.BeliefSetException { Test__Tuple __t = new Test__Tuple(); __Cursor __c = new __Cursor(__t); __t.tag = __v0; if (!__v1.check_unifiable(StringType)) throw new BeliefSetException("Test:get:IO: arg 1 value Incorrect Variable type"); if (__v1.isGround()) { try { __t.value = __v1.as_string(); } catch (Exception e) { throw new BeliefSetException("Test:get:IO: got " + e.toString()); } } else __c.value = __v1; __c.init(0,this); return __c; } public BeliefSetCursor get(Variable __v0, String __v1) throws aos.jack.jak.beliefset.BeliefSetException { Test__Tuple __t = new Test__Tuple(); __Cursor __c = new __Cursor(__t); if (!__v0.check_unifiable(StringType)) throw new BeliefSetException("Test:get:OI: arg 0 tag Incorrect Variable type"); if (__v0.isGround()) { try { __t.tag = __v0.as_string(); } catch (Exception e) { throw new BeliefSetException("Test:get:OI: got " + e.toString()); } } else __c.tag = __v0; __t.value = __v1; __c.init(2,this); return __c; } public int keyIndex() { return 0; } public int fullIndex() { return 1; } public int nIndexes() { return 3; } public Tuple newTuple() { return new Test__Tuple(); } public Tuple getTuple(int t, int l) { return __tables[t][l]; } public Tuple[] newTable(int t) { return new Test__Tuple[t]; } public Tuple[][] newTables(int t) { return new Test__Tuple[t][]; } public Tuple[] getTable(int t) { return __tables[t]; } public Tuple[][] getTables() { return __tables; } public void setTables(Tuple[][] t) { __tables = (Test__Tuple[][]) t; } public BeliefSetCursor newCursor(Tuple __t) { if (__t instanceof Test__Tuple) return new __Cursor((Test__Tuple) __t); return null; } public void add(String __v0, String __v1) throws aos.jack.jak.beliefset.BeliefSetException { add(__v0,__v1,Cursor.TRUE); } public void add(String __v0, String __v1, BeliefState __d) throws aos.jack.jak.beliefset.BeliefSetException { Test__Tuple __t = new Test__Tuple(); __t.tag = __v0; __t.value = __v1; super.assertTuple(__t,__d); } public void remove(String __v0, String __v1) throws aos.jack.jak.beliefset.BeliefSetException { remove(__v0,__v1,Cursor.TRUE); } public void remove(String __v0, String __v1, BeliefState __d) throws aos.jack.jak.beliefset.BeliefSetException { Test__Tuple __t = new Test__Tuple(); __t.tag = __v0; __t.value = __v1; super.retractTuple(__t,__d); } public Test() { } public Test(String n) { super(); read(n); } class __Cursor extends ClosedWorldCursor { public Test__Tuple __tuple = null; public Variable tag; public Variable value; public __Cursor() { __tuple = __hole; } public __Cursor(Test__Tuple __t) { super(); __tuple = __t; } public int match(int __ti, int __st, int __c, boolean __k, int __ind) { Test__Tuple[] __tab = __tables[__ti]; Test__Tuple __t; int __sz = __tab.length; int __i; if ((Jak.debugging & Jak.LOG_DB) != 0) { Jak.log.log("Test__Tuple:match:" + __ti + ":" + __st + ":" + __c + ":" + __k + ":" + __ind); Jak.log.log("Tuple=" + __tuple); Jak.log.log("Outputs are"); Jak.log.log(" tag:" + tag); Jak.log.log(" value:" + value); } for (__i = __st; __c > 0; __i = (__i + 1) % __sz, __c-- ) { __t = __tab[__i]; if (__t == null) { if (__ind < 0) continue; return -1; } if (__t == __hole) continue; if (__t.isFree) { __tab[__i] = __hole; continue; } if ((Jak.debugging & Jak.LOG_DB) != 0) Jak.log.log("t" + __i + ":" + __t); try { if (cp != null) cp.backtrack(); if (tag == null) { if (!__tuple.tag.equals(__t.tag)) continue; } else { if (!tag.unify(__t.tag)) continue; } if (__k) return __i; if (value == null) { if (!__tuple.value.equals(__t.value)) continue; } else { if (!value.unify(__t.value)) continue; } } catch (Exception e) { continue; } return __i; } return -1; } public int hash(int __i) { return (__tuple == null?0:__tuple.hash(__i)); } public ChoicePoint getChoicePoint() { if (tag != null) return tag.env.newChoicePoint(); if (value != null) return value.env.newChoicePoint(); return null; } public boolean isKeyGround() { if (tag != null) return false; return true; } }}	As I told professor Voles on the phone, I'd be happy to look into this bug if you can provide me with a complete .zip file and simple instructions for reproducing your error using that .zip file. This probably means that you need to include the JACK jar file as well.Thanks to the code submitted by Feilong Chen this was easy to track down and fix in the current tree.The cause of the bug is that the .jar file for JACK contains .class files that appear to violate section 4.7.5 "The InnerClasses Attribute" of the JVM Spec v2. The compiler was assuming that class files would obey that section. The fix was to relax that assumption.There is currently no test in the test suite for this bug because of the difficulty in constructing class files that violate the spec and our inability to include the proprietary jack code in our test suite.I've changed the status of this bug to enhancement to keep the not that we need a test case for this situation.***has been marked as a duplicate of this bug. ***LATER/REMIND bugs are being automatically reopened as P5 because the LATER and REMIND resolutions are deprecated.	4.0
id=42070	REOPENED	AspectJ	IDE	1.1.0	PC Windows XP	P5 enhancement	Mik Kersten	2003-08-26 21:46 EDT by	Douglas Sellers	2009-08-30 02:49 EDT (	0 users	When an aspect is decorated with a perthis modifier the aspectj browser will no longer show any of the advice that is contained within that aspect as affecting any code. I have verified this by both removing the perthis and noticing tha the aspectj browser then did correctly recognize the code that the aspects are affecting and by running the aspects with the perthis present to verify that it works.	The ASM needs to improved to better handle both per-clauses and aspect inheritance. This is partly document in org.aspectj/modules/docs/developer/asm.doc, and related to. Marking as enhancement.not fixing in the short term ... ajbrowser is practically deprecated... it is possible the changes to allow the model to look correct in AJDT will make it magically work in ajbrowser, but I haven't tried it.Sounds right to me. There has been something of a resurgence on the AspectJ for NetBeans front thanks to Ramon whom I've been helping along, so that might provide us with a driver to make the ASM complete:LATER/REMIND bugs are being automatically reopened as P5 because the LATER and REMIND resolutions are deprecated.	4.0
id=42572	REOPENED	AspectJ	Compiler	1.1.0	PC Windows NT	P5 enhancement	Mik Kersten	2003-09-04 18:21 EDT by	Wes Isberg	2009-08-30 02:49 EDT (	1 user	Configuration files (.lst files) have single-string entries for injars,sourceroots, classpath, bootclasspath, etc. that require platform-specificinternal delimiters, which means the .lst files can't be reused across platforms.I recommend updating the path parsers to accept both the local platformdelimiter or one of ';' or ',' as a delimiter for these paths.	This seems to be a non-issue at this point, since the VMs are happy with thedefaultpath separator.Why is this invalid? Does ':' or ';' work on all platforms? The default varieswith platform.It has been a non-issue since I reported it way back. My sense was that ';' wasstarting to be like '/' and working on all the VMs, but I'm not certain. Ifanyone on another platform encounters a problem we can reopen it. But you'reright, it shouldn't be marked as invalid.Resolving as LATER until there is user feedback that this needs fixing.LATER/REMIND bugs are being automatically reopened as P5 because the LATER and REMIND resolutions are deprecated.	5.0
id=81654%0D%0A	REOPENED	AspectJ	Docs	1.2.1	PC Windows XP	P5 normal	Wes Isberg	2004-12-20 11:21 EST by	Wes Isberg	2009-08-30 02:50 EDT (	1 user	Fix xml-pdf target in modules/docs/build.xml	CreatedPatch to enable xml-pdf targetCreatedPatch to fix a couple of problems with PDF generation of AspectJ devguideCreatedPatch to fix mater-name bug in version of dockbook that AspectJ usesCreatedPatch to fix the progguide PDF generationThanks very much for the patches. They're hard to evaluate because there are alot of whitespace and formatting changes; e.g., it appears that entire sectionsof the build scripts and documentation were changed. I suspect most are justthat, but it might take a while to verify. (The doc build can only be validatedeither by inspection of the input build changes or by inspection of the output,the latter of which I'd like to avoid.) Most likely rather than apply thepatches, I'll try to find and make the same changes you did.I went through this and integrated some of it. I was able to generate pdf forall the guides, but the result was so poor as to be unusable. In particular,tables were not rendered (use informaltable instead) or rendered quit poorly (noauto-layout) and much of the literal text in the dev guide overwrites itself. Also, we'd need to add things like page headers and footers, etc. (Findcomments in the docs readme.) It was hard to integrate the patch because thexml had been formatted in addition to being updated, so it was tough to find thechanges. For the programming guide, I happened upon a few places where the xmlstructure had been changed (accidentally I think), so I did not commit theprogramming guide. As a result, the fop ant task throws a NullPointerExceptionon the programming guide. (nice error handling). More generally, it doesn'tlook to me like the dream of docbook actually works for pdf right now, given thelevel of tool support and the quality of the output, though if we can get aworking document, we can probably manage not to break it. If I recall, this wasErik's conclusion as well.Looks like we're not going to be able to do anything about this in the AJ 1.5.0timeframe, marking as "LATER" for consideration in future release planning.LATER/REMIND bugs are being automatically reopened as P5 because the LATER and REMIND resolutions are deprecated.	8.0
